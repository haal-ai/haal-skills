# Assess GenAI Initiative: Step-by-Step Tutorial

**How to Execute the "Assess GenAI Initiative Idea" Workflow**

This tutorial shows how to evaluate a GenAI initiative idea using structured research and analysis.

## Prerequisites

- Clear description of the GenAI initiative you're considering
- Understanding of your business context and constraints
- Decision-making authority or input into the initiative

## Step-by-Step Instructions

### Step 1: Invoke the Competency
Initiate the assessment process

**User Action:**
1. Open a new conversation with OLAF
2. Type the command: `assess genai initiative`
3. Provide a brief description of your initiative idea

**OLAF Response:**
OLAF will acknowledge the request and begin the research and analysis process

### Step 2: Provide Initiative Details
**User Action:** Describe your GenAI initiative idea
```
We want to build an AI-powered code review assistant that automatically 
checks pull requests for security vulnerabilities and suggests improvements
```

**Provide Context:**
- **Industry**: Software development / SaaS
- **Team Size**: 50 developers
- **Current Process**: Manual code reviews taking 2-3 days per PR
- **Budget**: $50K initial investment

### Step 3: Research Phase
**What OLAF Does:**
- Researches similar GenAI initiatives and solutions
- Analyzes market trends and existing tools
- Identifies technical approaches and frameworks
- Gathers implementation examples and case studies

**You Should See:** Research summary with staging about similar initiatives

### Step 4: Challenge Analysis
**What OLAF Does:**
- Generates critical challenge questions
- Identifies potential risks and obstacles
- Evaluates technical feasibility
- Assesses resource requirements

**You Should See:** List of challenge questions and considerations specific to your initiative

### Step 5: Review Recommendations
**User Action:** Review the analysis and recommendations
- Read through research staging
- Consider challenge questions
- Evaluate the recommendation (proceed/modify/abandon)
- Ask follow-up questions if needed

## Verification Checklist

✅ **Research staging cover similar initiatives in your domain**
✅ **Challenge questions address your specific concerns**
✅ **Technical feasibility is clearly assessed**
✅ **Clear recommendation provided with rationale**

## Troubleshooting

**If research seems too generic:**
Provide more specific details about your industry, use case, and constraints

**If you need deeper analysis on specific aspects:**
- Ask follow-up questions about specific concerns
- Request deeper dive into technical approaches
- Ask for comparison with specific alternatives

## Key Learning Points

1. **Research-Driven**: Decisions based on market research and existing solutions
2. **Challenge-Based**: Critical questions help identify risks early
3. **Actionable**: Clear recommendations with next steps
4. **Iterative**: Can refine analysis based on additional information

## Next Steps to Try

- If approved: Use `find expert contact` to locate implementation experts
- If modified: Refine the initiative based on feedback and reassess
- If uncertain: Use `should i use ai` for simpler appropriateness check

## Expected Timeline

- **Total assessment time:** 5-10 minutes
- **User input required:** Initial description and context (2-3 minutes)
- **OLAF execution time:** Research and analysis (3-7 minutes)
