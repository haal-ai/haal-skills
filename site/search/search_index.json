{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HAAL Skills Docs \u00b6 This site publishes per-skill documentation from this repository. Browse the full list of skills: Skills What\u2019s published \u00b6 For each skill folder that contains docs/description.md and/or docs/tutorial.md , the site publishes: Description Tutorial These pages are generated automatically during the GitHub Pages build.","title":"Home"},{"location":"#haal-skills-docs","text":"This site publishes per-skill documentation from this repository. Browse the full list of skills: Skills","title":"HAAL Skills Docs"},{"location":"#whats-published","text":"For each skill folder that contains docs/description.md and/or docs/tutorial.md , the site publishes: Description Tutorial These pages are generated automatically during the GitHub Pages build.","title":"What\u2019s published"},{"location":"skills/","text":"Skills \u00b6 Browse skill documentation (generated from each /<skill>/docs/ folder). align-spec-openapi-code-tests \u2014 Description | Tutorial analyze-api-change-impact-from-deprecation-spec \u2014 Description | Tutorial analyze-api-consistency \u2014 Description | Tutorial analyze-business-requirements \u2014 Description | Tutorial analyze-changelog-and-report \u2014 Description | Tutorial analyze-db-api-fit \u2014 Description | Tutorial analyze-function-complexity \u2014 Description | Tutorial analyze-spec-vs-code \u2014 Description | Tutorial archive-changelog-entries \u2014 Description | Tutorial assess-code-quality-principles \u2014 Description | Tutorial assess-genai-initiative-idea \u2014 Description | Tutorial assist-me-as-prompt-engineer \u2014 Description | Tutorial augment-code-unit-test \u2014 Description | Tutorial bootstrap-functional-spec-from-code \u2014 Description | Tutorial carry-on-session \u2014 Description | Tutorial carry-over-session \u2014 Description | Tutorial challenge-me \u2014 Description | Tutorial check-todos-in-code \u2014 Description | Tutorial code-in-go \u2014 Description | Tutorial code-in-rust \u2014 Description | Tutorial convert-prompt-to-skill \u2014 Description | Tutorial create-decision-record \u2014 Description | Tutorial create-feature-for-pr \u2014 Description | Tutorial create-job \u2014 Description | Tutorial create-otf-variable \u2014 Description | Tutorial create-person-record \u2014 Description | Tutorial create-presentation-plan \u2014 Description | Tutorial create-prompt \u2014 Description | Tutorial create-skill \u2014 Description | Tutorial create-skill-description \u2014 Description | Tutorial deepen-tech-spec-developer \u2014 Description | Tutorial detect-schema-drift \u2014 Description | Tutorial detect-test-directives \u2014 Description | Tutorial evaluate-prompt-for-adoption \u2014 Description | Tutorial evolve-code-iteratively \u2014 Description | Tutorial extend-specification \u2014 Description | Tutorial extract-notes-from-skube-site \u2014 Description find-expert-contact \u2014 Description | Tutorial fix-code-smells \u2014 Description | Tutorial generate-ai-agent-instructions \u2014 Description | Tutorial generate-code-mapper-docs \u2014 Description | Tutorial generate-commits-from-changelog \u2014 Description | Tutorial generate-contract-kit \u2014 Description | Tutorial generate-ddl-and-seed \u2014 Description | Tutorial generate-jsdoc \u2014 Description | Tutorial generate-orchestrator \u2014 Description | Tutorial generate-post-from-plan \u2014 Description | Tutorial generate-pptx-from-plan \u2014 Tutorial generate-professional-release-notes \u2014 Description | Tutorial generate-questionnaire \u2014 Description | Tutorial generate-tasklist \u2014 Description | Tutorial generate-tech-spec-from-code \u2014 Description | Tutorial generate-validation-report \u2014 Description | Tutorial get-bms-expertise \u2014 Description | Tutorial git-add-commit \u2014 Description | Tutorial help-me-olaf \u2014 Description | Tutorial improve-cyclomatic-complexity \u2014 Description | Tutorial improve-spec \u2014 Description | Tutorial measure-ai-impact \u2014 Description | Tutorial merge-branch-with-safety \u2014 Description | Tutorial onboard-me \u2014 Description | Tutorial plan-db-api-remediation \u2014 Description | Tutorial propose-commit-thread \u2014 Description | Tutorial report-my-daily \u2014 Description | Tutorial research-and-report \u2014 Tutorial review-code \u2014 Description | Tutorial review-code-accessibility \u2014 Description | Tutorial review-diff \u2014 Description | Tutorial review-github-pr \u2014 Description | Tutorial review-human-written-spec \u2014 Description | Tutorial review-prd-spec \u2014 Description | Tutorial review-producer-api-as-consumer \u2014 Description | Tutorial review-progress \u2014 Description | Tutorial review-user-story \u2014 Description | Tutorial run-redocumentation \u2014 Description | Tutorial scaffold-angular-frontend-from-spec \u2014 Description | Tutorial scaffold-api-from-spec \u2014 Description | Tutorial scaffold-quarkus-microservice \u2014 Description | Tutorial search-and-learn \u2014 Tutorial should-i-use-ai \u2014 Description | Tutorial stash-restart-session \u2014 Description | Tutorial store-conversation-record \u2014 Description | Tutorial switch-context \u2014 Description | Tutorial tell-me \u2014 Description | Tutorial test-create-skill \u2014 Description | Tutorial validate-prompt-value \u2014 Description | Tutorial work-on-job \u2014 Description | Tutorial Total published skills: 87","title":"Skills"},{"location":"skills/#skills","text":"Browse skill documentation (generated from each /<skill>/docs/ folder). align-spec-openapi-code-tests \u2014 Description | Tutorial analyze-api-change-impact-from-deprecation-spec \u2014 Description | Tutorial analyze-api-consistency \u2014 Description | Tutorial analyze-business-requirements \u2014 Description | Tutorial analyze-changelog-and-report \u2014 Description | Tutorial analyze-db-api-fit \u2014 Description | Tutorial analyze-function-complexity \u2014 Description | Tutorial analyze-spec-vs-code \u2014 Description | Tutorial archive-changelog-entries \u2014 Description | Tutorial assess-code-quality-principles \u2014 Description | Tutorial assess-genai-initiative-idea \u2014 Description | Tutorial assist-me-as-prompt-engineer \u2014 Description | Tutorial augment-code-unit-test \u2014 Description | Tutorial bootstrap-functional-spec-from-code \u2014 Description | Tutorial carry-on-session \u2014 Description | Tutorial carry-over-session \u2014 Description | Tutorial challenge-me \u2014 Description | Tutorial check-todos-in-code \u2014 Description | Tutorial code-in-go \u2014 Description | Tutorial code-in-rust \u2014 Description | Tutorial convert-prompt-to-skill \u2014 Description | Tutorial create-decision-record \u2014 Description | Tutorial create-feature-for-pr \u2014 Description | Tutorial create-job \u2014 Description | Tutorial create-otf-variable \u2014 Description | Tutorial create-person-record \u2014 Description | Tutorial create-presentation-plan \u2014 Description | Tutorial create-prompt \u2014 Description | Tutorial create-skill \u2014 Description | Tutorial create-skill-description \u2014 Description | Tutorial deepen-tech-spec-developer \u2014 Description | Tutorial detect-schema-drift \u2014 Description | Tutorial detect-test-directives \u2014 Description | Tutorial evaluate-prompt-for-adoption \u2014 Description | Tutorial evolve-code-iteratively \u2014 Description | Tutorial extend-specification \u2014 Description | Tutorial extract-notes-from-skube-site \u2014 Description find-expert-contact \u2014 Description | Tutorial fix-code-smells \u2014 Description | Tutorial generate-ai-agent-instructions \u2014 Description | Tutorial generate-code-mapper-docs \u2014 Description | Tutorial generate-commits-from-changelog \u2014 Description | Tutorial generate-contract-kit \u2014 Description | Tutorial generate-ddl-and-seed \u2014 Description | Tutorial generate-jsdoc \u2014 Description | Tutorial generate-orchestrator \u2014 Description | Tutorial generate-post-from-plan \u2014 Description | Tutorial generate-pptx-from-plan \u2014 Tutorial generate-professional-release-notes \u2014 Description | Tutorial generate-questionnaire \u2014 Description | Tutorial generate-tasklist \u2014 Description | Tutorial generate-tech-spec-from-code \u2014 Description | Tutorial generate-validation-report \u2014 Description | Tutorial get-bms-expertise \u2014 Description | Tutorial git-add-commit \u2014 Description | Tutorial help-me-olaf \u2014 Description | Tutorial improve-cyclomatic-complexity \u2014 Description | Tutorial improve-spec \u2014 Description | Tutorial measure-ai-impact \u2014 Description | Tutorial merge-branch-with-safety \u2014 Description | Tutorial onboard-me \u2014 Description | Tutorial plan-db-api-remediation \u2014 Description | Tutorial propose-commit-thread \u2014 Description | Tutorial report-my-daily \u2014 Description | Tutorial research-and-report \u2014 Tutorial review-code \u2014 Description | Tutorial review-code-accessibility \u2014 Description | Tutorial review-diff \u2014 Description | Tutorial review-github-pr \u2014 Description | Tutorial review-human-written-spec \u2014 Description | Tutorial review-prd-spec \u2014 Description | Tutorial review-producer-api-as-consumer \u2014 Description | Tutorial review-progress \u2014 Description | Tutorial review-user-story \u2014 Description | Tutorial run-redocumentation \u2014 Description | Tutorial scaffold-angular-frontend-from-spec \u2014 Description | Tutorial scaffold-api-from-spec \u2014 Description | Tutorial scaffold-quarkus-microservice \u2014 Description | Tutorial search-and-learn \u2014 Tutorial should-i-use-ai \u2014 Description | Tutorial stash-restart-session \u2014 Description | Tutorial store-conversation-record \u2014 Description | Tutorial switch-context \u2014 Description | Tutorial tell-me \u2014 Description | Tutorial test-create-skill \u2014 Description | Tutorial validate-prompt-value \u2014 Description | Tutorial work-on-job \u2014 Description | Tutorial Total published skills: 87","title":"Skills"},{"location":"skills/align-spec-openapi-code-tests/description/","text":"Align Spec, OpenAPI, Code, and Tests \u00b6 Detect drift across functional specifications, OpenAPI, implementation code, and Bruno CLI tests for a given demand. The skill produces a drift report and an alignment plan under docs/specifications/{demand_folder}/08-drift-analysis/ . Defaults: - Source of truth: code - Output folder: docs/specifications/{demand_folder}/08-drift-analysis Constraints: - DB/DDL artifacts are never modified.","title":"Align Spec, OpenAPI, Code, and Tests"},{"location":"skills/align-spec-openapi-code-tests/description/#align-spec-openapi-code-and-tests","text":"Detect drift across functional specifications, OpenAPI, implementation code, and Bruno CLI tests for a given demand. The skill produces a drift report and an alignment plan under docs/specifications/{demand_folder}/08-drift-analysis/ . Defaults: - Source of truth: code - Output folder: docs/specifications/{demand_folder}/08-drift-analysis Constraints: - DB/DDL artifacts are never modified.","title":"Align Spec, OpenAPI, Code, and Tests"},{"location":"skills/align-spec-openapi-code-tests/tutorial/","text":"Tutorial \u00b6 Provide a demand_folder (example: pet-clinic-01 ). Confirm which artifact is the source of truth (default is code). Review the proposed drift report + alignment plan outputs under docs/specifications/{demand_folder}/08-drift-analysis/ . Confirm the alignment changes. Re-run tests and validate alignment. Notes: - If implementation is pending, explicitly choose the source of truth. - DB/DDL artifacts are not modified by this skill.","title":"Tutorial"},{"location":"skills/align-spec-openapi-code-tests/tutorial/#tutorial","text":"Provide a demand_folder (example: pet-clinic-01 ). Confirm which artifact is the source of truth (default is code). Review the proposed drift report + alignment plan outputs under docs/specifications/{demand_folder}/08-drift-analysis/ . Confirm the alignment changes. Re-run tests and validate alignment. Notes: - If implementation is pending, explicitly choose the source of truth. - DB/DDL artifacts are not modified by this skill.","title":"Tutorial"},{"location":"skills/analyze-api-change-impact-from-deprecation-spec/description/","text":"Analyze API Change Impact From Deprecation Spec \u00b6 Purpose \u00b6 This skill helps API consumers analyze the impact of changed, evolved, or deprecated endpoints. It produces an impact map and a tasklist of changes + retesting required in consumer code. Default output \u00b6 docs/specifications/{demand_folder}/10-consumer-change-impact/{timestamp}-{demand_folder}-consumer-impact-tasklist.md Notes \u00b6 This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Analyze API Change Impact From Deprecation Spec"},{"location":"skills/analyze-api-change-impact-from-deprecation-spec/description/#analyze-api-change-impact-from-deprecation-spec","text":"","title":"Analyze API Change Impact From Deprecation Spec"},{"location":"skills/analyze-api-change-impact-from-deprecation-spec/description/#purpose","text":"This skill helps API consumers analyze the impact of changed, evolved, or deprecated endpoints. It produces an impact map and a tasklist of changes + retesting required in consumer code.","title":"Purpose"},{"location":"skills/analyze-api-change-impact-from-deprecation-spec/description/#default-output","text":"docs/specifications/{demand_folder}/10-consumer-change-impact/{timestamp}-{demand_folder}-consumer-impact-tasklist.md","title":"Default output"},{"location":"skills/analyze-api-change-impact-from-deprecation-spec/description/#notes","text":"This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Notes"},{"location":"skills/analyze-api-change-impact-from-deprecation-spec/tutorial/","text":"Analyze API Change Impact From Deprecation Spec \u00b6 Run: @[/analyze-api-change-impact-from-deprecation-spec] demand_folder: <demand_folder> change_spec_path: <path-to-change-spec> Optionally provide: - openapi_old_path - openapi_new_path - consumer_code_roots The skill will: - read the change spec (and OpenAPI diffs if provided) - propose a search and impact analysis plan - after approval, generate an impact map, tasklist, and retest plan under 10-consumer-change-impact/","title":"Analyze API Change Impact From Deprecation Spec"},{"location":"skills/analyze-api-change-impact-from-deprecation-spec/tutorial/#analyze-api-change-impact-from-deprecation-spec","text":"Run: @[/analyze-api-change-impact-from-deprecation-spec] demand_folder: <demand_folder> change_spec_path: <path-to-change-spec> Optionally provide: - openapi_old_path - openapi_new_path - consumer_code_roots The skill will: - read the change spec (and OpenAPI diffs if provided) - propose a search and impact analysis plan - after approval, generate an impact map, tasklist, and retest plan under 10-consumer-change-impact/","title":"Analyze API Change Impact From Deprecation Spec"},{"location":"skills/analyze-api-consistency/description/","text":"Analyze API Consistency (Code-Mapper Skill) \u00b6 This skill runs full code-mapper foundation analysis on a target repository and generates an API consistency report for selected modules/packages. It uses the code-map output to extract complete public API signatures and analyzes naming, parameter, and return-pattern consistency, producing a structured report following templates/api-consistency-analysis-structure.md .","title":"Analyze API Consistency (Code-Mapper Skill)"},{"location":"skills/analyze-api-consistency/description/#analyze-api-consistency-code-mapper-skill","text":"This skill runs full code-mapper foundation analysis on a target repository and generates an API consistency report for selected modules/packages. It uses the code-map output to extract complete public API signatures and analyzes naming, parameter, and return-pattern consistency, producing a structured report following templates/api-consistency-analysis-structure.md .","title":"Analyze API Consistency (Code-Mapper Skill)"},{"location":"skills/analyze-api-consistency/tutorial/","text":"Analyze API Consistency - Tutorial \u00b6 From your workspace root (directory containing .olaf/ ), identify the target project path. Run full code-mapper foundation analysis: bash cd <workspace-root> python scripts/code-mapper/run.py --foundation <project-path> Invoke the analyze-api-consistency skill and provide: project_path (absolute or workspace-root\u2013relative). code_mapper_path if different from the default scripts/code-mapper . Optional custom output directory under .olaf/work/staging/code-mapper/ . One or more target modules/packages to analyze. The skill will: Reuse or rerun full foundation as needed. Extract public API signatures for the selected modules from the code-map. Analyze naming, parameter, and return-pattern consistency. Generate a markdown report following templates/api-consistency-analysis-structure.md . Review the report and, if desired, confirm a path under .olaf/work/staging/code-mapper/<repo-name>/ to save it (for example api-consistency-analysis.md ).","title":"Analyze API Consistency - Tutorial"},{"location":"skills/analyze-api-consistency/tutorial/#analyze-api-consistency-tutorial","text":"From your workspace root (directory containing .olaf/ ), identify the target project path. Run full code-mapper foundation analysis: bash cd <workspace-root> python scripts/code-mapper/run.py --foundation <project-path> Invoke the analyze-api-consistency skill and provide: project_path (absolute or workspace-root\u2013relative). code_mapper_path if different from the default scripts/code-mapper . Optional custom output directory under .olaf/work/staging/code-mapper/ . One or more target modules/packages to analyze. The skill will: Reuse or rerun full foundation as needed. Extract public API signatures for the selected modules from the code-map. Analyze naming, parameter, and return-pattern consistency. Generate a markdown report following templates/api-consistency-analysis-structure.md . Review the report and, if desired, confirm a path under .olaf/work/staging/code-mapper/<repo-name>/ to save it (for example api-consistency-analysis.md ).","title":"Analyze API Consistency - Tutorial"},{"location":"skills/analyze-business-requirements/description/","text":"Analyze Business Requirements \u00b6 Enhanced skill migrated from business-analyst competency. Usage \u00b6 This skill provides analyze business requirements functionality with self-contained dependencies and enhanced error handling.","title":"Analyze Business Requirements"},{"location":"skills/analyze-business-requirements/description/#analyze-business-requirements","text":"Enhanced skill migrated from business-analyst competency.","title":"Analyze Business Requirements"},{"location":"skills/analyze-business-requirements/description/#usage","text":"This skill provides analyze business requirements functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/analyze-business-requirements/tutorial/","text":"Analyze Business Requirements Tutorial \u00b6 Step-by-step guide for using the analyze-business-requirements skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Analyze Business Requirements Tutorial"},{"location":"skills/analyze-business-requirements/tutorial/#analyze-business-requirements-tutorial","text":"Step-by-step guide for using the analyze-business-requirements skill.","title":"Analyze Business Requirements Tutorial"},{"location":"skills/analyze-business-requirements/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/analyze-business-requirements/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/analyze-changelog-and-report/description/","text":"Analyze Changelog And Report \u00b6 Enhanced skill migrated from project-manager competency. Usage \u00b6 This skill provides analyze changelog and report functionality with self-contained dependencies and enhanced error handling.","title":"Analyze Changelog And Report"},{"location":"skills/analyze-changelog-and-report/description/#analyze-changelog-and-report","text":"Enhanced skill migrated from project-manager competency.","title":"Analyze Changelog And Report"},{"location":"skills/analyze-changelog-and-report/description/#usage","text":"This skill provides analyze changelog and report functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/analyze-changelog-and-report/tutorial/","text":"Analyze Changelog And Report Tutorial \u00b6 Step-by-step guide for using the analyze-changelog-and-report skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Analyze Changelog And Report Tutorial"},{"location":"skills/analyze-changelog-and-report/tutorial/#analyze-changelog-and-report-tutorial","text":"Step-by-step guide for using the analyze-changelog-and-report skill.","title":"Analyze Changelog And Report Tutorial"},{"location":"skills/analyze-changelog-and-report/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/analyze-changelog-and-report/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/analyze-db-api-fit/description/","text":"Analyze DB API Fit \u00b6 What this skill does \u00b6 This skill analyzes a functional specification and OpenAPI contract against existing database schema artifacts in order to: - Extract the data requirements needed to implement the API business logic - Propose candidate microservice boundaries and data ownership assumptions - Map required API/domain data to existing DB tables/columns when DB artifacts are provided - Identify data gaps, constraints mismatches, and decisions required to proceed When to use \u00b6 Use this skill when you have: - A detailed functional spec and an OpenAPI definition - An existing database (or multiple databases) that may already contain the data - A need to determine whether the API can be implemented without changing the database Outputs \u00b6 A markdown data-fit analysis written under: docs/specifications/<demand_folder>/05-data-fit-analysis/ (after user confirmation) DB artifacts expected \u00b6 The skill can run in two modes: - Without DB artifacts : produces a data requirements inventory plus a structured request list for DB schemas and SME questions. - With DB artifacts : produces a DB \u2194 requirements mapping and a gap/risk assessment. Protocol \u00b6 This skill uses Propose-Confirm-Act because it writes files into the repository.","title":"Analyze DB API Fit"},{"location":"skills/analyze-db-api-fit/description/#analyze-db-api-fit","text":"","title":"Analyze DB API Fit"},{"location":"skills/analyze-db-api-fit/description/#what-this-skill-does","text":"This skill analyzes a functional specification and OpenAPI contract against existing database schema artifacts in order to: - Extract the data requirements needed to implement the API business logic - Propose candidate microservice boundaries and data ownership assumptions - Map required API/domain data to existing DB tables/columns when DB artifacts are provided - Identify data gaps, constraints mismatches, and decisions required to proceed","title":"What this skill does"},{"location":"skills/analyze-db-api-fit/description/#when-to-use","text":"Use this skill when you have: - A detailed functional spec and an OpenAPI definition - An existing database (or multiple databases) that may already contain the data - A need to determine whether the API can be implemented without changing the database","title":"When to use"},{"location":"skills/analyze-db-api-fit/description/#outputs","text":"A markdown data-fit analysis written under: docs/specifications/<demand_folder>/05-data-fit-analysis/ (after user confirmation)","title":"Outputs"},{"location":"skills/analyze-db-api-fit/description/#db-artifacts-expected","text":"The skill can run in two modes: - Without DB artifacts : produces a data requirements inventory plus a structured request list for DB schemas and SME questions. - With DB artifacts : produces a DB \u2194 requirements mapping and a gap/risk assessment.","title":"DB artifacts expected"},{"location":"skills/analyze-db-api-fit/description/#protocol","text":"This skill uses Propose-Confirm-Act because it writes files into the repository.","title":"Protocol"},{"location":"skills/analyze-db-api-fit/tutorial/","text":"Tutorial: Analyze DB \u2194 API Fit \u00b6 1) Prerequisites \u00b6 You should have a demand folder under docs/specifications/ containing: - 04-specifications/ (functional spec + OpenAPI) 2) Run the skill (first pass) \u00b6 Invoke the skill and provide: - demand_folder (example: pet-clinic-01 ) The skill will: - Extract data requirements from the functional specs + OpenAPI - Produce a DB artifacts request list and SME questions - Propose an output file path under docs/specifications/<demand_folder>/05-data-fit-analysis/ - Ask for confirmation before writing 3) Provide DB artifacts \u00b6 Gather one or more of: - DDL (schema export) - Migrations (Flyway/Liquibase/EF/Alembic) - ERD - Data dictionary Provide their paths as db_artifacts_paths on the next run. 4) Run the skill (follow-up mapping) \u00b6 @[/olaf-analyze-db-api-fit] demand_folder: <demand_folder> analysis_mode: followup previous_analysis_path: <path-to-previous-data-fit-analysis> db_artifacts_paths: - <path-to-ddl-or-migrations> - <path-to-erd-or-data-dictionary> The follow-up run will: - Map required API/domain data to DB tables/columns - Identify missing fields and other blockers - Produce an updated report in 05-data-fit-analysis/","title":"Tutorial: Analyze DB \u2194 API Fit"},{"location":"skills/analyze-db-api-fit/tutorial/#tutorial-analyze-db-api-fit","text":"","title":"Tutorial: Analyze DB \u2194 API Fit"},{"location":"skills/analyze-db-api-fit/tutorial/#1-prerequisites","text":"You should have a demand folder under docs/specifications/ containing: - 04-specifications/ (functional spec + OpenAPI)","title":"1) Prerequisites"},{"location":"skills/analyze-db-api-fit/tutorial/#2-run-the-skill-first-pass","text":"Invoke the skill and provide: - demand_folder (example: pet-clinic-01 ) The skill will: - Extract data requirements from the functional specs + OpenAPI - Produce a DB artifacts request list and SME questions - Propose an output file path under docs/specifications/<demand_folder>/05-data-fit-analysis/ - Ask for confirmation before writing","title":"2) Run the skill (first pass)"},{"location":"skills/analyze-db-api-fit/tutorial/#3-provide-db-artifacts","text":"Gather one or more of: - DDL (schema export) - Migrations (Flyway/Liquibase/EF/Alembic) - ERD - Data dictionary Provide their paths as db_artifacts_paths on the next run.","title":"3) Provide DB artifacts"},{"location":"skills/analyze-db-api-fit/tutorial/#4-run-the-skill-follow-up-mapping","text":"@[/olaf-analyze-db-api-fit] demand_folder: <demand_folder> analysis_mode: followup previous_analysis_path: <path-to-previous-data-fit-analysis> db_artifacts_paths: - <path-to-ddl-or-migrations> - <path-to-erd-or-data-dictionary> The follow-up run will: - Map required API/domain data to DB tables/columns - Identify missing fields and other blockers - Produce an updated report in 05-data-fit-analysis/","title":"4) Run the skill (follow-up mapping)"},{"location":"skills/analyze-function-complexity/description/","text":"Analyze Function Complexity \u00b6 Overview \u00b6 This competency performs in-depth analysis of individual functions or methods, calculating cyclomatic complexity metrics, evaluating code structure, and providing actionable recommendations for improving maintainability and testability. Purpose \u00b6 Complex functions are harder to understand, test, and maintain, leading to increased bug rates and slower development velocity. This competency identifies complexity hotspots by analyzing decision points, nesting depth, and code structure, then provides specific guidance for reducing complexity while preserving functionality. Usage \u00b6 Command : analyze function complexity (or aliases: analyze complexity , function complexity , complexity analysis ) Protocol : Act When to Use : Use when you need to understand why a specific function is difficult to work with, establish complexity baselines before refactoring, prioritize technical debt reduction, or validate that refactoring efforts have reduced complexity. Parameters \u00b6 Required Inputs \u00b6 function_name : Name of the function to analyze file_path : Path to the file containing the function (optional if workspace search is acceptable) language : Programming language (auto-detected if file_path provided) Optional Inputs \u00b6 context : Additional information about the function's purpose or constraints target_complexity : Desired complexity threshold (default: <10) Context Requirements \u00b6 Access to source code containing the target function Syntactically valid code Understanding of the function's role in the system helps contextualize staging Output \u00b6 Generates a comprehensive function complexity analysis report with metrics and recommendations. Deliverables : - Function signature and metadata extraction - Cyclomatic complexity score calculation - Decision point breakdown by type (conditionals, loops, switches, logical operators) - Nesting depth analysis - Risk assessment using industry-standard thresholds - Code quality indicators (readability, maintainability, testability scores) - Dependency and coupling analysis - Specific, actionable refactoring recommendations - Test coverage recommendations based on complexity Format : Structured markdown report using the function-complexity-analysis template Examples \u00b6 Example 1: Pre-Refactoring Assessment \u00b6 Scenario : A function has become difficult to test and maintain over time Command : analyze function complexity Input : function_name: calculateShippingCost file_path: src/shipping/calculator.ts Result : Report showed complexity of 16 (high risk), identified 8 nested conditionals, recommended extracting 4 helper functions, and provided specific line ranges for extraction. Example 2: Validating Refactoring Success \u00b6 Scenario : After refactoring, verify that complexity has been reduced Command : analyze complexity Input : function_name: calculateShippingCost file_path: src/shipping/calculator.ts Result : Confirmed complexity reduced from 16 to 7, nesting depth decreased from 4 to 2, maintainability score improved from 45 to 78. Related Competencies \u00b6 improve-cyclomatic-complexity : Follow-up competency that implements the refactoring recommendations from this analysis review-code : Broader code review that includes complexity assessment among other quality checks fix-code-smells : Addresses complexity as one type of code smell evolve-code-iteratively : Iterative improvement approach that can incorporate complexity reduction Tips & Best Practices \u00b6 Analyze functions before refactoring to establish measurable success criteria Prioritize functions with complexity >15 for immediate attention Use the decision point breakdown to identify extraction opportunities Consider domain complexity vs. accidental complexity when evaluating results Combine with unit test analysis to ensure safe refactoring Re-analyze after refactoring to validate improvements Track complexity trends across the codebase to identify systemic issues Limitations \u00b6 Measures syntactic complexity, not semantic or domain complexity Cannot determine if complexity is justified by business requirements Requires valid, parseable code Language-specific idioms may affect accuracy Does not validate correctness or functionality Cannot assess runtime performance implications","title":"Analyze Function Complexity"},{"location":"skills/analyze-function-complexity/description/#analyze-function-complexity","text":"","title":"Analyze Function Complexity"},{"location":"skills/analyze-function-complexity/description/#overview","text":"This competency performs in-depth analysis of individual functions or methods, calculating cyclomatic complexity metrics, evaluating code structure, and providing actionable recommendations for improving maintainability and testability.","title":"Overview"},{"location":"skills/analyze-function-complexity/description/#purpose","text":"Complex functions are harder to understand, test, and maintain, leading to increased bug rates and slower development velocity. This competency identifies complexity hotspots by analyzing decision points, nesting depth, and code structure, then provides specific guidance for reducing complexity while preserving functionality.","title":"Purpose"},{"location":"skills/analyze-function-complexity/description/#usage","text":"Command : analyze function complexity (or aliases: analyze complexity , function complexity , complexity analysis ) Protocol : Act When to Use : Use when you need to understand why a specific function is difficult to work with, establish complexity baselines before refactoring, prioritize technical debt reduction, or validate that refactoring efforts have reduced complexity.","title":"Usage"},{"location":"skills/analyze-function-complexity/description/#parameters","text":"","title":"Parameters"},{"location":"skills/analyze-function-complexity/description/#required-inputs","text":"function_name : Name of the function to analyze file_path : Path to the file containing the function (optional if workspace search is acceptable) language : Programming language (auto-detected if file_path provided)","title":"Required Inputs"},{"location":"skills/analyze-function-complexity/description/#optional-inputs","text":"context : Additional information about the function's purpose or constraints target_complexity : Desired complexity threshold (default: <10)","title":"Optional Inputs"},{"location":"skills/analyze-function-complexity/description/#context-requirements","text":"Access to source code containing the target function Syntactically valid code Understanding of the function's role in the system helps contextualize staging","title":"Context Requirements"},{"location":"skills/analyze-function-complexity/description/#output","text":"Generates a comprehensive function complexity analysis report with metrics and recommendations. Deliverables : - Function signature and metadata extraction - Cyclomatic complexity score calculation - Decision point breakdown by type (conditionals, loops, switches, logical operators) - Nesting depth analysis - Risk assessment using industry-standard thresholds - Code quality indicators (readability, maintainability, testability scores) - Dependency and coupling analysis - Specific, actionable refactoring recommendations - Test coverage recommendations based on complexity Format : Structured markdown report using the function-complexity-analysis template","title":"Output"},{"location":"skills/analyze-function-complexity/description/#examples","text":"","title":"Examples"},{"location":"skills/analyze-function-complexity/description/#example-1-pre-refactoring-assessment","text":"Scenario : A function has become difficult to test and maintain over time Command : analyze function complexity Input : function_name: calculateShippingCost file_path: src/shipping/calculator.ts Result : Report showed complexity of 16 (high risk), identified 8 nested conditionals, recommended extracting 4 helper functions, and provided specific line ranges for extraction.","title":"Example 1: Pre-Refactoring Assessment"},{"location":"skills/analyze-function-complexity/description/#example-2-validating-refactoring-success","text":"Scenario : After refactoring, verify that complexity has been reduced Command : analyze complexity Input : function_name: calculateShippingCost file_path: src/shipping/calculator.ts Result : Confirmed complexity reduced from 16 to 7, nesting depth decreased from 4 to 2, maintainability score improved from 45 to 78.","title":"Example 2: Validating Refactoring Success"},{"location":"skills/analyze-function-complexity/description/#related-competencies","text":"improve-cyclomatic-complexity : Follow-up competency that implements the refactoring recommendations from this analysis review-code : Broader code review that includes complexity assessment among other quality checks fix-code-smells : Addresses complexity as one type of code smell evolve-code-iteratively : Iterative improvement approach that can incorporate complexity reduction","title":"Related Competencies"},{"location":"skills/analyze-function-complexity/description/#tips-best-practices","text":"Analyze functions before refactoring to establish measurable success criteria Prioritize functions with complexity >15 for immediate attention Use the decision point breakdown to identify extraction opportunities Consider domain complexity vs. accidental complexity when evaluating results Combine with unit test analysis to ensure safe refactoring Re-analyze after refactoring to validate improvements Track complexity trends across the codebase to identify systemic issues","title":"Tips &amp; Best Practices"},{"location":"skills/analyze-function-complexity/description/#limitations","text":"Measures syntactic complexity, not semantic or domain complexity Cannot determine if complexity is justified by business requirements Requires valid, parseable code Language-specific idioms may affect accuracy Does not validate correctness or functionality Cannot assess runtime performance implications","title":"Limitations"},{"location":"skills/analyze-function-complexity/tutorial/","text":"Step-by-Step Tutorial \u00b6 Analyze Function Complexity: Step-by-Step Tutorial How to Execute the \"Function Complexity Analysis\" Workflow This tutorial shows exactly how to execute a detailed function complexity analysis using the OLAF developer competency's analyze-function-complexity functionality. This workflow analyzes a specific function's complexity, structure, and provides detailed metrics similar to complexity analyzer tools. Prerequisites \u00b6 OLAF framework properly installed and configured Function code to analyze (either file path or function name in workspace) Basic understanding of code complexity concepts Access to project files or codebase Step-by-Step Instructions \u00b6 Step 1: Initiate Function Complexity Analysis \u00b6 [Brief description: Start the function complexity analysis process by invoking the OLAF analyze-function-complexity competency] User Action: Open your terminal or OLAF interface Navigate to your project directory (if analyzing functions in workspace) Execute the OLAF analyze-function-complexity competency using one of these methods: Direct invocation: olaf analyze-function-complexity Via aliases: olaf analyze complexity , olaf function complexity , olaf complexity analysis OLAF Response: The system will prompt you to provide the required parameters for function analysis. Step 2: Provide Function Parameters \u00b6 User Action: Specify the function to analyze and optional context Required Parameters: - function_name: Name of the function to analyze - file_path: Path to the file containing the function (optional) - language: Programming language (optional, auto-detected if file provided) - context: Additional context about the function's purpose (optional) Provide Requirements/Parameters: function_name : [Example - we used \"calculateTotalPrice\"] file_path : [Example - we used \"src/services/orderService.js\"] (optional) language : [Example - we used \"JavaScript\"] (optional) context : [Example - we used \"E-commerce order processing function\"] (optional) Step 3: Function Location and Extraction \u00b6 What OLAF Does: If file_path provided: Locates the function in the specified file If only function_name provided: Searches the current workspace for the function Extracts the complete function code including signature and body Validates that the function exists and is accessible Gets current timestamp for analysis report You Should See: Confirmation that the function was located and extracted successfully Step 4: Comprehensive Complexity Analysis \u00b6 What OLAF Does: Calculates cyclomatic complexity using standard patterns: Decision points: if, else if, else, switch, case Loops: for, foreach, while, do-while Logical operators: &&, ||, and, or Exception handling: try, catch, except, finally Ternary operators: ? : Counts lines of code (excluding comments and blank lines) Calculates complexity density (complexity / line_count) Analyzes function structure (parameters, return type, nesting depth) Performs dependency analysis (functions/methods called) You Should See: Progress updates for complexity calculations and structural analysis Step 5: Quality Assessment and Report Generation \u00b6 User Action: Review the complexity analysis results when presented What OLAF Does: Generates code readability score and maintainability indicators Identifies potential refactoring opportunities Assesses best practices adherence Creates risk assessment with standard thresholds Generates comprehensive analysis report using the function-complexity-analysis template Provides specific, actionable recommendations for improvement You Should See: Complete complexity analysis report with metrics, risk assessment, and recommendations Verification Checklist \u00b6 \u2705 Function successfully located and extracted \u2705 Cyclomatic complexity calculated with breakdown by construct type \u2705 Lines of code counted (excluding comments and blank lines) \u2705 Complexity density calculated and assessed \u2705 Function structure analyzed (signature, nesting, dependencies) \u2705 Quality assessment completed with specific recommendations Troubleshooting \u00b6 If function cannot be located: grep -r \"function functionName\" . --include=\"*.js\" --include=\"*.ts\" --include=\"*.py\" --include=\"*.java\" find . -name \"*.js\" -exec grep -l \"functionName\" {} \\; If complexity calculations seem incorrect: Verify the programming language is correctly identified Check that all decision points and loops are counted Ensure nested complexity is properly calculated Review language-specific complexity patterns If no refactoring opportunities identified: Consider that the function may already be well-structured Review the complexity thresholds for the specific language Check if the function follows single responsibility principle Key Learning Points \u00b6 Cyclomatic Complexity: Measures the number of linearly independent paths through a program's source code, helping identify testing requirements Quality Indicators: Analysis includes readability, maintainability, and testability assessments beyond just complexity numbers Actionable Recommendations: All suggestions are specific, prioritized, and include refactoring opportunities Next Steps to Try \u00b6 Use the complexity analysis to prioritize functions for refactoring Apply the recommended improvements and re-analyze to measure progress Set up complexity thresholds for your team's coding standards Use complexity density metrics to identify overly complex functions Expected Timeline \u00b6 Total analysis time: 2-5 minutes (depending on function size and complexity) User input required: Function identification and parameters (30 seconds - 1 minute) OLAF execution time: Function extraction, complexity calculation, and analysis (1-3 minutes) Report generation: Detailed analysis report with recommendations (30 seconds - 1 minute)","title":"Step-by-Step Tutorial"},{"location":"skills/analyze-function-complexity/tutorial/#step-by-step-tutorial","text":"Analyze Function Complexity: Step-by-Step Tutorial How to Execute the \"Function Complexity Analysis\" Workflow This tutorial shows exactly how to execute a detailed function complexity analysis using the OLAF developer competency's analyze-function-complexity functionality. This workflow analyzes a specific function's complexity, structure, and provides detailed metrics similar to complexity analyzer tools.","title":"Step-by-Step Tutorial"},{"location":"skills/analyze-function-complexity/tutorial/#prerequisites","text":"OLAF framework properly installed and configured Function code to analyze (either file path or function name in workspace) Basic understanding of code complexity concepts Access to project files or codebase","title":"Prerequisites"},{"location":"skills/analyze-function-complexity/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/analyze-function-complexity/tutorial/#step-1-initiate-function-complexity-analysis","text":"[Brief description: Start the function complexity analysis process by invoking the OLAF analyze-function-complexity competency] User Action: Open your terminal or OLAF interface Navigate to your project directory (if analyzing functions in workspace) Execute the OLAF analyze-function-complexity competency using one of these methods: Direct invocation: olaf analyze-function-complexity Via aliases: olaf analyze complexity , olaf function complexity , olaf complexity analysis OLAF Response: The system will prompt you to provide the required parameters for function analysis.","title":"Step 1: Initiate Function Complexity Analysis"},{"location":"skills/analyze-function-complexity/tutorial/#step-2-provide-function-parameters","text":"User Action: Specify the function to analyze and optional context Required Parameters: - function_name: Name of the function to analyze - file_path: Path to the file containing the function (optional) - language: Programming language (optional, auto-detected if file provided) - context: Additional context about the function's purpose (optional) Provide Requirements/Parameters: function_name : [Example - we used \"calculateTotalPrice\"] file_path : [Example - we used \"src/services/orderService.js\"] (optional) language : [Example - we used \"JavaScript\"] (optional) context : [Example - we used \"E-commerce order processing function\"] (optional)","title":"Step 2: Provide Function Parameters"},{"location":"skills/analyze-function-complexity/tutorial/#step-3-function-location-and-extraction","text":"What OLAF Does: If file_path provided: Locates the function in the specified file If only function_name provided: Searches the current workspace for the function Extracts the complete function code including signature and body Validates that the function exists and is accessible Gets current timestamp for analysis report You Should See: Confirmation that the function was located and extracted successfully","title":"Step 3: Function Location and Extraction"},{"location":"skills/analyze-function-complexity/tutorial/#step-4-comprehensive-complexity-analysis","text":"What OLAF Does: Calculates cyclomatic complexity using standard patterns: Decision points: if, else if, else, switch, case Loops: for, foreach, while, do-while Logical operators: &&, ||, and, or Exception handling: try, catch, except, finally Ternary operators: ? : Counts lines of code (excluding comments and blank lines) Calculates complexity density (complexity / line_count) Analyzes function structure (parameters, return type, nesting depth) Performs dependency analysis (functions/methods called) You Should See: Progress updates for complexity calculations and structural analysis","title":"Step 4: Comprehensive Complexity Analysis"},{"location":"skills/analyze-function-complexity/tutorial/#step-5-quality-assessment-and-report-generation","text":"User Action: Review the complexity analysis results when presented What OLAF Does: Generates code readability score and maintainability indicators Identifies potential refactoring opportunities Assesses best practices adherence Creates risk assessment with standard thresholds Generates comprehensive analysis report using the function-complexity-analysis template Provides specific, actionable recommendations for improvement You Should See: Complete complexity analysis report with metrics, risk assessment, and recommendations","title":"Step 5: Quality Assessment and Report Generation"},{"location":"skills/analyze-function-complexity/tutorial/#verification-checklist","text":"\u2705 Function successfully located and extracted \u2705 Cyclomatic complexity calculated with breakdown by construct type \u2705 Lines of code counted (excluding comments and blank lines) \u2705 Complexity density calculated and assessed \u2705 Function structure analyzed (signature, nesting, dependencies) \u2705 Quality assessment completed with specific recommendations","title":"Verification Checklist"},{"location":"skills/analyze-function-complexity/tutorial/#troubleshooting","text":"If function cannot be located: grep -r \"function functionName\" . --include=\"*.js\" --include=\"*.ts\" --include=\"*.py\" --include=\"*.java\" find . -name \"*.js\" -exec grep -l \"functionName\" {} \\; If complexity calculations seem incorrect: Verify the programming language is correctly identified Check that all decision points and loops are counted Ensure nested complexity is properly calculated Review language-specific complexity patterns If no refactoring opportunities identified: Consider that the function may already be well-structured Review the complexity thresholds for the specific language Check if the function follows single responsibility principle","title":"Troubleshooting"},{"location":"skills/analyze-function-complexity/tutorial/#key-learning-points","text":"Cyclomatic Complexity: Measures the number of linearly independent paths through a program's source code, helping identify testing requirements Quality Indicators: Analysis includes readability, maintainability, and testability assessments beyond just complexity numbers Actionable Recommendations: All suggestions are specific, prioritized, and include refactoring opportunities","title":"Key Learning Points"},{"location":"skills/analyze-function-complexity/tutorial/#next-steps-to-try","text":"Use the complexity analysis to prioritize functions for refactoring Apply the recommended improvements and re-analyze to measure progress Set up complexity thresholds for your team's coding standards Use complexity density metrics to identify overly complex functions","title":"Next Steps to Try"},{"location":"skills/analyze-function-complexity/tutorial/#expected-timeline","text":"Total analysis time: 2-5 minutes (depending on function size and complexity) User input required: Function identification and parameters (30 seconds - 1 minute) OLAF execution time: Function extraction, complexity calculation, and analysis (1-3 minutes) Report generation: Detailed analysis report with recommendations (30 seconds - 1 minute)","title":"Expected Timeline"},{"location":"skills/analyze-spec-vs-code/description/","text":"Analyze Spec Vs Code \u00b6 Enhanced skill migrated from business-analyst competency. Usage \u00b6 This skill provides analyze spec vs code functionality with self-contained dependencies and enhanced error handling.","title":"Analyze Spec Vs Code"},{"location":"skills/analyze-spec-vs-code/description/#analyze-spec-vs-code","text":"Enhanced skill migrated from business-analyst competency.","title":"Analyze Spec Vs Code"},{"location":"skills/analyze-spec-vs-code/description/#usage","text":"This skill provides analyze spec vs code functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/analyze-spec-vs-code/tutorial/","text":"Analyze Spec Vs Code Tutorial \u00b6 Step-by-step guide for using the analyze-spec-vs-code skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Analyze Spec Vs Code Tutorial"},{"location":"skills/analyze-spec-vs-code/tutorial/#analyze-spec-vs-code-tutorial","text":"Step-by-step guide for using the analyze-spec-vs-code skill.","title":"Analyze Spec Vs Code Tutorial"},{"location":"skills/analyze-spec-vs-code/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/analyze-spec-vs-code/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/archive-changelog-entries/description/","text":"Archive Changelog Entries \u00b6 Enhanced skill migrated from project-manager competency. Usage \u00b6 This skill provides archive changelog entries functionality with self-contained dependencies and enhanced error handling.","title":"Archive Changelog Entries"},{"location":"skills/archive-changelog-entries/description/#archive-changelog-entries","text":"Enhanced skill migrated from project-manager competency.","title":"Archive Changelog Entries"},{"location":"skills/archive-changelog-entries/description/#usage","text":"This skill provides archive changelog entries functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/archive-changelog-entries/tutorial/","text":"Archive Changelog Entries Tutorial \u00b6 Step-by-step guide for using the archive-changelog-entries skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Archive Changelog Entries Tutorial"},{"location":"skills/archive-changelog-entries/tutorial/#archive-changelog-entries-tutorial","text":"Step-by-step guide for using the archive-changelog-entries skill.","title":"Archive Changelog Entries Tutorial"},{"location":"skills/archive-changelog-entries/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/archive-changelog-entries/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/assess-code-quality-principles/description/","text":"Assess Code Quality Principles \u00b6 Source : skills/assess-code-quality-principles/prompts/assess-code-quality-principles.md Overview \u00b6 Critical evaluation of codebase against established engineering principles (SOLID, DRY, YAGNI) with evidence-based scoring and specific improvement recommendations. Provides comprehensive quality scorecard with actionable insights. Purpose \u00b6 Software projects often accumulate technical debt and quality issues over time. This skill provides systematic evaluation of code quality against industry-standard principles, helping teams identify areas for improvement, prioritize refactoring efforts, and maintain high code quality standards. It transforms subjective code reviews into objective, measurable assessments. Usage \u00b6 Skill : assess-code-quality-principles Protocol : Propose-Act When to Use : - Before major refactoring initiatives to establish baseline - During technical debt assessment and planning - For code quality audits and compliance reviews - When onboarding to understand codebase quality - To validate architecture and design decisions Parameters \u00b6 Required Inputs \u00b6 application_name : Name of the application for file naming (kebab-case format) code_path : Path to the codebase directory to assess Optional Inputs \u00b6 tech_spec_path : Path to existing technical specification for context focus_areas : Specific areas to focus assessment on (defaults to all categories) Context Requirements \u00b6 Access to complete codebase source files Ability to analyze file structure and dependencies Optional: existing technical documentation for context Output \u00b6 Comprehensive quality assessment report with evidence-based scoring across multiple dimensions. Deliverables : - Quality scorecard with overall and category-specific grades (A-F scale) - Detailed staging with specific code examples - Prioritized improvement recommendations with effort estimates - Metrics and measurements for each assessment category Format : Markdown document saved to .olaf/work/staging/assessments/code-quality-assessment-{application_name}-YYYYMMDD-NNN.md Examples \u00b6 Example 1: Full Codebase Assessment \u00b6 Scenario : Evaluating overall code quality before major refactoring Skill Usage : assess-code-quality-principles Input : - application_name: \"payment-service\" - code_path: \"./src\" Result : Complete assessment report with grades for SOLID principles (B), Code Quality (C), Testing (D), Architecture (B), Security (B), and Performance (C), including 15 prioritized recommendations Example 2: Focused SOLID Assessment \u00b6 Scenario : Evaluating design principles compliance Skill Usage : assess-code-quality-principles Input : - application_name: \"user-management\" - code_path: \"./src\" - focus_areas: [\"SOLID Principles\", \"Architecture Quality\"] Result : Targeted assessment focusing on design principles and architecture with detailed violation examples and refactoring suggestions Related Skills \u00b6 review-code : Use for detailed code review after identifying quality issues fix-code-smells : Apply to address specific code smells identified in assessment improve-cyclomatic-complexity : Use to reduce complexity issues found augment-code-unit-test : Apply to improve test coverage gaps identified generate-tech-spec-from-code : Create specification to document current architecture Tips & Best Practices \u00b6 Run assessment before planning major refactoring to establish baseline metrics Focus on high-impact, low-effort improvements first for quick wins Use assessment results to guide technical debt prioritization Re-run periodically to track quality improvements over time Share scorecard with team to build consensus on quality goals Combine with tech spec analysis for comprehensive understanding Limitations \u00b6 Assessment quality depends on codebase accessibility and completeness Some metrics require static analysis tools for precise calculation Subjective elements in grading despite evidence-based approach May not capture runtime behavior or performance issues Requires understanding of assessed principles for interpretation","title":"Assess Code Quality Principles"},{"location":"skills/assess-code-quality-principles/description/#assess-code-quality-principles","text":"Source : skills/assess-code-quality-principles/prompts/assess-code-quality-principles.md","title":"Assess Code Quality Principles"},{"location":"skills/assess-code-quality-principles/description/#overview","text":"Critical evaluation of codebase against established engineering principles (SOLID, DRY, YAGNI) with evidence-based scoring and specific improvement recommendations. Provides comprehensive quality scorecard with actionable insights.","title":"Overview"},{"location":"skills/assess-code-quality-principles/description/#purpose","text":"Software projects often accumulate technical debt and quality issues over time. This skill provides systematic evaluation of code quality against industry-standard principles, helping teams identify areas for improvement, prioritize refactoring efforts, and maintain high code quality standards. It transforms subjective code reviews into objective, measurable assessments.","title":"Purpose"},{"location":"skills/assess-code-quality-principles/description/#usage","text":"Skill : assess-code-quality-principles Protocol : Propose-Act When to Use : - Before major refactoring initiatives to establish baseline - During technical debt assessment and planning - For code quality audits and compliance reviews - When onboarding to understand codebase quality - To validate architecture and design decisions","title":"Usage"},{"location":"skills/assess-code-quality-principles/description/#parameters","text":"","title":"Parameters"},{"location":"skills/assess-code-quality-principles/description/#required-inputs","text":"application_name : Name of the application for file naming (kebab-case format) code_path : Path to the codebase directory to assess","title":"Required Inputs"},{"location":"skills/assess-code-quality-principles/description/#optional-inputs","text":"tech_spec_path : Path to existing technical specification for context focus_areas : Specific areas to focus assessment on (defaults to all categories)","title":"Optional Inputs"},{"location":"skills/assess-code-quality-principles/description/#context-requirements","text":"Access to complete codebase source files Ability to analyze file structure and dependencies Optional: existing technical documentation for context","title":"Context Requirements"},{"location":"skills/assess-code-quality-principles/description/#output","text":"Comprehensive quality assessment report with evidence-based scoring across multiple dimensions. Deliverables : - Quality scorecard with overall and category-specific grades (A-F scale) - Detailed staging with specific code examples - Prioritized improvement recommendations with effort estimates - Metrics and measurements for each assessment category Format : Markdown document saved to .olaf/work/staging/assessments/code-quality-assessment-{application_name}-YYYYMMDD-NNN.md","title":"Output"},{"location":"skills/assess-code-quality-principles/description/#examples","text":"","title":"Examples"},{"location":"skills/assess-code-quality-principles/description/#example-1-full-codebase-assessment","text":"Scenario : Evaluating overall code quality before major refactoring Skill Usage : assess-code-quality-principles Input : - application_name: \"payment-service\" - code_path: \"./src\" Result : Complete assessment report with grades for SOLID principles (B), Code Quality (C), Testing (D), Architecture (B), Security (B), and Performance (C), including 15 prioritized recommendations","title":"Example 1: Full Codebase Assessment"},{"location":"skills/assess-code-quality-principles/description/#example-2-focused-solid-assessment","text":"Scenario : Evaluating design principles compliance Skill Usage : assess-code-quality-principles Input : - application_name: \"user-management\" - code_path: \"./src\" - focus_areas: [\"SOLID Principles\", \"Architecture Quality\"] Result : Targeted assessment focusing on design principles and architecture with detailed violation examples and refactoring suggestions","title":"Example 2: Focused SOLID Assessment"},{"location":"skills/assess-code-quality-principles/description/#related-skills","text":"review-code : Use for detailed code review after identifying quality issues fix-code-smells : Apply to address specific code smells identified in assessment improve-cyclomatic-complexity : Use to reduce complexity issues found augment-code-unit-test : Apply to improve test coverage gaps identified generate-tech-spec-from-code : Create specification to document current architecture","title":"Related Skills"},{"location":"skills/assess-code-quality-principles/description/#tips-best-practices","text":"Run assessment before planning major refactoring to establish baseline metrics Focus on high-impact, low-effort improvements first for quick wins Use assessment results to guide technical debt prioritization Re-run periodically to track quality improvements over time Share scorecard with team to build consensus on quality goals Combine with tech spec analysis for comprehensive understanding","title":"Tips &amp; Best Practices"},{"location":"skills/assess-code-quality-principles/description/#limitations","text":"Assessment quality depends on codebase accessibility and completeness Some metrics require static analysis tools for precise calculation Subjective elements in grading despite evidence-based approach May not capture runtime behavior or performance issues Requires understanding of assessed principles for interpretation","title":"Limitations"},{"location":"skills/assess-code-quality-principles/tutorial/","text":"Assess Code Quality Principles: Step-by-Step Tutorial \u00b6 How to Execute the \"Assess Code Quality Principles\" Skill This tutorial shows exactly how to use the comprehensive code quality assessment skill to evaluate codebases against established engineering principles (SOLID, DRY, YAGNI) with evidence-based scoring. Prerequisites \u00b6 Access to OLAF Framework with assess-code-quality-principles skill Complete codebase to assess (source code directory) Basic understanding of SOLID principles and code quality concepts Optional: Existing technical specification for additional context File system access to read source files and write assessment reports Step-by-Step Instructions \u00b6 Step 1: Initialize Quality Assessment \u00b6 Brief description: Start the comprehensive code quality assessment workflow by invoking the assess-code-quality-principles skill. User Action: Navigate to your project workspace Execute the skill: assess-code-quality-principles Prepare to provide application name and codebase path System Response: The system will prompt for required parameters using Propose-Act protocol and begin gathering assessment inputs. Step 2: Provide Assessment Parameters \u00b6 User Action: Provide required parameters when prompted Provide Requirements/Parameters: application_name : Name for file naming - we used \"payment-service\" (kebab-case format) code_path : Path to codebase - we used \"./src\" (relative or absolute path) tech_spec_path : Optional tech spec - we used \"\" (leave empty if not available) focus_areas : Optional focus - we used [] (empty for all categories) Example Input: Application Name: payment-service Code Path: ./src Tech Spec Path: [press Enter to skip] Focus Areas: [press Enter for all categories] Step 3: Codebase Discovery and Analysis \u00b6 What System Does: Scans all source files in specified code path Identifies file types, languages, and architectural patterns Maps module structure and dependencies Extracts initial metrics (file count, LOC, complexity) Catalogs design patterns and anti-patterns You Should See: Progress indicators showing file discovery and initial analysis completion Step 4: SOLID Principles Evaluation \u00b6 What System Does: Single Responsibility : Analyzes classes for multiple responsibilities and cohesion Open/Closed : Evaluates extensibility patterns and modification hotspots Liskov Substitution : Checks inheritance hierarchies and interface implementations Interface Segregation : Assesses interface design and client dependencies Dependency Inversion : Evaluates abstraction usage and dependency injection You Should See: SOLID principles assessment with specific code examples and violation counts Step 5: Code Quality Metrics Analysis \u00b6 What System Does: DRY Assessment : Detects code duplication and quantifies impact YAGNI Assessment : Identifies unused code and over-engineering Complexity Analysis : Calculates cyclomatic and cognitive complexity Naming Conventions : Evaluates code readability and consistency Maintainability : Assesses overall code maintainability index You Should See: Code quality metrics with specific measurements and violation examples Step 6: Testing Quality Evaluation \u00b6 What System Does: Analyzes test coverage (line, branch, method coverage) Evaluates test quality and design patterns Assesses test maintainability and effectiveness Checks test pyramid compliance Identifies missing test scenarios You Should See: Testing quality assessment with coverage percentages and test quality scores Step 7: Architecture and Security Assessment \u00b6 What System Does: Architecture Quality: - Evaluates module structure and package organization - Analyzes coupling and cohesion metrics - Identifies circular dependencies - Assesses layer separation and boundaries Security Practices: - Reviews input validation patterns - Evaluates authentication/authorization implementation - Identifies potential security vulnerabilities - Assesses cryptographic usage Performance Patterns: - Detects performance anti-patterns - Evaluates resource management - Assesses caching strategies - Reviews database interaction patterns You Should See: Architecture, security, and performance assessments with specific staging Step 8: Evidence Collection and Scoring \u00b6 What System Does: Collects specific code examples for each violation Quantifies impact of quality issues with metrics Calculates scores for each assessment category (A-F scale) Computes overall quality score Prioritizes staging by impact and effort You Should See: Quality scorecard with grades and supporting evidence Step 9: Recommendations and Action Plan \u00b6 What System Does: Generates prioritized improvement recommendations Provides specific code examples for problems and solutions Estimates implementation effort for each recommendation Creates action plan organized by priority (high/medium/low) Suggests quick wins and long-term improvements You Should See: Comprehensive improvement plan with effort estimates and priorities Step 10: Report Generation and Review \u00b6 What System Does: Compiles complete assessment report with all staging Formats report following OLAF standards Saves report to staging directory with timestamp Presents summary scorecard for user review Requests feedback and incorporates adjustments You Should See: Complete assessment document saved to work/staging/assessments/code-quality-assessment-{application_name}-YYYYMMDD-NNN.md Verification Checklist \u00b6 \u2705 Parameters provided : Application name and code path specified correctly \u2705 Codebase analyzed : All source files discovered and scanned \u2705 SOLID principles evaluated : Each principle assessed with evidence \u2705 Code quality measured : DRY, YAGNI, complexity metrics calculated \u2705 Testing assessed : Test coverage and quality evaluated \u2705 Architecture reviewed : Module structure and coupling analyzed \u2705 Security checked : Security practices and vulnerabilities identified \u2705 Scores calculated : Grades assigned for each category (A-F scale) \u2705 Recommendations generated : Prioritized improvement plan created \u2705 Report saved : Assessment document created in staging directory Troubleshooting \u00b6 If codebase analysis fails: # Verify code path exists and is accessible ls -la ./src # Check file permissions # Ensure path is relative to workspace root If assessment seems incomplete: Verify all source files are in specified code_path Check that file types are recognized (common languages supported) Ensure sufficient file system permissions for reading Consider providing tech_spec_path for additional context If scores seem inaccurate: Review specific code examples provided as evidence Check if focus_areas parameter limited assessment scope Verify codebase represents complete application (not partial) Consider running assessment on specific modules separately If report generation fails: # Verify staging directory exists mkdir -p work/staging/assessments # Check write permissions # Ensure sufficient disk space Key Learning Points \u00b6 Evidence-based assessment : All grades supported by specific code examples and metrics Comprehensive evaluation : Covers SOLID, code quality, testing, architecture, security, and performance Actionable recommendations : Prioritized improvements with effort estimates and code examples Objective scoring : A-F grading scale with clear criteria for each category Baseline establishment : Creates measurable baseline for tracking quality improvements over time Next Steps to Try \u00b6 Review high-priority recommendations and plan implementation Use fix-code-smells skill to address specific code smells identified Apply improve-cyclomatic-complexity to reduce complexity issues Use augment-code-unit-test to improve test coverage gaps Re-run assessment periodically to track quality improvements Share scorecard with team to build consensus on quality goals Integrate assessment into CI/CD pipeline for continuous monitoring Expected Timeline \u00b6 Total assessment time: 20-60 minutes depending on codebase size and complexity User input required: Parameter setup and review (5-10 minutes) Codebase analysis: File discovery and initial scanning (5-15 minutes) Skill evaluation: SOLID, quality, testing, architecture assessment (10-30 minutes) Report generation: Scoring, recommendations, and documentation (5-10 minutes) Review and feedback: User validation and adjustments (5-10 minutes)","title":"Assess Code Quality Principles: Step-by-Step Tutorial"},{"location":"skills/assess-code-quality-principles/tutorial/#assess-code-quality-principles-step-by-step-tutorial","text":"How to Execute the \"Assess Code Quality Principles\" Skill This tutorial shows exactly how to use the comprehensive code quality assessment skill to evaluate codebases against established engineering principles (SOLID, DRY, YAGNI) with evidence-based scoring.","title":"Assess Code Quality Principles: Step-by-Step Tutorial"},{"location":"skills/assess-code-quality-principles/tutorial/#prerequisites","text":"Access to OLAF Framework with assess-code-quality-principles skill Complete codebase to assess (source code directory) Basic understanding of SOLID principles and code quality concepts Optional: Existing technical specification for additional context File system access to read source files and write assessment reports","title":"Prerequisites"},{"location":"skills/assess-code-quality-principles/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/assess-code-quality-principles/tutorial/#step-1-initialize-quality-assessment","text":"Brief description: Start the comprehensive code quality assessment workflow by invoking the assess-code-quality-principles skill. User Action: Navigate to your project workspace Execute the skill: assess-code-quality-principles Prepare to provide application name and codebase path System Response: The system will prompt for required parameters using Propose-Act protocol and begin gathering assessment inputs.","title":"Step 1: Initialize Quality Assessment"},{"location":"skills/assess-code-quality-principles/tutorial/#step-2-provide-assessment-parameters","text":"User Action: Provide required parameters when prompted Provide Requirements/Parameters: application_name : Name for file naming - we used \"payment-service\" (kebab-case format) code_path : Path to codebase - we used \"./src\" (relative or absolute path) tech_spec_path : Optional tech spec - we used \"\" (leave empty if not available) focus_areas : Optional focus - we used [] (empty for all categories) Example Input: Application Name: payment-service Code Path: ./src Tech Spec Path: [press Enter to skip] Focus Areas: [press Enter for all categories]","title":"Step 2: Provide Assessment Parameters"},{"location":"skills/assess-code-quality-principles/tutorial/#step-3-codebase-discovery-and-analysis","text":"What System Does: Scans all source files in specified code path Identifies file types, languages, and architectural patterns Maps module structure and dependencies Extracts initial metrics (file count, LOC, complexity) Catalogs design patterns and anti-patterns You Should See: Progress indicators showing file discovery and initial analysis completion","title":"Step 3: Codebase Discovery and Analysis"},{"location":"skills/assess-code-quality-principles/tutorial/#step-4-solid-principles-evaluation","text":"What System Does: Single Responsibility : Analyzes classes for multiple responsibilities and cohesion Open/Closed : Evaluates extensibility patterns and modification hotspots Liskov Substitution : Checks inheritance hierarchies and interface implementations Interface Segregation : Assesses interface design and client dependencies Dependency Inversion : Evaluates abstraction usage and dependency injection You Should See: SOLID principles assessment with specific code examples and violation counts","title":"Step 4: SOLID Principles Evaluation"},{"location":"skills/assess-code-quality-principles/tutorial/#step-5-code-quality-metrics-analysis","text":"What System Does: DRY Assessment : Detects code duplication and quantifies impact YAGNI Assessment : Identifies unused code and over-engineering Complexity Analysis : Calculates cyclomatic and cognitive complexity Naming Conventions : Evaluates code readability and consistency Maintainability : Assesses overall code maintainability index You Should See: Code quality metrics with specific measurements and violation examples","title":"Step 5: Code Quality Metrics Analysis"},{"location":"skills/assess-code-quality-principles/tutorial/#step-6-testing-quality-evaluation","text":"What System Does: Analyzes test coverage (line, branch, method coverage) Evaluates test quality and design patterns Assesses test maintainability and effectiveness Checks test pyramid compliance Identifies missing test scenarios You Should See: Testing quality assessment with coverage percentages and test quality scores","title":"Step 6: Testing Quality Evaluation"},{"location":"skills/assess-code-quality-principles/tutorial/#step-7-architecture-and-security-assessment","text":"What System Does: Architecture Quality: - Evaluates module structure and package organization - Analyzes coupling and cohesion metrics - Identifies circular dependencies - Assesses layer separation and boundaries Security Practices: - Reviews input validation patterns - Evaluates authentication/authorization implementation - Identifies potential security vulnerabilities - Assesses cryptographic usage Performance Patterns: - Detects performance anti-patterns - Evaluates resource management - Assesses caching strategies - Reviews database interaction patterns You Should See: Architecture, security, and performance assessments with specific staging","title":"Step 7: Architecture and Security Assessment"},{"location":"skills/assess-code-quality-principles/tutorial/#step-8-evidence-collection-and-scoring","text":"What System Does: Collects specific code examples for each violation Quantifies impact of quality issues with metrics Calculates scores for each assessment category (A-F scale) Computes overall quality score Prioritizes staging by impact and effort You Should See: Quality scorecard with grades and supporting evidence","title":"Step 8: Evidence Collection and Scoring"},{"location":"skills/assess-code-quality-principles/tutorial/#step-9-recommendations-and-action-plan","text":"What System Does: Generates prioritized improvement recommendations Provides specific code examples for problems and solutions Estimates implementation effort for each recommendation Creates action plan organized by priority (high/medium/low) Suggests quick wins and long-term improvements You Should See: Comprehensive improvement plan with effort estimates and priorities","title":"Step 9: Recommendations and Action Plan"},{"location":"skills/assess-code-quality-principles/tutorial/#step-10-report-generation-and-review","text":"What System Does: Compiles complete assessment report with all staging Formats report following OLAF standards Saves report to staging directory with timestamp Presents summary scorecard for user review Requests feedback and incorporates adjustments You Should See: Complete assessment document saved to work/staging/assessments/code-quality-assessment-{application_name}-YYYYMMDD-NNN.md","title":"Step 10: Report Generation and Review"},{"location":"skills/assess-code-quality-principles/tutorial/#verification-checklist","text":"\u2705 Parameters provided : Application name and code path specified correctly \u2705 Codebase analyzed : All source files discovered and scanned \u2705 SOLID principles evaluated : Each principle assessed with evidence \u2705 Code quality measured : DRY, YAGNI, complexity metrics calculated \u2705 Testing assessed : Test coverage and quality evaluated \u2705 Architecture reviewed : Module structure and coupling analyzed \u2705 Security checked : Security practices and vulnerabilities identified \u2705 Scores calculated : Grades assigned for each category (A-F scale) \u2705 Recommendations generated : Prioritized improvement plan created \u2705 Report saved : Assessment document created in staging directory","title":"Verification Checklist"},{"location":"skills/assess-code-quality-principles/tutorial/#troubleshooting","text":"If codebase analysis fails: # Verify code path exists and is accessible ls -la ./src # Check file permissions # Ensure path is relative to workspace root If assessment seems incomplete: Verify all source files are in specified code_path Check that file types are recognized (common languages supported) Ensure sufficient file system permissions for reading Consider providing tech_spec_path for additional context If scores seem inaccurate: Review specific code examples provided as evidence Check if focus_areas parameter limited assessment scope Verify codebase represents complete application (not partial) Consider running assessment on specific modules separately If report generation fails: # Verify staging directory exists mkdir -p work/staging/assessments # Check write permissions # Ensure sufficient disk space","title":"Troubleshooting"},{"location":"skills/assess-code-quality-principles/tutorial/#key-learning-points","text":"Evidence-based assessment : All grades supported by specific code examples and metrics Comprehensive evaluation : Covers SOLID, code quality, testing, architecture, security, and performance Actionable recommendations : Prioritized improvements with effort estimates and code examples Objective scoring : A-F grading scale with clear criteria for each category Baseline establishment : Creates measurable baseline for tracking quality improvements over time","title":"Key Learning Points"},{"location":"skills/assess-code-quality-principles/tutorial/#next-steps-to-try","text":"Review high-priority recommendations and plan implementation Use fix-code-smells skill to address specific code smells identified Apply improve-cyclomatic-complexity to reduce complexity issues Use augment-code-unit-test to improve test coverage gaps Re-run assessment periodically to track quality improvements Share scorecard with team to build consensus on quality goals Integrate assessment into CI/CD pipeline for continuous monitoring","title":"Next Steps to Try"},{"location":"skills/assess-code-quality-principles/tutorial/#expected-timeline","text":"Total assessment time: 20-60 minutes depending on codebase size and complexity User input required: Parameter setup and review (5-10 minutes) Codebase analysis: File discovery and initial scanning (5-15 minutes) Skill evaluation: SOLID, quality, testing, architecture assessment (10-30 minutes) Report generation: Scoring, recommendations, and documentation (5-10 minutes) Review and feedback: User validation and adjustments (5-10 minutes)","title":"Expected Timeline"},{"location":"skills/assess-genai-initiative-idea/description/","text":"Assess GenAI Initiative Idea \u00b6 Overview \u00b6 Evaluates GenAI initiative ideas through research-driven analysis and challenge-based questioning to determine feasibility, value, and implementation approach. Purpose \u00b6 Decision-makers often need to evaluate whether a GenAI initiative is worth pursuing. This competency provides structured analysis combining market research, technical feasibility assessment, and critical challenge questions to make informed go/no-go decisions. Usage \u00b6 Command : assess genai initiative Protocol : Propose-Act When to Use : When considering a new GenAI project, feature, or initiative and need objective evaluation before committing resources. Parameters \u00b6 Required Inputs \u00b6 Initiative Description : Brief description of the GenAI idea or initiative being considered Optional Inputs \u00b6 Business Context : Industry, company size, existing tech stack Constraints : Budget, timeline, team capabilities Context Requirements \u00b6 Clear understanding of the initiative's intended purpose Access to relevant business context Output \u00b6 Deliverables : - Research summary on similar initiatives - Feasibility assessment - Challenge questions and considerations - Recommendation (proceed/modify/abandon) Format : Structured markdown report with sections for research staging, analysis, and recommendations Examples \u00b6 Example 1: Customer Service Chatbot \u00b6 Scenario : Company considering AI chatbot for customer support Command : assess genai initiative Input : \"We want to build an AI chatbot to handle tier-1 customer support inquiries\" Result : Analysis covering existing solutions, implementation complexity, ROI considerations, and specific challenges for the use case Example 2: Document Analysis System \u00b6 Scenario : Legal firm evaluating document review automation Command : assess genai initiative Result : Research on legal AI tools, compliance considerations, accuracy requirements, and implementation roadmap Related Competencies \u00b6 should-i-use-ai : Use this for simpler yes/no AI appropriateness decisions find-expert-contact : Follow up to find experts who can help implement approved initiatives use-skill : Can route to this skill when initiative assessment is needed Tips & Best Practices \u00b6 Provide specific details about your use case for more targeted analysis Be honest about constraints - better to know early if something won't work Use the challenge questions to stress-test your assumptions Consider starting with a pilot/MVP based on recommendations Limitations \u00b6 Analysis quality depends on publicly available information Cannot access proprietary competitive intelligence Recommendations are guidance, not guarantees of success","title":"Assess GenAI Initiative Idea"},{"location":"skills/assess-genai-initiative-idea/description/#assess-genai-initiative-idea","text":"","title":"Assess GenAI Initiative Idea"},{"location":"skills/assess-genai-initiative-idea/description/#overview","text":"Evaluates GenAI initiative ideas through research-driven analysis and challenge-based questioning to determine feasibility, value, and implementation approach.","title":"Overview"},{"location":"skills/assess-genai-initiative-idea/description/#purpose","text":"Decision-makers often need to evaluate whether a GenAI initiative is worth pursuing. This competency provides structured analysis combining market research, technical feasibility assessment, and critical challenge questions to make informed go/no-go decisions.","title":"Purpose"},{"location":"skills/assess-genai-initiative-idea/description/#usage","text":"Command : assess genai initiative Protocol : Propose-Act When to Use : When considering a new GenAI project, feature, or initiative and need objective evaluation before committing resources.","title":"Usage"},{"location":"skills/assess-genai-initiative-idea/description/#parameters","text":"","title":"Parameters"},{"location":"skills/assess-genai-initiative-idea/description/#required-inputs","text":"Initiative Description : Brief description of the GenAI idea or initiative being considered","title":"Required Inputs"},{"location":"skills/assess-genai-initiative-idea/description/#optional-inputs","text":"Business Context : Industry, company size, existing tech stack Constraints : Budget, timeline, team capabilities","title":"Optional Inputs"},{"location":"skills/assess-genai-initiative-idea/description/#context-requirements","text":"Clear understanding of the initiative's intended purpose Access to relevant business context","title":"Context Requirements"},{"location":"skills/assess-genai-initiative-idea/description/#output","text":"Deliverables : - Research summary on similar initiatives - Feasibility assessment - Challenge questions and considerations - Recommendation (proceed/modify/abandon) Format : Structured markdown report with sections for research staging, analysis, and recommendations","title":"Output"},{"location":"skills/assess-genai-initiative-idea/description/#examples","text":"","title":"Examples"},{"location":"skills/assess-genai-initiative-idea/description/#example-1-customer-service-chatbot","text":"Scenario : Company considering AI chatbot for customer support Command : assess genai initiative Input : \"We want to build an AI chatbot to handle tier-1 customer support inquiries\" Result : Analysis covering existing solutions, implementation complexity, ROI considerations, and specific challenges for the use case","title":"Example 1: Customer Service Chatbot"},{"location":"skills/assess-genai-initiative-idea/description/#example-2-document-analysis-system","text":"Scenario : Legal firm evaluating document review automation Command : assess genai initiative Result : Research on legal AI tools, compliance considerations, accuracy requirements, and implementation roadmap","title":"Example 2: Document Analysis System"},{"location":"skills/assess-genai-initiative-idea/description/#related-competencies","text":"should-i-use-ai : Use this for simpler yes/no AI appropriateness decisions find-expert-contact : Follow up to find experts who can help implement approved initiatives use-skill : Can route to this skill when initiative assessment is needed","title":"Related Competencies"},{"location":"skills/assess-genai-initiative-idea/description/#tips-best-practices","text":"Provide specific details about your use case for more targeted analysis Be honest about constraints - better to know early if something won't work Use the challenge questions to stress-test your assumptions Consider starting with a pilot/MVP based on recommendations","title":"Tips &amp; Best Practices"},{"location":"skills/assess-genai-initiative-idea/description/#limitations","text":"Analysis quality depends on publicly available information Cannot access proprietary competitive intelligence Recommendations are guidance, not guarantees of success","title":"Limitations"},{"location":"skills/assess-genai-initiative-idea/tutorial/","text":"Assess GenAI Initiative: Step-by-Step Tutorial \u00b6 How to Execute the \"Assess GenAI Initiative Idea\" Workflow This tutorial shows how to evaluate a GenAI initiative idea using structured research and analysis. Prerequisites \u00b6 Clear description of the GenAI initiative you're considering Understanding of your business context and constraints Decision-making authority or input into the initiative Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 Initiate the assessment process User Action: 1. Open a new conversation with OLAF 2. Type the command: assess genai initiative 3. Provide a brief description of your initiative idea OLAF Response: OLAF will acknowledge the request and begin the research and analysis process Step 2: Provide Initiative Details \u00b6 User Action: Describe your GenAI initiative idea We want to build an AI-powered code review assistant that automatically checks pull requests for security vulnerabilities and suggests improvements Provide Context: - Industry : Software development / SaaS - Team Size : 50 developers - Current Process : Manual code reviews taking 2-3 days per PR - Budget : $50K initial investment Step 3: Research Phase \u00b6 What OLAF Does: - Researches similar GenAI initiatives and solutions - Analyzes market trends and existing tools - Identifies technical approaches and frameworks - Gathers implementation examples and case studies You Should See: Research summary with staging about similar initiatives Step 4: Challenge Analysis \u00b6 What OLAF Does: - Generates critical challenge questions - Identifies potential risks and obstacles - Evaluates technical feasibility - Assesses resource requirements You Should See: List of challenge questions and considerations specific to your initiative Step 5: Review Recommendations \u00b6 User Action: Review the analysis and recommendations - Read through research staging - Consider challenge questions - Evaluate the recommendation (proceed/modify/abandon) - Ask follow-up questions if needed Verification Checklist \u00b6 \u2705 Research staging cover similar initiatives in your domain \u2705 Challenge questions address your specific concerns \u2705 Technical feasibility is clearly assessed \u2705 Clear recommendation provided with rationale Troubleshooting \u00b6 If research seems too generic: Provide more specific details about your industry, use case, and constraints If you need deeper analysis on specific aspects: - Ask follow-up questions about specific concerns - Request deeper dive into technical approaches - Ask for comparison with specific alternatives Key Learning Points \u00b6 Research-Driven : Decisions based on market research and existing solutions Challenge-Based : Critical questions help identify risks early Actionable : Clear recommendations with next steps Iterative : Can refine analysis based on additional information Next Steps to Try \u00b6 If approved: Use find expert contact to locate implementation experts If modified: Refine the initiative based on feedback and reassess If uncertain: Use should i use ai for simpler appropriateness check Expected Timeline \u00b6 Total assessment time: 5-10 minutes User input required: Initial description and context (2-3 minutes) OLAF execution time: Research and analysis (3-7 minutes)","title":"Assess GenAI Initiative: Step-by-Step Tutorial"},{"location":"skills/assess-genai-initiative-idea/tutorial/#assess-genai-initiative-step-by-step-tutorial","text":"How to Execute the \"Assess GenAI Initiative Idea\" Workflow This tutorial shows how to evaluate a GenAI initiative idea using structured research and analysis.","title":"Assess GenAI Initiative: Step-by-Step Tutorial"},{"location":"skills/assess-genai-initiative-idea/tutorial/#prerequisites","text":"Clear description of the GenAI initiative you're considering Understanding of your business context and constraints Decision-making authority or input into the initiative","title":"Prerequisites"},{"location":"skills/assess-genai-initiative-idea/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/assess-genai-initiative-idea/tutorial/#step-1-invoke-the-competency","text":"Initiate the assessment process User Action: 1. Open a new conversation with OLAF 2. Type the command: assess genai initiative 3. Provide a brief description of your initiative idea OLAF Response: OLAF will acknowledge the request and begin the research and analysis process","title":"Step 1: Invoke the Competency"},{"location":"skills/assess-genai-initiative-idea/tutorial/#step-2-provide-initiative-details","text":"User Action: Describe your GenAI initiative idea We want to build an AI-powered code review assistant that automatically checks pull requests for security vulnerabilities and suggests improvements Provide Context: - Industry : Software development / SaaS - Team Size : 50 developers - Current Process : Manual code reviews taking 2-3 days per PR - Budget : $50K initial investment","title":"Step 2: Provide Initiative Details"},{"location":"skills/assess-genai-initiative-idea/tutorial/#step-3-research-phase","text":"What OLAF Does: - Researches similar GenAI initiatives and solutions - Analyzes market trends and existing tools - Identifies technical approaches and frameworks - Gathers implementation examples and case studies You Should See: Research summary with staging about similar initiatives","title":"Step 3: Research Phase"},{"location":"skills/assess-genai-initiative-idea/tutorial/#step-4-challenge-analysis","text":"What OLAF Does: - Generates critical challenge questions - Identifies potential risks and obstacles - Evaluates technical feasibility - Assesses resource requirements You Should See: List of challenge questions and considerations specific to your initiative","title":"Step 4: Challenge Analysis"},{"location":"skills/assess-genai-initiative-idea/tutorial/#step-5-review-recommendations","text":"User Action: Review the analysis and recommendations - Read through research staging - Consider challenge questions - Evaluate the recommendation (proceed/modify/abandon) - Ask follow-up questions if needed","title":"Step 5: Review Recommendations"},{"location":"skills/assess-genai-initiative-idea/tutorial/#verification-checklist","text":"\u2705 Research staging cover similar initiatives in your domain \u2705 Challenge questions address your specific concerns \u2705 Technical feasibility is clearly assessed \u2705 Clear recommendation provided with rationale","title":"Verification Checklist"},{"location":"skills/assess-genai-initiative-idea/tutorial/#troubleshooting","text":"If research seems too generic: Provide more specific details about your industry, use case, and constraints If you need deeper analysis on specific aspects: - Ask follow-up questions about specific concerns - Request deeper dive into technical approaches - Ask for comparison with specific alternatives","title":"Troubleshooting"},{"location":"skills/assess-genai-initiative-idea/tutorial/#key-learning-points","text":"Research-Driven : Decisions based on market research and existing solutions Challenge-Based : Critical questions help identify risks early Actionable : Clear recommendations with next steps Iterative : Can refine analysis based on additional information","title":"Key Learning Points"},{"location":"skills/assess-genai-initiative-idea/tutorial/#next-steps-to-try","text":"If approved: Use find expert contact to locate implementation experts If modified: Refine the initiative based on feedback and reassess If uncertain: Use should i use ai for simpler appropriateness check","title":"Next Steps to Try"},{"location":"skills/assess-genai-initiative-idea/tutorial/#expected-timeline","text":"Total assessment time: 5-10 minutes User input required: Initial description and context (2-3 minutes) OLAF execution time: Research and analysis (3-7 minutes)","title":"Expected Timeline"},{"location":"skills/assist-me-as-prompt-engineer/description/","text":"Prompt Engineering Assistant \u00b6 Overview \u00b6 The Prompt Engineering Assistant is your intelligent guide through OLAF's comprehensive prompt engineering capabilities. It assesses your expertise level and recommends the right skills, workflows, and learning paths to accomplish your goals. Purpose \u00b6 Smart Skill Discovery : Automatically recommends appropriate skills based on your task and expertise Leveled Learning : Organizes skills by expertise level (beginner -> trained -> advanced) Workflow Orchestration : Guides complex multi-skill workflows Progressive Learning : Suggests advancement paths as you grow Expertise Levels \u00b6 Beginner Level \u00b6 Focus : Creating and sharing basic prompts Available Skills : - create-prompt - Draft a prompt and stage it under .olaf/staging/generated-prompts/ - check-prompt-compliance - Check prompt compliance and directive quality Typical Goals : - Creating first prompts - Learning prompt structure - Sharing work with team Trained Level \u00b6 Focus : Skill development and prompt management Available Skills : - create-skill - Build complete skills with prompts - evaluate-prompt-for-adoption - Assess external prompts - convert-prompt-to-skill - Convert prompt content into a skill structure - create-skill-description - Generate docs for an existing skill Typical Goals : - Building reusable skills - Converting old prompts - Managing prompt collections Advanced Level \u00b6 Focus : Orchestration and validation Available Skills : - generate-orchestrator - Create orchestrator skills - convert-skill-to-chain - Build executable skill chains - validate-prompt-value - Deep effectiveness analysis - validate-olaf-artifacts - System-wide validation of local artifacts Typical Goals : - Orchestrating multiple skills - Creating workflow chains - Measuring prompt ROI How It Works \u00b6 1. Task Assessment \u00b6 Describe what you want to accomplish. The assistant analyzes: - Task complexity - Required capabilities - Your current expertise level 2. Skill Recommendation \u00b6 Receive tailored recommendations: - Primary skill to use - Supporting skills if needed - Clear usage instructions - Expected outcomes 3. Workflow Guidance \u00b6 For complex tasks: - Multi-step workflow proposed - Dependencies explained - Option to execute automatically 4. Learning Paths \u00b6 Progressive skill suggestions: - Next skills to learn - Prerequisite recommendations - Advancement opportunities Key Features \u00b6 Intelligent Matching \u00b6 Analyzes task requirements Maps to appropriate skill level Considers user expertise Clear Guidance \u00b6 Step-by-step instructions Usage examples Expected outcomes Next actions Workflow Support \u00b6 Multi-skill orchestration Dependency management Automated execution option Progressive Learning \u00b6 Skill level advancement Learning path suggestions Prerequisite guidance When to Use \u00b6 Perfect For : - \"What skill should I use for...?\" - \"How do I accomplish...?\" - \"I'm new to prompt engineering\" - \"What's the best way to...?\" - \"I need help with multiple steps\" Example Scenarios : - Creating your first prompt - Converting legacy prompts - Building complex workflows - Contributing to OLAF framework - Learning prompt engineering Integration \u00b6 Works With : - All prompt engineering skills - Learning and documentation skills - Workflow generation capabilities Complements : - help-me-olaf - General OLAF assistance - tell-me - Contextual help and knowledge routing Success Criteria \u00b6 You'll know this skill is effective when: - You quickly find the right skill for your task - You understand how to use recommended skills - You progress through expertise levels smoothly - Complex tasks are broken into clear workflows - You know exactly what to do next Getting Started \u00b6 Simply describe your goal: olaf prompt assistant \"I need to create a code review prompt\" olaf prompt help \"Is this prompt compliant?\" olaf guide me \"I want to build a workflow for prompt deployment\" The assistant will assess your need and guide you to the right solution.","title":"Prompt Engineering Assistant"},{"location":"skills/assist-me-as-prompt-engineer/description/#prompt-engineering-assistant","text":"","title":"Prompt Engineering Assistant"},{"location":"skills/assist-me-as-prompt-engineer/description/#overview","text":"The Prompt Engineering Assistant is your intelligent guide through OLAF's comprehensive prompt engineering capabilities. It assesses your expertise level and recommends the right skills, workflows, and learning paths to accomplish your goals.","title":"Overview"},{"location":"skills/assist-me-as-prompt-engineer/description/#purpose","text":"Smart Skill Discovery : Automatically recommends appropriate skills based on your task and expertise Leveled Learning : Organizes skills by expertise level (beginner -> trained -> advanced) Workflow Orchestration : Guides complex multi-skill workflows Progressive Learning : Suggests advancement paths as you grow","title":"Purpose"},{"location":"skills/assist-me-as-prompt-engineer/description/#expertise-levels","text":"","title":"Expertise Levels"},{"location":"skills/assist-me-as-prompt-engineer/description/#beginner-level","text":"Focus : Creating and sharing basic prompts Available Skills : - create-prompt - Draft a prompt and stage it under .olaf/staging/generated-prompts/ - check-prompt-compliance - Check prompt compliance and directive quality Typical Goals : - Creating first prompts - Learning prompt structure - Sharing work with team","title":"Beginner Level"},{"location":"skills/assist-me-as-prompt-engineer/description/#trained-level","text":"Focus : Skill development and prompt management Available Skills : - create-skill - Build complete skills with prompts - evaluate-prompt-for-adoption - Assess external prompts - convert-prompt-to-skill - Convert prompt content into a skill structure - create-skill-description - Generate docs for an existing skill Typical Goals : - Building reusable skills - Converting old prompts - Managing prompt collections","title":"Trained Level"},{"location":"skills/assist-me-as-prompt-engineer/description/#advanced-level","text":"Focus : Orchestration and validation Available Skills : - generate-orchestrator - Create orchestrator skills - convert-skill-to-chain - Build executable skill chains - validate-prompt-value - Deep effectiveness analysis - validate-olaf-artifacts - System-wide validation of local artifacts Typical Goals : - Orchestrating multiple skills - Creating workflow chains - Measuring prompt ROI","title":"Advanced Level"},{"location":"skills/assist-me-as-prompt-engineer/description/#how-it-works","text":"","title":"How It Works"},{"location":"skills/assist-me-as-prompt-engineer/description/#1-task-assessment","text":"Describe what you want to accomplish. The assistant analyzes: - Task complexity - Required capabilities - Your current expertise level","title":"1. Task Assessment"},{"location":"skills/assist-me-as-prompt-engineer/description/#2-skill-recommendation","text":"Receive tailored recommendations: - Primary skill to use - Supporting skills if needed - Clear usage instructions - Expected outcomes","title":"2. Skill Recommendation"},{"location":"skills/assist-me-as-prompt-engineer/description/#3-workflow-guidance","text":"For complex tasks: - Multi-step workflow proposed - Dependencies explained - Option to execute automatically","title":"3. Workflow Guidance"},{"location":"skills/assist-me-as-prompt-engineer/description/#4-learning-paths","text":"Progressive skill suggestions: - Next skills to learn - Prerequisite recommendations - Advancement opportunities","title":"4. Learning Paths"},{"location":"skills/assist-me-as-prompt-engineer/description/#key-features","text":"","title":"Key Features"},{"location":"skills/assist-me-as-prompt-engineer/description/#intelligent-matching","text":"Analyzes task requirements Maps to appropriate skill level Considers user expertise","title":"Intelligent Matching"},{"location":"skills/assist-me-as-prompt-engineer/description/#clear-guidance","text":"Step-by-step instructions Usage examples Expected outcomes Next actions","title":"Clear Guidance"},{"location":"skills/assist-me-as-prompt-engineer/description/#workflow-support","text":"Multi-skill orchestration Dependency management Automated execution option","title":"Workflow Support"},{"location":"skills/assist-me-as-prompt-engineer/description/#progressive-learning","text":"Skill level advancement Learning path suggestions Prerequisite guidance","title":"Progressive Learning"},{"location":"skills/assist-me-as-prompt-engineer/description/#when-to-use","text":"Perfect For : - \"What skill should I use for...?\" - \"How do I accomplish...?\" - \"I'm new to prompt engineering\" - \"What's the best way to...?\" - \"I need help with multiple steps\" Example Scenarios : - Creating your first prompt - Converting legacy prompts - Building complex workflows - Contributing to OLAF framework - Learning prompt engineering","title":"When to Use"},{"location":"skills/assist-me-as-prompt-engineer/description/#integration","text":"Works With : - All prompt engineering skills - Learning and documentation skills - Workflow generation capabilities Complements : - help-me-olaf - General OLAF assistance - tell-me - Contextual help and knowledge routing","title":"Integration"},{"location":"skills/assist-me-as-prompt-engineer/description/#success-criteria","text":"You'll know this skill is effective when: - You quickly find the right skill for your task - You understand how to use recommended skills - You progress through expertise levels smoothly - Complex tasks are broken into clear workflows - You know exactly what to do next","title":"Success Criteria"},{"location":"skills/assist-me-as-prompt-engineer/description/#getting-started","text":"Simply describe your goal: olaf prompt assistant \"I need to create a code review prompt\" olaf prompt help \"Is this prompt compliant?\" olaf guide me \"I want to build a workflow for prompt deployment\" The assistant will assess your need and guide you to the right solution.","title":"Getting Started"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/","text":"Prompt Engineering Assistant - Tutorial \u00b6 Introduction \u00b6 This tutorial walks you through using the Prompt Engineering Assistant to navigate OLAF's prompt engineering capabilities based on your expertise level. Prerequisites \u00b6 OLAF framework installed Basic understanding of prompt engineering concepts Access to terminal/command line Learning Path \u00b6 Level 1: Beginner Tasks \u00b6 Scenario 1: Creating Your First Prompt \u00b6 Goal : Create a code review prompt Step 1 : Ask for assistance olaf prompt assistant \"I need to create a code review prompt\" Expected Response : Assessment: Beginner level task - first prompt creation Recommendation: create-prompt This skill guides you through creating a structured code review prompt using proven templates. Usage: use the `create-prompt` skill Expected Outcome: - Staged prompt file in `.olaf/staging/generated-prompts/` - Prompt follows prompt engineering principles - Ready-to-use code review capability Next Step: Tell me what you want the prompt to do and I\u2019ll draft it. Scenario 2: Checking Prompt Compliance \u00b6 Goal : Validate a prompt before using it Command : olaf prompt help \"Is this prompt compliant?\" Expected Guidance : - Recommendation: check-prompt-compliance - What is non-compliant and why - Concrete edits to make it compliant Scenario 3: Importing Existing Prompts \u00b6 Goal : Bring a ChatGPT prompt into OLAF Command : olaf guide me \"I have a prompt from ChatGPT to import\" Expected Guidance : - Recommendation: convert-prompt-to-skill - Import process steps - Where prompt will be stored Level 2: Trained Tasks \u00b6 Scenario 4: Building Your First Skill \u00b6 Goal : Create a skill with multiple prompts Step 1 : Request assistance olaf prompt assistant \"I want to create a skill with multiple prompts\" Expected Response : Assessment: Trained level task - skill development Recommendation: create-skill Ready to build complete capabilities? This skill helps you create a full skill package with prompts, docs, and workflows. Usage: olaf create skill Expected Outcome: - Complete skill structure - Multiple prompts organized - Documentation generated Next Step: Run `olaf create skill` to begin. Step 2 : Execute the skill creation Scenario 5: Modernizing Legacy Prompts \u00b6 Goal : Update old prompts to OLAF standards Command : olaf prompt help \"I have old prompts that need updating\" Expected Guidance : - Recommendation: convert-prompt-to-skill - Conversion/packaging steps explained - Validation steps included Scenario 6: Creating Prompt Documentation \u00b6 Goal : Generate documentation for a prompt/skill Command : olaf guide me \"Generate docs for this prompt\" Expected Guidance : - Recommendation: create-skill-description - What it will extract and how it structures the docs Level 3: Advanced Tasks \u00b6 Scenario 7: Creating a Workflow \u00b6 Goal : Build workflow that validates then deploys prompts Step 1 : Request workflow guidance olaf prompt assistant \"I need a workflow that validates then deploys prompts\" Expected Response : Assessment: Advanced level task - workflow orchestration Recommendation: Multi-step workflow Workflow: 1. evaluate-prompt-for-adoption - Assess prompt quality 2. check-prompt-compliance - Ensure directive quality and compliance 3. convert-prompt-to-skill - Package prompt content into a skill structure 4. validate-prompt-value - Verify effectiveness 5. validate-olaf-artifacts - Validate local artifacts holistically (optional) Alternative: Use generate-orchestrator to create an orchestrator. Next Step: Would you like me to execute this workflow, or create a permanent workflow chain? (workflow/chain) Step 2 : Choose execution or chain creation # For one-time execution > workflow # For reusable chain > chain Scenario 8: Skill Chain Creation \u00b6 Goal : Convert skill to executable chain Command : olaf prompt help \"How do I chain multiple skills together?\" Expected Guidance : - Recommendation: convert-skill-to-chain - Chain architecture explained - Execution model described Common Patterns \u00b6 Pattern 1: \"I Don't Know What Skill to Use\" \u00b6 Solution : Describe your goal, let the assistant recommend olaf prompt assistant \"I want to [your goal]\" Pattern 2: \"I'm Not Sure About My Level\" \u00b6 Solution : The assistant auto-assesses based on your task No need to specify level - it's determined automatically Pattern 3: \"I Need Multiple Skills\" \u00b6 Solution : Request workflow orchestration olaf prompt help \"I need to [complex multi-step goal]\" The assistant will propose a complete workflow Pattern 4: \"I Want to Learn More\" \u00b6 Solution : Ask about advancement olaf guide me \"What should I learn next?\" Progression Path \u00b6 Beginner to Trained \u00b6 When Ready : - Comfortable with create-prompt - Created several prompts successfully - Understand prompt structure Next Steps : - Try create-skill - Explore convert-prompt-to-skill - Try create-skill-description Trained to Advanced \u00b6 When Ready : - Built multiple skills - Managed prompt collections - Understand skill architecture Next Steps : - Try generate-orchestrator - Explore convert-skill-to-chain - Try validate-olaf-artifacts Tips and Best Practices \u00b6 Tip 1: Be Specific About Your Goal \u00b6 Less Effective : \"Help with prompts\" More Effective : \"I need to create a prompt that reviews Python code for security issues\" Tip 2: Don't Worry About Your Level \u00b6 The assistant automatically assesses and recommends appropriately Tip 3: Ask for Workflows \u00b6 For multi-step tasks, explicitly mention \"workflow\" to get orchestration guidance Tip 4: Use Aliases \u00b6 Multiple ways to invoke: - olaf prompt assistant - olaf prompt help - olaf guide me - olaf pe assistant Tip 5: Follow Learning Paths \u00b6 Progress naturally through levels - the assistant will suggest when you're ready for more Troubleshooting \u00b6 Issue: \"I Got a Skill I Don't Understand\" \u00b6 Solution : Ask for tutorial olaf tell me about [skill-name] Issue: \"The Recommended Skill Seems Too Advanced\" \u00b6 Solution : Ask for prerequisites olaf prompt help \"What do I need to learn before [skill-name]?\" Issue: \"I Need Multiple Skills But Don't Know the Order\" \u00b6 Solution : Request workflow olaf prompt assistant \"workflow for [your complex goal]\" Issue: \"I'm Not Finding the Right Skill\" \u00b6 Solution : Browse all skills olaf list skills Then describe to assistant which one matches your need Next Steps \u00b6 Start Simple : Begin with beginner skills Practice Regularly : Create prompts frequently Progress Gradually : Move to next level when comfortable Ask Questions : Use the assistant whenever unsure Contribute Back : Share your prompts with the community Related Skills \u00b6 help-me-olaf - General OLAF assistance tell-me - Learn about OLAF features Summary \u00b6 The Prompt Engineering Assistant is your guide through OLAF's capabilities: - Assesses your expertise automatically - Recommends appropriate skills - Guides complex workflows - Suggests learning paths - Adapts to your growth Start with simple tasks, progress naturally, and let the assistant guide your journey from beginner to advanced prompt engineer.","title":"Prompt Engineering Assistant - Tutorial"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#prompt-engineering-assistant-tutorial","text":"","title":"Prompt Engineering Assistant - Tutorial"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#introduction","text":"This tutorial walks you through using the Prompt Engineering Assistant to navigate OLAF's prompt engineering capabilities based on your expertise level.","title":"Introduction"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#prerequisites","text":"OLAF framework installed Basic understanding of prompt engineering concepts Access to terminal/command line","title":"Prerequisites"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#learning-path","text":"","title":"Learning Path"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#level-1-beginner-tasks","text":"","title":"Level 1: Beginner Tasks"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#scenario-1-creating-your-first-prompt","text":"Goal : Create a code review prompt Step 1 : Ask for assistance olaf prompt assistant \"I need to create a code review prompt\" Expected Response : Assessment: Beginner level task - first prompt creation Recommendation: create-prompt This skill guides you through creating a structured code review prompt using proven templates. Usage: use the `create-prompt` skill Expected Outcome: - Staged prompt file in `.olaf/staging/generated-prompts/` - Prompt follows prompt engineering principles - Ready-to-use code review capability Next Step: Tell me what you want the prompt to do and I\u2019ll draft it.","title":"Scenario 1: Creating Your First Prompt"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#scenario-2-checking-prompt-compliance","text":"Goal : Validate a prompt before using it Command : olaf prompt help \"Is this prompt compliant?\" Expected Guidance : - Recommendation: check-prompt-compliance - What is non-compliant and why - Concrete edits to make it compliant","title":"Scenario 2: Checking Prompt Compliance"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#scenario-3-importing-existing-prompts","text":"Goal : Bring a ChatGPT prompt into OLAF Command : olaf guide me \"I have a prompt from ChatGPT to import\" Expected Guidance : - Recommendation: convert-prompt-to-skill - Import process steps - Where prompt will be stored","title":"Scenario 3: Importing Existing Prompts"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#level-2-trained-tasks","text":"","title":"Level 2: Trained Tasks"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#scenario-4-building-your-first-skill","text":"Goal : Create a skill with multiple prompts Step 1 : Request assistance olaf prompt assistant \"I want to create a skill with multiple prompts\" Expected Response : Assessment: Trained level task - skill development Recommendation: create-skill Ready to build complete capabilities? This skill helps you create a full skill package with prompts, docs, and workflows. Usage: olaf create skill Expected Outcome: - Complete skill structure - Multiple prompts organized - Documentation generated Next Step: Run `olaf create skill` to begin. Step 2 : Execute the skill creation","title":"Scenario 4: Building Your First Skill"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#scenario-5-modernizing-legacy-prompts","text":"Goal : Update old prompts to OLAF standards Command : olaf prompt help \"I have old prompts that need updating\" Expected Guidance : - Recommendation: convert-prompt-to-skill - Conversion/packaging steps explained - Validation steps included","title":"Scenario 5: Modernizing Legacy Prompts"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#scenario-6-creating-prompt-documentation","text":"Goal : Generate documentation for a prompt/skill Command : olaf guide me \"Generate docs for this prompt\" Expected Guidance : - Recommendation: create-skill-description - What it will extract and how it structures the docs","title":"Scenario 6: Creating Prompt Documentation"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#level-3-advanced-tasks","text":"","title":"Level 3: Advanced Tasks"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#scenario-7-creating-a-workflow","text":"Goal : Build workflow that validates then deploys prompts Step 1 : Request workflow guidance olaf prompt assistant \"I need a workflow that validates then deploys prompts\" Expected Response : Assessment: Advanced level task - workflow orchestration Recommendation: Multi-step workflow Workflow: 1. evaluate-prompt-for-adoption - Assess prompt quality 2. check-prompt-compliance - Ensure directive quality and compliance 3. convert-prompt-to-skill - Package prompt content into a skill structure 4. validate-prompt-value - Verify effectiveness 5. validate-olaf-artifacts - Validate local artifacts holistically (optional) Alternative: Use generate-orchestrator to create an orchestrator. Next Step: Would you like me to execute this workflow, or create a permanent workflow chain? (workflow/chain) Step 2 : Choose execution or chain creation # For one-time execution > workflow # For reusable chain > chain","title":"Scenario 7: Creating a Workflow"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#scenario-8-skill-chain-creation","text":"Goal : Convert skill to executable chain Command : olaf prompt help \"How do I chain multiple skills together?\" Expected Guidance : - Recommendation: convert-skill-to-chain - Chain architecture explained - Execution model described","title":"Scenario 8: Skill Chain Creation"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#common-patterns","text":"","title":"Common Patterns"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#pattern-1-i-dont-know-what-skill-to-use","text":"Solution : Describe your goal, let the assistant recommend olaf prompt assistant \"I want to [your goal]\"","title":"Pattern 1: \"I Don't Know What Skill to Use\""},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#pattern-2-im-not-sure-about-my-level","text":"Solution : The assistant auto-assesses based on your task No need to specify level - it's determined automatically","title":"Pattern 2: \"I'm Not Sure About My Level\""},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#pattern-3-i-need-multiple-skills","text":"Solution : Request workflow orchestration olaf prompt help \"I need to [complex multi-step goal]\" The assistant will propose a complete workflow","title":"Pattern 3: \"I Need Multiple Skills\""},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#pattern-4-i-want-to-learn-more","text":"Solution : Ask about advancement olaf guide me \"What should I learn next?\"","title":"Pattern 4: \"I Want to Learn More\""},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#progression-path","text":"","title":"Progression Path"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#beginner-to-trained","text":"When Ready : - Comfortable with create-prompt - Created several prompts successfully - Understand prompt structure Next Steps : - Try create-skill - Explore convert-prompt-to-skill - Try create-skill-description","title":"Beginner to Trained"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#trained-to-advanced","text":"When Ready : - Built multiple skills - Managed prompt collections - Understand skill architecture Next Steps : - Try generate-orchestrator - Explore convert-skill-to-chain - Try validate-olaf-artifacts","title":"Trained to Advanced"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#tips-and-best-practices","text":"","title":"Tips and Best Practices"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#tip-1-be-specific-about-your-goal","text":"Less Effective : \"Help with prompts\" More Effective : \"I need to create a prompt that reviews Python code for security issues\"","title":"Tip 1: Be Specific About Your Goal"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#tip-2-dont-worry-about-your-level","text":"The assistant automatically assesses and recommends appropriately","title":"Tip 2: Don't Worry About Your Level"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#tip-3-ask-for-workflows","text":"For multi-step tasks, explicitly mention \"workflow\" to get orchestration guidance","title":"Tip 3: Ask for Workflows"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#tip-4-use-aliases","text":"Multiple ways to invoke: - olaf prompt assistant - olaf prompt help - olaf guide me - olaf pe assistant","title":"Tip 4: Use Aliases"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#tip-5-follow-learning-paths","text":"Progress naturally through levels - the assistant will suggest when you're ready for more","title":"Tip 5: Follow Learning Paths"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#issue-i-got-a-skill-i-dont-understand","text":"Solution : Ask for tutorial olaf tell me about [skill-name]","title":"Issue: \"I Got a Skill I Don't Understand\""},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#issue-the-recommended-skill-seems-too-advanced","text":"Solution : Ask for prerequisites olaf prompt help \"What do I need to learn before [skill-name]?\"","title":"Issue: \"The Recommended Skill Seems Too Advanced\""},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#issue-i-need-multiple-skills-but-dont-know-the-order","text":"Solution : Request workflow olaf prompt assistant \"workflow for [your complex goal]\"","title":"Issue: \"I Need Multiple Skills But Don't Know the Order\""},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#issue-im-not-finding-the-right-skill","text":"Solution : Browse all skills olaf list skills Then describe to assistant which one matches your need","title":"Issue: \"I'm Not Finding the Right Skill\""},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#next-steps","text":"Start Simple : Begin with beginner skills Practice Regularly : Create prompts frequently Progress Gradually : Move to next level when comfortable Ask Questions : Use the assistant whenever unsure Contribute Back : Share your prompts with the community","title":"Next Steps"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#related-skills","text":"help-me-olaf - General OLAF assistance tell-me - Learn about OLAF features","title":"Related Skills"},{"location":"skills/assist-me-as-prompt-engineer/tutorial/#summary","text":"The Prompt Engineering Assistant is your guide through OLAF's capabilities: - Assesses your expertise automatically - Recommends appropriate skills - Guides complex workflows - Suggests learning paths - Adapts to your growth Start with simple tasks, progress naturally, and let the assistant guide your journey from beginner to advanced prompt engineer.","title":"Summary"},{"location":"skills/augment-code-unit-test/description/","text":"Create Unit Tests \u00b6 Overview \u00b6 This competency generates comprehensive unit tests for code modules by analyzing existing test patterns, identifying coverage gaps, and creating meaningful tests that validate core functionality while avoiding trivial test anti-patterns. Purpose \u00b6 Adequate unit test coverage is essential for maintaining code quality, enabling safe refactoring, and catching bugs early. This competency systematically improves test coverage by analyzing code complexity, identifying untested paths, and generating tests that focus on meaningful validation rather than trivial assertions like getter/setter tests. Usage \u00b6 Command : create unit tests (or aliases: augment tests , augment unit test , improve test coverage , unit test augmentation ) Protocol : Propose-Act When to Use : Use when you need to improve test coverage for complex modules, establish testing patterns for new code, validate critical business logic, or prepare code for refactoring by ensuring adequate test protection. Parameters \u00b6 Required Inputs \u00b6 code_path : Directory path containing the codebase to test target_coverage : Desired test coverage percentage (default: 55%) Optional Inputs \u00b6 file_filter : Specific file types or patterns to focus on batch_size : Number of files to process per iteration (default: 10) max_iterations : Maximum number of improvement cycles (default: 10) Context Requirements \u00b6 Existing codebase with some test infrastructure Testing framework installed and configured Write access to test directories Understanding of existing test patterns helps maintain consistency Output \u00b6 Generates unit tests and produces comprehensive coverage reports. Deliverables : - New unit test files following existing patterns - Updated test coverage metrics - Iteration results documenting progress - Final report with coverage statistics - Recommendations for future testing improvements Format : Test files in appropriate testing framework format, JSON reports for metrics tracking Examples \u00b6 Example 1: Improving Coverage for Complex Business Logic \u00b6 Scenario : Core business logic has only 30% test coverage Command : create unit tests Input : code_path: src/business-logic target_coverage: 55% Result : Generated 34 new unit tests across 7 modules, increased coverage from 30% to 58%, focused on complex validation and calculation functions, avoided trivial getter/setter tests. Example 2: Preparing for Refactoring \u00b6 Scenario : Need test protection before refactoring a legacy module Command : augment unit test Input : code_path: src/legacy/payment-processor target_coverage: 70% max_iterations: 5 Result : Created comprehensive test suite with 45 tests covering edge cases, error handling, and business rules, enabling safe refactoring with confidence. Related Competencies \u00b6 analyze-function-complexity : Identify complex functions that need thorough testing review-code : Includes test coverage assessment as part of code review evolve-code-iteratively : Iterative improvement that includes test enhancement fix-code-smells : Often requires adding tests to enable safe refactoring Tips & Best Practices \u00b6 Start with the most complex modules first for maximum impact Focus on meaningful tests that validate business logic, not trivial assertions Follow existing test patterns and naming conventions in the codebase Run tests after each iteration to ensure they pass Aim for 55-80% coverage as a practical target (100% is often impractical) Test edge cases, error conditions, and boundary values Avoid testing framework code or simple getters/setters Use the iterative approach to manage large codebases effectively Limitations \u00b6 Cannot generate tests for code that requires complex external dependencies without mocking Test quality depends on understanding of business requirements May require manual adjustment for framework-specific testing patterns Cannot validate that tests actually test the right behavior Limited to unit tests - does not create integration or end-to-end tests Requires existing test infrastructure and framework May hit session limits on very large codebases (use batch processing)","title":"Create Unit Tests"},{"location":"skills/augment-code-unit-test/description/#create-unit-tests","text":"","title":"Create Unit Tests"},{"location":"skills/augment-code-unit-test/description/#overview","text":"This competency generates comprehensive unit tests for code modules by analyzing existing test patterns, identifying coverage gaps, and creating meaningful tests that validate core functionality while avoiding trivial test anti-patterns.","title":"Overview"},{"location":"skills/augment-code-unit-test/description/#purpose","text":"Adequate unit test coverage is essential for maintaining code quality, enabling safe refactoring, and catching bugs early. This competency systematically improves test coverage by analyzing code complexity, identifying untested paths, and generating tests that focus on meaningful validation rather than trivial assertions like getter/setter tests.","title":"Purpose"},{"location":"skills/augment-code-unit-test/description/#usage","text":"Command : create unit tests (or aliases: augment tests , augment unit test , improve test coverage , unit test augmentation ) Protocol : Propose-Act When to Use : Use when you need to improve test coverage for complex modules, establish testing patterns for new code, validate critical business logic, or prepare code for refactoring by ensuring adequate test protection.","title":"Usage"},{"location":"skills/augment-code-unit-test/description/#parameters","text":"","title":"Parameters"},{"location":"skills/augment-code-unit-test/description/#required-inputs","text":"code_path : Directory path containing the codebase to test target_coverage : Desired test coverage percentage (default: 55%)","title":"Required Inputs"},{"location":"skills/augment-code-unit-test/description/#optional-inputs","text":"file_filter : Specific file types or patterns to focus on batch_size : Number of files to process per iteration (default: 10) max_iterations : Maximum number of improvement cycles (default: 10)","title":"Optional Inputs"},{"location":"skills/augment-code-unit-test/description/#context-requirements","text":"Existing codebase with some test infrastructure Testing framework installed and configured Write access to test directories Understanding of existing test patterns helps maintain consistency","title":"Context Requirements"},{"location":"skills/augment-code-unit-test/description/#output","text":"Generates unit tests and produces comprehensive coverage reports. Deliverables : - New unit test files following existing patterns - Updated test coverage metrics - Iteration results documenting progress - Final report with coverage statistics - Recommendations for future testing improvements Format : Test files in appropriate testing framework format, JSON reports for metrics tracking","title":"Output"},{"location":"skills/augment-code-unit-test/description/#examples","text":"","title":"Examples"},{"location":"skills/augment-code-unit-test/description/#example-1-improving-coverage-for-complex-business-logic","text":"Scenario : Core business logic has only 30% test coverage Command : create unit tests Input : code_path: src/business-logic target_coverage: 55% Result : Generated 34 new unit tests across 7 modules, increased coverage from 30% to 58%, focused on complex validation and calculation functions, avoided trivial getter/setter tests.","title":"Example 1: Improving Coverage for Complex Business Logic"},{"location":"skills/augment-code-unit-test/description/#example-2-preparing-for-refactoring","text":"Scenario : Need test protection before refactoring a legacy module Command : augment unit test Input : code_path: src/legacy/payment-processor target_coverage: 70% max_iterations: 5 Result : Created comprehensive test suite with 45 tests covering edge cases, error handling, and business rules, enabling safe refactoring with confidence.","title":"Example 2: Preparing for Refactoring"},{"location":"skills/augment-code-unit-test/description/#related-competencies","text":"analyze-function-complexity : Identify complex functions that need thorough testing review-code : Includes test coverage assessment as part of code review evolve-code-iteratively : Iterative improvement that includes test enhancement fix-code-smells : Often requires adding tests to enable safe refactoring","title":"Related Competencies"},{"location":"skills/augment-code-unit-test/description/#tips-best-practices","text":"Start with the most complex modules first for maximum impact Focus on meaningful tests that validate business logic, not trivial assertions Follow existing test patterns and naming conventions in the codebase Run tests after each iteration to ensure they pass Aim for 55-80% coverage as a practical target (100% is often impractical) Test edge cases, error conditions, and boundary values Avoid testing framework code or simple getters/setters Use the iterative approach to manage large codebases effectively","title":"Tips &amp; Best Practices"},{"location":"skills/augment-code-unit-test/description/#limitations","text":"Cannot generate tests for code that requires complex external dependencies without mocking Test quality depends on understanding of business requirements May require manual adjustment for framework-specific testing patterns Cannot validate that tests actually test the right behavior Limited to unit tests - does not create integration or end-to-end tests Requires existing test infrastructure and framework May hit session limits on very large codebases (use batch processing)","title":"Limitations"},{"location":"skills/augment-code-unit-test/tutorial/","text":"Augment Code Unit Test: Step-by-Step Tutorial \u00b6 How to Execute the \"Augment Code Unit Test\" Workflow This tutorial shows how to use the Developer competency's unit test enhancement workflow to improve test coverage and quality. Prerequisites \u00b6 OLAF Framework with developer competency pack Existing codebase with unit tests Testing framework in place Step-by-Step Instructions \u00b6 Step 1: Initialize Test Augmentation \u00b6 User Action: Execute olaf augment tests or improve test coverage Step 2: Specify Code and Test Parameters \u00b6 Provide: Code location, test framework, coverage goals Step 3: Test Analysis and Enhancement \u00b6 System: Analyzes existing tests, identifies gaps, generates new tests using Propose-Act protocol Expected Timeline: 15-30 minutes \u00b6","title":"Augment Code Unit Test: Step-by-Step Tutorial"},{"location":"skills/augment-code-unit-test/tutorial/#augment-code-unit-test-step-by-step-tutorial","text":"How to Execute the \"Augment Code Unit Test\" Workflow This tutorial shows how to use the Developer competency's unit test enhancement workflow to improve test coverage and quality.","title":"Augment Code Unit Test: Step-by-Step Tutorial"},{"location":"skills/augment-code-unit-test/tutorial/#prerequisites","text":"OLAF Framework with developer competency pack Existing codebase with unit tests Testing framework in place","title":"Prerequisites"},{"location":"skills/augment-code-unit-test/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/augment-code-unit-test/tutorial/#step-1-initialize-test-augmentation","text":"User Action: Execute olaf augment tests or improve test coverage","title":"Step 1: Initialize Test Augmentation"},{"location":"skills/augment-code-unit-test/tutorial/#step-2-specify-code-and-test-parameters","text":"Provide: Code location, test framework, coverage goals","title":"Step 2: Specify Code and Test Parameters"},{"location":"skills/augment-code-unit-test/tutorial/#step-3-test-analysis-and-enhancement","text":"System: Analyzes existing tests, identifies gaps, generates new tests using Propose-Act protocol","title":"Step 3: Test Analysis and Enhancement"},{"location":"skills/augment-code-unit-test/tutorial/#expected-timeline-15-30-minutes","text":"","title":"Expected Timeline: 15-30 minutes"},{"location":"skills/bootstrap-functional-spec-from-code/description/","text":"Bootstrap Functional Spec from Code \u00b6 Overview \u00b6 This competency analyzes existing source code to extract and document its functionalities from a business and user perspective, creating a draft functional specification. It reverse-engineers the implementation to produce business-focused documentation that explains what the system does and why, without requiring deep technical knowledge. Purpose \u00b6 Many software projects lack up-to-date functional specifications, especially legacy systems or rapidly developed applications. When documentation is missing or outdated, this competency solves the problem by analyzing the actual implementation to generate a business-readable specification. This is invaluable for modernization projects, knowledge transfer, or creating documentation for undocumented systems. Usage \u00b6 Command : bootstrap functional spec from code Protocol : Act When to Use : Use this competency when you have working code but missing or outdated functional specifications, when preparing for application modernization or migration, when onboarding new team members to legacy systems, or when stakeholders need business-level documentation of technical implementations. Parameters \u00b6 Required Inputs \u00b6 source_path : Path to the application's source code or codebase directory to analyze Optional Inputs \u00b6 output_format : Output format for the specification (markdown, html, or pdf; default: markdown) detail_level : Level of detail to include (overview, standard, or detailed; default: standard) Context Requirements \u00b6 Source code must be accessible in the workspace or specified directory Functional specification template is automatically loaded from competency templates Code should be reasonably structured for effective analysis Output \u00b6 This competency produces a business-focused functional specification document extracted from code analysis. Deliverables : - Functional specification document saved to data/specs/FunctionalSpec-YYYYMMDD-NNN.md - Executive summary of identified components and business processes - User stories derived from code functionality - Data models and integration points documentation Format : Structured markdown document following the functional-specification-template, written in business-focused language with technical details relegated to appendices. Includes visual diagrams where helpful. Examples \u00b6 Example 1: Legacy System Documentation \u00b6 Scenario : A 5-year-old customer management system lacks documentation, and the team needs a functional spec before planning a modernization effort. Command : olaf bootstrap functional spec from code Input : source_path: ./legacy-crm/src detail_level: detailed Result : Generated comprehensive functional specification documenting customer lifecycle management, reporting capabilities, integration with payment systems, and data models. Identified 12 core business processes and 8 external integrations. Example 2: Quick System Overview \u00b6 Scenario : New product manager needs to understand what an existing microservice does from a business perspective. Command : olaf bootstrap functional spec from code Input : source_path: ./services/notification-service detail_level: overview Result : High-level functional specification describing notification delivery capabilities, supported channels (email, SMS, push), and business rules for notification routing. Related Competencies \u00b6 extend-specification : Use after bootstrapping to add missing UI/UX details and frontend requirements improve-spec : Enhance the bootstrapped specification with visual diagrams and detailed data definitions analyze-business-requirements : Validate the extracted requirements against business needs generate-technical-specification (architect): Create technical architecture documentation to complement the functional spec Tips & Best Practices \u00b6 Start with overview detail level for initial assessment, then run detailed analysis for specific components Review the generated specification with original developers if available to validate accuracy Use this as a starting point\u2014expect to refine and enhance the specification with stakeholder input Combine with code comments and commit history analysis for better context Focus on well-structured code first; refactor unclear code before bootstrapping if possible Maintain traceability between specification sections and source code locations Limitations \u00b6 Cannot infer business intent or rationale\u2014only documents what the code does, not why Quality depends on code structure and clarity\u2014poorly organized code yields less useful specifications May miss implicit business rules or undocumented assumptions in the implementation Cannot validate if the implementation matches original business requirements Does not modify or analyze code quality\u2014purely extracts functional behavior Requires human review to ensure business accuracy and completeness Source : core/competencies/business-analyst/prompts/bootstrap-functional-spec-from-code.md","title":"Bootstrap Functional Spec from Code"},{"location":"skills/bootstrap-functional-spec-from-code/description/#bootstrap-functional-spec-from-code","text":"","title":"Bootstrap Functional Spec from Code"},{"location":"skills/bootstrap-functional-spec-from-code/description/#overview","text":"This competency analyzes existing source code to extract and document its functionalities from a business and user perspective, creating a draft functional specification. It reverse-engineers the implementation to produce business-focused documentation that explains what the system does and why, without requiring deep technical knowledge.","title":"Overview"},{"location":"skills/bootstrap-functional-spec-from-code/description/#purpose","text":"Many software projects lack up-to-date functional specifications, especially legacy systems or rapidly developed applications. When documentation is missing or outdated, this competency solves the problem by analyzing the actual implementation to generate a business-readable specification. This is invaluable for modernization projects, knowledge transfer, or creating documentation for undocumented systems.","title":"Purpose"},{"location":"skills/bootstrap-functional-spec-from-code/description/#usage","text":"Command : bootstrap functional spec from code Protocol : Act When to Use : Use this competency when you have working code but missing or outdated functional specifications, when preparing for application modernization or migration, when onboarding new team members to legacy systems, or when stakeholders need business-level documentation of technical implementations.","title":"Usage"},{"location":"skills/bootstrap-functional-spec-from-code/description/#parameters","text":"","title":"Parameters"},{"location":"skills/bootstrap-functional-spec-from-code/description/#required-inputs","text":"source_path : Path to the application's source code or codebase directory to analyze","title":"Required Inputs"},{"location":"skills/bootstrap-functional-spec-from-code/description/#optional-inputs","text":"output_format : Output format for the specification (markdown, html, or pdf; default: markdown) detail_level : Level of detail to include (overview, standard, or detailed; default: standard)","title":"Optional Inputs"},{"location":"skills/bootstrap-functional-spec-from-code/description/#context-requirements","text":"Source code must be accessible in the workspace or specified directory Functional specification template is automatically loaded from competency templates Code should be reasonably structured for effective analysis","title":"Context Requirements"},{"location":"skills/bootstrap-functional-spec-from-code/description/#output","text":"This competency produces a business-focused functional specification document extracted from code analysis. Deliverables : - Functional specification document saved to data/specs/FunctionalSpec-YYYYMMDD-NNN.md - Executive summary of identified components and business processes - User stories derived from code functionality - Data models and integration points documentation Format : Structured markdown document following the functional-specification-template, written in business-focused language with technical details relegated to appendices. Includes visual diagrams where helpful.","title":"Output"},{"location":"skills/bootstrap-functional-spec-from-code/description/#examples","text":"","title":"Examples"},{"location":"skills/bootstrap-functional-spec-from-code/description/#example-1-legacy-system-documentation","text":"Scenario : A 5-year-old customer management system lacks documentation, and the team needs a functional spec before planning a modernization effort. Command : olaf bootstrap functional spec from code Input : source_path: ./legacy-crm/src detail_level: detailed Result : Generated comprehensive functional specification documenting customer lifecycle management, reporting capabilities, integration with payment systems, and data models. Identified 12 core business processes and 8 external integrations.","title":"Example 1: Legacy System Documentation"},{"location":"skills/bootstrap-functional-spec-from-code/description/#example-2-quick-system-overview","text":"Scenario : New product manager needs to understand what an existing microservice does from a business perspective. Command : olaf bootstrap functional spec from code Input : source_path: ./services/notification-service detail_level: overview Result : High-level functional specification describing notification delivery capabilities, supported channels (email, SMS, push), and business rules for notification routing.","title":"Example 2: Quick System Overview"},{"location":"skills/bootstrap-functional-spec-from-code/description/#related-competencies","text":"extend-specification : Use after bootstrapping to add missing UI/UX details and frontend requirements improve-spec : Enhance the bootstrapped specification with visual diagrams and detailed data definitions analyze-business-requirements : Validate the extracted requirements against business needs generate-technical-specification (architect): Create technical architecture documentation to complement the functional spec","title":"Related Competencies"},{"location":"skills/bootstrap-functional-spec-from-code/description/#tips-best-practices","text":"Start with overview detail level for initial assessment, then run detailed analysis for specific components Review the generated specification with original developers if available to validate accuracy Use this as a starting point\u2014expect to refine and enhance the specification with stakeholder input Combine with code comments and commit history analysis for better context Focus on well-structured code first; refactor unclear code before bootstrapping if possible Maintain traceability between specification sections and source code locations","title":"Tips &amp; Best Practices"},{"location":"skills/bootstrap-functional-spec-from-code/description/#limitations","text":"Cannot infer business intent or rationale\u2014only documents what the code does, not why Quality depends on code structure and clarity\u2014poorly organized code yields less useful specifications May miss implicit business rules or undocumented assumptions in the implementation Cannot validate if the implementation matches original business requirements Does not modify or analyze code quality\u2014purely extracts functional behavior Requires human review to ensure business accuracy and completeness Source : core/competencies/business-analyst/prompts/bootstrap-functional-spec-from-code.md","title":"Limitations"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/","text":"Step-by-Step Tutorial \u00b6 Bootstrap Functional Spec from Code: Step-by-Step Tutorial \u00b6 How to Execute the \"Bootstrap Functional Spec from Code\" Workflow This tutorial shows exactly how to analyze source code and extract functionalities to create a draft functional specification using the OLAF business-analyst competency. Prerequisites \u00b6 OLAF framework properly installed and configured Access to a source code directory or codebase to analyze Understanding of functional specification structure Access to the business-analyst competency pack Step-by-Step Instructions \u00b6 Step 1: Prepare the Source Code \u00b6 [Ensure you have the codebase ready for analysis] User Action: Locate the application's source code or codebase directory Ensure the directory is accessible and contains the main application code Note the full path to the source code directory System Response: Directory should be readable and contain analyzable source code files. Step 2: Invoke the Bootstrap Command \u00b6 User Action: Execute the OLAF command to start functional spec generation olaf bootstrap functional spec from code Provide Parameters: source_path : [path/to/your/source-code] - Full path to the codebase directory output_format : [markdown/html/pdf] - Output format (default: markdown) detail_level : [overview/standard/detailed] - Level of detail (default: standard) Step 3: Code Analysis Process \u00b6 What OLAF Does: Scans the directory structure and identifies entry points Analyzes main components and their relationships Extracts business logic and workflows from the source code Documents data models and system relationships You Should See: Progress messages indicating directory scanning and code analysis phases Step 4: Business Logic Extraction \u00b6 What OLAF Does: Identifies core business rules embedded in the code Maps out user flows and system interactions Documents system boundaries and external dependencies Identifies integration points and external services You Should See: Summary of identified business processes and system components Step 5: Specification Generation \u00b6 What OLAF Does: Loads the functional specification template Structures extracted content for business audience Translates technical code into business-focused language Includes relevant code examples and visual diagrams where helpful You Should See: Formatted functional specification following the standard template structure Step 6: Output Generation and Saving \u00b6 What OLAF Does: Generates filename in format: FunctionalSpec-YYYYMMDD-NNN.md Saves the specification to data/specs/ directory Creates business-focused documentation without technical jargon Includes technical details in appendices for reference You Should See: Complete functional specification in chosen format File save confirmation with location Executive summary of identified functionalities Clear separation between business and technical views Verification Checklist \u00b6 \u2705 Source code successfully analyzed and components identified \u2705 Business logic extracted and documented in business terms \u2705 Functional specification generated following template structure \u2705 Specification saved to data/specs/ with proper naming convention \u2705 Business-focused language used (no technical jargon in main sections) \u2705 Traceability to source code maintained for validation Troubleshooting \u00b6 If source code cannot be analyzed: Verify the source path is correct and accessible Ensure the directory contains recognizable source code files Check if the codebase uses supported programming languages If business logic extraction is incomplete: Try using 'detailed' level for more comprehensive analysis Ensure the source code contains meaningful business logic Check if code comments and documentation help with context If specification template errors occur: Verify the functional specification template exists in the competency pack Check if the template is properly formatted and accessible Key Learning Points \u00b6 Code-to-Business Translation: The workflow translates technical implementation into business-understandable functional requirements Template-Driven Consistency: Uses standardized templates to ensure consistent specification structure Traceability Maintenance: Maintains clear links between generated specification and source code for validation Next Steps to Try \u00b6 Review the generated functional specification with business stakeholders Validate the extracted functionalities against actual system behavior Use the specification as a starting point for requirements refinement Update and maintain the specification as the codebase evolves Expected Timeline \u00b6 Total analysis time: 5-15 minutes depending on codebase size User input required: Providing source path and configuration parameters OLAF execution time: Automated code analysis, business logic extraction, and specification generation","title":"Step-by-Step Tutorial"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#step-by-step-tutorial","text":"","title":"Step-by-Step Tutorial"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#bootstrap-functional-spec-from-code-step-by-step-tutorial","text":"How to Execute the \"Bootstrap Functional Spec from Code\" Workflow This tutorial shows exactly how to analyze source code and extract functionalities to create a draft functional specification using the OLAF business-analyst competency.","title":"Bootstrap Functional Spec from Code: Step-by-Step Tutorial"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#prerequisites","text":"OLAF framework properly installed and configured Access to a source code directory or codebase to analyze Understanding of functional specification structure Access to the business-analyst competency pack","title":"Prerequisites"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#step-1-prepare-the-source-code","text":"[Ensure you have the codebase ready for analysis] User Action: Locate the application's source code or codebase directory Ensure the directory is accessible and contains the main application code Note the full path to the source code directory System Response: Directory should be readable and contain analyzable source code files.","title":"Step 1: Prepare the Source Code"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#step-2-invoke-the-bootstrap-command","text":"User Action: Execute the OLAF command to start functional spec generation olaf bootstrap functional spec from code Provide Parameters: source_path : [path/to/your/source-code] - Full path to the codebase directory output_format : [markdown/html/pdf] - Output format (default: markdown) detail_level : [overview/standard/detailed] - Level of detail (default: standard)","title":"Step 2: Invoke the Bootstrap Command"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#step-3-code-analysis-process","text":"What OLAF Does: Scans the directory structure and identifies entry points Analyzes main components and their relationships Extracts business logic and workflows from the source code Documents data models and system relationships You Should See: Progress messages indicating directory scanning and code analysis phases","title":"Step 3: Code Analysis Process"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#step-4-business-logic-extraction","text":"What OLAF Does: Identifies core business rules embedded in the code Maps out user flows and system interactions Documents system boundaries and external dependencies Identifies integration points and external services You Should See: Summary of identified business processes and system components","title":"Step 4: Business Logic Extraction"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#step-5-specification-generation","text":"What OLAF Does: Loads the functional specification template Structures extracted content for business audience Translates technical code into business-focused language Includes relevant code examples and visual diagrams where helpful You Should See: Formatted functional specification following the standard template structure","title":"Step 5: Specification Generation"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#step-6-output-generation-and-saving","text":"What OLAF Does: Generates filename in format: FunctionalSpec-YYYYMMDD-NNN.md Saves the specification to data/specs/ directory Creates business-focused documentation without technical jargon Includes technical details in appendices for reference You Should See: Complete functional specification in chosen format File save confirmation with location Executive summary of identified functionalities Clear separation between business and technical views","title":"Step 6: Output Generation and Saving"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#verification-checklist","text":"\u2705 Source code successfully analyzed and components identified \u2705 Business logic extracted and documented in business terms \u2705 Functional specification generated following template structure \u2705 Specification saved to data/specs/ with proper naming convention \u2705 Business-focused language used (no technical jargon in main sections) \u2705 Traceability to source code maintained for validation","title":"Verification Checklist"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#troubleshooting","text":"If source code cannot be analyzed: Verify the source path is correct and accessible Ensure the directory contains recognizable source code files Check if the codebase uses supported programming languages If business logic extraction is incomplete: Try using 'detailed' level for more comprehensive analysis Ensure the source code contains meaningful business logic Check if code comments and documentation help with context If specification template errors occur: Verify the functional specification template exists in the competency pack Check if the template is properly formatted and accessible","title":"Troubleshooting"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#key-learning-points","text":"Code-to-Business Translation: The workflow translates technical implementation into business-understandable functional requirements Template-Driven Consistency: Uses standardized templates to ensure consistent specification structure Traceability Maintenance: Maintains clear links between generated specification and source code for validation","title":"Key Learning Points"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#next-steps-to-try","text":"Review the generated functional specification with business stakeholders Validate the extracted functionalities against actual system behavior Use the specification as a starting point for requirements refinement Update and maintain the specification as the codebase evolves","title":"Next Steps to Try"},{"location":"skills/bootstrap-functional-spec-from-code/tutorial/#expected-timeline","text":"Total analysis time: 5-15 minutes depending on codebase size User input required: Providing source path and configuration parameters OLAF execution time: Automated code analysis, business logic extraction, and specification generation","title":"Expected Timeline"},{"location":"skills/carry-on-session/description/","text":"Carry-On Session - Description \u00b6 Overview \u00b6 Carry-On loads the latest carry-over note file and proposes resuming work from where you left off. What It Does \u00b6 Finds the most recent carry-over file in .olaf/carry-over/ Parses the file sections (NEXT PROMPT, FILES NEEDED, OPTIONAL context) Proposes the plan from the carry-over note Waits for user approval before taking action Opens/reads required files upon approval How It Works \u00b6 User requests carry-on with command like \"carry on\" Copilot searches for latest carry-over-YYYYMMDD-HHmm.txt file by timestamp Parses carry-over file : Extracts NEXT PROMPT section Extracts FILES NEEDED (absolute paths) Extracts OPTIONAL context if present Proposes plan to user showing: Carry-over file name and date Proposed plan (from NEXT PROMPT) Files to open (from FILES NEEDED) Waits for approval - Does NOT auto-execute On approval , proceeds with proposed plan Key Files \u00b6 Carry-Over Directory : .olaf/carry-over/ File Pattern : carry-over-YYYYMMDD-HHmm.txt (finds most recent) Skill Prompt : skills/carry-on-session/prompts/carry-on-session.md Companion Skill : carry-over-session.md (creates the note) Commands \u00b6 carry on - Load and resume from latest carry-over resume work - Same as above continue work - Same as above When to Use \u00b6 Starting a new session and want to resume previous work Need to load context from where you left off Have a carry-over note from previous session Companion Feature \u00b6 Use carry over to create the carry-over note that this skill loads. Protocol \u00b6 Act - Loads carry-over and proposes plan, but waits for approval before executing.","title":"Carry-On Session - Description"},{"location":"skills/carry-on-session/description/#carry-on-session-description","text":"","title":"Carry-On Session - Description"},{"location":"skills/carry-on-session/description/#overview","text":"Carry-On loads the latest carry-over note file and proposes resuming work from where you left off.","title":"Overview"},{"location":"skills/carry-on-session/description/#what-it-does","text":"Finds the most recent carry-over file in .olaf/carry-over/ Parses the file sections (NEXT PROMPT, FILES NEEDED, OPTIONAL context) Proposes the plan from the carry-over note Waits for user approval before taking action Opens/reads required files upon approval","title":"What It Does"},{"location":"skills/carry-on-session/description/#how-it-works","text":"User requests carry-on with command like \"carry on\" Copilot searches for latest carry-over-YYYYMMDD-HHmm.txt file by timestamp Parses carry-over file : Extracts NEXT PROMPT section Extracts FILES NEEDED (absolute paths) Extracts OPTIONAL context if present Proposes plan to user showing: Carry-over file name and date Proposed plan (from NEXT PROMPT) Files to open (from FILES NEEDED) Waits for approval - Does NOT auto-execute On approval , proceeds with proposed plan","title":"How It Works"},{"location":"skills/carry-on-session/description/#key-files","text":"Carry-Over Directory : .olaf/carry-over/ File Pattern : carry-over-YYYYMMDD-HHmm.txt (finds most recent) Skill Prompt : skills/carry-on-session/prompts/carry-on-session.md Companion Skill : carry-over-session.md (creates the note)","title":"Key Files"},{"location":"skills/carry-on-session/description/#commands","text":"carry on - Load and resume from latest carry-over resume work - Same as above continue work - Same as above","title":"Commands"},{"location":"skills/carry-on-session/description/#when-to-use","text":"Starting a new session and want to resume previous work Need to load context from where you left off Have a carry-over note from previous session","title":"When to Use"},{"location":"skills/carry-on-session/description/#companion-feature","text":"Use carry over to create the carry-over note that this skill loads.","title":"Companion Feature"},{"location":"skills/carry-on-session/description/#protocol","text":"Act - Loads carry-over and proposes plan, but waits for approval before executing.","title":"Protocol"},{"location":"skills/carry-on-session/tutorial/","text":"Carry-On Session: Step-by-Step Tutorial \u00b6 How to Execute the \"Carry-On Session\" Workflow This tutorial shows exactly how to resume work from a carry-over note. Prerequisites \u00b6 OLAF framework installed and active At least one carry-over file in .olaf/carry-over/ Previous session where you created a carry-over note Access to GitHub Copilot Chat or compatible IDE Step-by-Step Instructions \u00b6 Step 1: Start New Session and Request Carry-On \u00b6 Brief: Load the latest carry-over note User Action: 1. Open GitHub Copilot Chat (new session) 2. Type: carry on 3. Press Enter Alternative commands: resume work continue work Step 2: Copilot Finds Latest Carry-Over \u00b6 What Copilot Does: - Scans .olaf/carry-over/ directory - Finds most recent file matching pattern carry-over-YYYYMMDD-HHmm.txt - Reads and parses the file You Should See: Copilot processing the carry-over file Step 3: Carry-Over File Parsed \u00b6 What Copilot Does: - Extracts NEXT PROMPT section (the exact prompt to continue) - Extracts FILES NEEDED section (absolute file paths) - Extracts OPTIONAL context if present Step 4: Proposal Presented \u00b6 Copilot Response: ## Resuming from Carry-Over - Carry-Over File: carry-over-20251114-1430.txt - Session Date: 2025-11-14 14:30 ### Proposed Plan (from NEXT PROMPT) Add JWT validation to AuthService, update login to return token, and add middleware to protect routes. ### Files To Open c:\\users\\<user-name>\\coderepos\\project\\src\\services\\AuthService.ts c:\\users\\<user-name>\\coderepos\\project\\src\\middleware\\auth.ts c:\\users\\<user-name>\\coderepos\\project\\src\\routes\\api.ts c:\\users\\<user-name>\\coderepos\\project\\config\\jwt.config.ts c:\\users\\<user-name>\\coderepos\\project\\tests\\auth.test.ts Confirm: Proceed with the proposed plan? (Yes/No) If No, please specify adjustments. User Action: Review the proposed plan Step 5: User Approves or Adjusts \u00b6 User Action: Type your response: Yes or No, let's focus only on AuthService first Provide Confirmation: - Yes - Proceed as proposed - No - Specify adjustments needed Step 6: Copilot Proceeds (if approved) \u00b6 What Copilot Does: - Opens/reads the specified files - Executes the NEXT PROMPT as the working instruction - Continues with the work described in the carry-over You Should See: Work resuming from where previous session ended Verification Checklist \u00b6 \u2705 Latest carry-over loaded - Correct file by timestamp \u2705 Plan presented - NEXT PROMPT shown clearly \u2705 Files listed - All absolute paths displayed \u2705 Approval requested - Copilot waits before acting \u2705 Work resumed - Continues from previous session context Troubleshooting \u00b6 If no carry-over found: Error: No carry-over files found in .olaf/carry-over/ Create a carry-over note first using \"carry over\" If carry-over file corrupted: - Check file exists in .olaf/carry-over/ - Verify file format matches template - Ensure NEXT PROMPT section exists If wrong carry-over loaded: - Carry-on loads MOST RECENT by timestamp - Check file timestamps in .olaf/carry-over/ - Rename or delete unwanted carry-over files If files not found: - Verify absolute paths in carry-over file are correct - Update paths if workspace location changed - Edit carry-over file manually if needed Key Learning Points \u00b6 Proposal first, action second: Carry-on always proposes the plan and waits for approval. It never auto-executes. Most recent by timestamp: The file with the latest YYYYMMDD-HHmm timestamp is selected automatically. NEXT PROMPT becomes instruction: The exact prompt from the carry-over becomes the working instruction once approved. Session continuity: Carry-over + carry-on workflow enables seamless work across sessions without losing context. User control: You can adjust the plan before proceeding - it's not all-or-nothing. Next Steps to Try \u00b6 Create a carry-over with carry over , then resume it with carry on Try adjusting the proposed plan instead of accepting it as-is Create multiple carry-overs and see which one loads (most recent) Edit a carry-over file manually before using carry on Expected Timeline \u00b6 Total carry-on execution time: 10-30 seconds User input required: Approval/adjustment of proposed plan Copilot execution time: Instant for loading, variable for work execution","title":"Carry-On Session: Step-by-Step Tutorial"},{"location":"skills/carry-on-session/tutorial/#carry-on-session-step-by-step-tutorial","text":"How to Execute the \"Carry-On Session\" Workflow This tutorial shows exactly how to resume work from a carry-over note.","title":"Carry-On Session: Step-by-Step Tutorial"},{"location":"skills/carry-on-session/tutorial/#prerequisites","text":"OLAF framework installed and active At least one carry-over file in .olaf/carry-over/ Previous session where you created a carry-over note Access to GitHub Copilot Chat or compatible IDE","title":"Prerequisites"},{"location":"skills/carry-on-session/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/carry-on-session/tutorial/#step-1-start-new-session-and-request-carry-on","text":"Brief: Load the latest carry-over note User Action: 1. Open GitHub Copilot Chat (new session) 2. Type: carry on 3. Press Enter Alternative commands: resume work continue work","title":"Step 1: Start New Session and Request Carry-On"},{"location":"skills/carry-on-session/tutorial/#step-2-copilot-finds-latest-carry-over","text":"What Copilot Does: - Scans .olaf/carry-over/ directory - Finds most recent file matching pattern carry-over-YYYYMMDD-HHmm.txt - Reads and parses the file You Should See: Copilot processing the carry-over file","title":"Step 2: Copilot Finds Latest Carry-Over"},{"location":"skills/carry-on-session/tutorial/#step-3-carry-over-file-parsed","text":"What Copilot Does: - Extracts NEXT PROMPT section (the exact prompt to continue) - Extracts FILES NEEDED section (absolute file paths) - Extracts OPTIONAL context if present","title":"Step 3: Carry-Over File Parsed"},{"location":"skills/carry-on-session/tutorial/#step-4-proposal-presented","text":"Copilot Response: ## Resuming from Carry-Over - Carry-Over File: carry-over-20251114-1430.txt - Session Date: 2025-11-14 14:30 ### Proposed Plan (from NEXT PROMPT) Add JWT validation to AuthService, update login to return token, and add middleware to protect routes. ### Files To Open c:\\users\\<user-name>\\coderepos\\project\\src\\services\\AuthService.ts c:\\users\\<user-name>\\coderepos\\project\\src\\middleware\\auth.ts c:\\users\\<user-name>\\coderepos\\project\\src\\routes\\api.ts c:\\users\\<user-name>\\coderepos\\project\\config\\jwt.config.ts c:\\users\\<user-name>\\coderepos\\project\\tests\\auth.test.ts Confirm: Proceed with the proposed plan? (Yes/No) If No, please specify adjustments. User Action: Review the proposed plan","title":"Step 4: Proposal Presented"},{"location":"skills/carry-on-session/tutorial/#step-5-user-approves-or-adjusts","text":"User Action: Type your response: Yes or No, let's focus only on AuthService first Provide Confirmation: - Yes - Proceed as proposed - No - Specify adjustments needed","title":"Step 5: User Approves or Adjusts"},{"location":"skills/carry-on-session/tutorial/#step-6-copilot-proceeds-if-approved","text":"What Copilot Does: - Opens/reads the specified files - Executes the NEXT PROMPT as the working instruction - Continues with the work described in the carry-over You Should See: Work resuming from where previous session ended","title":"Step 6: Copilot Proceeds (if approved)"},{"location":"skills/carry-on-session/tutorial/#verification-checklist","text":"\u2705 Latest carry-over loaded - Correct file by timestamp \u2705 Plan presented - NEXT PROMPT shown clearly \u2705 Files listed - All absolute paths displayed \u2705 Approval requested - Copilot waits before acting \u2705 Work resumed - Continues from previous session context","title":"Verification Checklist"},{"location":"skills/carry-on-session/tutorial/#troubleshooting","text":"If no carry-over found: Error: No carry-over files found in .olaf/carry-over/ Create a carry-over note first using \"carry over\" If carry-over file corrupted: - Check file exists in .olaf/carry-over/ - Verify file format matches template - Ensure NEXT PROMPT section exists If wrong carry-over loaded: - Carry-on loads MOST RECENT by timestamp - Check file timestamps in .olaf/carry-over/ - Rename or delete unwanted carry-over files If files not found: - Verify absolute paths in carry-over file are correct - Update paths if workspace location changed - Edit carry-over file manually if needed","title":"Troubleshooting"},{"location":"skills/carry-on-session/tutorial/#key-learning-points","text":"Proposal first, action second: Carry-on always proposes the plan and waits for approval. It never auto-executes. Most recent by timestamp: The file with the latest YYYYMMDD-HHmm timestamp is selected automatically. NEXT PROMPT becomes instruction: The exact prompt from the carry-over becomes the working instruction once approved. Session continuity: Carry-over + carry-on workflow enables seamless work across sessions without losing context. User control: You can adjust the plan before proceeding - it's not all-or-nothing.","title":"Key Learning Points"},{"location":"skills/carry-on-session/tutorial/#next-steps-to-try","text":"Create a carry-over with carry over , then resume it with carry on Try adjusting the proposed plan instead of accepting it as-is Create multiple carry-overs and see which one loads (most recent) Edit a carry-over file manually before using carry on","title":"Next Steps to Try"},{"location":"skills/carry-on-session/tutorial/#expected-timeline","text":"Total carry-on execution time: 10-30 seconds User input required: Approval/adjustment of proposed plan Copilot execution time: Instant for loading, variable for work execution","title":"Expected Timeline"},{"location":"skills/carry-over-session/description/","text":"Carry-Over Session - Description \u00b6 Overview \u00b6 Carry-Over creates a simple note file to resume work in a future session with minimal context and maximum clarity. What It Does \u00b6 Creates a carry-over note file in .olaf/carry-over/ Captures the exact next prompt to use Lists absolute file paths needed Optionally includes brief context (1-2 lines) Names file with timestamp: carry-over-YYYYMMDD-HHmm.txt How It Works \u00b6 User requests carry-over with command like \"carry over\" Copilot analyzes current session to determine next action Generates carry-over file with: NEXT PROMPT : Exact prompt to continue work FILES NEEDED : Absolute paths to files OPTIONAL context : Brief 1-2 line summary if critical Saves file to .olaf/carry-over/ directory File Structure \u00b6 CARRY-OVER - 2025-11-14 14:30 ======================== ## NEXT PROMPT <Exact prompt for next session> ## FILES NEEDED (Absolute Paths) <Full paths to files> ## OPTIONAL - Brief Context <1-2 lines if needed> Key Files \u00b6 Carry-Over Directory : .olaf/carry-over/ File Pattern : carry-over-YYYYMMDD-HHmm.txt Skill Prompt : skills/carry-over-session/carry-over-session.md Companion Skill : carry-on-session.md (to resume) Commands \u00b6 carry over - Create carry-over note for current session create carry over - Same as above carry over note - Same as above When to Use \u00b6 Ending work session but want to resume later Switching to different task temporarily Need to remember exact next action Want to preserve file context between sessions Companion Feature \u00b6 Use carry on in next session to load and resume from the carry-over note.","title":"Carry-Over Session - Description"},{"location":"skills/carry-over-session/description/#carry-over-session-description","text":"","title":"Carry-Over Session - Description"},{"location":"skills/carry-over-session/description/#overview","text":"Carry-Over creates a simple note file to resume work in a future session with minimal context and maximum clarity.","title":"Overview"},{"location":"skills/carry-over-session/description/#what-it-does","text":"Creates a carry-over note file in .olaf/carry-over/ Captures the exact next prompt to use Lists absolute file paths needed Optionally includes brief context (1-2 lines) Names file with timestamp: carry-over-YYYYMMDD-HHmm.txt","title":"What It Does"},{"location":"skills/carry-over-session/description/#how-it-works","text":"User requests carry-over with command like \"carry over\" Copilot analyzes current session to determine next action Generates carry-over file with: NEXT PROMPT : Exact prompt to continue work FILES NEEDED : Absolute paths to files OPTIONAL context : Brief 1-2 line summary if critical Saves file to .olaf/carry-over/ directory","title":"How It Works"},{"location":"skills/carry-over-session/description/#file-structure","text":"CARRY-OVER - 2025-11-14 14:30 ======================== ## NEXT PROMPT <Exact prompt for next session> ## FILES NEEDED (Absolute Paths) <Full paths to files> ## OPTIONAL - Brief Context <1-2 lines if needed>","title":"File Structure"},{"location":"skills/carry-over-session/description/#key-files","text":"Carry-Over Directory : .olaf/carry-over/ File Pattern : carry-over-YYYYMMDD-HHmm.txt Skill Prompt : skills/carry-over-session/carry-over-session.md Companion Skill : carry-on-session.md (to resume)","title":"Key Files"},{"location":"skills/carry-over-session/description/#commands","text":"carry over - Create carry-over note for current session create carry over - Same as above carry over note - Same as above","title":"Commands"},{"location":"skills/carry-over-session/description/#when-to-use","text":"Ending work session but want to resume later Switching to different task temporarily Need to remember exact next action Want to preserve file context between sessions","title":"When to Use"},{"location":"skills/carry-over-session/description/#companion-feature","text":"Use carry on in next session to load and resume from the carry-over note.","title":"Companion Feature"},{"location":"skills/carry-over-session/tutorial/","text":"Carry-Over Session: Step-by-Step Tutorial \u00b6 How to Execute the \"Carry-Over Session\" Workflow This tutorial shows exactly how to create a carry-over note to resume work in a future session. Prerequisites \u00b6 OLAF framework installed and active .olaf/carry-over/ directory exists (created automatically if needed) Active work session with tasks in progress Access to GitHub Copilot Chat or compatible IDE Step-by-Step Instructions \u00b6 Step 1: Request Carry-Over \u00b6 Brief: Signal that you want to create a carry-over note User Action: 1. Open GitHub Copilot Chat 2. Type: carry over 3. Press Enter Alternative commands: create carry over carry over note Step 2: Copilot Analyzes Current Session \u00b6 What Copilot Does: - Reviews the current conversation and work context - Identifies the logical next action/prompt - Determines which files are relevant - Extracts absolute file paths You Should See: Copilot processing your request Step 3: Carry-Over File Generation \u00b6 What Copilot Does: - Creates timestamp: YYYYMMDD-HHmm format - Generates carry-over file content: - Section 1: NEXT PROMPT (exact prompt for next session) - Section 2: FILES NEEDED (absolute paths) - Section 3: OPTIONAL context (brief summary if critical) - Saves to .olaf/carry-over/carry-over-YYYYMMDD-HHmm.txt Example Generated File: CARRY-OVER - 2025-11-14 14:30 ======================== ## NEXT PROMPT Add JWT validation to AuthService, update login to return token, and add middleware to protect routes. ## FILES NEEDED (Absolute Paths) c:\\users\\<user-name>\\coderepos\\project\\src\\services\\AuthService.ts c:\\users\\<user-name>\\coderepos\\project\\src\\middleware\\auth.ts c:\\users\\<user-name>\\coderepos\\project\\src\\routes\\api.ts c:\\users\\<user-name>\\coderepos\\project\\config\\jwt.config.ts c:\\users\\<user-name>\\coderepos\\project\\tests\\auth.test.ts ## OPTIONAL - Brief Context Working on authentication feature. Login endpoint exists but needs JWT implementation. Step 4: Confirmation \u00b6 Copilot Response: \u2713 Carry-over note created: .olaf/carry-over/carry-over-20251114-1430.txt Use \"carry on\" in next session to resume User Action: Note the confirmation, end your session Step 5: Resume in Future Session (Using Carry-On) \u00b6 User Action: 1. Start new Copilot Chat session 2. Type: carry on 3. Press Enter What Copilot Does: - Finds latest carry-over file - Loads NEXT PROMPT and FILES NEEDED - Proposes plan and asks for approval Copilot Response: ## Resuming from Carry-Over - Carry-Over File: carry-over-20251114-1430.txt - Session Date: 2025-11-14 14:30 ### Proposed Plan (from NEXT PROMPT) Add JWT validation to AuthService, update login to return token, and add middleware to protect routes. ### Files To Open c:\\users\\<user-name>\\coderepos\\project\\src\\services\\AuthService.ts c:\\users\\<user-name>\\coderepos\\project\\src\\middleware\\auth.ts c:\\users\\<user-name>\\coderepos\\project\\src\\routes\\api.ts c:\\users\\<user-name>\\coderepos\\project\\config\\jwt.config.ts c:\\users\\<user-name>\\coderepos\\project\\tests\\auth.test.ts Confirm: Proceed with the proposed plan? (Yes/No) User Action: Respond Yes to proceed Verification Checklist \u00b6 \u2705 Carry-over file created - Check .olaf/carry-over/ directory \u2705 Timestamp format correct - File named carry-over-YYYYMMDD-HHmm.txt \u2705 NEXT PROMPT included - Clear actionable prompt present \u2705 FILES NEEDED listed - Absolute paths to relevant files \u2705 Resumable in next session - Can use carry on to load Troubleshooting \u00b6 If carry-over file not created: Check .olaf/carry-over/ directory exists Copilot may need write permissions If files have relative paths instead of absolute: - Manually edit the carry-over file - Convert to absolute paths using workspace root - Format: c:\\Users\\<user>\\coderepos\\<project>\\<path> If NEXT PROMPT is unclear: - Manually edit the carry-over file - Make the prompt more specific and actionable - Add any critical context If resuming doesn't work: - Check carry-over file exists and isn't corrupted - Verify file follows correct template format - Try carry on command again Key Learning Points \u00b6 Minimal but sufficient: Carry-over notes are intentionally brief. Include only what's needed to resume work immediately. Absolute paths critical: File paths must be absolute (full workspace path) so they work across sessions without ambiguity. NEXT PROMPT is key: This is the exact prompt you or Copilot will use to continue work. Make it clear and actionable. Companion workflow: Carry-over creates the note, carry on loads it. They work together as a pair. Personal workspace: .olaf/ directory is typically in .gitignore , keeping carry-over notes private. Next Steps to Try \u00b6 Create a carry-over note and resume it in next session using carry on Edit a carry-over file manually to refine the NEXT PROMPT Create multiple carry-over notes for different tasks (use descriptive timestamps) Compare carry-over with stash workflow (stash is for pausing, carry-over is for session continuity) Expected Timeline \u00b6 Total carry-over creation time: 10-30 seconds User input required: Request carry-over command Copilot execution time: Instant (file generation) Resume time: 10-20 seconds in next session with carry on","title":"Carry-Over Session: Step-by-Step Tutorial"},{"location":"skills/carry-over-session/tutorial/#carry-over-session-step-by-step-tutorial","text":"How to Execute the \"Carry-Over Session\" Workflow This tutorial shows exactly how to create a carry-over note to resume work in a future session.","title":"Carry-Over Session: Step-by-Step Tutorial"},{"location":"skills/carry-over-session/tutorial/#prerequisites","text":"OLAF framework installed and active .olaf/carry-over/ directory exists (created automatically if needed) Active work session with tasks in progress Access to GitHub Copilot Chat or compatible IDE","title":"Prerequisites"},{"location":"skills/carry-over-session/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/carry-over-session/tutorial/#step-1-request-carry-over","text":"Brief: Signal that you want to create a carry-over note User Action: 1. Open GitHub Copilot Chat 2. Type: carry over 3. Press Enter Alternative commands: create carry over carry over note","title":"Step 1: Request Carry-Over"},{"location":"skills/carry-over-session/tutorial/#step-2-copilot-analyzes-current-session","text":"What Copilot Does: - Reviews the current conversation and work context - Identifies the logical next action/prompt - Determines which files are relevant - Extracts absolute file paths You Should See: Copilot processing your request","title":"Step 2: Copilot Analyzes Current Session"},{"location":"skills/carry-over-session/tutorial/#step-3-carry-over-file-generation","text":"What Copilot Does: - Creates timestamp: YYYYMMDD-HHmm format - Generates carry-over file content: - Section 1: NEXT PROMPT (exact prompt for next session) - Section 2: FILES NEEDED (absolute paths) - Section 3: OPTIONAL context (brief summary if critical) - Saves to .olaf/carry-over/carry-over-YYYYMMDD-HHmm.txt Example Generated File: CARRY-OVER - 2025-11-14 14:30 ======================== ## NEXT PROMPT Add JWT validation to AuthService, update login to return token, and add middleware to protect routes. ## FILES NEEDED (Absolute Paths) c:\\users\\<user-name>\\coderepos\\project\\src\\services\\AuthService.ts c:\\users\\<user-name>\\coderepos\\project\\src\\middleware\\auth.ts c:\\users\\<user-name>\\coderepos\\project\\src\\routes\\api.ts c:\\users\\<user-name>\\coderepos\\project\\config\\jwt.config.ts c:\\users\\<user-name>\\coderepos\\project\\tests\\auth.test.ts ## OPTIONAL - Brief Context Working on authentication feature. Login endpoint exists but needs JWT implementation.","title":"Step 3: Carry-Over File Generation"},{"location":"skills/carry-over-session/tutorial/#step-4-confirmation","text":"Copilot Response: \u2713 Carry-over note created: .olaf/carry-over/carry-over-20251114-1430.txt Use \"carry on\" in next session to resume User Action: Note the confirmation, end your session","title":"Step 4: Confirmation"},{"location":"skills/carry-over-session/tutorial/#step-5-resume-in-future-session-using-carry-on","text":"User Action: 1. Start new Copilot Chat session 2. Type: carry on 3. Press Enter What Copilot Does: - Finds latest carry-over file - Loads NEXT PROMPT and FILES NEEDED - Proposes plan and asks for approval Copilot Response: ## Resuming from Carry-Over - Carry-Over File: carry-over-20251114-1430.txt - Session Date: 2025-11-14 14:30 ### Proposed Plan (from NEXT PROMPT) Add JWT validation to AuthService, update login to return token, and add middleware to protect routes. ### Files To Open c:\\users\\<user-name>\\coderepos\\project\\src\\services\\AuthService.ts c:\\users\\<user-name>\\coderepos\\project\\src\\middleware\\auth.ts c:\\users\\<user-name>\\coderepos\\project\\src\\routes\\api.ts c:\\users\\<user-name>\\coderepos\\project\\config\\jwt.config.ts c:\\users\\<user-name>\\coderepos\\project\\tests\\auth.test.ts Confirm: Proceed with the proposed plan? (Yes/No) User Action: Respond Yes to proceed","title":"Step 5: Resume in Future Session (Using Carry-On)"},{"location":"skills/carry-over-session/tutorial/#verification-checklist","text":"\u2705 Carry-over file created - Check .olaf/carry-over/ directory \u2705 Timestamp format correct - File named carry-over-YYYYMMDD-HHmm.txt \u2705 NEXT PROMPT included - Clear actionable prompt present \u2705 FILES NEEDED listed - Absolute paths to relevant files \u2705 Resumable in next session - Can use carry on to load","title":"Verification Checklist"},{"location":"skills/carry-over-session/tutorial/#troubleshooting","text":"If carry-over file not created: Check .olaf/carry-over/ directory exists Copilot may need write permissions If files have relative paths instead of absolute: - Manually edit the carry-over file - Convert to absolute paths using workspace root - Format: c:\\Users\\<user>\\coderepos\\<project>\\<path> If NEXT PROMPT is unclear: - Manually edit the carry-over file - Make the prompt more specific and actionable - Add any critical context If resuming doesn't work: - Check carry-over file exists and isn't corrupted - Verify file follows correct template format - Try carry on command again","title":"Troubleshooting"},{"location":"skills/carry-over-session/tutorial/#key-learning-points","text":"Minimal but sufficient: Carry-over notes are intentionally brief. Include only what's needed to resume work immediately. Absolute paths critical: File paths must be absolute (full workspace path) so they work across sessions without ambiguity. NEXT PROMPT is key: This is the exact prompt you or Copilot will use to continue work. Make it clear and actionable. Companion workflow: Carry-over creates the note, carry on loads it. They work together as a pair. Personal workspace: .olaf/ directory is typically in .gitignore , keeping carry-over notes private.","title":"Key Learning Points"},{"location":"skills/carry-over-session/tutorial/#next-steps-to-try","text":"Create a carry-over note and resume it in next session using carry on Edit a carry-over file manually to refine the NEXT PROMPT Create multiple carry-over notes for different tasks (use descriptive timestamps) Compare carry-over with stash workflow (stash is for pausing, carry-over is for session continuity)","title":"Next Steps to Try"},{"location":"skills/carry-over-session/tutorial/#expected-timeline","text":"Total carry-over creation time: 10-30 seconds User input required: Request carry-over command Copilot execution time: Instant (file generation) Resume time: 10-20 seconds in next session with carry on","title":"Expected Timeline"},{"location":"skills/challenge-me/description/","text":"Challenge Me Skill - User Guide \u00b6 Version : 2.0 (Enhanced Multi-Source Research) Last Updated : 2025-11-19 Skill Path : skills/challenge-me/prompts/challenge-me.md Overview \u00b6 The Challenge Me skill is an interactive ideation engine that challenges your ideas, provides insights, and tracks collaborative refinement through iterative cycles. The enhanced version integrates multiple research sources including local codebases, documentation, and web resources to provide evidence-based challenges and insights. How It Works \u00b6 flowchart TD A[User Request: \"challenge me\"] --> B[Parameter Collection] B --> C[Session Initialization] C --> D[Multi-Source Setup] D --> E[Iterative Cycles] E --> F{User Says Stop/Save?} F -->|No| G[Next Cycle] F -->|Yes| H[Generate Deliverables] D --> D1[Scan Codebase] D --> D2[Index Documentation] D --> D3[Prepare Web Search] G --> G1[Analyze Current Ideas] G --> G2[Research Codebase] G --> G3[Review Documentation] G --> G4[Web Research] G --> G5[Present Challenges] G --> G6[Generate Insights] G --> G7[Track Citations] G --> G8[Update Trajectory] G8 --> E H --> H1[think.md] H --> H2[path.md] H --> H3[sources.md] H --> H4[reco.md] Getting Started \u00b6 Basic Usage \u00b6 Simply type: olaf challenge me The system will prompt you for required parameters: Required Parameters \u00b6 Subject : The topic or subject area for ideation Initial Thoughts : Your starting ideas or description Optional Parameters \u00b6 Codebase Path : Path to local repository/codebase for analysis Documentation Path : Path to folder containing relevant documentation Web Search URLs : Specific URLs for research or leave empty for general search Research Depth : shallow|moderate|deep (default: moderate) Challenge Intensity : gentle|moderate|rigorous (default: moderate) Example Session Start \u00b6 User: olaf challenge me Agent: I'll help you with an interactive ideation session. I need some information to get started: **Subject**: What topic would you like to explore? (REQUIRED) **Initial Thoughts**: What are your current ideas or thoughts on this topic? (REQUIRED) **Codebase Path**: Do you have a local repository I should analyze? (Optional - provide path) **Documentation Path**: Any documentation folder I should review? (Optional - provide path) **Web Search URLs**: Specific URLs to research, or leave empty for general search (Optional) **Research Depth**: How deep should I research? (shallow/moderate/deep - default: moderate) **Challenge Intensity**: How aggressively should I challenge ideas? (gentle/moderate/rigorous - default: moderate) User: Subject: API design patterns for microservices Initial Thoughts: I'm thinking about using REST APIs with JSON, but wondering about GraphQL and event-driven patterns Codebase Path: ./my-microservices-project Documentation Path: ./docs/architecture Web Search URLs: (leave empty for general search) Session Flow \u00b6 1. Session Initialization \u00b6 The system creates a unique session identifier and sets up multi-source research: Session ID: api-design-patterns-20251119-1653 \u2713 Codebase scanned: ./my-microservices-project (15 services found) \u2713 Documentation indexed: ./docs/architecture (8 documents) \u2713 Web search strategy: General API design research \u2713 Citation tracking initialized 2. Iterative Cycles \u00b6 Each cycle follows this structure: graph LR A[Analysis] --> B[Codebase Review] B --> C[Documentation Search] C --> D[Web Research] D --> E[Challenge Generation] E --> F[Insight Delivery] F --> G[Citation Tracking] G --> H[Trajectory Update] H --> I[User Response] I --> A Output Files \u00b6 When you say \"save\", the system generates four files in [staging_dir]/think-tank/<subject-3-words>-YYYYMMDD-HHMM/ : 1. think.md - Final Refined Ideas \u00b6 Contains your final conclusions with source attribution 2. path.md - Evolution Trajectory \u00b6 Documents how your thinking evolved through the session 3. sources.md - Comprehensive Citations \u00b6 Complete citation database organized by source type 4. reco.md - Actionable Recommendations \u00b6 Honest, actionable recommendations based on all cycle exchanges including go/no-go decisions and alternatives Enhanced Collaborative Features \u00b6 Interactive Question Formats \u00b6 The system uses specific formatting for different types of engagement: Numbered Lists (1, 2, 3, 4) for: - Choice-based questions (selecting between options) - Priority rankings and polls - Decision-oriented prompts Lettered Lists (A, B, C, D) for: - Clarification questions (what do you mean by...?) - Vision/perspective requests (how do you see...?) - Understanding checks (which resonates with you?) Collaborative Engagement Rules \u00b6 Never repeats questions - always builds on previous responses Presents web feedback and asks for your perspective Invites explanation rather than making assumptions Uses multiple-choice formats to keep you actively involved Builds trajectory based on your responses and reasoning Advanced Features \u00b6 Citation Tracking \u00b6 Every insight and challenge is backed by specific sources: - Code references : File paths, line numbers, specific functions - Documentation : Document names, sections, page numbers - Web resources : Full URLs, titles, access timestamps Multi-Source Synthesis \u00b6 The system combines findings from all sources to provide: - Evidence-based challenges grounded in your actual codebase - Contextual insights informed by your documentation - Industry-validated approaches from web research Honest Recommendations System \u00b6 Every session now produces actionable recommendations that can include: - Go/No-Go decisions with clear reasoning - Alternative approaches if current path isn't recommended - Negative recommendations (\"don't do it\" with alternatives) - Risk assessments and mitigation strategies - Specific next steps with timelines and resources Best Practices \u00b6 Preparing for a Session \u00b6 Organize your codebase : Ensure the path is accessible and well-structured Prepare documentation : Have relevant docs in a single folder Define clear scope : Be specific about what aspect you want to explore Set realistic expectations : Complex topics may need multiple sessions During the Session \u00b6 Engage actively : Respond thoughtfully to challenges Ask for clarification : If sources seem unclear, ask for specifics Challenge back : The system learns from your pushback Request deeper dives : Ask to explore specific sources more thoroughly After the Session \u00b6 Review all four files : Each provides different value Follow citation trails : Explore referenced sources independently Plan implementation : Use insights for concrete next steps Schedule follow-ups : Complex topics benefit from multiple sessions Troubleshooting \u00b6 Common Issues \u00b6 \"Codebase path not found\" - Verify the path is correct and accessible - Use relative paths from your current directory - The system will continue without codebase analysis if needed \"Too many sources overwhelming the discussion\" - Request focus on specific source types - Ask for prioritization of most relevant sources - Use \"shallow\" research depth for simpler sessions \"Citations seem incomplete\" - The system maintains manual backups if tracking fails - Request specific source verification during cycles - Check sources.md for comprehensive citation database \"Cycles becoming repetitive\" - Ask for new research angles or unexplored sources - Request deeper analysis of specific findings - Consider switching to different documentation areas Getting Help \u00b6 Use \"explain your reasoning\" to understand source selection Ask \"what sources are you consulting?\" for transparency Request \"show me the specific code/doc section\" for verification This guide covers the enhanced Challenge Me skill with collaborative engagement, comprehensive source tracking, and honest recommendations. The system will actively involve you in the ideation process while providing evidence-based insights and actionable outcomes.","title":"Challenge Me Skill - User Guide"},{"location":"skills/challenge-me/description/#challenge-me-skill-user-guide","text":"Version : 2.0 (Enhanced Multi-Source Research) Last Updated : 2025-11-19 Skill Path : skills/challenge-me/prompts/challenge-me.md","title":"Challenge Me Skill - User Guide"},{"location":"skills/challenge-me/description/#overview","text":"The Challenge Me skill is an interactive ideation engine that challenges your ideas, provides insights, and tracks collaborative refinement through iterative cycles. The enhanced version integrates multiple research sources including local codebases, documentation, and web resources to provide evidence-based challenges and insights.","title":"Overview"},{"location":"skills/challenge-me/description/#how-it-works","text":"flowchart TD A[User Request: \"challenge me\"] --> B[Parameter Collection] B --> C[Session Initialization] C --> D[Multi-Source Setup] D --> E[Iterative Cycles] E --> F{User Says Stop/Save?} F -->|No| G[Next Cycle] F -->|Yes| H[Generate Deliverables] D --> D1[Scan Codebase] D --> D2[Index Documentation] D --> D3[Prepare Web Search] G --> G1[Analyze Current Ideas] G --> G2[Research Codebase] G --> G3[Review Documentation] G --> G4[Web Research] G --> G5[Present Challenges] G --> G6[Generate Insights] G --> G7[Track Citations] G --> G8[Update Trajectory] G8 --> E H --> H1[think.md] H --> H2[path.md] H --> H3[sources.md] H --> H4[reco.md]","title":"How It Works"},{"location":"skills/challenge-me/description/#getting-started","text":"","title":"Getting Started"},{"location":"skills/challenge-me/description/#basic-usage","text":"Simply type: olaf challenge me The system will prompt you for required parameters:","title":"Basic Usage"},{"location":"skills/challenge-me/description/#required-parameters","text":"Subject : The topic or subject area for ideation Initial Thoughts : Your starting ideas or description","title":"Required Parameters"},{"location":"skills/challenge-me/description/#optional-parameters","text":"Codebase Path : Path to local repository/codebase for analysis Documentation Path : Path to folder containing relevant documentation Web Search URLs : Specific URLs for research or leave empty for general search Research Depth : shallow|moderate|deep (default: moderate) Challenge Intensity : gentle|moderate|rigorous (default: moderate)","title":"Optional Parameters"},{"location":"skills/challenge-me/description/#example-session-start","text":"User: olaf challenge me Agent: I'll help you with an interactive ideation session. I need some information to get started: **Subject**: What topic would you like to explore? (REQUIRED) **Initial Thoughts**: What are your current ideas or thoughts on this topic? (REQUIRED) **Codebase Path**: Do you have a local repository I should analyze? (Optional - provide path) **Documentation Path**: Any documentation folder I should review? (Optional - provide path) **Web Search URLs**: Specific URLs to research, or leave empty for general search (Optional) **Research Depth**: How deep should I research? (shallow/moderate/deep - default: moderate) **Challenge Intensity**: How aggressively should I challenge ideas? (gentle/moderate/rigorous - default: moderate) User: Subject: API design patterns for microservices Initial Thoughts: I'm thinking about using REST APIs with JSON, but wondering about GraphQL and event-driven patterns Codebase Path: ./my-microservices-project Documentation Path: ./docs/architecture Web Search URLs: (leave empty for general search)","title":"Example Session Start"},{"location":"skills/challenge-me/description/#session-flow","text":"","title":"Session Flow"},{"location":"skills/challenge-me/description/#1-session-initialization","text":"The system creates a unique session identifier and sets up multi-source research: Session ID: api-design-patterns-20251119-1653 \u2713 Codebase scanned: ./my-microservices-project (15 services found) \u2713 Documentation indexed: ./docs/architecture (8 documents) \u2713 Web search strategy: General API design research \u2713 Citation tracking initialized","title":"1. Session Initialization"},{"location":"skills/challenge-me/description/#2-iterative-cycles","text":"Each cycle follows this structure: graph LR A[Analysis] --> B[Codebase Review] B --> C[Documentation Search] C --> D[Web Research] D --> E[Challenge Generation] E --> F[Insight Delivery] F --> G[Citation Tracking] G --> H[Trajectory Update] H --> I[User Response] I --> A","title":"2. Iterative Cycles"},{"location":"skills/challenge-me/description/#output-files","text":"When you say \"save\", the system generates four files in [staging_dir]/think-tank/<subject-3-words>-YYYYMMDD-HHMM/ :","title":"Output Files"},{"location":"skills/challenge-me/description/#1-thinkmd-final-refined-ideas","text":"Contains your final conclusions with source attribution","title":"1. think.md - Final Refined Ideas"},{"location":"skills/challenge-me/description/#2-pathmd-evolution-trajectory","text":"Documents how your thinking evolved through the session","title":"2. path.md - Evolution Trajectory"},{"location":"skills/challenge-me/description/#3-sourcesmd-comprehensive-citations","text":"Complete citation database organized by source type","title":"3. sources.md - Comprehensive Citations"},{"location":"skills/challenge-me/description/#4-recomd-actionable-recommendations","text":"Honest, actionable recommendations based on all cycle exchanges including go/no-go decisions and alternatives","title":"4. reco.md - Actionable Recommendations"},{"location":"skills/challenge-me/description/#enhanced-collaborative-features","text":"","title":"Enhanced Collaborative Features"},{"location":"skills/challenge-me/description/#interactive-question-formats","text":"The system uses specific formatting for different types of engagement: Numbered Lists (1, 2, 3, 4) for: - Choice-based questions (selecting between options) - Priority rankings and polls - Decision-oriented prompts Lettered Lists (A, B, C, D) for: - Clarification questions (what do you mean by...?) - Vision/perspective requests (how do you see...?) - Understanding checks (which resonates with you?)","title":"Interactive Question Formats"},{"location":"skills/challenge-me/description/#collaborative-engagement-rules","text":"Never repeats questions - always builds on previous responses Presents web feedback and asks for your perspective Invites explanation rather than making assumptions Uses multiple-choice formats to keep you actively involved Builds trajectory based on your responses and reasoning","title":"Collaborative Engagement Rules"},{"location":"skills/challenge-me/description/#advanced-features","text":"","title":"Advanced Features"},{"location":"skills/challenge-me/description/#citation-tracking","text":"Every insight and challenge is backed by specific sources: - Code references : File paths, line numbers, specific functions - Documentation : Document names, sections, page numbers - Web resources : Full URLs, titles, access timestamps","title":"Citation Tracking"},{"location":"skills/challenge-me/description/#multi-source-synthesis","text":"The system combines findings from all sources to provide: - Evidence-based challenges grounded in your actual codebase - Contextual insights informed by your documentation - Industry-validated approaches from web research","title":"Multi-Source Synthesis"},{"location":"skills/challenge-me/description/#honest-recommendations-system","text":"Every session now produces actionable recommendations that can include: - Go/No-Go decisions with clear reasoning - Alternative approaches if current path isn't recommended - Negative recommendations (\"don't do it\" with alternatives) - Risk assessments and mitigation strategies - Specific next steps with timelines and resources","title":"Honest Recommendations System"},{"location":"skills/challenge-me/description/#best-practices","text":"","title":"Best Practices"},{"location":"skills/challenge-me/description/#preparing-for-a-session","text":"Organize your codebase : Ensure the path is accessible and well-structured Prepare documentation : Have relevant docs in a single folder Define clear scope : Be specific about what aspect you want to explore Set realistic expectations : Complex topics may need multiple sessions","title":"Preparing for a Session"},{"location":"skills/challenge-me/description/#during-the-session","text":"Engage actively : Respond thoughtfully to challenges Ask for clarification : If sources seem unclear, ask for specifics Challenge back : The system learns from your pushback Request deeper dives : Ask to explore specific sources more thoroughly","title":"During the Session"},{"location":"skills/challenge-me/description/#after-the-session","text":"Review all four files : Each provides different value Follow citation trails : Explore referenced sources independently Plan implementation : Use insights for concrete next steps Schedule follow-ups : Complex topics benefit from multiple sessions","title":"After the Session"},{"location":"skills/challenge-me/description/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/challenge-me/description/#common-issues","text":"\"Codebase path not found\" - Verify the path is correct and accessible - Use relative paths from your current directory - The system will continue without codebase analysis if needed \"Too many sources overwhelming the discussion\" - Request focus on specific source types - Ask for prioritization of most relevant sources - Use \"shallow\" research depth for simpler sessions \"Citations seem incomplete\" - The system maintains manual backups if tracking fails - Request specific source verification during cycles - Check sources.md for comprehensive citation database \"Cycles becoming repetitive\" - Ask for new research angles or unexplored sources - Request deeper analysis of specific findings - Consider switching to different documentation areas","title":"Common Issues"},{"location":"skills/challenge-me/description/#getting-help","text":"Use \"explain your reasoning\" to understand source selection Ask \"what sources are you consulting?\" for transparency Request \"show me the specific code/doc section\" for verification This guide covers the enhanced Challenge Me skill with collaborative engagement, comprehensive source tracking, and honest recommendations. The system will actively involve you in the ideation process while providing evidence-based insights and actionable outcomes.","title":"Getting Help"},{"location":"skills/challenge-me/tutorial/","text":"Challenge Me: Step-by-Step Tutorial \u00b6 How to Execute the \"Challenge Me\" Workflow This tutorial shows exactly how to use the Challenge Me skill to challenge ideas, gain insights, and track collaborative refinement through dynamic engagement. Prerequisites \u00b6 Access to OLAF Framework with challenge-me skill Initial ideas or thoughts on a specific topic Openness to constructive criticism and alternative perspectives Optional: Access to relevant codebase or documentation for deeper analysis Step-by-Step Instructions \u00b6 Step 1: Initialize Challenge Session \u00b6 Brief description: Start the interactive ideation workflow by invoking the challenge me skill. User Action: Navigate to your workspace Execute the command: olaf challenge me or simply challenge me Prepare to share your initial ideas and thoughts System Response: The system will prompt for your subject and initial thoughts, then immediately begin challenging and exploring your ideas using Act protocol. Step 2: Provide Initial Ideas and Context \u00b6 User Action: Provide your subject area and initial thoughts when prompted Subject: [your-topic-area] Initial Thoughts: [your-current-ideas-or-perspective] Codebase Path: [optional-path-to-relevant-code] Documentation Path: [optional-path-to-docs] Web Search URLs: [optional-specific-urls] Research Depth: [shallow|moderate|deep] Challenge Intensity: [gentle|moderate|rigorous] Provide Requirements/Parameters: subject : Topic area for ideation - we used \"microservices architecture design\" initial_thoughts : Your current ideas - we used \"Planning to break monolith into 5 services\" codebase_path : Optional code path - we used \"/path/to/monolith-code\" research_depth : Research level - we used \"moderate\" challenge_intensity : Challenge approach - we used \"moderate\" Step 3: Session Initialization and Context Analysis \u00b6 What System Does: Creates ideation session with timestamp identifier Analyzes your initial thoughts for assumptions and gaps Extracts 3-word subject identifier for organization Initializes challenge framework based on intensity level Prepares multi-modal research approach if paths provided You Should See: Session setup confirmation with challenge approach and research strategy Step 4: Initial Challenge and Counter-Perspectives \u00b6 What System Does: Immediately challenges assumptions in your initial thoughts Provides alternative perspectives and approaches Raises critical questions about your ideas Presents counter-arguments and potential issues Encourages deeper thinking about implications You Should See: Direct challenges to your ideas with probing questions and alternative viewpoints Step 5: Interactive Ideation Cycles \u00b6 What System Does: Responds to your clarifications and refinements Continues challenging evolved ideas iteratively Introduces new angles and considerations Tracks ideation trajectory and evolution Maintains collaborative yet critical engagement You Should See: Ongoing back-and-forth dialogue that pushes your thinking further Step 6: Research-Enhanced Challenges \u00b6 What System Does: Conducts web research to find supporting/contradicting evidence Analyzes provided codebase for practical constraints Reviews documentation for existing approaches Brings external insights to challenge assumptions Combines research findings with ideation process You Should See: Research-backed challenges and insights that add depth to the ideation Step 7: Refinement Tracking and Evolution \u00b6 What System Does: Tracks how your ideas evolve through challenges Documents key turning points in thinking Identifies breakthrough insights and pivots Maintains history of ideation progression Recognizes when ideas reach mature state You Should See: Clear tracking of how your thinking has evolved and improved Step 8: Session Summary and Next Steps \u00b6 What System Does: Summarizes key insights and breakthroughs Documents final refined ideas and approaches Provides actionable next steps for implementation Saves complete ideation trajectory to staging area Suggests follow-up challenge areas You Should See: Comprehensive summary of ideation journey with refined outcomes and action items Verification Checklist \u00b6 \u2705 Initial ideas challenged : Original thoughts questioned and examined critically \u2705 Alternative perspectives explored : Multiple viewpoints and approaches considered \u2705 Research integration completed : External insights incorporated into ideation \u2705 Ideation trajectory tracked : Evolution of thinking documented throughout \u2705 Refined outcomes achieved : Ideas improved through collaborative challenge process \u2705 Action items identified : Clear next steps for implementing refined ideas \u2705 Session documented : Complete ideation journey saved for future reference Troubleshooting \u00b6 If challenges seem too aggressive: # Adjust challenge intensity to a gentler level Challenge Intensity: gentle # Focus on collaborative refinement rather than criticism If ideation stalls or becomes repetitive: Introduce new subject angles or focus areas Provide additional context through codebase or documentation paths Increase research depth for fresh external perspectives Share more specific aspects of your ideas for targeted challenges If research integration fails: Verify internet connectivity for web research Check accessibility of provided codebase and documentation paths Ensure file permissions allow reading of specified directories Consider simplifying research scope if too broad Key Learning Points \u00b6 Constructive challenge approach : Ideas are challenged to strengthen, not destroy them Iterative refinement : Thinking evolves through multiple challenge cycles Research-enhanced ideation : External insights add credibility and depth Trajectory awareness : Understanding how ideas evolve is as valuable as final outcomes Collaborative intelligence : Human creativity enhanced by AI critical thinking Next Steps to Try \u00b6 Apply refined ideas to actual implementation planning Use challenge methodology on other concepts and projects Share ideation results with team for additional input Implement action items identified during the session Schedule follow-up challenge sessions for continued refinement Expected Timeline \u00b6 Total session time: 30-60 minutes depending on idea complexity and engagement depth User input required: Continuous interactive engagement throughout session Initial challenge phase: First round of critical examination (5-10 minutes) Iterative refinement: Multiple challenge and response cycles (15-35 minutes) Research integration: External insight incorporation (5-15 minutes if applicable)","title":"Challenge Me: Step-by-Step Tutorial"},{"location":"skills/challenge-me/tutorial/#challenge-me-step-by-step-tutorial","text":"How to Execute the \"Challenge Me\" Workflow This tutorial shows exactly how to use the Challenge Me skill to challenge ideas, gain insights, and track collaborative refinement through dynamic engagement.","title":"Challenge Me: Step-by-Step Tutorial"},{"location":"skills/challenge-me/tutorial/#prerequisites","text":"Access to OLAF Framework with challenge-me skill Initial ideas or thoughts on a specific topic Openness to constructive criticism and alternative perspectives Optional: Access to relevant codebase or documentation for deeper analysis","title":"Prerequisites"},{"location":"skills/challenge-me/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/challenge-me/tutorial/#step-1-initialize-challenge-session","text":"Brief description: Start the interactive ideation workflow by invoking the challenge me skill. User Action: Navigate to your workspace Execute the command: olaf challenge me or simply challenge me Prepare to share your initial ideas and thoughts System Response: The system will prompt for your subject and initial thoughts, then immediately begin challenging and exploring your ideas using Act protocol.","title":"Step 1: Initialize Challenge Session"},{"location":"skills/challenge-me/tutorial/#step-2-provide-initial-ideas-and-context","text":"User Action: Provide your subject area and initial thoughts when prompted Subject: [your-topic-area] Initial Thoughts: [your-current-ideas-or-perspective] Codebase Path: [optional-path-to-relevant-code] Documentation Path: [optional-path-to-docs] Web Search URLs: [optional-specific-urls] Research Depth: [shallow|moderate|deep] Challenge Intensity: [gentle|moderate|rigorous] Provide Requirements/Parameters: subject : Topic area for ideation - we used \"microservices architecture design\" initial_thoughts : Your current ideas - we used \"Planning to break monolith into 5 services\" codebase_path : Optional code path - we used \"/path/to/monolith-code\" research_depth : Research level - we used \"moderate\" challenge_intensity : Challenge approach - we used \"moderate\"","title":"Step 2: Provide Initial Ideas and Context"},{"location":"skills/challenge-me/tutorial/#step-3-session-initialization-and-context-analysis","text":"What System Does: Creates ideation session with timestamp identifier Analyzes your initial thoughts for assumptions and gaps Extracts 3-word subject identifier for organization Initializes challenge framework based on intensity level Prepares multi-modal research approach if paths provided You Should See: Session setup confirmation with challenge approach and research strategy","title":"Step 3: Session Initialization and Context Analysis"},{"location":"skills/challenge-me/tutorial/#step-4-initial-challenge-and-counter-perspectives","text":"What System Does: Immediately challenges assumptions in your initial thoughts Provides alternative perspectives and approaches Raises critical questions about your ideas Presents counter-arguments and potential issues Encourages deeper thinking about implications You Should See: Direct challenges to your ideas with probing questions and alternative viewpoints","title":"Step 4: Initial Challenge and Counter-Perspectives"},{"location":"skills/challenge-me/tutorial/#step-5-interactive-ideation-cycles","text":"What System Does: Responds to your clarifications and refinements Continues challenging evolved ideas iteratively Introduces new angles and considerations Tracks ideation trajectory and evolution Maintains collaborative yet critical engagement You Should See: Ongoing back-and-forth dialogue that pushes your thinking further","title":"Step 5: Interactive Ideation Cycles"},{"location":"skills/challenge-me/tutorial/#step-6-research-enhanced-challenges","text":"What System Does: Conducts web research to find supporting/contradicting evidence Analyzes provided codebase for practical constraints Reviews documentation for existing approaches Brings external insights to challenge assumptions Combines research findings with ideation process You Should See: Research-backed challenges and insights that add depth to the ideation","title":"Step 6: Research-Enhanced Challenges"},{"location":"skills/challenge-me/tutorial/#step-7-refinement-tracking-and-evolution","text":"What System Does: Tracks how your ideas evolve through challenges Documents key turning points in thinking Identifies breakthrough insights and pivots Maintains history of ideation progression Recognizes when ideas reach mature state You Should See: Clear tracking of how your thinking has evolved and improved","title":"Step 7: Refinement Tracking and Evolution"},{"location":"skills/challenge-me/tutorial/#step-8-session-summary-and-next-steps","text":"What System Does: Summarizes key insights and breakthroughs Documents final refined ideas and approaches Provides actionable next steps for implementation Saves complete ideation trajectory to staging area Suggests follow-up challenge areas You Should See: Comprehensive summary of ideation journey with refined outcomes and action items","title":"Step 8: Session Summary and Next Steps"},{"location":"skills/challenge-me/tutorial/#verification-checklist","text":"\u2705 Initial ideas challenged : Original thoughts questioned and examined critically \u2705 Alternative perspectives explored : Multiple viewpoints and approaches considered \u2705 Research integration completed : External insights incorporated into ideation \u2705 Ideation trajectory tracked : Evolution of thinking documented throughout \u2705 Refined outcomes achieved : Ideas improved through collaborative challenge process \u2705 Action items identified : Clear next steps for implementing refined ideas \u2705 Session documented : Complete ideation journey saved for future reference","title":"Verification Checklist"},{"location":"skills/challenge-me/tutorial/#troubleshooting","text":"If challenges seem too aggressive: # Adjust challenge intensity to a gentler level Challenge Intensity: gentle # Focus on collaborative refinement rather than criticism If ideation stalls or becomes repetitive: Introduce new subject angles or focus areas Provide additional context through codebase or documentation paths Increase research depth for fresh external perspectives Share more specific aspects of your ideas for targeted challenges If research integration fails: Verify internet connectivity for web research Check accessibility of provided codebase and documentation paths Ensure file permissions allow reading of specified directories Consider simplifying research scope if too broad","title":"Troubleshooting"},{"location":"skills/challenge-me/tutorial/#key-learning-points","text":"Constructive challenge approach : Ideas are challenged to strengthen, not destroy them Iterative refinement : Thinking evolves through multiple challenge cycles Research-enhanced ideation : External insights add credibility and depth Trajectory awareness : Understanding how ideas evolve is as valuable as final outcomes Collaborative intelligence : Human creativity enhanced by AI critical thinking","title":"Key Learning Points"},{"location":"skills/challenge-me/tutorial/#next-steps-to-try","text":"Apply refined ideas to actual implementation planning Use challenge methodology on other concepts and projects Share ideation results with team for additional input Implement action items identified during the session Schedule follow-up challenge sessions for continued refinement","title":"Next Steps to Try"},{"location":"skills/challenge-me/tutorial/#expected-timeline","text":"Total session time: 30-60 minutes depending on idea complexity and engagement depth User input required: Continuous interactive engagement throughout session Initial challenge phase: First round of critical examination (5-10 minutes) Iterative refinement: Multiple challenge and response cycles (15-35 minutes) Research integration: External insight incorporation (5-15 minutes if applicable)","title":"Expected Timeline"},{"location":"skills/check-todos-in-code/description/","text":"Check TODOs In Code \u00b6 Source : core/competencies/developer/prompts/check-todos-in-code.md Overview \u00b6 Search and analyze TODO comments in codebase, assess validity, and generate complete code solutions with user decision tracking. Provides actionable resolution plan with actual replacement code. Purpose \u00b6 TODO comments accumulate in codebases over time, representing technical debt and deferred work. This competency systematically identifies, analyzes, and provides concrete solutions for TODOs, helping teams prioritize and resolve technical debt efficiently. Unlike simple TODO scanners, it provides actual code solutions and implementation guidance. Usage \u00b6 Command : check todos Protocol : Propose-Act When to Use : - Before release to identify and resolve pending work - During technical debt cleanup initiatives - When onboarding to understand deferred work - For sprint planning to estimate TODO resolution effort - To track and prioritize technical debt systematically Parameters \u00b6 Required Inputs \u00b6 target_path : Path to folder or repository to scan repository_name : Name of the repository being analyzed Optional Inputs \u00b6 file_extensions : File extensions to include (defaults to common code files) todo_patterns : TODO patterns to search for (defaults to TODO, FIXME, HACK, XXX, BUG) save_document : Save resolution document (default: true) max_todos_threshold : Maximum TODOs to analyze in one session (default: 50) Context Requirements \u00b6 Access to codebase source files Ability to read and analyze code context around TODOs Optional: version control history for author information Output \u00b6 Comprehensive TODO analysis with concrete solutions and implementation guidance. Deliverables : - TODO inventory organized by repository \u2192 folder \u2192 file hierarchy - Priority classification for each TODO (Critical, High, Medium, Low) - Actual replacement code solutions (not just recommendations) - Specific line ranges to replace - Implementation and testing instructions - Effort estimates and dependency identification Format : Markdown document following todo-resolution-template.md structure Examples \u00b6 Example 1: Full Repository Scan \u00b6 Scenario : Preparing for release, need to identify all pending TODOs Command : check todos Input : - target_path: \"./src\" - repository_name: \"payment-service\" Result : Found 23 TODOs, analyzed and prioritized with 5 critical items requiring immediate attention, complete with replacement code for each Example 2: Focused Scan with Subset \u00b6 Scenario : Large codebase with 150 TODOs, focusing on critical items Command : check todos Input : - target_path: \"./src\" - repository_name: \"user-service\" - todo_patterns: [\"FIXME\", \"BUG\"] Result : Identified 12 critical TODOs (FIXME/BUG patterns), provided solutions for immediate resolution Related Competencies \u00b6 review-code : Use for comprehensive code review after TODO resolution fix-code-smells : Apply to address code quality issues found in TODOs augment-code-unit-test : Create tests for TODO resolutions evolve-code-iteratively : Use for complex TODO resolutions requiring iteration Tips & Best Practices \u00b6 Start with FIXME and BUG patterns for highest priority items Use subset selection for large codebases (>50 TODOs) Review TODO context carefully before applying solutions Test each TODO resolution independently Track resolved TODOs to measure technical debt reduction Run periodically to prevent TODO accumulation Limitations \u00b6 Solutions require manual review and testing before application May not capture all context for complex TODOs Author information depends on comment format Large codebases may require multiple sessions Some TODOs may require architectural changes beyond code replacement","title":"Check TODOs In Code"},{"location":"skills/check-todos-in-code/description/#check-todos-in-code","text":"Source : core/competencies/developer/prompts/check-todos-in-code.md","title":"Check TODOs In Code"},{"location":"skills/check-todos-in-code/description/#overview","text":"Search and analyze TODO comments in codebase, assess validity, and generate complete code solutions with user decision tracking. Provides actionable resolution plan with actual replacement code.","title":"Overview"},{"location":"skills/check-todos-in-code/description/#purpose","text":"TODO comments accumulate in codebases over time, representing technical debt and deferred work. This competency systematically identifies, analyzes, and provides concrete solutions for TODOs, helping teams prioritize and resolve technical debt efficiently. Unlike simple TODO scanners, it provides actual code solutions and implementation guidance.","title":"Purpose"},{"location":"skills/check-todos-in-code/description/#usage","text":"Command : check todos Protocol : Propose-Act When to Use : - Before release to identify and resolve pending work - During technical debt cleanup initiatives - When onboarding to understand deferred work - For sprint planning to estimate TODO resolution effort - To track and prioritize technical debt systematically","title":"Usage"},{"location":"skills/check-todos-in-code/description/#parameters","text":"","title":"Parameters"},{"location":"skills/check-todos-in-code/description/#required-inputs","text":"target_path : Path to folder or repository to scan repository_name : Name of the repository being analyzed","title":"Required Inputs"},{"location":"skills/check-todos-in-code/description/#optional-inputs","text":"file_extensions : File extensions to include (defaults to common code files) todo_patterns : TODO patterns to search for (defaults to TODO, FIXME, HACK, XXX, BUG) save_document : Save resolution document (default: true) max_todos_threshold : Maximum TODOs to analyze in one session (default: 50)","title":"Optional Inputs"},{"location":"skills/check-todos-in-code/description/#context-requirements","text":"Access to codebase source files Ability to read and analyze code context around TODOs Optional: version control history for author information","title":"Context Requirements"},{"location":"skills/check-todos-in-code/description/#output","text":"Comprehensive TODO analysis with concrete solutions and implementation guidance. Deliverables : - TODO inventory organized by repository \u2192 folder \u2192 file hierarchy - Priority classification for each TODO (Critical, High, Medium, Low) - Actual replacement code solutions (not just recommendations) - Specific line ranges to replace - Implementation and testing instructions - Effort estimates and dependency identification Format : Markdown document following todo-resolution-template.md structure","title":"Output"},{"location":"skills/check-todos-in-code/description/#examples","text":"","title":"Examples"},{"location":"skills/check-todos-in-code/description/#example-1-full-repository-scan","text":"Scenario : Preparing for release, need to identify all pending TODOs Command : check todos Input : - target_path: \"./src\" - repository_name: \"payment-service\" Result : Found 23 TODOs, analyzed and prioritized with 5 critical items requiring immediate attention, complete with replacement code for each","title":"Example 1: Full Repository Scan"},{"location":"skills/check-todos-in-code/description/#example-2-focused-scan-with-subset","text":"Scenario : Large codebase with 150 TODOs, focusing on critical items Command : check todos Input : - target_path: \"./src\" - repository_name: \"user-service\" - todo_patterns: [\"FIXME\", \"BUG\"] Result : Identified 12 critical TODOs (FIXME/BUG patterns), provided solutions for immediate resolution","title":"Example 2: Focused Scan with Subset"},{"location":"skills/check-todos-in-code/description/#related-competencies","text":"review-code : Use for comprehensive code review after TODO resolution fix-code-smells : Apply to address code quality issues found in TODOs augment-code-unit-test : Create tests for TODO resolutions evolve-code-iteratively : Use for complex TODO resolutions requiring iteration","title":"Related Competencies"},{"location":"skills/check-todos-in-code/description/#tips-best-practices","text":"Start with FIXME and BUG patterns for highest priority items Use subset selection for large codebases (>50 TODOs) Review TODO context carefully before applying solutions Test each TODO resolution independently Track resolved TODOs to measure technical debt reduction Run periodically to prevent TODO accumulation","title":"Tips &amp; Best Practices"},{"location":"skills/check-todos-in-code/description/#limitations","text":"Solutions require manual review and testing before application May not capture all context for complex TODOs Author information depends on comment format Large codebases may require multiple sessions Some TODOs may require architectural changes beyond code replacement","title":"Limitations"},{"location":"skills/check-todos-in-code/tutorial/","text":"Step-by-Step Tutorial \u00b6 Check TODOs in Code: Step-by-Step Tutorial How to Execute the \"TODO Analysis and Resolution Planning\" Workflow This tutorial shows exactly how to search, analyze, and provide solutions for TODO comments with user decision tracking using the OLAF developer competency's check-todos-in-code functionality. This workflow systematically identifies and provides actionable solutions for technical debt items. Prerequisites \u00b6 OLAF framework properly installed and configured Codebase with TODO comments to analyze Repository or project folder to scan Basic understanding of code maintenance and technical debt concepts Write access to workspace for document generation Step-by-Step Instructions \u00b6 Step 1: Initiate TODO Analysis \u00b6 [Brief description: Start the comprehensive TODO analysis process by invoking the OLAF check-todos-in-code competency] User Action: Open your terminal or OLAF interface Navigate to or identify the repository/project directory to analyze Execute the OLAF check-todos-in-code competency using one of these methods: Direct invocation: olaf check-todos-in-code Via aliases: olaf check todos , olaf todo analysis , olaf scan todos OLAF Response: The system will prompt you to provide the required parameters for TODO analysis. Step 2: Provide Repository and Scan Parameters \u00b6 User Action: Specify the repository details and scanning preferences Required Parameters: - target_path: Path to folder or repository to scan (REQUIRED) - repository_name: Name of the repository being analyzed (REQUIRED) - file_extensions: File extensions to include (optional, defaults to common code files) - todo_patterns: TODO patterns to search for (optional, defaults to TODO, FIXME, HACK, XXX, BUG) - save_document: Save resolution document (optional, default: true) - max_todos_threshold: Maximum TODOs to analyze in one session (optional, default: 50) Provide Requirements/Parameters: target_path : [Example - we used \"/src/main/java/com/company/project\"] repository_name : [Example - we used \"e-commerce-backend\"] file_extensions : [Example - we used [\".java\", \".js\", \".py\"]] (optional) todo_patterns : [Example - we used [\"TODO\", \"FIXME\", \"BUG\", \"HACK\"]] (optional) save_document : [Example - we used \"true\"] (optional) Step 3: Initial Count and Subset Selection \u00b6 What OLAF Does: Executes quick TODO count across all specified file types Presents total count to user immediately Gets current timestamp for document generation Assesses if TODO count exceeds threshold (default: 50) User Action (if TODOs > threshold): Choose subset approach: Subset Options: 1. By Priority: Focus on FIXME/BUG patterns only (critical items) 2. By Folder: Choose specific folder or subfolder 3. By File Type: Limit to specific extensions 4. By Author: Focus on specific author's TODOs 5. By Date: Most recent TODOs only 6. Proceed Anyway: Analyze all (may be slow/incomplete) You Should See: Clear breakdown of TODO count with recommended subset options for manageability Step 4: Targeted Search and Context Extraction \u00b6 What OLAF Does: Executes targeted TODO search based on your subset choice Parses results by repository structure: Repo \u2192 Folder Path \u2192 File \u2192 Line Extracts TODO context including surrounding code (\u00b15 lines) Identifies author information if available in comments Organizes staging hierarchically for systematic analysis You Should See: Progress updates during search and context extraction phases Step 5: Comprehensive TODO Analysis \u00b6 What OLAF Does for Each TODO: Current validity assessment : Determines if TODO is still relevant Priority classification : \ud83d\udd25 Critical, \u26a0\ufe0f High, \ud83d\udcdd Medium, \ud83d\udca1 Low Actual replacement code solution : Complete, syntactically correct code (not just recommendations) Specific line ranges to replace : Exact locations for implementation Implementation and testing instructions : Step-by-step guidance Effort estimation : Time and complexity assessment Dependencies identification : Required changes or prerequisites You Should See: Detailed analysis with actionable solutions for each TODO item Step 6: Document Generation and User Decision Tracking \u00b6 User Action: Approve saving the TODO resolution document What OLAF Does: Loads the TODO resolution template Populates template with structured staging in repository hierarchy Includes user decision tracking sections for each TODO (defaults to \"NO\" for safety) Generates unique document: todo-resolution-{repo_name}-{timestamp}.md Saves document to workspace with complete analysis and solutions You Should See: Complete TODO resolution document with user decision tracking and implementation guidance Verification Checklist \u00b6 \u2705 Repository successfully scanned for TODO patterns \u2705 TODO count assessed and subset approach selected (if needed) \u2705 Each TODO analyzed with validity, priority, and solution \u2705 Actual replacement code provided (not just recommendations) \u2705 User decision tracking sections included for each TODO \u2705 TODO resolution document saved with unique identifier Troubleshooting \u00b6 If no TODOs are found: # Manual search to verify TODOs exist grep -r \"TODO\\|FIXME\\|HACK\\|XXX\\|BUG\" . --include=\"*.java\" --include=\"*.js\" --include=\"*.py\" find . -name \"*.java\" -exec grep -l \"TODO\" {} \\; If TODO count is overwhelming: Use subset selection by priority (focus on FIXME and BUG first) Limit analysis to specific critical folders (e.g., /src/main) Filter by file types that are most actively maintained If generated solutions seem incorrect: Review the surrounding code context provided Check that file extensions match the programming language Verify that TODO patterns were correctly identified Key Learning Points \u00b6 Hierarchical Organization: TODOs are organized by Repository \u2192 Folder \u2192 File structure for systematic resolution Actionable Solutions: Each TODO receives actual replacement code with specific line ranges, not just recommendations User Decision Control: All resolution decisions default to \"NO\" for safety, requiring explicit user approval for implementation Next Steps to Try \u00b6 Use the generated document to systematically address TODOs by priority Implement the provided solutions following the detailed instructions Track progress by updating user decisions from \"NO\" to \"YES\" as TODOs are resolved Set up regular TODO analysis to prevent technical debt accumulation Expected Timeline \u00b6 Total analysis time: 10-30 minutes (depending on TODO count and complexity) User input required: Repository details and subset selection (2-5 minutes) OLAF scanning time: TODO search and context extraction (3-10 minutes) Analysis and documentation: Solution generation and document creation (5-15 minutes)","title":"Step-by-Step Tutorial"},{"location":"skills/check-todos-in-code/tutorial/#step-by-step-tutorial","text":"Check TODOs in Code: Step-by-Step Tutorial How to Execute the \"TODO Analysis and Resolution Planning\" Workflow This tutorial shows exactly how to search, analyze, and provide solutions for TODO comments with user decision tracking using the OLAF developer competency's check-todos-in-code functionality. This workflow systematically identifies and provides actionable solutions for technical debt items.","title":"Step-by-Step Tutorial"},{"location":"skills/check-todos-in-code/tutorial/#prerequisites","text":"OLAF framework properly installed and configured Codebase with TODO comments to analyze Repository or project folder to scan Basic understanding of code maintenance and technical debt concepts Write access to workspace for document generation","title":"Prerequisites"},{"location":"skills/check-todos-in-code/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/check-todos-in-code/tutorial/#step-1-initiate-todo-analysis","text":"[Brief description: Start the comprehensive TODO analysis process by invoking the OLAF check-todos-in-code competency] User Action: Open your terminal or OLAF interface Navigate to or identify the repository/project directory to analyze Execute the OLAF check-todos-in-code competency using one of these methods: Direct invocation: olaf check-todos-in-code Via aliases: olaf check todos , olaf todo analysis , olaf scan todos OLAF Response: The system will prompt you to provide the required parameters for TODO analysis.","title":"Step 1: Initiate TODO Analysis"},{"location":"skills/check-todos-in-code/tutorial/#step-2-provide-repository-and-scan-parameters","text":"User Action: Specify the repository details and scanning preferences Required Parameters: - target_path: Path to folder or repository to scan (REQUIRED) - repository_name: Name of the repository being analyzed (REQUIRED) - file_extensions: File extensions to include (optional, defaults to common code files) - todo_patterns: TODO patterns to search for (optional, defaults to TODO, FIXME, HACK, XXX, BUG) - save_document: Save resolution document (optional, default: true) - max_todos_threshold: Maximum TODOs to analyze in one session (optional, default: 50) Provide Requirements/Parameters: target_path : [Example - we used \"/src/main/java/com/company/project\"] repository_name : [Example - we used \"e-commerce-backend\"] file_extensions : [Example - we used [\".java\", \".js\", \".py\"]] (optional) todo_patterns : [Example - we used [\"TODO\", \"FIXME\", \"BUG\", \"HACK\"]] (optional) save_document : [Example - we used \"true\"] (optional)","title":"Step 2: Provide Repository and Scan Parameters"},{"location":"skills/check-todos-in-code/tutorial/#step-3-initial-count-and-subset-selection","text":"What OLAF Does: Executes quick TODO count across all specified file types Presents total count to user immediately Gets current timestamp for document generation Assesses if TODO count exceeds threshold (default: 50) User Action (if TODOs > threshold): Choose subset approach: Subset Options: 1. By Priority: Focus on FIXME/BUG patterns only (critical items) 2. By Folder: Choose specific folder or subfolder 3. By File Type: Limit to specific extensions 4. By Author: Focus on specific author's TODOs 5. By Date: Most recent TODOs only 6. Proceed Anyway: Analyze all (may be slow/incomplete) You Should See: Clear breakdown of TODO count with recommended subset options for manageability","title":"Step 3: Initial Count and Subset Selection"},{"location":"skills/check-todos-in-code/tutorial/#step-4-targeted-search-and-context-extraction","text":"What OLAF Does: Executes targeted TODO search based on your subset choice Parses results by repository structure: Repo \u2192 Folder Path \u2192 File \u2192 Line Extracts TODO context including surrounding code (\u00b15 lines) Identifies author information if available in comments Organizes staging hierarchically for systematic analysis You Should See: Progress updates during search and context extraction phases","title":"Step 4: Targeted Search and Context Extraction"},{"location":"skills/check-todos-in-code/tutorial/#step-5-comprehensive-todo-analysis","text":"What OLAF Does for Each TODO: Current validity assessment : Determines if TODO is still relevant Priority classification : \ud83d\udd25 Critical, \u26a0\ufe0f High, \ud83d\udcdd Medium, \ud83d\udca1 Low Actual replacement code solution : Complete, syntactically correct code (not just recommendations) Specific line ranges to replace : Exact locations for implementation Implementation and testing instructions : Step-by-step guidance Effort estimation : Time and complexity assessment Dependencies identification : Required changes or prerequisites You Should See: Detailed analysis with actionable solutions for each TODO item","title":"Step 5: Comprehensive TODO Analysis"},{"location":"skills/check-todos-in-code/tutorial/#step-6-document-generation-and-user-decision-tracking","text":"User Action: Approve saving the TODO resolution document What OLAF Does: Loads the TODO resolution template Populates template with structured staging in repository hierarchy Includes user decision tracking sections for each TODO (defaults to \"NO\" for safety) Generates unique document: todo-resolution-{repo_name}-{timestamp}.md Saves document to workspace with complete analysis and solutions You Should See: Complete TODO resolution document with user decision tracking and implementation guidance","title":"Step 6: Document Generation and User Decision Tracking"},{"location":"skills/check-todos-in-code/tutorial/#verification-checklist","text":"\u2705 Repository successfully scanned for TODO patterns \u2705 TODO count assessed and subset approach selected (if needed) \u2705 Each TODO analyzed with validity, priority, and solution \u2705 Actual replacement code provided (not just recommendations) \u2705 User decision tracking sections included for each TODO \u2705 TODO resolution document saved with unique identifier","title":"Verification Checklist"},{"location":"skills/check-todos-in-code/tutorial/#troubleshooting","text":"If no TODOs are found: # Manual search to verify TODOs exist grep -r \"TODO\\|FIXME\\|HACK\\|XXX\\|BUG\" . --include=\"*.java\" --include=\"*.js\" --include=\"*.py\" find . -name \"*.java\" -exec grep -l \"TODO\" {} \\; If TODO count is overwhelming: Use subset selection by priority (focus on FIXME and BUG first) Limit analysis to specific critical folders (e.g., /src/main) Filter by file types that are most actively maintained If generated solutions seem incorrect: Review the surrounding code context provided Check that file extensions match the programming language Verify that TODO patterns were correctly identified","title":"Troubleshooting"},{"location":"skills/check-todos-in-code/tutorial/#key-learning-points","text":"Hierarchical Organization: TODOs are organized by Repository \u2192 Folder \u2192 File structure for systematic resolution Actionable Solutions: Each TODO receives actual replacement code with specific line ranges, not just recommendations User Decision Control: All resolution decisions default to \"NO\" for safety, requiring explicit user approval for implementation","title":"Key Learning Points"},{"location":"skills/check-todos-in-code/tutorial/#next-steps-to-try","text":"Use the generated document to systematically address TODOs by priority Implement the provided solutions following the detailed instructions Track progress by updating user decisions from \"NO\" to \"YES\" as TODOs are resolved Set up regular TODO analysis to prevent technical debt accumulation","title":"Next Steps to Try"},{"location":"skills/check-todos-in-code/tutorial/#expected-timeline","text":"Total analysis time: 10-30 minutes (depending on TODO count and complexity) User input required: Repository details and subset selection (2-5 minutes) OLAF scanning time: TODO search and context extraction (3-10 minutes) Analysis and documentation: Solution generation and document creation (5-15 minutes)","title":"Expected Timeline"},{"location":"skills/code-in-go/description/","text":"Code in Go \u00b6 Overview \u00b6 The Code in Go skill provides Go development assistance while strictly enforcing team practices. It loads coding standards, Go-specific guidance, and Git workflow practices from the local .olaf/data/practices/ folder and ensures all code assistance adheres to these standards. Key Features \u00b6 Practice Enforcement : Automatically loads and enforces all relevant practices SOLID Principles : Ensures code follows SRP, Dependency Injection, and other SOLID principles Go Idioms : Applies Go-specific best practices for error handling, naming, and structure Git Workflow : Verifies worktree usage, requires a new branch before coding, and guides toward small, frequent commits Violation Alerts : Warns when requested code would violate loaded practices Phased Delivery : Collects requirements, performs impact analysis, proposes a solution, and asks for explicit approval before generating code Practices Loaded \u00b6 Universal Coding Standards ( standards/universal-coding-standards.md ) Single Responsibility Principle Dependency Injection Function size and complexity limits Naming and readability Go Coding Guidance ( guidances/coding/go-coding-guidance.md ) Go idioms and conventions Error handling patterns Project structure Testing practices Git Workflow Guidance ( guidances/git/git-workflow-guidance.md ) Worktree setup before coding Small, focused commits Commit message format Branch strategy When to Use \u00b6 Use this skill when: - Starting a Go coding session - Implementing new Go features - Refactoring existing Go code - You want strict enforcement of team practices Trigger Phrases \u00b6 \"olaf code in go\" \"olaf go coding\" \"olaf golang assistance\" \"olaf go development\"","title":"Code in Go"},{"location":"skills/code-in-go/description/#code-in-go","text":"","title":"Code in Go"},{"location":"skills/code-in-go/description/#overview","text":"The Code in Go skill provides Go development assistance while strictly enforcing team practices. It loads coding standards, Go-specific guidance, and Git workflow practices from the local .olaf/data/practices/ folder and ensures all code assistance adheres to these standards.","title":"Overview"},{"location":"skills/code-in-go/description/#key-features","text":"Practice Enforcement : Automatically loads and enforces all relevant practices SOLID Principles : Ensures code follows SRP, Dependency Injection, and other SOLID principles Go Idioms : Applies Go-specific best practices for error handling, naming, and structure Git Workflow : Verifies worktree usage, requires a new branch before coding, and guides toward small, frequent commits Violation Alerts : Warns when requested code would violate loaded practices Phased Delivery : Collects requirements, performs impact analysis, proposes a solution, and asks for explicit approval before generating code","title":"Key Features"},{"location":"skills/code-in-go/description/#practices-loaded","text":"Universal Coding Standards ( standards/universal-coding-standards.md ) Single Responsibility Principle Dependency Injection Function size and complexity limits Naming and readability Go Coding Guidance ( guidances/coding/go-coding-guidance.md ) Go idioms and conventions Error handling patterns Project structure Testing practices Git Workflow Guidance ( guidances/git/git-workflow-guidance.md ) Worktree setup before coding Small, focused commits Commit message format Branch strategy","title":"Practices Loaded"},{"location":"skills/code-in-go/description/#when-to-use","text":"Use this skill when: - Starting a Go coding session - Implementing new Go features - Refactoring existing Go code - You want strict enforcement of team practices","title":"When to Use"},{"location":"skills/code-in-go/description/#trigger-phrases","text":"\"olaf code in go\" \"olaf go coding\" \"olaf golang assistance\" \"olaf go development\"","title":"Trigger Phrases"},{"location":"skills/code-in-go/tutorial/","text":"Code in Go - Tutorial \u00b6 Quick Start \u00b6 Step 1: Invoke the Skill \u00b6 olaf code in go The skill will: 1. Load all practice files 2. Check your Git worktree status 3. Be ready to assist with Go coding Step 2: Describe Your Task \u00b6 Tell the skill what you want to implement: I need to create a User service that fetches users from a database Step 3: Follow the Guidance \u00b6 The skill will: - Suggest setting up a worktree if you haven't - Provide code that follows all loaded practices - Remind you to commit after changes Example Session \u00b6 User : olaf code in go - I need to add a function to validate email addresses Skill Response : \ud83d\udd27 Go Coding Session Active Loaded practices: - Universal Coding Standards (SOLID, DI, complexity limits) - Go Coding Guidance (idioms, error handling, testing) - Git Workflow Guidance (worktree, small commits) ## Worktree Check [Verifies you're in a worktree or guides setup] ## Implementation Here's an email validation function following our practices: ```go package validation import ( \"fmt\" \"regexp\" ) var emailRegex = regexp.MustCompile(`^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$`) // ValidateEmail checks if the provided email address is valid. // Returns an error with context if validation fails. func ValidateEmail(email string) error { if email == \"\" { return fmt.Errorf(\"validate email: %w\", ErrEmptyEmail) } if !emailRegex.MatchString(email) { return fmt.Errorf(\"validate email %q: %w\", email, ErrInvalidFormat) } return nil } Commit Suggestion \u00b6 feat(validation): add email validation function Implements RFC 5322 basic email format validation. Next Steps \u00b6 Add unit tests using table-driven pattern Commit this change Continue with next validation function ## Practice Violation Example If you request code that violates practices: **User**: Can you add a function that ignores the error from the database call? **Skill Response**: \u26a0\ufe0f Practice Violation Detected The requested approach violates: Go Coding Guidance - Error Handling Guidance says: \"Always check errors: Never ignore returned errors with _\" Compliant alternative: func GetUser(ctx context.Context, id string) (*User, error) { user, err := db.FindUser(ctx, id) if err != nil { return nil, fmt.Errorf(\"get user %s: %w\", id, err) } return user, nil } This properly handles and wraps the error with context. ``` Tips \u00b6 Always start with worktree : The skill will remind you, but it's faster to set up beforehand Describe intent, not implementation : Let the skill suggest practice-compliant approaches Commit frequently : Follow the skill's commit suggestions to maintain small changesets Ask about violations : If you disagree with a practice, discuss it - the skill will explain the rationale","title":"Code in Go - Tutorial"},{"location":"skills/code-in-go/tutorial/#code-in-go-tutorial","text":"","title":"Code in Go - Tutorial"},{"location":"skills/code-in-go/tutorial/#quick-start","text":"","title":"Quick Start"},{"location":"skills/code-in-go/tutorial/#step-1-invoke-the-skill","text":"olaf code in go The skill will: 1. Load all practice files 2. Check your Git worktree status 3. Be ready to assist with Go coding","title":"Step 1: Invoke the Skill"},{"location":"skills/code-in-go/tutorial/#step-2-describe-your-task","text":"Tell the skill what you want to implement: I need to create a User service that fetches users from a database","title":"Step 2: Describe Your Task"},{"location":"skills/code-in-go/tutorial/#step-3-follow-the-guidance","text":"The skill will: - Suggest setting up a worktree if you haven't - Provide code that follows all loaded practices - Remind you to commit after changes","title":"Step 3: Follow the Guidance"},{"location":"skills/code-in-go/tutorial/#example-session","text":"User : olaf code in go - I need to add a function to validate email addresses Skill Response : \ud83d\udd27 Go Coding Session Active Loaded practices: - Universal Coding Standards (SOLID, DI, complexity limits) - Go Coding Guidance (idioms, error handling, testing) - Git Workflow Guidance (worktree, small commits) ## Worktree Check [Verifies you're in a worktree or guides setup] ## Implementation Here's an email validation function following our practices: ```go package validation import ( \"fmt\" \"regexp\" ) var emailRegex = regexp.MustCompile(`^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$`) // ValidateEmail checks if the provided email address is valid. // Returns an error with context if validation fails. func ValidateEmail(email string) error { if email == \"\" { return fmt.Errorf(\"validate email: %w\", ErrEmptyEmail) } if !emailRegex.MatchString(email) { return fmt.Errorf(\"validate email %q: %w\", email, ErrInvalidFormat) } return nil }","title":"Example Session"},{"location":"skills/code-in-go/tutorial/#commit-suggestion","text":"feat(validation): add email validation function Implements RFC 5322 basic email format validation.","title":"Commit Suggestion"},{"location":"skills/code-in-go/tutorial/#next-steps","text":"Add unit tests using table-driven pattern Commit this change Continue with next validation function ## Practice Violation Example If you request code that violates practices: **User**: Can you add a function that ignores the error from the database call? **Skill Response**: \u26a0\ufe0f Practice Violation Detected The requested approach violates: Go Coding Guidance - Error Handling Guidance says: \"Always check errors: Never ignore returned errors with _\" Compliant alternative: func GetUser(ctx context.Context, id string) (*User, error) { user, err := db.FindUser(ctx, id) if err != nil { return nil, fmt.Errorf(\"get user %s: %w\", id, err) } return user, nil } This properly handles and wraps the error with context. ```","title":"Next Steps"},{"location":"skills/code-in-go/tutorial/#tips","text":"Always start with worktree : The skill will remind you, but it's faster to set up beforehand Describe intent, not implementation : Let the skill suggest practice-compliant approaches Commit frequently : Follow the skill's commit suggestions to maintain small changesets Ask about violations : If you disagree with a practice, discuss it - the skill will explain the rationale","title":"Tips"},{"location":"skills/code-in-rust/description/","text":"Code in Rust \u00b6 Overview \u00b6 The Code in Rust skill provides Rust development assistance while strictly enforcing team practices. It loads coding standards, Rust-specific guidance, and Git workflow practices from the local .olaf/data/practices/ folder and ensures all code assistance adheres to these standards. Key Features \u00b6 Practice Enforcement : Automatically loads and enforces all relevant practices SOLID Principles : Ensures code follows SRP, Dependency Injection, and other SOLID principles Rust Idioms : Applies Rust best practices for error handling, naming, module structure, and ownership Git Workflow : Verifies worktree usage, requires a new branch before coding, and guides toward small, frequent commits Violation Alerts : Warns when requested code would violate loaded practices Phased Delivery : Collects requirements, performs impact analysis, proposes a solution, and asks for explicit approval before generating code Practices Loaded \u00b6 Universal Coding Standards ( standards/universal-coding-standards.md ) Single Responsibility Principle Dependency Injection Function size and complexity limits Naming and readability Rust Coding Guidance ( guidances/coding/rust-coding-guidance.md ) Rust idioms and conventions Error handling patterns Project structure Testing practices Git Workflow Guidance ( guidances/git/git-workflow-guidance.md ) Worktree setup before coding Small, focused commits Commit message format Branch strategy When to Use \u00b6 Use this skill when: - Starting a Rust coding session - Implementing new Rust features - Refactoring existing Rust code - You want strict enforcement of team practices Trigger Phrases \u00b6 \"olaf code in rust\" \"olaf rust coding\" \"olaf rust assistance\" \"olaf rust development\"","title":"Code in Rust"},{"location":"skills/code-in-rust/description/#code-in-rust","text":"","title":"Code in Rust"},{"location":"skills/code-in-rust/description/#overview","text":"The Code in Rust skill provides Rust development assistance while strictly enforcing team practices. It loads coding standards, Rust-specific guidance, and Git workflow practices from the local .olaf/data/practices/ folder and ensures all code assistance adheres to these standards.","title":"Overview"},{"location":"skills/code-in-rust/description/#key-features","text":"Practice Enforcement : Automatically loads and enforces all relevant practices SOLID Principles : Ensures code follows SRP, Dependency Injection, and other SOLID principles Rust Idioms : Applies Rust best practices for error handling, naming, module structure, and ownership Git Workflow : Verifies worktree usage, requires a new branch before coding, and guides toward small, frequent commits Violation Alerts : Warns when requested code would violate loaded practices Phased Delivery : Collects requirements, performs impact analysis, proposes a solution, and asks for explicit approval before generating code","title":"Key Features"},{"location":"skills/code-in-rust/description/#practices-loaded","text":"Universal Coding Standards ( standards/universal-coding-standards.md ) Single Responsibility Principle Dependency Injection Function size and complexity limits Naming and readability Rust Coding Guidance ( guidances/coding/rust-coding-guidance.md ) Rust idioms and conventions Error handling patterns Project structure Testing practices Git Workflow Guidance ( guidances/git/git-workflow-guidance.md ) Worktree setup before coding Small, focused commits Commit message format Branch strategy","title":"Practices Loaded"},{"location":"skills/code-in-rust/description/#when-to-use","text":"Use this skill when: - Starting a Rust coding session - Implementing new Rust features - Refactoring existing Rust code - You want strict enforcement of team practices","title":"When to Use"},{"location":"skills/code-in-rust/description/#trigger-phrases","text":"\"olaf code in rust\" \"olaf rust coding\" \"olaf rust assistance\" \"olaf rust development\"","title":"Trigger Phrases"},{"location":"skills/code-in-rust/tutorial/","text":"Code in Rust - Tutorial \u00b6 Quick Start \u00b6 Step 1: Invoke the Skill \u00b6 olaf code in rust The skill will: 1. Load all practice files 2. Check your Git worktree status 3. Be ready to assist with Rust coding Step 2: Describe Your Task \u00b6 Tell the skill what you want to implement: I need to add a repository trait and service that fetches users from a database Step 3: Follow the Guidance \u00b6 The skill will: - Suggest setting up a worktree if you haven't - Provide code that follows all loaded practices - Remind you to commit after changes Example Session \u00b6 User : olaf code in rust - I need to validate email addresses in a request model Skill Response : \ud83d\udd27 Rust Coding Session Active Loaded practices: - Universal Coding Standards (SOLID, DI, complexity limits) - Rust Coding Guidance (idioms, error handling, testing) - Git Workflow Guidance (worktree, small commits) ## Worktree Check [Verifies you're in a worktree or guides setup] ## Implementation Here's a small email validation helper following our practices: ```rust use anyhow::{anyhow, Result}; pub fn validate_email(email: &str) -> Result<()> { if email.trim().is_empty() { return Err(anyhow!(\"validate email: empty value\")); } if !email.contains('@') { return Err(anyhow!(\"validate email: missing '@'\")); } Ok(()) } Commit Suggestion \u00b6 feat(validation): add basic email validation helper - Validate non-empty email and presence of '@' Next Steps \u00b6 Add unit tests (table-driven style) Run cargo fmt and cargo clippy Commit this change ## Practice Violation Example If you request code that violates practices: **User**: Can you just unwrap the DB result to keep it short? **Skill Response**: \u26a0\ufe0f Practice Violation Detected The requested approach violates: Rust Coding Guidance - Error Handling Guidance says: \"Avoid unwrap/expect except in tests or unreachable states\" Compliant alternative: pub fn get_user(id: &str) -> anyhow::Result<User> { let user = db.find_user(id).context(\"find user\")?; Ok(user) } This returns a Result and adds error context. ``` Tips \u00b6 Always start with worktree : The skill will remind you, but it's faster to set up beforehand Describe intent, not implementation : Let the skill suggest practice-compliant approaches Commit frequently : Follow the skill's commit suggestions to maintain small changesets Ask about violations : If you disagree with a practice, discuss it - the skill will explain the rationale","title":"Code in Rust - Tutorial"},{"location":"skills/code-in-rust/tutorial/#code-in-rust-tutorial","text":"","title":"Code in Rust - Tutorial"},{"location":"skills/code-in-rust/tutorial/#quick-start","text":"","title":"Quick Start"},{"location":"skills/code-in-rust/tutorial/#step-1-invoke-the-skill","text":"olaf code in rust The skill will: 1. Load all practice files 2. Check your Git worktree status 3. Be ready to assist with Rust coding","title":"Step 1: Invoke the Skill"},{"location":"skills/code-in-rust/tutorial/#step-2-describe-your-task","text":"Tell the skill what you want to implement: I need to add a repository trait and service that fetches users from a database","title":"Step 2: Describe Your Task"},{"location":"skills/code-in-rust/tutorial/#step-3-follow-the-guidance","text":"The skill will: - Suggest setting up a worktree if you haven't - Provide code that follows all loaded practices - Remind you to commit after changes","title":"Step 3: Follow the Guidance"},{"location":"skills/code-in-rust/tutorial/#example-session","text":"User : olaf code in rust - I need to validate email addresses in a request model Skill Response : \ud83d\udd27 Rust Coding Session Active Loaded practices: - Universal Coding Standards (SOLID, DI, complexity limits) - Rust Coding Guidance (idioms, error handling, testing) - Git Workflow Guidance (worktree, small commits) ## Worktree Check [Verifies you're in a worktree or guides setup] ## Implementation Here's a small email validation helper following our practices: ```rust use anyhow::{anyhow, Result}; pub fn validate_email(email: &str) -> Result<()> { if email.trim().is_empty() { return Err(anyhow!(\"validate email: empty value\")); } if !email.contains('@') { return Err(anyhow!(\"validate email: missing '@'\")); } Ok(()) }","title":"Example Session"},{"location":"skills/code-in-rust/tutorial/#commit-suggestion","text":"feat(validation): add basic email validation helper - Validate non-empty email and presence of '@'","title":"Commit Suggestion"},{"location":"skills/code-in-rust/tutorial/#next-steps","text":"Add unit tests (table-driven style) Run cargo fmt and cargo clippy Commit this change ## Practice Violation Example If you request code that violates practices: **User**: Can you just unwrap the DB result to keep it short? **Skill Response**: \u26a0\ufe0f Practice Violation Detected The requested approach violates: Rust Coding Guidance - Error Handling Guidance says: \"Avoid unwrap/expect except in tests or unreachable states\" Compliant alternative: pub fn get_user(id: &str) -> anyhow::Result<User> { let user = db.find_user(id).context(\"find user\")?; Ok(user) } This returns a Result and adds error context. ```","title":"Next Steps"},{"location":"skills/code-in-rust/tutorial/#tips","text":"Always start with worktree : The skill will remind you, but it's faster to set up beforehand Describe intent, not implementation : Let the skill suggest practice-compliant approaches Commit frequently : Follow the skill's commit suggestions to maintain small changesets Ask about violations : If you disagree with a practice, discuss it - the skill will explain the rationale","title":"Tips"},{"location":"skills/convert-prompt-to-skill/description/","text":"Convert Prompt to Skill \u00b6 Overview \u00b6 Convert Prompt to Skill turns one or more existing prompt files (legacy prompts, external prompts, ad-hoc docs) into a new skill folder that matches the current OLAF skill layout. It preserves the original intent while restructuring it into a single skill.md entry point, plus docs/ and any optional component folders (templates/tools/helpers/kb) as needed. Purpose \u00b6 Teams often have valuable prompts that are: - not written as OLAF skills - missing clear input parameters and success criteria - embedding templates inline instead of referencing external files This skill provides a repeatable conversion workflow so your skill library stays consistent and maintainable. Usage \u00b6 Skill : convert-prompt-to-skill Protocol : Propose-Confirm-Act Use this when you want to create a new skill from existing prompt material rather than starting from scratch. Parameters \u00b6 Required Inputs \u00b6 existing_prompt_path : path or list of paths to source prompt file(s) target_plugin : plugin name to assign the created skill to Optional Inputs \u00b6 skill_name : new skill folder name (kebab-case, max 4 words) user_request : extra constraints (what to preserve, what to change) needs_templates/tools/helpers/kb (+ corresponding lists): whether to create optional component folders Output \u00b6 Creates a new skill folder at the repo root: [skill_name]/skill.md [skill_name]/docs/description.md [skill_name]/docs/tutorial.md Optional folders created only when requested: - templates/ , tools/ , helpers/ , kb/ The new skill.md frontmatter includes plugin assignment ( plugins: [target_plugin] ). Related Skills \u00b6 create-skill : create a brand new skill without a source prompt check-prompt-compliance : validate the converted skill.md quality and conventions Limitations \u00b6 Conversion quality depends on the clarity of the source prompt(s) Some prompts may require follow-up iterations to clarify missing inputs/outputs","title":"Convert Prompt to Skill"},{"location":"skills/convert-prompt-to-skill/description/#convert-prompt-to-skill","text":"","title":"Convert Prompt to Skill"},{"location":"skills/convert-prompt-to-skill/description/#overview","text":"Convert Prompt to Skill turns one or more existing prompt files (legacy prompts, external prompts, ad-hoc docs) into a new skill folder that matches the current OLAF skill layout. It preserves the original intent while restructuring it into a single skill.md entry point, plus docs/ and any optional component folders (templates/tools/helpers/kb) as needed.","title":"Overview"},{"location":"skills/convert-prompt-to-skill/description/#purpose","text":"Teams often have valuable prompts that are: - not written as OLAF skills - missing clear input parameters and success criteria - embedding templates inline instead of referencing external files This skill provides a repeatable conversion workflow so your skill library stays consistent and maintainable.","title":"Purpose"},{"location":"skills/convert-prompt-to-skill/description/#usage","text":"Skill : convert-prompt-to-skill Protocol : Propose-Confirm-Act Use this when you want to create a new skill from existing prompt material rather than starting from scratch.","title":"Usage"},{"location":"skills/convert-prompt-to-skill/description/#parameters","text":"","title":"Parameters"},{"location":"skills/convert-prompt-to-skill/description/#required-inputs","text":"existing_prompt_path : path or list of paths to source prompt file(s) target_plugin : plugin name to assign the created skill to","title":"Required Inputs"},{"location":"skills/convert-prompt-to-skill/description/#optional-inputs","text":"skill_name : new skill folder name (kebab-case, max 4 words) user_request : extra constraints (what to preserve, what to change) needs_templates/tools/helpers/kb (+ corresponding lists): whether to create optional component folders","title":"Optional Inputs"},{"location":"skills/convert-prompt-to-skill/description/#output","text":"Creates a new skill folder at the repo root: [skill_name]/skill.md [skill_name]/docs/description.md [skill_name]/docs/tutorial.md Optional folders created only when requested: - templates/ , tools/ , helpers/ , kb/ The new skill.md frontmatter includes plugin assignment ( plugins: [target_plugin] ).","title":"Output"},{"location":"skills/convert-prompt-to-skill/description/#related-skills","text":"create-skill : create a brand new skill without a source prompt check-prompt-compliance : validate the converted skill.md quality and conventions","title":"Related Skills"},{"location":"skills/convert-prompt-to-skill/description/#limitations","text":"Conversion quality depends on the clarity of the source prompt(s) Some prompts may require follow-up iterations to clarify missing inputs/outputs","title":"Limitations"},{"location":"skills/convert-prompt-to-skill/tutorial/","text":"Tutorial: Convert Prompt to Skill \u00b6 Overview \u00b6 This tutorial walks through converting one or more existing prompt files into a new OLAF skill folder ( skill.md + docs + optional components). Prerequisites \u00b6 You have at least one prompt file to convert You know which plugin should own the new skill (the target_plugin value) Estimated Time \u00b6 15-30 minutes (depends on prompt complexity) Steps \u00b6 Step 1: Provide Source Prompt Path(s) \u00b6 Give the file path (or list of file paths) for the prompt(s) you want to convert. Step 2: Provide Target Plugin \u00b6 Specify the plugin to assign the new skill to: 1. existing plugin name, or 2. a new plugin name (it will be added to .olaf/plugins.json ) Step 3: Provide Skill Name (Optional) \u00b6 If you don\u2019t provide one, the conversion will propose a kebab-case name (max 4 words). Step 4: Decide on Optional Components \u00b6 Answer whether the new skill needs any of: 1. templates 2. tools 3. helpers 4. knowledge base files Only the requested component folders/files are created. Step 5: Review the Proposed Skill \u00b6 Review the proposed new skill folder: - skill.md matches the skill template structure - external templates are referenced, not embedded - error handling and success criteria are explicit Step 6: Confirm and Generate \u00b6 Approve the conversion (Propose-Confirm-Act), then generate the skill folder and files. Verification Checklist \u00b6 [ ] New folder created at repo root with the expected name [ ] skill.md exists and is the main entry point [ ] docs/description.md exists [ ] docs/tutorial.md exists [ ] Optional component folders only exist if requested [ ] Skill plugin assignment recorded in skill.md metadata and .olaf/plugins.json Troubleshooting \u00b6 Source file not found : verify the path(s) and try again Skill name conflict : choose a different kebab-case name Unclear prompt intent : add user_request guidance (what to preserve/change) Next Steps \u00b6 Run check-prompt-compliance on the generated skill.md Test the skill with a real example invocation","title":"Tutorial: Convert Prompt to Skill"},{"location":"skills/convert-prompt-to-skill/tutorial/#tutorial-convert-prompt-to-skill","text":"","title":"Tutorial: Convert Prompt to Skill"},{"location":"skills/convert-prompt-to-skill/tutorial/#overview","text":"This tutorial walks through converting one or more existing prompt files into a new OLAF skill folder ( skill.md + docs + optional components).","title":"Overview"},{"location":"skills/convert-prompt-to-skill/tutorial/#prerequisites","text":"You have at least one prompt file to convert You know which plugin should own the new skill (the target_plugin value)","title":"Prerequisites"},{"location":"skills/convert-prompt-to-skill/tutorial/#estimated-time","text":"15-30 minutes (depends on prompt complexity)","title":"Estimated Time"},{"location":"skills/convert-prompt-to-skill/tutorial/#steps","text":"","title":"Steps"},{"location":"skills/convert-prompt-to-skill/tutorial/#step-1-provide-source-prompt-paths","text":"Give the file path (or list of file paths) for the prompt(s) you want to convert.","title":"Step 1: Provide Source Prompt Path(s)"},{"location":"skills/convert-prompt-to-skill/tutorial/#step-2-provide-target-plugin","text":"Specify the plugin to assign the new skill to: 1. existing plugin name, or 2. a new plugin name (it will be added to .olaf/plugins.json )","title":"Step 2: Provide Target Plugin"},{"location":"skills/convert-prompt-to-skill/tutorial/#step-3-provide-skill-name-optional","text":"If you don\u2019t provide one, the conversion will propose a kebab-case name (max 4 words).","title":"Step 3: Provide Skill Name (Optional)"},{"location":"skills/convert-prompt-to-skill/tutorial/#step-4-decide-on-optional-components","text":"Answer whether the new skill needs any of: 1. templates 2. tools 3. helpers 4. knowledge base files Only the requested component folders/files are created.","title":"Step 4: Decide on Optional Components"},{"location":"skills/convert-prompt-to-skill/tutorial/#step-5-review-the-proposed-skill","text":"Review the proposed new skill folder: - skill.md matches the skill template structure - external templates are referenced, not embedded - error handling and success criteria are explicit","title":"Step 5: Review the Proposed Skill"},{"location":"skills/convert-prompt-to-skill/tutorial/#step-6-confirm-and-generate","text":"Approve the conversion (Propose-Confirm-Act), then generate the skill folder and files.","title":"Step 6: Confirm and Generate"},{"location":"skills/convert-prompt-to-skill/tutorial/#verification-checklist","text":"[ ] New folder created at repo root with the expected name [ ] skill.md exists and is the main entry point [ ] docs/description.md exists [ ] docs/tutorial.md exists [ ] Optional component folders only exist if requested [ ] Skill plugin assignment recorded in skill.md metadata and .olaf/plugins.json","title":"Verification Checklist"},{"location":"skills/convert-prompt-to-skill/tutorial/#troubleshooting","text":"Source file not found : verify the path(s) and try again Skill name conflict : choose a different kebab-case name Unclear prompt intent : add user_request guidance (what to preserve/change)","title":"Troubleshooting"},{"location":"skills/convert-prompt-to-skill/tutorial/#next-steps","text":"Run check-prompt-compliance on the generated skill.md Test the skill with a real example invocation","title":"Next Steps"},{"location":"skills/create-decision-record/description/","text":"Create Decision Record \u00b6 Overview \u00b6 Creates structured decision records following a standardized template to document important project, architectural, business, and technical decisions with full traceability and stakeholder tracking. Purpose \u00b6 Project teams need to maintain a clear record of why decisions were made, what alternatives were considered, and who was involved. This competency solves the problem of lost institutional knowledge by creating formal decision records that capture context, rationale, and outcomes in a consistent format that can be referenced throughout the project lifecycle. Usage \u00b6 Command : create decision record Protocol : Propose-Confirm-Act When to Use : Use this competency whenever a significant decision needs to be documented, including architectural choices, project direction changes, business strategy decisions, technical implementations, security policies, or any decision that will impact the project's future direction or stakeholders. Parameters \u00b6 Required Inputs \u00b6 title : Concise description of the decision being made type : Category of decision (Architecture, Project, Business, Functional, People, Technical, Security, or Other) context : Background information and problem statement that led to this decision drivers : Key factors, constraints, or requirements influencing the decision options : Alternative options that were considered, including pros and cons for each decision_makers : Individuals responsible for making the final decision stakeholders : Parties affected by or interested in this decision Optional Inputs \u00b6 status : Current status of the decision (Proposed, Accepted, Replaced, Superseded) - defaults to \"Proposed\" decision : The selected option if already determined (can be left blank for proposed decisions) Context Requirements \u00b6 Access to decision records directory ( .olaf/data/product/decision-records/ ) Access to decision records register ( .olaf/data/product/decision-records/decision-records-register.md ) Access to changelog register for tracking the creation Decision record template available at competency templates folder Output \u00b6 Deliverables : - New decision record file with unique ID (DR-YYYYMMDD-NN format) - Updated decision records register with new entry - Changelog entry documenting the record creation Format : Markdown file following the standard decision record template structure with metadata, context, options analysis, decision rationale, and consequences sections. Examples \u00b6 Example 1: Architecture Decision \u00b6 Scenario : Team needs to decide between microservices and monolithic architecture for a new application Command : create decision record Input : Title: Application Architecture Pattern Selection Type: Architecture Context: Building new customer portal with expected growth to 100K users Drivers: Scalability requirements, team expertise, deployment complexity, maintenance costs Options: 1. Microservices - Better scalability but higher complexity 2. Monolithic - Simpler to start but harder to scale 3. Modular monolith - Middle ground approach Decision Makers: CTO, Lead Architect, Engineering Manager Stakeholders: Development team, DevOps team, Product team Result : Created DR-20251027-01.md with full decision documentation, updated register, and changelog entry Example 2: Project Decision \u00b6 Scenario : Deciding whether to postpone a feature to meet release deadline Command : create decision record Input : Title: Q4 Feature Scope Reduction Type: Project Status: Proposed Context: Current sprint velocity indicates we'll miss Q4 release date with all planned features Drivers: Release deadline commitment, customer expectations, technical debt concerns Options: 1. Postpone advanced reporting feature to Q1 2. Extend deadline by 2 weeks 3. Add resources to complete on time Decision Makers: Product Owner, Project Manager Stakeholders: Sales team, Customer Success, Development team Result : Created decision record for team review and approval before finalizing Related Competencies \u00b6 create-changelog-entry : Use after creating a decision record to log the activity in the project changelog review-progress : Decision records are reviewed during progress assessments to track decision outcomes create-job : Decisions often lead to new work items that need to be tracked as jobs store-conversation-record : Related decision discussions can be stored for additional context Tips & Best Practices \u00b6 Document decisions as close to the decision-making moment as possible while context is fresh Include all seriously considered alternatives, not just the winner - this prevents revisiting rejected options Be specific about drivers and constraints - vague rationale leads to confusion later Update decision status when circumstances change (e.g., from Proposed to Accepted, or Accepted to Superseded) Link related decisions together to show decision evolution over time Keep decision records concise but complete - aim for clarity over comprehensiveness Limitations \u00b6 Requires manual input of decision details - does not automatically extract from meeting notes or conversations Does not automatically notify stakeholders - notification must be handled separately Cannot retroactively create decision records with past dates - uses current timestamp Does not validate that all stakeholders have been consulted before recording the decision Source : core/competencies/project-manager/prompts/create-decision-record.md","title":"Create Decision Record"},{"location":"skills/create-decision-record/description/#create-decision-record","text":"","title":"Create Decision Record"},{"location":"skills/create-decision-record/description/#overview","text":"Creates structured decision records following a standardized template to document important project, architectural, business, and technical decisions with full traceability and stakeholder tracking.","title":"Overview"},{"location":"skills/create-decision-record/description/#purpose","text":"Project teams need to maintain a clear record of why decisions were made, what alternatives were considered, and who was involved. This competency solves the problem of lost institutional knowledge by creating formal decision records that capture context, rationale, and outcomes in a consistent format that can be referenced throughout the project lifecycle.","title":"Purpose"},{"location":"skills/create-decision-record/description/#usage","text":"Command : create decision record Protocol : Propose-Confirm-Act When to Use : Use this competency whenever a significant decision needs to be documented, including architectural choices, project direction changes, business strategy decisions, technical implementations, security policies, or any decision that will impact the project's future direction or stakeholders.","title":"Usage"},{"location":"skills/create-decision-record/description/#parameters","text":"","title":"Parameters"},{"location":"skills/create-decision-record/description/#required-inputs","text":"title : Concise description of the decision being made type : Category of decision (Architecture, Project, Business, Functional, People, Technical, Security, or Other) context : Background information and problem statement that led to this decision drivers : Key factors, constraints, or requirements influencing the decision options : Alternative options that were considered, including pros and cons for each decision_makers : Individuals responsible for making the final decision stakeholders : Parties affected by or interested in this decision","title":"Required Inputs"},{"location":"skills/create-decision-record/description/#optional-inputs","text":"status : Current status of the decision (Proposed, Accepted, Replaced, Superseded) - defaults to \"Proposed\" decision : The selected option if already determined (can be left blank for proposed decisions)","title":"Optional Inputs"},{"location":"skills/create-decision-record/description/#context-requirements","text":"Access to decision records directory ( .olaf/data/product/decision-records/ ) Access to decision records register ( .olaf/data/product/decision-records/decision-records-register.md ) Access to changelog register for tracking the creation Decision record template available at competency templates folder","title":"Context Requirements"},{"location":"skills/create-decision-record/description/#output","text":"Deliverables : - New decision record file with unique ID (DR-YYYYMMDD-NN format) - Updated decision records register with new entry - Changelog entry documenting the record creation Format : Markdown file following the standard decision record template structure with metadata, context, options analysis, decision rationale, and consequences sections.","title":"Output"},{"location":"skills/create-decision-record/description/#examples","text":"","title":"Examples"},{"location":"skills/create-decision-record/description/#example-1-architecture-decision","text":"Scenario : Team needs to decide between microservices and monolithic architecture for a new application Command : create decision record Input : Title: Application Architecture Pattern Selection Type: Architecture Context: Building new customer portal with expected growth to 100K users Drivers: Scalability requirements, team expertise, deployment complexity, maintenance costs Options: 1. Microservices - Better scalability but higher complexity 2. Monolithic - Simpler to start but harder to scale 3. Modular monolith - Middle ground approach Decision Makers: CTO, Lead Architect, Engineering Manager Stakeholders: Development team, DevOps team, Product team Result : Created DR-20251027-01.md with full decision documentation, updated register, and changelog entry","title":"Example 1: Architecture Decision"},{"location":"skills/create-decision-record/description/#example-2-project-decision","text":"Scenario : Deciding whether to postpone a feature to meet release deadline Command : create decision record Input : Title: Q4 Feature Scope Reduction Type: Project Status: Proposed Context: Current sprint velocity indicates we'll miss Q4 release date with all planned features Drivers: Release deadline commitment, customer expectations, technical debt concerns Options: 1. Postpone advanced reporting feature to Q1 2. Extend deadline by 2 weeks 3. Add resources to complete on time Decision Makers: Product Owner, Project Manager Stakeholders: Sales team, Customer Success, Development team Result : Created decision record for team review and approval before finalizing","title":"Example 2: Project Decision"},{"location":"skills/create-decision-record/description/#related-competencies","text":"create-changelog-entry : Use after creating a decision record to log the activity in the project changelog review-progress : Decision records are reviewed during progress assessments to track decision outcomes create-job : Decisions often lead to new work items that need to be tracked as jobs store-conversation-record : Related decision discussions can be stored for additional context","title":"Related Competencies"},{"location":"skills/create-decision-record/description/#tips-best-practices","text":"Document decisions as close to the decision-making moment as possible while context is fresh Include all seriously considered alternatives, not just the winner - this prevents revisiting rejected options Be specific about drivers and constraints - vague rationale leads to confusion later Update decision status when circumstances change (e.g., from Proposed to Accepted, or Accepted to Superseded) Link related decisions together to show decision evolution over time Keep decision records concise but complete - aim for clarity over comprehensiveness","title":"Tips &amp; Best Practices"},{"location":"skills/create-decision-record/description/#limitations","text":"Requires manual input of decision details - does not automatically extract from meeting notes or conversations Does not automatically notify stakeholders - notification must be handled separately Cannot retroactively create decision records with past dates - uses current timestamp Does not validate that all stakeholders have been consulted before recording the decision Source : core/competencies/project-manager/prompts/create-decision-record.md","title":"Limitations"},{"location":"skills/create-decision-record/tutorial/","text":"Create Decision Record: Step-by-Step Tutorial \u00b6 How to Execute the \"Create Decision Record\" Competency This tutorial shows exactly how to create a structured decision record following the OLAF framework template and update all related documentation. Prerequisites \u00b6 OLAF framework loaded and active Access to decision records directory ( data/product/documentations/decision-records/ ) Decision record template available Understanding of decision types and statuses Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 Initiate the decision record creation process. User Action: 1. Type: olaf create decision record 2. Or use any alias: olaf decision record , olaf new decision , olaf dr 3. Press Enter to start the process AI Response: The AI will acknowledge the request and begin gathering required information using the Propose-Confirm-Act protocol. Step 2: Provide Decision Details \u00b6 User Action: Respond to prompts with decision information Required Parameters: - title : \"Migrate authentication to OAuth 2.0\" - type : Select from: Architecture, Project, Business, Functional, People, Technical, Security, Other - context : \"Current basic auth is insecure and doesn't support SSO\" - drivers : \"Security requirements, user experience, compliance needs\" - options : \"1) OAuth 2.0 with PKCE, 2) SAML, 3) Keep basic auth with MFA\" - decision_makers : \"@TechLead, @SecurityOfficer\" - stakeholders : \"@DevTeam, @ProductOwner, @EndUsers\" Optional Parameters: - status : Proposed (default), Accepted, Replaced, Superseded - decision : Selected option if already determined Step 3: Review Proposed Decision Record \u00b6 What AI Does: - Retrieves current timestamp using terminal command - Generates unique decision ID (format: DR-YYYYMMDD-NN) - Loads decision record template - Populates all sections with provided information - Presents complete decision record for review You Should See: A formatted decision record with all sections filled, including metadata, context, options analysis, and stakeholder information. Step 4: Confirm or Request Changes \u00b6 User Action: 1. Review the proposed decision record carefully 2. Type \"approved\" or \"yes\" to proceed 3. Or request specific changes: \"update the context section to include...\" AI Response: If approved, AI will create the files and update registers. If changes requested, AI will revise and present again for confirmation. Step 5: Automatic Documentation Updates \u00b6 What AI Does: 1. Creates decision record file: data/product/documentations/decision-records/YYYYMMDD-title-as-kebab-case.md 2. Updates decision records register with new entry 3. Creates changelog entry documenting the decision record creation 4. Verifies all cross-references are correct You Should See: Confirmation message with file location, assigned decision ID, and summary of all updates made. Verification Checklist \u00b6 \u2705 Decision record file created in correct directory with proper naming \u2705 Unique decision ID assigned (DR-YYYYMMDD-NN format) \u2705 Decision records register updated with new entry \u2705 Changelog entry created documenting the action \u2705 All required fields populated (title, type, context, drivers, options, decision makers, stakeholders) \u2705 Template structure followed exactly Troubleshooting \u00b6 If decision ID conflicts occur: # Check existing decision records ls data/product/documentations/decision-records/ The AI will automatically increment the sequence number to avoid conflicts. If template not found: - Verify template exists at: core/competencies/project-manager/templates/decision-record-template.md - Check memory-map.md for correct path resolution If register update fails: - Ensure decision records register file exists - Check file permissions - Verify path in memory-map.md Key Learning Points \u00b6 Propose-Confirm-Act Protocol : This competency uses a two-step confirmation process to ensure accuracy before creating permanent records. Unique ID Generation : Decision IDs follow the DR-YYYYMMDD-NN format where NN is a sequence number for decisions created on the same day. Comprehensive Documentation : Creating a decision record automatically updates multiple files (record, register, changelog) to maintain consistency across the project. Decision Traceability : All decisions are tracked with stakeholders, decision makers, and timestamps for full audit trail. Next Steps to Try \u00b6 Create a follow-up decision that supersedes an existing one Link decisions to related jobs or tasks Review decision records register to see all project decisions Use decision records as input for architecture documentation Expected Timeline \u00b6 Total process time: 3-5 minutes User input required: 2-3 minutes to provide decision details and review AI execution time: 1-2 minutes for file creation and documentation updates","title":"Create Decision Record: Step-by-Step Tutorial"},{"location":"skills/create-decision-record/tutorial/#create-decision-record-step-by-step-tutorial","text":"How to Execute the \"Create Decision Record\" Competency This tutorial shows exactly how to create a structured decision record following the OLAF framework template and update all related documentation.","title":"Create Decision Record: Step-by-Step Tutorial"},{"location":"skills/create-decision-record/tutorial/#prerequisites","text":"OLAF framework loaded and active Access to decision records directory ( data/product/documentations/decision-records/ ) Decision record template available Understanding of decision types and statuses","title":"Prerequisites"},{"location":"skills/create-decision-record/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/create-decision-record/tutorial/#step-1-invoke-the-competency","text":"Initiate the decision record creation process. User Action: 1. Type: olaf create decision record 2. Or use any alias: olaf decision record , olaf new decision , olaf dr 3. Press Enter to start the process AI Response: The AI will acknowledge the request and begin gathering required information using the Propose-Confirm-Act protocol.","title":"Step 1: Invoke the Competency"},{"location":"skills/create-decision-record/tutorial/#step-2-provide-decision-details","text":"User Action: Respond to prompts with decision information Required Parameters: - title : \"Migrate authentication to OAuth 2.0\" - type : Select from: Architecture, Project, Business, Functional, People, Technical, Security, Other - context : \"Current basic auth is insecure and doesn't support SSO\" - drivers : \"Security requirements, user experience, compliance needs\" - options : \"1) OAuth 2.0 with PKCE, 2) SAML, 3) Keep basic auth with MFA\" - decision_makers : \"@TechLead, @SecurityOfficer\" - stakeholders : \"@DevTeam, @ProductOwner, @EndUsers\" Optional Parameters: - status : Proposed (default), Accepted, Replaced, Superseded - decision : Selected option if already determined","title":"Step 2: Provide Decision Details"},{"location":"skills/create-decision-record/tutorial/#step-3-review-proposed-decision-record","text":"What AI Does: - Retrieves current timestamp using terminal command - Generates unique decision ID (format: DR-YYYYMMDD-NN) - Loads decision record template - Populates all sections with provided information - Presents complete decision record for review You Should See: A formatted decision record with all sections filled, including metadata, context, options analysis, and stakeholder information.","title":"Step 3: Review Proposed Decision Record"},{"location":"skills/create-decision-record/tutorial/#step-4-confirm-or-request-changes","text":"User Action: 1. Review the proposed decision record carefully 2. Type \"approved\" or \"yes\" to proceed 3. Or request specific changes: \"update the context section to include...\" AI Response: If approved, AI will create the files and update registers. If changes requested, AI will revise and present again for confirmation.","title":"Step 4: Confirm or Request Changes"},{"location":"skills/create-decision-record/tutorial/#step-5-automatic-documentation-updates","text":"What AI Does: 1. Creates decision record file: data/product/documentations/decision-records/YYYYMMDD-title-as-kebab-case.md 2. Updates decision records register with new entry 3. Creates changelog entry documenting the decision record creation 4. Verifies all cross-references are correct You Should See: Confirmation message with file location, assigned decision ID, and summary of all updates made.","title":"Step 5: Automatic Documentation Updates"},{"location":"skills/create-decision-record/tutorial/#verification-checklist","text":"\u2705 Decision record file created in correct directory with proper naming \u2705 Unique decision ID assigned (DR-YYYYMMDD-NN format) \u2705 Decision records register updated with new entry \u2705 Changelog entry created documenting the action \u2705 All required fields populated (title, type, context, drivers, options, decision makers, stakeholders) \u2705 Template structure followed exactly","title":"Verification Checklist"},{"location":"skills/create-decision-record/tutorial/#troubleshooting","text":"If decision ID conflicts occur: # Check existing decision records ls data/product/documentations/decision-records/ The AI will automatically increment the sequence number to avoid conflicts. If template not found: - Verify template exists at: core/competencies/project-manager/templates/decision-record-template.md - Check memory-map.md for correct path resolution If register update fails: - Ensure decision records register file exists - Check file permissions - Verify path in memory-map.md","title":"Troubleshooting"},{"location":"skills/create-decision-record/tutorial/#key-learning-points","text":"Propose-Confirm-Act Protocol : This competency uses a two-step confirmation process to ensure accuracy before creating permanent records. Unique ID Generation : Decision IDs follow the DR-YYYYMMDD-NN format where NN is a sequence number for decisions created on the same day. Comprehensive Documentation : Creating a decision record automatically updates multiple files (record, register, changelog) to maintain consistency across the project. Decision Traceability : All decisions are tracked with stakeholders, decision makers, and timestamps for full audit trail.","title":"Key Learning Points"},{"location":"skills/create-decision-record/tutorial/#next-steps-to-try","text":"Create a follow-up decision that supersedes an existing one Link decisions to related jobs or tasks Review decision records register to see all project decisions Use decision records as input for architecture documentation","title":"Next Steps to Try"},{"location":"skills/create-decision-record/tutorial/#expected-timeline","text":"Total process time: 3-5 minutes User input required: 2-3 minutes to provide decision details and review AI execution time: 1-2 minutes for file creation and documentation updates","title":"Expected Timeline"},{"location":"skills/create-feature-for-pr/description/","text":"Create Feature For Pr \u00b6 Enhanced skill migrated from git-assistant competency. Usage \u00b6 This skill provides create feature for pr functionality with self-contained dependencies and enhanced error handling.","title":"Create Feature For Pr"},{"location":"skills/create-feature-for-pr/description/#create-feature-for-pr","text":"Enhanced skill migrated from git-assistant competency.","title":"Create Feature For Pr"},{"location":"skills/create-feature-for-pr/description/#usage","text":"This skill provides create feature for pr functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/create-feature-for-pr/tutorial/","text":"Create Feature For Pr Tutorial \u00b6 Step-by-step guide for using the create-feature-for-pr skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Create Feature For Pr Tutorial"},{"location":"skills/create-feature-for-pr/tutorial/#create-feature-for-pr-tutorial","text":"Step-by-step guide for using the create-feature-for-pr skill.","title":"Create Feature For Pr Tutorial"},{"location":"skills/create-feature-for-pr/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/create-feature-for-pr/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/create-job/description/","text":"Create Job \u00b6 Overview \u00b6 Creates structured job records following a standardized template with unique ID generation, proper metadata, and integration with the project's job tracking system for comprehensive work management. Purpose \u00b6 Projects need a formal system for tracking work items beyond simple task lists. This competency solves the problem of informal work tracking by creating detailed job records that capture requirements, tasks, status, and metadata in a consistent format that enables systematic work management, progress tracking, and team coordination. Usage \u00b6 Command : create job Protocol : Propose-Confirm-Act When to Use : Use this competency when defining new work items such as user stories, bug fixes, features, refactoring efforts, or any significant work that requires formal tracking, assignment, and status management throughout its lifecycle. Parameters \u00b6 Required Inputs \u00b6 job_title : Concise, clear title describing the job's main purpose job_type : Category of work (User Story, Bug Fix, Task, Refactoring, Spike, Feature Enhancement, or Other) priority : Urgency level (High, Medium, or Low) job_description : Brief explanation of what the job aims to accomplish Optional Inputs \u00b6 initial_tasks : List of specific tasks or steps already identified for this job reference_links : URLs or references to relevant documentation, requirements, or resources assignee : Person assigned to the job (defaults to @AssigneeName if not provided) Context Requirements \u00b6 Access to job template for structure Access to jobs register ( .olaf/data/projects/jobs-register.md ) for ID generation and tracking Access to jobs directory ( .olaf/data/projects/jobs/ ) for storing job files Current serial number from jobs register for unique ID generation Output \u00b6 Deliverables : - New job file with unique ID (format: JOB-{serial}.md ) - Updated jobs register with new entry and incremented serial number - Job metadata including creation date, status, type, priority, and assignee - Structured sections for description, tasks, progress tracking, and references Format : Markdown file following the job template structure with frontmatter metadata and organized content sections. Examples \u00b6 Example 1: User Story \u00b6 Scenario : Creating a job for implementing user authentication feature Command : create job Input : Job Title: Implement OAuth2 User Authentication Job Type: User Story Priority: High Job Description: Enable users to authenticate using OAuth2 providers (Google, GitHub) Initial Tasks: - Research OAuth2 libraries - Design authentication flow - Implement provider integration - Add user session management - Write integration tests Reference Links: https://oauth.net/2/, design-doc-auth.md Assignee: @john-developer Result : Created JOB-042.md with full job details, updated register to serial 42, ready for work to begin Example 2: Bug Fix \u00b6 Scenario : Tracking a critical production bug Command : create job Input : Job Title: Fix Memory Leak in Background Processor Job Type: Bug Fix Priority: High Job Description: Resolve memory leak causing server crashes every 6 hours in production Reference Links: issue-789, monitoring-dashboard-url Assignee: @sarah-engineer Result : Created JOB-043.md for immediate attention, high priority bug tracking Example 3: Technical Spike \u00b6 Scenario : Research task for evaluating new technology Command : create job Input : Job Title: Evaluate GraphQL vs REST for New API Job Type: Spike Priority: Medium Job Description: Research and compare GraphQL and REST approaches for the new customer API, provide recommendation Initial Tasks: - Review GraphQL capabilities and ecosystem - Assess REST API best practices - Compare performance characteristics - Evaluate team learning curve - Document recommendation with rationale Assignee: @alex-architect Result : Created JOB-044.md for research and evaluation work Related Competencies \u00b6 work-on-job : Execute and track progress on the created job generate-tasklist : Generate detailed task breakdowns that can inform job creation create-changelog-entry : Log job creation and completion in the project changelog review-progress : Review job status and progress during project assessments create-decision-record : Jobs may require decisions that should be formally documented Tips & Best Practices \u00b6 Write clear, specific job titles that immediately convey the work's purpose Include enough description detail for someone unfamiliar with the context to understand the goal Add initial tasks if known, but don't feel obligated to have a complete task list upfront Set priority realistically - not everything can be high priority Include reference links to requirements, designs, or related documentation for context Use appropriate job types to enable filtering and reporting by work category Update the job file as work progresses rather than creating a new job for related work Limitations \u00b6 Requires manual input of job details - does not automatically extract from requirements or conversations Job IDs are sequential and cannot be customized - follows JOB-{serial} format strictly Does not automatically notify assignees - notification must be handled separately Cannot create jobs with past creation dates - always uses current timestamp Job register and job file must both succeed - no partial creation (atomic operation) Does not validate that assignee exists or has capacity for the work Source : core/competencies/project-manager/prompts/create-job.md","title":"Create Job"},{"location":"skills/create-job/description/#create-job","text":"","title":"Create Job"},{"location":"skills/create-job/description/#overview","text":"Creates structured job records following a standardized template with unique ID generation, proper metadata, and integration with the project's job tracking system for comprehensive work management.","title":"Overview"},{"location":"skills/create-job/description/#purpose","text":"Projects need a formal system for tracking work items beyond simple task lists. This competency solves the problem of informal work tracking by creating detailed job records that capture requirements, tasks, status, and metadata in a consistent format that enables systematic work management, progress tracking, and team coordination.","title":"Purpose"},{"location":"skills/create-job/description/#usage","text":"Command : create job Protocol : Propose-Confirm-Act When to Use : Use this competency when defining new work items such as user stories, bug fixes, features, refactoring efforts, or any significant work that requires formal tracking, assignment, and status management throughout its lifecycle.","title":"Usage"},{"location":"skills/create-job/description/#parameters","text":"","title":"Parameters"},{"location":"skills/create-job/description/#required-inputs","text":"job_title : Concise, clear title describing the job's main purpose job_type : Category of work (User Story, Bug Fix, Task, Refactoring, Spike, Feature Enhancement, or Other) priority : Urgency level (High, Medium, or Low) job_description : Brief explanation of what the job aims to accomplish","title":"Required Inputs"},{"location":"skills/create-job/description/#optional-inputs","text":"initial_tasks : List of specific tasks or steps already identified for this job reference_links : URLs or references to relevant documentation, requirements, or resources assignee : Person assigned to the job (defaults to @AssigneeName if not provided)","title":"Optional Inputs"},{"location":"skills/create-job/description/#context-requirements","text":"Access to job template for structure Access to jobs register ( .olaf/data/projects/jobs-register.md ) for ID generation and tracking Access to jobs directory ( .olaf/data/projects/jobs/ ) for storing job files Current serial number from jobs register for unique ID generation","title":"Context Requirements"},{"location":"skills/create-job/description/#output","text":"Deliverables : - New job file with unique ID (format: JOB-{serial}.md ) - Updated jobs register with new entry and incremented serial number - Job metadata including creation date, status, type, priority, and assignee - Structured sections for description, tasks, progress tracking, and references Format : Markdown file following the job template structure with frontmatter metadata and organized content sections.","title":"Output"},{"location":"skills/create-job/description/#examples","text":"","title":"Examples"},{"location":"skills/create-job/description/#example-1-user-story","text":"Scenario : Creating a job for implementing user authentication feature Command : create job Input : Job Title: Implement OAuth2 User Authentication Job Type: User Story Priority: High Job Description: Enable users to authenticate using OAuth2 providers (Google, GitHub) Initial Tasks: - Research OAuth2 libraries - Design authentication flow - Implement provider integration - Add user session management - Write integration tests Reference Links: https://oauth.net/2/, design-doc-auth.md Assignee: @john-developer Result : Created JOB-042.md with full job details, updated register to serial 42, ready for work to begin","title":"Example 1: User Story"},{"location":"skills/create-job/description/#example-2-bug-fix","text":"Scenario : Tracking a critical production bug Command : create job Input : Job Title: Fix Memory Leak in Background Processor Job Type: Bug Fix Priority: High Job Description: Resolve memory leak causing server crashes every 6 hours in production Reference Links: issue-789, monitoring-dashboard-url Assignee: @sarah-engineer Result : Created JOB-043.md for immediate attention, high priority bug tracking","title":"Example 2: Bug Fix"},{"location":"skills/create-job/description/#example-3-technical-spike","text":"Scenario : Research task for evaluating new technology Command : create job Input : Job Title: Evaluate GraphQL vs REST for New API Job Type: Spike Priority: Medium Job Description: Research and compare GraphQL and REST approaches for the new customer API, provide recommendation Initial Tasks: - Review GraphQL capabilities and ecosystem - Assess REST API best practices - Compare performance characteristics - Evaluate team learning curve - Document recommendation with rationale Assignee: @alex-architect Result : Created JOB-044.md for research and evaluation work","title":"Example 3: Technical Spike"},{"location":"skills/create-job/description/#related-competencies","text":"work-on-job : Execute and track progress on the created job generate-tasklist : Generate detailed task breakdowns that can inform job creation create-changelog-entry : Log job creation and completion in the project changelog review-progress : Review job status and progress during project assessments create-decision-record : Jobs may require decisions that should be formally documented","title":"Related Competencies"},{"location":"skills/create-job/description/#tips-best-practices","text":"Write clear, specific job titles that immediately convey the work's purpose Include enough description detail for someone unfamiliar with the context to understand the goal Add initial tasks if known, but don't feel obligated to have a complete task list upfront Set priority realistically - not everything can be high priority Include reference links to requirements, designs, or related documentation for context Use appropriate job types to enable filtering and reporting by work category Update the job file as work progresses rather than creating a new job for related work","title":"Tips &amp; Best Practices"},{"location":"skills/create-job/description/#limitations","text":"Requires manual input of job details - does not automatically extract from requirements or conversations Job IDs are sequential and cannot be customized - follows JOB-{serial} format strictly Does not automatically notify assignees - notification must be handled separately Cannot create jobs with past creation dates - always uses current timestamp Job register and job file must both succeed - no partial creation (atomic operation) Does not validate that assignee exists or has capacity for the work Source : core/competencies/project-manager/prompts/create-job.md","title":"Limitations"},{"location":"skills/create-job/tutorial/","text":"Create Job: Step-by-Step Tutorial \u00b6 How to Execute the \"Create Job\" Competency This tutorial shows exactly how to create a new job file in the jobs directory following the job template structure with proper ID generation and system integration. Prerequisites \u00b6 OLAF framework loaded and active Access to jobs directory and job register Job template available Understanding of job types and priorities Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 Initiate the job creation process. User Action: 1. Type: olaf create job 2. Or use any alias: olaf new job , olaf job record , olaf create work 3. Press Enter to start the process AI Response: The AI will acknowledge the request and begin gathering required information using the Propose-Confirm-Act protocol. Step 2: Provide Job Details \u00b6 User Action: Respond to prompts with job information Required Parameters: - job_title : \"Implement OAuth 2.0 token refresh\" - job_type : User Story | Bug Fix | Task | Refactoring | Spike | Feature Enhancement | Other - priority : High | Medium | Low - job_description : \"Add automatic token refresh to prevent session expiration\" Optional Parameters: - initial_tasks : \"1. Design refresh token flow, 2. Implement refresh endpoint, 3. Add client-side refresh logic\" - reference_links : \"https://oauth.net/2/refresh-tokens/, DR-20251027-01\" - assignee : \"@DevLead\" (defaults to @AssigneeName if not provided) Example Input: Job Title: Implement OAuth 2.0 token refresh Job Type: Feature Enhancement Priority: High Description: Add automatic token refresh to prevent session expiration Initial Tasks: Design refresh token flow, Implement refresh endpoint, Add client-side refresh logic Reference Links: https://oauth.net/2/refresh-tokens/ Assignee: @DevLead Step 3: Template and Register Loading \u00b6 What AI Does: 1. Reads job template: core/competencies/project-manager/templates/job-template.md 2. Reads job register: data/projects/jobs-register.md 3. Extracts current serial number from register 4. Validates template structure You Should See: Confirmation that template and register loaded successfully. Step 4: Job ID Generation \u00b6 What AI Does: - Increments serial number from job register - Creates new job ID format: JOB-{serial} (e.g., JOB-042) - Prepares filename: JOB-042.md - Ensures no duplicate IDs exist You Should See: Generated job ID displayed for confirmation. Step 5: Template Population \u00b6 What AI Does: - Uses job template structure as base - Fills all required sections with provided parameters: - Job title and description - Job type and priority - Assignee information - Initial tasks (if provided) - Reference links (if provided) - Sets creation date using terminal timestamp - Sets initial status to \"Open\" or \"To Do\" - Generates proper job metadata Template Sections Populated: # JOB-042: Implement OAuth 2.0 token refresh **Type:** Feature Enhancement **Priority:** High **Status:** Open **Assignee:** @DevLead **Created:** 2025-10-27 **Updated:** 2025-10-27 ## Description Add automatic token refresh to prevent session expiration ## Tasks - [ ] Design refresh token flow - [ ] Implement refresh endpoint - [ ] Add client-side refresh logic ## References - https://oauth.net/2/refresh-tokens/ Step 6: Review Proposed Job \u00b6 AI Presents: Complete job file for review User Action: 1. Review all sections carefully 2. Type \"approved\" or \"yes\" to proceed 3. Or request changes: \"update priority to Medium\" AI Response: If approved, creates files and updates register. If changes requested, revises and presents again. Step 7: File Creation and Register Update \u00b6 What AI Does: 1. Creates job file: data/projects/jobs/JOB-042.md 2. Updates job register with new entry 3. Increments serial number in register 4. Saves updated register file 5. Creates changelog entry documenting job creation Atomic Operation: Both job file and register update must succeed together to maintain consistency. Step 8: Confirmation \u00b6 AI Provides: - Job creation confirmation with ID: JOB-042 - File location: data/projects/jobs/JOB-042.md - Updated job register confirmation - Job details summary for verification - Next steps: Begin work using work-on-job competency You Should See: Complete confirmation with all file locations and next action recommendations. Verification Checklist \u00b6 \u2705 Unique job ID generated (JOB-{serial} format) \u2705 Job file created in correct directory \u2705 All required sections populated from template \u2705 Job register updated with new entry \u2705 Serial number incremented in register \u2705 Changelog entry created documenting the action \u2705 Template structure preserved exactly Troubleshooting \u00b6 If duplicate job ID error: # Check existing jobs ls data/projects/jobs/ # Verify job register serial number cat data/projects/jobs-register.md | grep \"Serial\" The AI should automatically handle this, but manual verification may be needed. If job register not found: - Verify path in memory-map.md: .olaf/data/projects/jobs-register.md - Create register file if missing - Initialize with serial number: 0 If template not found: Verify template exists at: core/competencies/project-manager/templates/job-template.md If file creation fails: - Check directory permissions - Verify sufficient disk space - Ensure no file locks on job directory Key Learning Points \u00b6 Atomic Operations : Job file and register update happen together to prevent inconsistencies. Sequential ID Generation : Job IDs are sequential (JOB-001, JOB-002, etc.) for easy tracking and reference. Template-Based Consistency : Using templates ensures all jobs have the same structure and required information. Propose-Confirm-Act Protocol : Two-step confirmation prevents accidental job creation with incorrect information. Next Steps to Try \u00b6 Use work-on-job competency to start executing the created job Link job to related decision records or changelog entries Create multiple jobs for a project and track in register Generate tasklists from job descriptions Review progress across all jobs using review-progress Expected Timeline \u00b6 Total process time: 3-5 minutes User input required: 2-3 minutes to provide job details and review AI execution time: 1-2 minutes for ID generation, template population, and file operations","title":"Create Job: Step-by-Step Tutorial"},{"location":"skills/create-job/tutorial/#create-job-step-by-step-tutorial","text":"How to Execute the \"Create Job\" Competency This tutorial shows exactly how to create a new job file in the jobs directory following the job template structure with proper ID generation and system integration.","title":"Create Job: Step-by-Step Tutorial"},{"location":"skills/create-job/tutorial/#prerequisites","text":"OLAF framework loaded and active Access to jobs directory and job register Job template available Understanding of job types and priorities","title":"Prerequisites"},{"location":"skills/create-job/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/create-job/tutorial/#step-1-invoke-the-competency","text":"Initiate the job creation process. User Action: 1. Type: olaf create job 2. Or use any alias: olaf new job , olaf job record , olaf create work 3. Press Enter to start the process AI Response: The AI will acknowledge the request and begin gathering required information using the Propose-Confirm-Act protocol.","title":"Step 1: Invoke the Competency"},{"location":"skills/create-job/tutorial/#step-2-provide-job-details","text":"User Action: Respond to prompts with job information Required Parameters: - job_title : \"Implement OAuth 2.0 token refresh\" - job_type : User Story | Bug Fix | Task | Refactoring | Spike | Feature Enhancement | Other - priority : High | Medium | Low - job_description : \"Add automatic token refresh to prevent session expiration\" Optional Parameters: - initial_tasks : \"1. Design refresh token flow, 2. Implement refresh endpoint, 3. Add client-side refresh logic\" - reference_links : \"https://oauth.net/2/refresh-tokens/, DR-20251027-01\" - assignee : \"@DevLead\" (defaults to @AssigneeName if not provided) Example Input: Job Title: Implement OAuth 2.0 token refresh Job Type: Feature Enhancement Priority: High Description: Add automatic token refresh to prevent session expiration Initial Tasks: Design refresh token flow, Implement refresh endpoint, Add client-side refresh logic Reference Links: https://oauth.net/2/refresh-tokens/ Assignee: @DevLead","title":"Step 2: Provide Job Details"},{"location":"skills/create-job/tutorial/#step-3-template-and-register-loading","text":"What AI Does: 1. Reads job template: core/competencies/project-manager/templates/job-template.md 2. Reads job register: data/projects/jobs-register.md 3. Extracts current serial number from register 4. Validates template structure You Should See: Confirmation that template and register loaded successfully.","title":"Step 3: Template and Register Loading"},{"location":"skills/create-job/tutorial/#step-4-job-id-generation","text":"What AI Does: - Increments serial number from job register - Creates new job ID format: JOB-{serial} (e.g., JOB-042) - Prepares filename: JOB-042.md - Ensures no duplicate IDs exist You Should See: Generated job ID displayed for confirmation.","title":"Step 4: Job ID Generation"},{"location":"skills/create-job/tutorial/#step-5-template-population","text":"What AI Does: - Uses job template structure as base - Fills all required sections with provided parameters: - Job title and description - Job type and priority - Assignee information - Initial tasks (if provided) - Reference links (if provided) - Sets creation date using terminal timestamp - Sets initial status to \"Open\" or \"To Do\" - Generates proper job metadata Template Sections Populated: # JOB-042: Implement OAuth 2.0 token refresh **Type:** Feature Enhancement **Priority:** High **Status:** Open **Assignee:** @DevLead **Created:** 2025-10-27 **Updated:** 2025-10-27 ## Description Add automatic token refresh to prevent session expiration ## Tasks - [ ] Design refresh token flow - [ ] Implement refresh endpoint - [ ] Add client-side refresh logic ## References - https://oauth.net/2/refresh-tokens/","title":"Step 5: Template Population"},{"location":"skills/create-job/tutorial/#step-6-review-proposed-job","text":"AI Presents: Complete job file for review User Action: 1. Review all sections carefully 2. Type \"approved\" or \"yes\" to proceed 3. Or request changes: \"update priority to Medium\" AI Response: If approved, creates files and updates register. If changes requested, revises and presents again.","title":"Step 6: Review Proposed Job"},{"location":"skills/create-job/tutorial/#step-7-file-creation-and-register-update","text":"What AI Does: 1. Creates job file: data/projects/jobs/JOB-042.md 2. Updates job register with new entry 3. Increments serial number in register 4. Saves updated register file 5. Creates changelog entry documenting job creation Atomic Operation: Both job file and register update must succeed together to maintain consistency.","title":"Step 7: File Creation and Register Update"},{"location":"skills/create-job/tutorial/#step-8-confirmation","text":"AI Provides: - Job creation confirmation with ID: JOB-042 - File location: data/projects/jobs/JOB-042.md - Updated job register confirmation - Job details summary for verification - Next steps: Begin work using work-on-job competency You Should See: Complete confirmation with all file locations and next action recommendations.","title":"Step 8: Confirmation"},{"location":"skills/create-job/tutorial/#verification-checklist","text":"\u2705 Unique job ID generated (JOB-{serial} format) \u2705 Job file created in correct directory \u2705 All required sections populated from template \u2705 Job register updated with new entry \u2705 Serial number incremented in register \u2705 Changelog entry created documenting the action \u2705 Template structure preserved exactly","title":"Verification Checklist"},{"location":"skills/create-job/tutorial/#troubleshooting","text":"If duplicate job ID error: # Check existing jobs ls data/projects/jobs/ # Verify job register serial number cat data/projects/jobs-register.md | grep \"Serial\" The AI should automatically handle this, but manual verification may be needed. If job register not found: - Verify path in memory-map.md: .olaf/data/projects/jobs-register.md - Create register file if missing - Initialize with serial number: 0 If template not found: Verify template exists at: core/competencies/project-manager/templates/job-template.md If file creation fails: - Check directory permissions - Verify sufficient disk space - Ensure no file locks on job directory","title":"Troubleshooting"},{"location":"skills/create-job/tutorial/#key-learning-points","text":"Atomic Operations : Job file and register update happen together to prevent inconsistencies. Sequential ID Generation : Job IDs are sequential (JOB-001, JOB-002, etc.) for easy tracking and reference. Template-Based Consistency : Using templates ensures all jobs have the same structure and required information. Propose-Confirm-Act Protocol : Two-step confirmation prevents accidental job creation with incorrect information.","title":"Key Learning Points"},{"location":"skills/create-job/tutorial/#next-steps-to-try","text":"Use work-on-job competency to start executing the created job Link job to related decision records or changelog entries Create multiple jobs for a project and track in register Generate tasklists from job descriptions Review progress across all jobs using review-progress","title":"Next Steps to Try"},{"location":"skills/create-job/tutorial/#expected-timeline","text":"Total process time: 3-5 minutes User input required: 2-3 minutes to provide job details and review AI execution time: 1-2 minutes for ID generation, template population, and file operations","title":"Expected Timeline"},{"location":"skills/create-otf-variable/description/","text":"Create OTF Variable \u00b6 Skill ID : create-otf-variable Version : 1.0.0 Status : Experimental Overview \u00b6 The create-otf-variable skill guides developers through adding OTF (Open Transaction Framework) variables to Amadeus C++ applications, ensuring proper XML configuration, environment-specific settings, and C++ accessor code following best practices. What is OTF? \u00b6 OTF (Open Transaction Framework) is a C++ application server framework used at Amadeus that acts as a service broker, enabling runtime configuration of application behavior without requiring recompilation. What This Skill Does \u00b6 This skill provides interactive guidance for: Gathering Requirements Variable naming (with convention suggestions) Purpose and valid values Default values and environment overrides XML Configuration Locating component XML files Adding variables to <common> section Setting environment-specific overrides in <phase> sections C++ Implementation Generating PropertiesManager accessor code Creating reusable accessor methods Following naming conventions Testing & Deployment Unit testing strategies Gradual rollout recommendations Environment-specific validation Use Cases \u00b6 Feature Flags \u00b6 Create runtime toggles for new features: <variable name=\"ENABLE_NEW_API\" value=\"false\" control=\"off\" description=\"Enable new API implementation\"/> Migration Toggles \u00b6 Gradual rollout of migration features: <variable name=\"MIG_ENABLE_LAYOVER\" value=\"N\" control=\"off\" description=\"Enable layover feature for migration\"/> Environment-Specific Configuration \u00b6 Different behavior per environment: <common> <variable name=\"MAX_RETRY_COUNT\" value=\"3\" control=\"off\" description=\"Maximum retry attempts\"/> </common> <phase name=\"PRD\"> <variable name=\"MAX_RETRY_COUNT\" value=\"5\" control=\"off\" description=\"Maximum retry attempts\"/> </phase> Key Features \u00b6 \u2705 Interactive workflow - Step-by-step guidance with prompts for required information \u2705 Pattern detection - Analyzes existing variables to match project conventions \u2705 Best practices - Enforces naming conventions and safe defaults \u2705 Code generation - Provides ready-to-use C++ accessor code \u2705 Testing guidance - Unit test examples and deployment strategies \u2705 Environment management - Proper phase-specific overrides What You'll Need \u00b6 Component XML file path (or component name to search) Variable purpose and expected values Target environments for the feature Understanding of the feature being controlled Benefits \u00b6 Reduces errors in XML configuration Standardizes feature flag implementation across teams Accelerates development with ready-to-use code patterns Ensures best practices for gradual rollout and testing Maintains consistency with existing project patterns Related Skills \u00b6 get-bms-expertise - BMS build system expertise for component management General C++ development and XML editing skills Knowledge Base \u00b6 This skill references: - OTF Configuration Guide - Comprehensive overview of OTF variables - OTF Workflow - Step-by-step implementation guide Who Should Use This \u00b6 Amadeus C++ developers working with OTF applications Teams implementing feature flags and runtime configuration Developers performing gradual feature migrations Anyone needing environment-specific application behavior Limitations \u00b6 Specific to Amadeus OTF framework and C++ applications Requires access to component XML files Assumes familiarity with C++ and basic XML structure Does not handle complex multi-component dependencies Example Output \u00b6 The skill will help you create: XML Configuration : <common> <variable name=\"MIG_ENABLE_LAYOVER\" value=\"N\" control=\"off\" description=\"Enable layover feature\"/> </common> <phase name=\"LOCAL\"> <variable name=\"MIG_ENABLE_LAYOVER\" value=\"Y\" control=\"off\" description=\"Enable layover feature\"/> </phase> C++ Accessor : bool ConfigManager::isLayoverEnabled() { return toolbox::PropertiesManager::GetInstance().isDefined(\"MIG_ENABLE_LAYOVER\") && toolbox::PropertiesManager::GetInstance().getValue(\"MIG_ENABLE_LAYOVER\") == \"Y\"; } Usage : if (ConfigManager::isLayoverEnabled()) { // New implementation } else { // Legacy implementation }","title":"Create OTF Variable"},{"location":"skills/create-otf-variable/description/#create-otf-variable","text":"Skill ID : create-otf-variable Version : 1.0.0 Status : Experimental","title":"Create OTF Variable"},{"location":"skills/create-otf-variable/description/#overview","text":"The create-otf-variable skill guides developers through adding OTF (Open Transaction Framework) variables to Amadeus C++ applications, ensuring proper XML configuration, environment-specific settings, and C++ accessor code following best practices.","title":"Overview"},{"location":"skills/create-otf-variable/description/#what-is-otf","text":"OTF (Open Transaction Framework) is a C++ application server framework used at Amadeus that acts as a service broker, enabling runtime configuration of application behavior without requiring recompilation.","title":"What is OTF?"},{"location":"skills/create-otf-variable/description/#what-this-skill-does","text":"This skill provides interactive guidance for: Gathering Requirements Variable naming (with convention suggestions) Purpose and valid values Default values and environment overrides XML Configuration Locating component XML files Adding variables to <common> section Setting environment-specific overrides in <phase> sections C++ Implementation Generating PropertiesManager accessor code Creating reusable accessor methods Following naming conventions Testing & Deployment Unit testing strategies Gradual rollout recommendations Environment-specific validation","title":"What This Skill Does"},{"location":"skills/create-otf-variable/description/#use-cases","text":"","title":"Use Cases"},{"location":"skills/create-otf-variable/description/#feature-flags","text":"Create runtime toggles for new features: <variable name=\"ENABLE_NEW_API\" value=\"false\" control=\"off\" description=\"Enable new API implementation\"/>","title":"Feature Flags"},{"location":"skills/create-otf-variable/description/#migration-toggles","text":"Gradual rollout of migration features: <variable name=\"MIG_ENABLE_LAYOVER\" value=\"N\" control=\"off\" description=\"Enable layover feature for migration\"/>","title":"Migration Toggles"},{"location":"skills/create-otf-variable/description/#environment-specific-configuration","text":"Different behavior per environment: <common> <variable name=\"MAX_RETRY_COUNT\" value=\"3\" control=\"off\" description=\"Maximum retry attempts\"/> </common> <phase name=\"PRD\"> <variable name=\"MAX_RETRY_COUNT\" value=\"5\" control=\"off\" description=\"Maximum retry attempts\"/> </phase>","title":"Environment-Specific Configuration"},{"location":"skills/create-otf-variable/description/#key-features","text":"\u2705 Interactive workflow - Step-by-step guidance with prompts for required information \u2705 Pattern detection - Analyzes existing variables to match project conventions \u2705 Best practices - Enforces naming conventions and safe defaults \u2705 Code generation - Provides ready-to-use C++ accessor code \u2705 Testing guidance - Unit test examples and deployment strategies \u2705 Environment management - Proper phase-specific overrides","title":"Key Features"},{"location":"skills/create-otf-variable/description/#what-youll-need","text":"Component XML file path (or component name to search) Variable purpose and expected values Target environments for the feature Understanding of the feature being controlled","title":"What You'll Need"},{"location":"skills/create-otf-variable/description/#benefits","text":"Reduces errors in XML configuration Standardizes feature flag implementation across teams Accelerates development with ready-to-use code patterns Ensures best practices for gradual rollout and testing Maintains consistency with existing project patterns","title":"Benefits"},{"location":"skills/create-otf-variable/description/#related-skills","text":"get-bms-expertise - BMS build system expertise for component management General C++ development and XML editing skills","title":"Related Skills"},{"location":"skills/create-otf-variable/description/#knowledge-base","text":"This skill references: - OTF Configuration Guide - Comprehensive overview of OTF variables - OTF Workflow - Step-by-step implementation guide","title":"Knowledge Base"},{"location":"skills/create-otf-variable/description/#who-should-use-this","text":"Amadeus C++ developers working with OTF applications Teams implementing feature flags and runtime configuration Developers performing gradual feature migrations Anyone needing environment-specific application behavior","title":"Who Should Use This"},{"location":"skills/create-otf-variable/description/#limitations","text":"Specific to Amadeus OTF framework and C++ applications Requires access to component XML files Assumes familiarity with C++ and basic XML structure Does not handle complex multi-component dependencies","title":"Limitations"},{"location":"skills/create-otf-variable/description/#example-output","text":"The skill will help you create: XML Configuration : <common> <variable name=\"MIG_ENABLE_LAYOVER\" value=\"N\" control=\"off\" description=\"Enable layover feature\"/> </common> <phase name=\"LOCAL\"> <variable name=\"MIG_ENABLE_LAYOVER\" value=\"Y\" control=\"off\" description=\"Enable layover feature\"/> </phase> C++ Accessor : bool ConfigManager::isLayoverEnabled() { return toolbox::PropertiesManager::GetInstance().isDefined(\"MIG_ENABLE_LAYOVER\") && toolbox::PropertiesManager::GetInstance().getValue(\"MIG_ENABLE_LAYOVER\") == \"Y\"; } Usage : if (ConfigManager::isLayoverEnabled()) { // New implementation } else { // Legacy implementation }","title":"Example Output"},{"location":"skills/create-otf-variable/tutorial/","text":"Tutorial: Create OTF Variable \u00b6 Learn how to use the create-otf-variable skill to add runtime configuration to your Amadeus C++ application. Quick Start \u00b6 olaf create-otf-variable The skill will guide you through an interactive workflow to create a new OTF variable. Example Walkthrough \u00b6 Scenario: Adding a Layover Feature Toggle \u00b6 Let's create an OTF variable to enable a new layover feature in a migration scenario. Step 1: Invoke the Skill \u00b6 User: olaf create-otf-variable Step 2: Provide Requirements \u00b6 The skill will prompt you for information: Assistant: I'll help you create a new OTF variable. Let me gather the details: - Variable name (suggestion: ENABLE_*, MIG_*, IS_*): - Purpose/Description: - Expected values (Y/N, true/false, numeric, etc.): - Default value (recommend OFF for safety): - Environments to override (LOCAL, UAT, PRD): - Component XML file path or name: Your Response : User: Variable name: MIG_ENABLE_LAYOVER Purpose: Enable layover feature for migration Values: Y/N Default: N Enable in LOCAL for development Component: booking_component.component.xml Step 3: XML Update \u00b6 The skill will: 1. Locate your component XML file 2. Check existing variable patterns 3. Add the variable to the XML: <common> <variable name=\"MIG_ENABLE_LAYOVER\" value=\"N\" control=\"off\" description=\"Enable layover feature for migration\"/> </common> <phase name=\"LOCAL\"> <variable name=\"MIG_ENABLE_LAYOVER\" value=\"Y\" control=\"off\" description=\"Enable layover feature for migration\"/> </phase> Step 4: C++ Accessor Code \u00b6 The skill provides ready-to-use accessor code: // Recommended: Create accessor method bool ConfigManager::isLayoverEnabled() { return toolbox::PropertiesManager::GetInstance().isDefined(\"MIG_ENABLE_LAYOVER\") && toolbox::PropertiesManager::GetInstance().getValue(\"MIG_ENABLE_LAYOVER\") == \"Y\"; } // Usage in your code if (ConfigManager::isLayoverEnabled()) { // New layover implementation processWithLayover(request); } else { // Legacy implementation processStandard(request); } Step 5: Testing Guidance \u00b6 The skill provides unit test examples: TEST(LayoverTest, WhenDisabled_UsesStandardLogic) { MockPropertiesManager::setValue(\"MIG_ENABLE_LAYOVER\", \"N\"); ASSERT_FALSE(ConfigManager::isLayoverEnabled()); // Test standard behavior } TEST(LayoverTest, WhenEnabled_UsesLayoverLogic) { MockPropertiesManager::setValue(\"MIG_ENABLE_LAYOVER\", \"Y\"); ASSERT_TRUE(ConfigManager::isLayoverEnabled()); // Test layover behavior } Step 6: Deployment Strategy \u00b6 The skill recommends a rollout plan: 1. \u2705 Deploy with default OFF (N) 2. \u2705 Test in LOCAL (enabled) 3. \u2705 Validate in UAT 4. \u2705 Monitor metrics 5. \u2705 Enable in PRD gradually 6. \u2705 Full rollout after validation Common Usage Patterns \u00b6 Pattern 1: Simple Feature Flag \u00b6 User: olaf create-otf-variable Create a feature flag for the new caching system: - Name: ENABLE_CACHE - Values: true/false - Default: false - Enable in LOCAL Result : <variable name=\"ENABLE_CACHE\" value=\"false\" control=\"off\" description=\"Enable response caching\"/> bool isCacheEnabled = toolbox::PropertiesManager::GetInstance().isDefined(\"ENABLE_CACHE\") && toolbox::PropertiesManager::GetInstance().getValue(\"ENABLE_CACHE\") == \"true\"; Pattern 2: Numeric Configuration \u00b6 User: olaf create-otf-variable Add retry count configuration: - Name: MAX_RETRY_COUNT - Values: numeric string - Default: 3 - Override in PRD: 5 Result : <common> <variable name=\"MAX_RETRY_COUNT\" value=\"3\" control=\"off\" description=\"Maximum retry attempts\"/> </common> <phase name=\"PRD\"> <variable name=\"MAX_RETRY_COUNT\" value=\"5\" control=\"off\" description=\"Maximum retry attempts\"/> </phase> std::string retryStr = toolbox::PropertiesManager::GetInstance().getValue(\"MAX_RETRY_COUNT\"); int maxRetries = std::stoi(retryStr); Pattern 3: Migration Flag \u00b6 User: olaf create-otf-variable Migration flag for new API: - Name: MIG_ENABLE_NEW_API - Values: Y/N - Default: N - Enable in LOCAL and UAT Result : <common> <variable name=\"MIG_ENABLE_NEW_API\" value=\"N\" control=\"off\" description=\"Enable new API implementation\"/> </common> <phase name=\"LOCAL\"> <variable name=\"MIG_ENABLE_NEW_API\" value=\"Y\" control=\"off\" description=\"Enable new API implementation\"/> </phase> <phase name=\"UAT\"> <variable name=\"MIG_ENABLE_NEW_API\" value=\"Y\" control=\"off\" description=\"Enable new API implementation\"/> </phase> Tips & Best Practices \u00b6 Naming Conventions \u00b6 \u2705 Good : - ENABLE_CACHE - Clear feature toggle - MIG_ENABLE_LAYOVER - Migration prefix - IS_PRODUCTION - State flag - MAX_RETRY_COUNT - Descriptive configuration \u274c Avoid : - ENABLE_IS_FEATURE_ENABLED - Redundant - flag1 - Not descriptive - enableCache - Wrong case convention - CACHE - Unclear purpose Default Values \u00b6 \u2705 Safe Defaults : - Feature flags: \"N\" or \"false\" (OFF by default) - Retry counts: Conservative values (e.g., \"3\" ) - Timeouts: Safe/tested values \u274c Risky Defaults : - Feature enabled by default without testing - Aggressive retry/timeout values - Production-only configurations Environment Strategy \u00b6 Recommended Rollout : 1. LOCAL - Always enable for development 2. UAT - Enable after initial validation 3. PRD - Enable gradually with monitoring Avoid : - Enabling in PRD before LOCAL/UAT testing - Same value across all environments (no override benefit) - Too many environment-specific overrides (complexity) Troubleshooting \u00b6 Variable Not Recognized \u00b6 Problem : Runtime error or feature not working Solutions : 1. Verify XML file is loaded by component 2. Check variable name spelling (case-sensitive) 3. Restart application to reload configuration 4. Check OTF logs for XML parsing errors Override Not Applied \u00b6 Problem : Getting common value instead of phase override Solutions : 1. Verify phase name matches environment exactly 2. Check XML syntax (properly closed tags) 3. Ensure phase section comes after common section 4. Restart application after XML changes Accessor Always Returns False \u00b6 Problem : Feature flag always disabled Solutions : 1. Verify isDefined() check passes 2. Check exact value comparison (case-sensitive) 3. Ensure XML has correct value 4. Debug PropertiesManager call to see actual value Next Steps \u00b6 After creating your OTF variable: Review the code with your team Write unit tests for both enabled/disabled states Test in LOCAL environment first Document the feature flag in your component docs Monitor behavior in each environment Plan cleanup after migration is complete Related Resources \u00b6 OTF Configuration Guide - Comprehensive reference OTF Workflow - Detailed step-by-step guide Component XML documentation - Project-specific structure Need Help? \u00b6 Check existing variables in your component XML for patterns Review C++ code for existing PropertiesManager usage Consult team for project-specific conventions Use olaf get-bms-expertise for component-level questions","title":"Tutorial: Create OTF Variable"},{"location":"skills/create-otf-variable/tutorial/#tutorial-create-otf-variable","text":"Learn how to use the create-otf-variable skill to add runtime configuration to your Amadeus C++ application.","title":"Tutorial: Create OTF Variable"},{"location":"skills/create-otf-variable/tutorial/#quick-start","text":"olaf create-otf-variable The skill will guide you through an interactive workflow to create a new OTF variable.","title":"Quick Start"},{"location":"skills/create-otf-variable/tutorial/#example-walkthrough","text":"","title":"Example Walkthrough"},{"location":"skills/create-otf-variable/tutorial/#scenario-adding-a-layover-feature-toggle","text":"Let's create an OTF variable to enable a new layover feature in a migration scenario.","title":"Scenario: Adding a Layover Feature Toggle"},{"location":"skills/create-otf-variable/tutorial/#step-1-invoke-the-skill","text":"User: olaf create-otf-variable","title":"Step 1: Invoke the Skill"},{"location":"skills/create-otf-variable/tutorial/#step-2-provide-requirements","text":"The skill will prompt you for information: Assistant: I'll help you create a new OTF variable. Let me gather the details: - Variable name (suggestion: ENABLE_*, MIG_*, IS_*): - Purpose/Description: - Expected values (Y/N, true/false, numeric, etc.): - Default value (recommend OFF for safety): - Environments to override (LOCAL, UAT, PRD): - Component XML file path or name: Your Response : User: Variable name: MIG_ENABLE_LAYOVER Purpose: Enable layover feature for migration Values: Y/N Default: N Enable in LOCAL for development Component: booking_component.component.xml","title":"Step 2: Provide Requirements"},{"location":"skills/create-otf-variable/tutorial/#step-3-xml-update","text":"The skill will: 1. Locate your component XML file 2. Check existing variable patterns 3. Add the variable to the XML: <common> <variable name=\"MIG_ENABLE_LAYOVER\" value=\"N\" control=\"off\" description=\"Enable layover feature for migration\"/> </common> <phase name=\"LOCAL\"> <variable name=\"MIG_ENABLE_LAYOVER\" value=\"Y\" control=\"off\" description=\"Enable layover feature for migration\"/> </phase>","title":"Step 3: XML Update"},{"location":"skills/create-otf-variable/tutorial/#step-4-c-accessor-code","text":"The skill provides ready-to-use accessor code: // Recommended: Create accessor method bool ConfigManager::isLayoverEnabled() { return toolbox::PropertiesManager::GetInstance().isDefined(\"MIG_ENABLE_LAYOVER\") && toolbox::PropertiesManager::GetInstance().getValue(\"MIG_ENABLE_LAYOVER\") == \"Y\"; } // Usage in your code if (ConfigManager::isLayoverEnabled()) { // New layover implementation processWithLayover(request); } else { // Legacy implementation processStandard(request); }","title":"Step 4: C++ Accessor Code"},{"location":"skills/create-otf-variable/tutorial/#step-5-testing-guidance","text":"The skill provides unit test examples: TEST(LayoverTest, WhenDisabled_UsesStandardLogic) { MockPropertiesManager::setValue(\"MIG_ENABLE_LAYOVER\", \"N\"); ASSERT_FALSE(ConfigManager::isLayoverEnabled()); // Test standard behavior } TEST(LayoverTest, WhenEnabled_UsesLayoverLogic) { MockPropertiesManager::setValue(\"MIG_ENABLE_LAYOVER\", \"Y\"); ASSERT_TRUE(ConfigManager::isLayoverEnabled()); // Test layover behavior }","title":"Step 5: Testing Guidance"},{"location":"skills/create-otf-variable/tutorial/#step-6-deployment-strategy","text":"The skill recommends a rollout plan: 1. \u2705 Deploy with default OFF (N) 2. \u2705 Test in LOCAL (enabled) 3. \u2705 Validate in UAT 4. \u2705 Monitor metrics 5. \u2705 Enable in PRD gradually 6. \u2705 Full rollout after validation","title":"Step 6: Deployment Strategy"},{"location":"skills/create-otf-variable/tutorial/#common-usage-patterns","text":"","title":"Common Usage Patterns"},{"location":"skills/create-otf-variable/tutorial/#pattern-1-simple-feature-flag","text":"User: olaf create-otf-variable Create a feature flag for the new caching system: - Name: ENABLE_CACHE - Values: true/false - Default: false - Enable in LOCAL Result : <variable name=\"ENABLE_CACHE\" value=\"false\" control=\"off\" description=\"Enable response caching\"/> bool isCacheEnabled = toolbox::PropertiesManager::GetInstance().isDefined(\"ENABLE_CACHE\") && toolbox::PropertiesManager::GetInstance().getValue(\"ENABLE_CACHE\") == \"true\";","title":"Pattern 1: Simple Feature Flag"},{"location":"skills/create-otf-variable/tutorial/#pattern-2-numeric-configuration","text":"User: olaf create-otf-variable Add retry count configuration: - Name: MAX_RETRY_COUNT - Values: numeric string - Default: 3 - Override in PRD: 5 Result : <common> <variable name=\"MAX_RETRY_COUNT\" value=\"3\" control=\"off\" description=\"Maximum retry attempts\"/> </common> <phase name=\"PRD\"> <variable name=\"MAX_RETRY_COUNT\" value=\"5\" control=\"off\" description=\"Maximum retry attempts\"/> </phase> std::string retryStr = toolbox::PropertiesManager::GetInstance().getValue(\"MAX_RETRY_COUNT\"); int maxRetries = std::stoi(retryStr);","title":"Pattern 2: Numeric Configuration"},{"location":"skills/create-otf-variable/tutorial/#pattern-3-migration-flag","text":"User: olaf create-otf-variable Migration flag for new API: - Name: MIG_ENABLE_NEW_API - Values: Y/N - Default: N - Enable in LOCAL and UAT Result : <common> <variable name=\"MIG_ENABLE_NEW_API\" value=\"N\" control=\"off\" description=\"Enable new API implementation\"/> </common> <phase name=\"LOCAL\"> <variable name=\"MIG_ENABLE_NEW_API\" value=\"Y\" control=\"off\" description=\"Enable new API implementation\"/> </phase> <phase name=\"UAT\"> <variable name=\"MIG_ENABLE_NEW_API\" value=\"Y\" control=\"off\" description=\"Enable new API implementation\"/> </phase>","title":"Pattern 3: Migration Flag"},{"location":"skills/create-otf-variable/tutorial/#tips-best-practices","text":"","title":"Tips &amp; Best Practices"},{"location":"skills/create-otf-variable/tutorial/#naming-conventions","text":"\u2705 Good : - ENABLE_CACHE - Clear feature toggle - MIG_ENABLE_LAYOVER - Migration prefix - IS_PRODUCTION - State flag - MAX_RETRY_COUNT - Descriptive configuration \u274c Avoid : - ENABLE_IS_FEATURE_ENABLED - Redundant - flag1 - Not descriptive - enableCache - Wrong case convention - CACHE - Unclear purpose","title":"Naming Conventions"},{"location":"skills/create-otf-variable/tutorial/#default-values","text":"\u2705 Safe Defaults : - Feature flags: \"N\" or \"false\" (OFF by default) - Retry counts: Conservative values (e.g., \"3\" ) - Timeouts: Safe/tested values \u274c Risky Defaults : - Feature enabled by default without testing - Aggressive retry/timeout values - Production-only configurations","title":"Default Values"},{"location":"skills/create-otf-variable/tutorial/#environment-strategy","text":"Recommended Rollout : 1. LOCAL - Always enable for development 2. UAT - Enable after initial validation 3. PRD - Enable gradually with monitoring Avoid : - Enabling in PRD before LOCAL/UAT testing - Same value across all environments (no override benefit) - Too many environment-specific overrides (complexity)","title":"Environment Strategy"},{"location":"skills/create-otf-variable/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/create-otf-variable/tutorial/#variable-not-recognized","text":"Problem : Runtime error or feature not working Solutions : 1. Verify XML file is loaded by component 2. Check variable name spelling (case-sensitive) 3. Restart application to reload configuration 4. Check OTF logs for XML parsing errors","title":"Variable Not Recognized"},{"location":"skills/create-otf-variable/tutorial/#override-not-applied","text":"Problem : Getting common value instead of phase override Solutions : 1. Verify phase name matches environment exactly 2. Check XML syntax (properly closed tags) 3. Ensure phase section comes after common section 4. Restart application after XML changes","title":"Override Not Applied"},{"location":"skills/create-otf-variable/tutorial/#accessor-always-returns-false","text":"Problem : Feature flag always disabled Solutions : 1. Verify isDefined() check passes 2. Check exact value comparison (case-sensitive) 3. Ensure XML has correct value 4. Debug PropertiesManager call to see actual value","title":"Accessor Always Returns False"},{"location":"skills/create-otf-variable/tutorial/#next-steps","text":"After creating your OTF variable: Review the code with your team Write unit tests for both enabled/disabled states Test in LOCAL environment first Document the feature flag in your component docs Monitor behavior in each environment Plan cleanup after migration is complete","title":"Next Steps"},{"location":"skills/create-otf-variable/tutorial/#related-resources","text":"OTF Configuration Guide - Comprehensive reference OTF Workflow - Detailed step-by-step guide Component XML documentation - Project-specific structure","title":"Related Resources"},{"location":"skills/create-otf-variable/tutorial/#need-help","text":"Check existing variables in your component XML for patterns Review C++ code for existing PropertiesManager usage Consult team for project-specific conventions Use olaf get-bms-expertise for component-level questions","title":"Need Help?"},{"location":"skills/create-person-record/description/","text":"Create Person Record \u00b6 Overview \u00b6 Creates structured person records following a standardized template to document team members and stakeholders with contact information, roles, expertise, responsibilities, and working preferences for effective team coordination. Purpose \u00b6 Projects involve multiple people with different roles, expertise, and availability. This competency solves the problem of scattered or missing team information by creating comprehensive person records that capture all relevant details in a consistent format, enabling better communication, coordination, and knowledge management across the project team. Usage \u00b6 Command : create person record Protocol : Propose-Act When to Use : Use this competency when onboarding new team members, documenting stakeholders, creating a team directory, or whenever you need to formally record information about people involved in the project for coordination and communication purposes. Parameters \u00b6 Required Inputs \u00b6 full_name : Person's complete name email : Professional email address for contact role : Current role in the project or organization project_start_date : When they joined the project (format: YYYYMMDD) contact_guidance : When and how to contact this person (e.g., \"Available Mon-Fri 9-5 EST, prefer email for non-urgent\") areas_of_expertise : Skills, technologies, and domains they specialize in project_responsibilities : Key responsibilities and accountabilities on the project preferred_contact_methods : How they prefer to be reached (email, Slack, phone, etc.) working_hours : Time zone and typical availability Optional Inputs \u00b6 nickname : Preferred nickname or shortened name project_end_date : When they left the project (format: YYYYMMDD) - for former team members notes : Additional relevant information, preferences, or context Context Requirements \u00b6 Access to peoples directory ( .olaf/data/peoples/ ) Access to people register ( .olaf/data/peoples/people-register.md ) Access to person record template Privacy and data protection guidelines Output \u00b6 Deliverables : - New person record file with format: [role]-[name]-[date].md - Updated people register with new entry Format : Markdown file following the people template structure with all contact information, expertise, responsibilities, and working preferences clearly documented. Examples \u00b6 Example 1: New Team Member Onboarding \u00b6 Scenario : Senior developer joining the project Command : create person record Input : Full Name: Sarah Chen Email: sarah.chen@company.com Role: Senior Backend Developer Project Start Date: 20251027 Contact Guidance: Available Mon-Fri 9am-6pm PST, responds to Slack within 2 hours during work hours Areas of Expertise: Python, PostgreSQL, API design, microservices, AWS Project Responsibilities: Backend API development, database optimization, code reviews Preferred Contact Methods: Slack for urgent, email for non-urgent, video calls for complex discussions Working Hours: 9am-6pm Pacific Time (UTC-8) Notes: Prefers morning meetings, works from home Wednesdays Result : Created senior-backend-developer-sarah-chen-20251027.md , updated people register, logged in changelog Example 2: Stakeholder Documentation \u00b6 Scenario : Recording product owner information Command : create person record Input : Full Name: Michael Rodriguez Nickname: Mike Email: m.rodriguez@company.com Role: Product Owner Project Start Date: 20250901 Contact Guidance: Available for questions during sprint planning and reviews, async communication preferred otherwise Areas of Expertise: Product strategy, user research, market analysis, agile methodologies Project Responsibilities: Product vision, backlog prioritization, stakeholder communication, acceptance criteria Preferred Contact Methods: Email for updates, Slack for quick questions, scheduled meetings for decisions Working Hours: 8am-5pm Eastern Time (UTC-5), limited availability Fridays Result : Created product owner record with all stakeholder contact and coordination information Example 3: Former Team Member Record \u00b6 Scenario : Documenting departing team member for knowledge retention Command : create person record Input : Full Name: Alex Thompson Email: alex.thompson@company.com Role: DevOps Engineer Project Start Date: 20240315 Project End Date: 20251020 Contact Guidance: No longer with project, contact DevOps team for handover questions Areas of Expertise: Kubernetes, CI/CD, monitoring, infrastructure as code Project Responsibilities: Deployment pipelines, infrastructure management, monitoring setup Notes: Left comprehensive documentation in /docs/devops/, handover completed with Jamie Lee Result : Created historical record documenting Alex's contributions and handover information Related Competencies \u00b6 create-decision-record : Person records identify decision makers and stakeholders for decision documentation create-job : Person records help with job assignment and identifying expertise for specific work prepare-conversation-handover : Person records provide contact information for handover coordination review-progress : Team member information informs resource allocation and capacity planning Tips & Best Practices \u00b6 Create person records during onboarding to ensure information is captured while fresh Keep contact information and working hours up to date - review quarterly Document communication preferences to respect people's working styles Include time zones explicitly to avoid scheduling conflicts Record areas of expertise to help with task assignment and knowledge sharing Update records when roles or responsibilities change significantly Create records for key stakeholders, not just team members Respect privacy - only include information relevant to project coordination Limitations \u00b6 Requires manual input of all person details - does not integrate with HR systems or directories Does not automatically notify the person when their record is created Cannot enforce privacy policies - relies on users to follow data protection guidelines Does not automatically update when information changes - requires manual maintenance Person records are local to the project - not synchronized with organization-wide directories Cannot validate email addresses or contact information accuracy Source : core/competencies/project-manager/prompts/create-person-record.md","title":"Create Person Record"},{"location":"skills/create-person-record/description/#create-person-record","text":"","title":"Create Person Record"},{"location":"skills/create-person-record/description/#overview","text":"Creates structured person records following a standardized template to document team members and stakeholders with contact information, roles, expertise, responsibilities, and working preferences for effective team coordination.","title":"Overview"},{"location":"skills/create-person-record/description/#purpose","text":"Projects involve multiple people with different roles, expertise, and availability. This competency solves the problem of scattered or missing team information by creating comprehensive person records that capture all relevant details in a consistent format, enabling better communication, coordination, and knowledge management across the project team.","title":"Purpose"},{"location":"skills/create-person-record/description/#usage","text":"Command : create person record Protocol : Propose-Act When to Use : Use this competency when onboarding new team members, documenting stakeholders, creating a team directory, or whenever you need to formally record information about people involved in the project for coordination and communication purposes.","title":"Usage"},{"location":"skills/create-person-record/description/#parameters","text":"","title":"Parameters"},{"location":"skills/create-person-record/description/#required-inputs","text":"full_name : Person's complete name email : Professional email address for contact role : Current role in the project or organization project_start_date : When they joined the project (format: YYYYMMDD) contact_guidance : When and how to contact this person (e.g., \"Available Mon-Fri 9-5 EST, prefer email for non-urgent\") areas_of_expertise : Skills, technologies, and domains they specialize in project_responsibilities : Key responsibilities and accountabilities on the project preferred_contact_methods : How they prefer to be reached (email, Slack, phone, etc.) working_hours : Time zone and typical availability","title":"Required Inputs"},{"location":"skills/create-person-record/description/#optional-inputs","text":"nickname : Preferred nickname or shortened name project_end_date : When they left the project (format: YYYYMMDD) - for former team members notes : Additional relevant information, preferences, or context","title":"Optional Inputs"},{"location":"skills/create-person-record/description/#context-requirements","text":"Access to peoples directory ( .olaf/data/peoples/ ) Access to people register ( .olaf/data/peoples/people-register.md ) Access to person record template Privacy and data protection guidelines","title":"Context Requirements"},{"location":"skills/create-person-record/description/#output","text":"Deliverables : - New person record file with format: [role]-[name]-[date].md - Updated people register with new entry Format : Markdown file following the people template structure with all contact information, expertise, responsibilities, and working preferences clearly documented.","title":"Output"},{"location":"skills/create-person-record/description/#examples","text":"","title":"Examples"},{"location":"skills/create-person-record/description/#example-1-new-team-member-onboarding","text":"Scenario : Senior developer joining the project Command : create person record Input : Full Name: Sarah Chen Email: sarah.chen@company.com Role: Senior Backend Developer Project Start Date: 20251027 Contact Guidance: Available Mon-Fri 9am-6pm PST, responds to Slack within 2 hours during work hours Areas of Expertise: Python, PostgreSQL, API design, microservices, AWS Project Responsibilities: Backend API development, database optimization, code reviews Preferred Contact Methods: Slack for urgent, email for non-urgent, video calls for complex discussions Working Hours: 9am-6pm Pacific Time (UTC-8) Notes: Prefers morning meetings, works from home Wednesdays Result : Created senior-backend-developer-sarah-chen-20251027.md , updated people register, logged in changelog","title":"Example 1: New Team Member Onboarding"},{"location":"skills/create-person-record/description/#example-2-stakeholder-documentation","text":"Scenario : Recording product owner information Command : create person record Input : Full Name: Michael Rodriguez Nickname: Mike Email: m.rodriguez@company.com Role: Product Owner Project Start Date: 20250901 Contact Guidance: Available for questions during sprint planning and reviews, async communication preferred otherwise Areas of Expertise: Product strategy, user research, market analysis, agile methodologies Project Responsibilities: Product vision, backlog prioritization, stakeholder communication, acceptance criteria Preferred Contact Methods: Email for updates, Slack for quick questions, scheduled meetings for decisions Working Hours: 8am-5pm Eastern Time (UTC-5), limited availability Fridays Result : Created product owner record with all stakeholder contact and coordination information","title":"Example 2: Stakeholder Documentation"},{"location":"skills/create-person-record/description/#example-3-former-team-member-record","text":"Scenario : Documenting departing team member for knowledge retention Command : create person record Input : Full Name: Alex Thompson Email: alex.thompson@company.com Role: DevOps Engineer Project Start Date: 20240315 Project End Date: 20251020 Contact Guidance: No longer with project, contact DevOps team for handover questions Areas of Expertise: Kubernetes, CI/CD, monitoring, infrastructure as code Project Responsibilities: Deployment pipelines, infrastructure management, monitoring setup Notes: Left comprehensive documentation in /docs/devops/, handover completed with Jamie Lee Result : Created historical record documenting Alex's contributions and handover information","title":"Example 3: Former Team Member Record"},{"location":"skills/create-person-record/description/#related-competencies","text":"create-decision-record : Person records identify decision makers and stakeholders for decision documentation create-job : Person records help with job assignment and identifying expertise for specific work prepare-conversation-handover : Person records provide contact information for handover coordination review-progress : Team member information informs resource allocation and capacity planning","title":"Related Competencies"},{"location":"skills/create-person-record/description/#tips-best-practices","text":"Create person records during onboarding to ensure information is captured while fresh Keep contact information and working hours up to date - review quarterly Document communication preferences to respect people's working styles Include time zones explicitly to avoid scheduling conflicts Record areas of expertise to help with task assignment and knowledge sharing Update records when roles or responsibilities change significantly Create records for key stakeholders, not just team members Respect privacy - only include information relevant to project coordination","title":"Tips &amp; Best Practices"},{"location":"skills/create-person-record/description/#limitations","text":"Requires manual input of all person details - does not integrate with HR systems or directories Does not automatically notify the person when their record is created Cannot enforce privacy policies - relies on users to follow data protection guidelines Does not automatically update when information changes - requires manual maintenance Person records are local to the project - not synchronized with organization-wide directories Cannot validate email addresses or contact information accuracy Source : core/competencies/project-manager/prompts/create-person-record.md","title":"Limitations"},{"location":"skills/create-person-record/tutorial/","text":"Create Person Record: Step-by-Step Tutorial \u00b6 How to Execute the \"Create Person Record\" Competency This tutorial shows exactly how to create a new person record following the standard template and update related indexes for team member and stakeholder tracking. Prerequisites \u00b6 OLAF framework loaded and active Access to peoples directory Person record template available Understanding of privacy and data protection requirements Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 User Action: 1. Type: olaf create person record 2. Or use aliases: olaf create person , olaf person record , olaf add contact 3. Press Enter AI Response: Acknowledges request and begins gathering person information using Propose-Act protocol. Step 2: Provide Person Details \u00b6 User Provides Required Information: - full_name : \"Jane Smith\" - email : \"jane.smith@company.com\" - role : \"Senior Developer\" - project_start_date : \"20251001\" (YYYYMMDD format) Optional Information: - nickname : \"Jane\" - project_end_date : \"20260930\" (if applicable) - contact_guidance : \"Available Mon-Fri 9am-5pm EST, prefer email for non-urgent\" - areas_of_expertise : \"OAuth 2.0, React, Node.js, PostgreSQL\" - project_responsibilities : \"Lead OAuth implementation, mentor junior developers\" - preferred_contact_methods : \"Email (primary), Slack (urgent), Teams (meetings)\" - working_hours : \"9am-5pm EST (UTC-5)\" - notes : \"On-call rotation: Week 1 of each month\" Step 3: Record Creation \u00b6 What AI Does: 1. Generates filename: senior-developer-jane-smith-20251001.md 2. Loads person template 3. Populates all sections with provided information 4. Creates file in peoples directory Filename Format: [role]-[name]-[date].md Step 4: Documentation Updates \u00b6 What AI Does: - Adds entry to people register - Updates team directory index Step 5: Validation \u00b6 What AI Does: - Verifies all required fields populated - Checks for existing records (duplicate detection) - Ensures consistent formatting - Validates email format - Confirms privacy compliance You Should See: Complete person record with all sections filled and confirmation of file creation. Verification Checklist \u00b6 \u2705 Person record file created with correct naming \u2705 All required fields populated \u2705 People register updated with new entry \u2705 Email format validated \u2705 Privacy guidelines followed \u2705 Template structure preserved Troubleshooting \u00b6 If email format invalid: - Verify email follows standard format: name@domain.com - Check for typos or special characters If duplicate record detected: - Review existing record - Update existing instead of creating new - Use different filename if intentional duplicate If template not found: Verify template at: core/competencies/project-manager/templates/people-template.md Key Learning Points \u00b6 Privacy First : Person records follow data protection guidelines Structured Information : Template ensures consistent contact information Traceability : All person records tracked in register Working Hours Respect : Documents availability to prevent off-hours contact Expected Timeline \u00b6 Total time: 3-5 minutes User input: 2-3 minutes for person details AI execution: 1-2 minutes for file creation and updates","title":"Create Person Record: Step-by-Step Tutorial"},{"location":"skills/create-person-record/tutorial/#create-person-record-step-by-step-tutorial","text":"How to Execute the \"Create Person Record\" Competency This tutorial shows exactly how to create a new person record following the standard template and update related indexes for team member and stakeholder tracking.","title":"Create Person Record: Step-by-Step Tutorial"},{"location":"skills/create-person-record/tutorial/#prerequisites","text":"OLAF framework loaded and active Access to peoples directory Person record template available Understanding of privacy and data protection requirements","title":"Prerequisites"},{"location":"skills/create-person-record/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/create-person-record/tutorial/#step-1-invoke-the-competency","text":"User Action: 1. Type: olaf create person record 2. Or use aliases: olaf create person , olaf person record , olaf add contact 3. Press Enter AI Response: Acknowledges request and begins gathering person information using Propose-Act protocol.","title":"Step 1: Invoke the Competency"},{"location":"skills/create-person-record/tutorial/#step-2-provide-person-details","text":"User Provides Required Information: - full_name : \"Jane Smith\" - email : \"jane.smith@company.com\" - role : \"Senior Developer\" - project_start_date : \"20251001\" (YYYYMMDD format) Optional Information: - nickname : \"Jane\" - project_end_date : \"20260930\" (if applicable) - contact_guidance : \"Available Mon-Fri 9am-5pm EST, prefer email for non-urgent\" - areas_of_expertise : \"OAuth 2.0, React, Node.js, PostgreSQL\" - project_responsibilities : \"Lead OAuth implementation, mentor junior developers\" - preferred_contact_methods : \"Email (primary), Slack (urgent), Teams (meetings)\" - working_hours : \"9am-5pm EST (UTC-5)\" - notes : \"On-call rotation: Week 1 of each month\"","title":"Step 2: Provide Person Details"},{"location":"skills/create-person-record/tutorial/#step-3-record-creation","text":"What AI Does: 1. Generates filename: senior-developer-jane-smith-20251001.md 2. Loads person template 3. Populates all sections with provided information 4. Creates file in peoples directory Filename Format: [role]-[name]-[date].md","title":"Step 3: Record Creation"},{"location":"skills/create-person-record/tutorial/#step-4-documentation-updates","text":"What AI Does: - Adds entry to people register - Updates team directory index","title":"Step 4: Documentation Updates"},{"location":"skills/create-person-record/tutorial/#step-5-validation","text":"What AI Does: - Verifies all required fields populated - Checks for existing records (duplicate detection) - Ensures consistent formatting - Validates email format - Confirms privacy compliance You Should See: Complete person record with all sections filled and confirmation of file creation.","title":"Step 5: Validation"},{"location":"skills/create-person-record/tutorial/#verification-checklist","text":"\u2705 Person record file created with correct naming \u2705 All required fields populated \u2705 People register updated with new entry \u2705 Email format validated \u2705 Privacy guidelines followed \u2705 Template structure preserved","title":"Verification Checklist"},{"location":"skills/create-person-record/tutorial/#troubleshooting","text":"If email format invalid: - Verify email follows standard format: name@domain.com - Check for typos or special characters If duplicate record detected: - Review existing record - Update existing instead of creating new - Use different filename if intentional duplicate If template not found: Verify template at: core/competencies/project-manager/templates/people-template.md","title":"Troubleshooting"},{"location":"skills/create-person-record/tutorial/#key-learning-points","text":"Privacy First : Person records follow data protection guidelines Structured Information : Template ensures consistent contact information Traceability : All person records tracked in register Working Hours Respect : Documents availability to prevent off-hours contact","title":"Key Learning Points"},{"location":"skills/create-person-record/tutorial/#expected-timeline","text":"Total time: 3-5 minutes User input: 2-3 minutes for person details AI execution: 1-2 minutes for file creation and updates","title":"Expected Timeline"},{"location":"skills/create-presentation-plan/description/","text":"Create Presentation Plan Skill \u00b6 Overview \u00b6 The create-presentation-plan skill is a professional presentation planning tool that creates comprehensive, structured presentation plans suitable for both reading-only documents and live presentation delivery. This skill serves as the foundation for PowerPoint generation and ensures well-organized, audience-focused presentation development. Purpose \u00b6 This skill transforms presentation requirements into detailed, actionable presentation plans that include: - Calculated slide counts based on presentation type and duration - Structured slide-by-slide content organization - Professional layout recommendations - Optional visual element guidance - Multi-language support Key Features \u00b6 Smart Slide Calculation : Automatically calculates optimal slide count based on presentation type (reading vs. live) and duration Template-Based Structure : Uses professional presentation plan templates for consistent output Multi-Language Support : Supports English, French, Spanish, and German Content Accuracy : Ensures content is based only on provided source materials Professional Formatting : Creates clean, bullet-free content suitable for presentation slides Integration Ready : Output designed for seamless PowerPoint generation Use Cases \u00b6 Primary Applications \u00b6 Business Presentations : Executive briefings, project updates, quarterly reviews Technical Presentations : Architecture reviews, system demonstrations, training sessions Academic Presentations : Research findings, educational content, conference presentations Marketing Presentations : Product launches, sales pitches, promotional content Audience Types \u00b6 Technical Teams : Developers, architects, engineers Business Stakeholders : Executives, managers, clients Academic Audiences : Researchers, students, conference attendees Mixed Audiences : Cross-functional teams, public presentations Integration with OLAF Ecosystem \u00b6 Workflow Integration \u00b6 Planning Phase : Use create-presentation-plan to structure content Content Generation : Use generate-post-from-plan for detailed slide content Multi-Format Creation : Use create-presentation-and-posts-workflow for comprehensive content pipeline PowerPoint Generation : Use generate-pptx-from-plan for automated slide creation Complementary Skills \u00b6 generate-step-by-step-tutorial : For educational presentation content generate-tech-spec-from-code : For technical presentation source material research-and-report : For presentation research and data gathering Technical Requirements \u00b6 Input : Presentation topic, audience, type, duration/slide count, language preference Output : Structured markdown presentation plan with timestamped filename Storage : Plans saved to OLAF staging directory for workflow continuity Templates : Requires presentation plan template for consistent structure Best Practices \u00b6 Content Development \u00b6 Base all content on documented source materials Avoid speculation or assumption beyond provided information Use clear, professional language appropriate for target audience Maintain consistency in messaging and structure throughout plan Presentation Planning \u00b6 Consider audience knowledge level and needs Structure logical flow from introduction to conclusion Balance content depth with presentation time constraints Include clear takeaways and next steps File Management \u00b6 Use descriptive presentation names for easy identification Leverage timestamp naming for version control Store plans in staging directory for workflow integration Maintain template consistency across all presentations Quality Assurance \u00b6 The skill ensures high-quality presentation planning through: - Parameter Validation : Confirms all required inputs before processing - Content Accuracy : Only includes verified, documented information - Structure Compliance : Follows professional presentation planning templates - Language Consistency : Maintains target language throughout all content - Output Validation : Verifies plan completeness and readiness for next steps","title":"Create Presentation Plan Skill"},{"location":"skills/create-presentation-plan/description/#create-presentation-plan-skill","text":"","title":"Create Presentation Plan Skill"},{"location":"skills/create-presentation-plan/description/#overview","text":"The create-presentation-plan skill is a professional presentation planning tool that creates comprehensive, structured presentation plans suitable for both reading-only documents and live presentation delivery. This skill serves as the foundation for PowerPoint generation and ensures well-organized, audience-focused presentation development.","title":"Overview"},{"location":"skills/create-presentation-plan/description/#purpose","text":"This skill transforms presentation requirements into detailed, actionable presentation plans that include: - Calculated slide counts based on presentation type and duration - Structured slide-by-slide content organization - Professional layout recommendations - Optional visual element guidance - Multi-language support","title":"Purpose"},{"location":"skills/create-presentation-plan/description/#key-features","text":"Smart Slide Calculation : Automatically calculates optimal slide count based on presentation type (reading vs. live) and duration Template-Based Structure : Uses professional presentation plan templates for consistent output Multi-Language Support : Supports English, French, Spanish, and German Content Accuracy : Ensures content is based only on provided source materials Professional Formatting : Creates clean, bullet-free content suitable for presentation slides Integration Ready : Output designed for seamless PowerPoint generation","title":"Key Features"},{"location":"skills/create-presentation-plan/description/#use-cases","text":"","title":"Use Cases"},{"location":"skills/create-presentation-plan/description/#primary-applications","text":"Business Presentations : Executive briefings, project updates, quarterly reviews Technical Presentations : Architecture reviews, system demonstrations, training sessions Academic Presentations : Research findings, educational content, conference presentations Marketing Presentations : Product launches, sales pitches, promotional content","title":"Primary Applications"},{"location":"skills/create-presentation-plan/description/#audience-types","text":"Technical Teams : Developers, architects, engineers Business Stakeholders : Executives, managers, clients Academic Audiences : Researchers, students, conference attendees Mixed Audiences : Cross-functional teams, public presentations","title":"Audience Types"},{"location":"skills/create-presentation-plan/description/#integration-with-olaf-ecosystem","text":"","title":"Integration with OLAF Ecosystem"},{"location":"skills/create-presentation-plan/description/#workflow-integration","text":"Planning Phase : Use create-presentation-plan to structure content Content Generation : Use generate-post-from-plan for detailed slide content Multi-Format Creation : Use create-presentation-and-posts-workflow for comprehensive content pipeline PowerPoint Generation : Use generate-pptx-from-plan for automated slide creation","title":"Workflow Integration"},{"location":"skills/create-presentation-plan/description/#complementary-skills","text":"generate-step-by-step-tutorial : For educational presentation content generate-tech-spec-from-code : For technical presentation source material research-and-report : For presentation research and data gathering","title":"Complementary Skills"},{"location":"skills/create-presentation-plan/description/#technical-requirements","text":"Input : Presentation topic, audience, type, duration/slide count, language preference Output : Structured markdown presentation plan with timestamped filename Storage : Plans saved to OLAF staging directory for workflow continuity Templates : Requires presentation plan template for consistent structure","title":"Technical Requirements"},{"location":"skills/create-presentation-plan/description/#best-practices","text":"","title":"Best Practices"},{"location":"skills/create-presentation-plan/description/#content-development","text":"Base all content on documented source materials Avoid speculation or assumption beyond provided information Use clear, professional language appropriate for target audience Maintain consistency in messaging and structure throughout plan","title":"Content Development"},{"location":"skills/create-presentation-plan/description/#presentation-planning","text":"Consider audience knowledge level and needs Structure logical flow from introduction to conclusion Balance content depth with presentation time constraints Include clear takeaways and next steps","title":"Presentation Planning"},{"location":"skills/create-presentation-plan/description/#file-management","text":"Use descriptive presentation names for easy identification Leverage timestamp naming for version control Store plans in staging directory for workflow integration Maintain template consistency across all presentations","title":"File Management"},{"location":"skills/create-presentation-plan/description/#quality-assurance","text":"The skill ensures high-quality presentation planning through: - Parameter Validation : Confirms all required inputs before processing - Content Accuracy : Only includes verified, documented information - Structure Compliance : Follows professional presentation planning templates - Language Consistency : Maintains target language throughout all content - Output Validation : Verifies plan completeness and readiness for next steps","title":"Quality Assurance"},{"location":"skills/create-presentation-plan/tutorial/","text":"Create Presentation Plan - Step-by-Step Tutorial \u00b6 Overview \u00b6 This tutorial guides you through using the create-presentation-plan skill to create professional, structured presentation plans that serve as the foundation for PowerPoint generation or live presentation delivery. Prerequisites \u00b6 Access to the OLAF framework with create-presentation-plan skill Clear understanding of your presentation topic and audience Decision on presentation type (reading-only vs. live presentation) Step-by-Step Process \u00b6 Step 1: Initiate the Skill \u00b6 Command : olaf create-presentation-plan The skill will start and request the required parameters for your presentation planning. Step 2: Provide Core Information \u00b6 You'll be prompted to provide essential information: Required Parameters: - Topic : Your presentation subject and key objectives - Example: \"Enterprise Cloud Migration Strategy and Implementation Roadmap\" - Audience : Target audience and their needs - Example: \"Executive leadership team and IT directors with mixed technical knowledge\" Example Response: Topic: Enterprise Cloud Migration Strategy and Implementation Roadmap Audience: Executive leadership team and IT directors with mixed technical knowledge Step 3: Select Presentation Type \u00b6 Choose between two presentation types: Option A: Reading-Only Presentation - For presentations that will be read but not presented live - You'll need to specify the number of slides (default: 5) - Example: \"Reading only, 7 slides\" Option B: Live Presentation - For presentations delivered to an audience - You'll need to specify duration in minutes - Slide count will be calculated automatically: (duration \u00f7 5) + 2 slides - Example: \"Live presentation, 30 minutes\" \u2192 Results in 8 slides Step 4: Configure Optional Settings \u00b6 Language Selection (Optional) - English (default) - French - Spanish - German Visual Elements (Optional) - Choose whether to include image prompts for visual elements - Default: No image prompts - If yes, descriptions for relevant visuals will be included Example Configuration: Presentation Type: Live presentation Duration: 25 minutes Language: English Include image prompts: No Step 5: Review the Calculated Structure \u00b6 The skill will present the planned structure: - Calculated slide count : Based on your type and duration - Presentation outline : Overview of planned structure - Content approach : How information will be organized Example Output: Calculated Slides: 7 slides (25-minute live presentation) Structure: Title \u2192 Agenda \u2192 Current State \u2192 Migration Strategy \u2192 Implementation Plan \u2192 Timeline & Next Steps \u2192 Q&A Step 6: Confirm Plan Creation \u00b6 The skill will ask for your approval before creating the detailed plan: - Review the proposed structure - Confirm the approach meets your needs - Approve creation of the detailed presentation plan Step 7: Review Generated Plan \u00b6 The skill will create and save a comprehensive presentation plan: File Location : [staging_directory]/[presentation-name]-plan-YYYYMMDD-HHmm.md Plan Content Includes: - Presentation metadata (title, audience, type, duration) - Slide-by-slide breakdown with layout recommendations - Content guidance for each slide - Optional image prompts (if requested) - Implementation notes Step 8: Next Steps Options \u00b6 After plan creation, you can: Option A: Edit the Plan - Review and modify the generated plan as needed - Add specific content details - Adjust structure or messaging Option B: Generate Content - Use generate-post-from-plan to create detailed slide content - Use create-presentation-and-posts-workflow for multi-format content Option C: Create PowerPoint - Use generate-pptx-from-plan to automatically generate PowerPoint slides - Requires the presentation plan as input Example Walkthrough \u00b6 Scenario: Technical Team Presentation \u00b6 Initial Request: \"I need to create a presentation about our new API architecture for the development team.\" Step-by-Step Interaction: User: olaf create-presentation-plan System: I'll help you create a comprehensive presentation plan. Let me gather the required information. Topic: New API Architecture Overview and Implementation Guide Audience: Development team (senior and junior developers) System: What type of presentation is this? User: Live presentation, 20 minutes System: Language preference? User: English System: Include image prompts for visual elements? User: Yes System: Based on your requirements: - Topic: New API Architecture Overview and Implementation Guide - Audience: Development team (senior and junior developers) - Type: Live presentation (20 minutes) - Calculated slides: 6 slides (20\u00f75 + 2 = 6) - Language: English - Visual elements: Yes Proposed structure: 1. Title Slide 2. Agenda & Objectives 3. Current Architecture vs. New API Design 4. Key Benefits & Technical Improvements 5. Implementation Timeline & Next Steps 6. Q&A & Discussion Shall I create this presentation plan? User: Yes, please create it. System: \u2705 Presentation plan created successfully! File saved: staging/api-architecture-presentation-plan-20251119-1145.md The plan is ready for review and can be used for: - Content generation with generate-post-from-plan - PowerPoint creation with generate-pptx-from-plan - Multi-format content with create-presentation-and-posts-workflow Common Use Cases and Tips \u00b6 Business Presentations \u00b6 Focus on outcomes and business value Include executive summary and key takeaways Consider time for questions and discussion Technical Presentations \u00b6 Balance technical depth with audience knowledge Include diagrams and visual aids Plan for demo time if applicable Training Presentations \u00b6 Structure for learning progression Include practice exercises or examples Plan for interaction and engagement Client Presentations \u00b6 Focus on client value and benefits Include clear next steps and calls to action Prepare for various question scenarios Troubleshooting \u00b6 Common Issues and Solutions \u00b6 Issue : \"Not enough content for the duration\" Solution : Adjust presentation type to reading-only with fewer slides, or add more detailed sections Issue : \"Too technical for the audience\" Solution : Revise audience description to be more specific about technical knowledge level Issue : \"Plan seems too high-level\" Solution : Use the plan as foundation and generate detailed content with generate-post-from-plan Issue : \"Need visual elements but didn't request them initially\" Solution : Re-run with image prompts enabled, or manually add visual descriptions to the plan Best Practices \u00b6 Effective Planning \u00b6 Be specific about audience knowledge and needs Consider presentation environment (formal vs. informal) Plan for interaction and engagement opportunities Allow buffer time for questions and discussion Content Organization \u00b6 Start with clear objectives and agenda Use logical flow from context to conclusion Include clear takeaways and next steps Balance content depth with time constraints Follow-up Actions \u00b6 Review and refine the generated plan Validate content accuracy with source materials Consider integration with other OLAF skills for complete content creation Test presentation flow and timing before delivery Integration Examples \u00b6 Complete Presentation Workflow \u00b6 Planning : create-presentation-plan \u2192 Generate structure Content : generate-post-from-plan \u2192 Create detailed content Slides : generate-pptx-from-plan \u2192 Produce PowerPoint Multi-format : Export to blog posts, documentation, etc. Research-Driven Presentations \u00b6 Research : research-and-report \u2192 Gather information Planning : create-presentation-plan \u2192 Structure findings Content : generate-post-from-plan \u2192 Develop detailed slides Generation : generate-pptx-from-plan \u2192 Create final presentation","title":"Create Presentation Plan - Step-by-Step Tutorial"},{"location":"skills/create-presentation-plan/tutorial/#create-presentation-plan-step-by-step-tutorial","text":"","title":"Create Presentation Plan - Step-by-Step Tutorial"},{"location":"skills/create-presentation-plan/tutorial/#overview","text":"This tutorial guides you through using the create-presentation-plan skill to create professional, structured presentation plans that serve as the foundation for PowerPoint generation or live presentation delivery.","title":"Overview"},{"location":"skills/create-presentation-plan/tutorial/#prerequisites","text":"Access to the OLAF framework with create-presentation-plan skill Clear understanding of your presentation topic and audience Decision on presentation type (reading-only vs. live presentation)","title":"Prerequisites"},{"location":"skills/create-presentation-plan/tutorial/#step-by-step-process","text":"","title":"Step-by-Step Process"},{"location":"skills/create-presentation-plan/tutorial/#step-1-initiate-the-skill","text":"Command : olaf create-presentation-plan The skill will start and request the required parameters for your presentation planning.","title":"Step 1: Initiate the Skill"},{"location":"skills/create-presentation-plan/tutorial/#step-2-provide-core-information","text":"You'll be prompted to provide essential information: Required Parameters: - Topic : Your presentation subject and key objectives - Example: \"Enterprise Cloud Migration Strategy and Implementation Roadmap\" - Audience : Target audience and their needs - Example: \"Executive leadership team and IT directors with mixed technical knowledge\" Example Response: Topic: Enterprise Cloud Migration Strategy and Implementation Roadmap Audience: Executive leadership team and IT directors with mixed technical knowledge","title":"Step 2: Provide Core Information"},{"location":"skills/create-presentation-plan/tutorial/#step-3-select-presentation-type","text":"Choose between two presentation types: Option A: Reading-Only Presentation - For presentations that will be read but not presented live - You'll need to specify the number of slides (default: 5) - Example: \"Reading only, 7 slides\" Option B: Live Presentation - For presentations delivered to an audience - You'll need to specify duration in minutes - Slide count will be calculated automatically: (duration \u00f7 5) + 2 slides - Example: \"Live presentation, 30 minutes\" \u2192 Results in 8 slides","title":"Step 3: Select Presentation Type"},{"location":"skills/create-presentation-plan/tutorial/#step-4-configure-optional-settings","text":"Language Selection (Optional) - English (default) - French - Spanish - German Visual Elements (Optional) - Choose whether to include image prompts for visual elements - Default: No image prompts - If yes, descriptions for relevant visuals will be included Example Configuration: Presentation Type: Live presentation Duration: 25 minutes Language: English Include image prompts: No","title":"Step 4: Configure Optional Settings"},{"location":"skills/create-presentation-plan/tutorial/#step-5-review-the-calculated-structure","text":"The skill will present the planned structure: - Calculated slide count : Based on your type and duration - Presentation outline : Overview of planned structure - Content approach : How information will be organized Example Output: Calculated Slides: 7 slides (25-minute live presentation) Structure: Title \u2192 Agenda \u2192 Current State \u2192 Migration Strategy \u2192 Implementation Plan \u2192 Timeline & Next Steps \u2192 Q&A","title":"Step 5: Review the Calculated Structure"},{"location":"skills/create-presentation-plan/tutorial/#step-6-confirm-plan-creation","text":"The skill will ask for your approval before creating the detailed plan: - Review the proposed structure - Confirm the approach meets your needs - Approve creation of the detailed presentation plan","title":"Step 6: Confirm Plan Creation"},{"location":"skills/create-presentation-plan/tutorial/#step-7-review-generated-plan","text":"The skill will create and save a comprehensive presentation plan: File Location : [staging_directory]/[presentation-name]-plan-YYYYMMDD-HHmm.md Plan Content Includes: - Presentation metadata (title, audience, type, duration) - Slide-by-slide breakdown with layout recommendations - Content guidance for each slide - Optional image prompts (if requested) - Implementation notes","title":"Step 7: Review Generated Plan"},{"location":"skills/create-presentation-plan/tutorial/#step-8-next-steps-options","text":"After plan creation, you can: Option A: Edit the Plan - Review and modify the generated plan as needed - Add specific content details - Adjust structure or messaging Option B: Generate Content - Use generate-post-from-plan to create detailed slide content - Use create-presentation-and-posts-workflow for multi-format content Option C: Create PowerPoint - Use generate-pptx-from-plan to automatically generate PowerPoint slides - Requires the presentation plan as input","title":"Step 8: Next Steps Options"},{"location":"skills/create-presentation-plan/tutorial/#example-walkthrough","text":"","title":"Example Walkthrough"},{"location":"skills/create-presentation-plan/tutorial/#scenario-technical-team-presentation","text":"Initial Request: \"I need to create a presentation about our new API architecture for the development team.\" Step-by-Step Interaction: User: olaf create-presentation-plan System: I'll help you create a comprehensive presentation plan. Let me gather the required information. Topic: New API Architecture Overview and Implementation Guide Audience: Development team (senior and junior developers) System: What type of presentation is this? User: Live presentation, 20 minutes System: Language preference? User: English System: Include image prompts for visual elements? User: Yes System: Based on your requirements: - Topic: New API Architecture Overview and Implementation Guide - Audience: Development team (senior and junior developers) - Type: Live presentation (20 minutes) - Calculated slides: 6 slides (20\u00f75 + 2 = 6) - Language: English - Visual elements: Yes Proposed structure: 1. Title Slide 2. Agenda & Objectives 3. Current Architecture vs. New API Design 4. Key Benefits & Technical Improvements 5. Implementation Timeline & Next Steps 6. Q&A & Discussion Shall I create this presentation plan? User: Yes, please create it. System: \u2705 Presentation plan created successfully! File saved: staging/api-architecture-presentation-plan-20251119-1145.md The plan is ready for review and can be used for: - Content generation with generate-post-from-plan - PowerPoint creation with generate-pptx-from-plan - Multi-format content with create-presentation-and-posts-workflow","title":"Scenario: Technical Team Presentation"},{"location":"skills/create-presentation-plan/tutorial/#common-use-cases-and-tips","text":"","title":"Common Use Cases and Tips"},{"location":"skills/create-presentation-plan/tutorial/#business-presentations","text":"Focus on outcomes and business value Include executive summary and key takeaways Consider time for questions and discussion","title":"Business Presentations"},{"location":"skills/create-presentation-plan/tutorial/#technical-presentations","text":"Balance technical depth with audience knowledge Include diagrams and visual aids Plan for demo time if applicable","title":"Technical Presentations"},{"location":"skills/create-presentation-plan/tutorial/#training-presentations","text":"Structure for learning progression Include practice exercises or examples Plan for interaction and engagement","title":"Training Presentations"},{"location":"skills/create-presentation-plan/tutorial/#client-presentations","text":"Focus on client value and benefits Include clear next steps and calls to action Prepare for various question scenarios","title":"Client Presentations"},{"location":"skills/create-presentation-plan/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/create-presentation-plan/tutorial/#common-issues-and-solutions","text":"Issue : \"Not enough content for the duration\" Solution : Adjust presentation type to reading-only with fewer slides, or add more detailed sections Issue : \"Too technical for the audience\" Solution : Revise audience description to be more specific about technical knowledge level Issue : \"Plan seems too high-level\" Solution : Use the plan as foundation and generate detailed content with generate-post-from-plan Issue : \"Need visual elements but didn't request them initially\" Solution : Re-run with image prompts enabled, or manually add visual descriptions to the plan","title":"Common Issues and Solutions"},{"location":"skills/create-presentation-plan/tutorial/#best-practices","text":"","title":"Best Practices"},{"location":"skills/create-presentation-plan/tutorial/#effective-planning","text":"Be specific about audience knowledge and needs Consider presentation environment (formal vs. informal) Plan for interaction and engagement opportunities Allow buffer time for questions and discussion","title":"Effective Planning"},{"location":"skills/create-presentation-plan/tutorial/#content-organization","text":"Start with clear objectives and agenda Use logical flow from context to conclusion Include clear takeaways and next steps Balance content depth with time constraints","title":"Content Organization"},{"location":"skills/create-presentation-plan/tutorial/#follow-up-actions","text":"Review and refine the generated plan Validate content accuracy with source materials Consider integration with other OLAF skills for complete content creation Test presentation flow and timing before delivery","title":"Follow-up Actions"},{"location":"skills/create-presentation-plan/tutorial/#integration-examples","text":"","title":"Integration Examples"},{"location":"skills/create-presentation-plan/tutorial/#complete-presentation-workflow","text":"Planning : create-presentation-plan \u2192 Generate structure Content : generate-post-from-plan \u2192 Create detailed content Slides : generate-pptx-from-plan \u2192 Produce PowerPoint Multi-format : Export to blog posts, documentation, etc.","title":"Complete Presentation Workflow"},{"location":"skills/create-presentation-plan/tutorial/#research-driven-presentations","text":"Research : research-and-report \u2192 Gather information Planning : create-presentation-plan \u2192 Structure findings Content : generate-post-from-plan \u2192 Develop detailed slides Generation : generate-pptx-from-plan \u2192 Create final presentation","title":"Research-Driven Presentations"},{"location":"skills/create-prompt/description/","text":"Create Prompt \u00b6 Overview \u00b6 Creates a staged OLAF prompt file from a raw user request. Purpose \u00b6 Use this when you want to quickly turn an idea into a well-structured prompt, without committing it into a skill folder yet. What It Does \u00b6 Asks for the user\u2019s goal and constraints Rewrites and expands the request into clear US English Generates an OLAF-formatted prompt markdown file (YAML front matter + <olaf> ) Saves it to .olaf/staging/generated-prompts/ Output \u00b6 .olaf/staging/generated-prompts/{timestamp}-{prompt_name}.md Notes \u00b6 The staging folder is intentionally separate from skill folders. The skill follows a Propose-Confirm-Act flow before writing files.","title":"Create Prompt"},{"location":"skills/create-prompt/description/#create-prompt","text":"","title":"Create Prompt"},{"location":"skills/create-prompt/description/#overview","text":"Creates a staged OLAF prompt file from a raw user request.","title":"Overview"},{"location":"skills/create-prompt/description/#purpose","text":"Use this when you want to quickly turn an idea into a well-structured prompt, without committing it into a skill folder yet.","title":"Purpose"},{"location":"skills/create-prompt/description/#what-it-does","text":"Asks for the user\u2019s goal and constraints Rewrites and expands the request into clear US English Generates an OLAF-formatted prompt markdown file (YAML front matter + <olaf> ) Saves it to .olaf/staging/generated-prompts/","title":"What It Does"},{"location":"skills/create-prompt/description/#output","text":".olaf/staging/generated-prompts/{timestamp}-{prompt_name}.md","title":"Output"},{"location":"skills/create-prompt/description/#notes","text":"The staging folder is intentionally separate from skill folders. The skill follows a Propose-Confirm-Act flow before writing files.","title":"Notes"},{"location":"skills/create-prompt/tutorial/","text":"Create Prompt - Tutorial \u00b6 Goal \u00b6 Draft a prompt from an idea and stage it for later use. Example \u00b6 User: - \"I need a prompt that reviews a PR diff for security issues\" Flow: 1. The skill asks for missing context/constraints. 2. It rewrites your request into clear US English and asks you to approve it. 3. It generates the final OLAF prompt markdown. 4. After your confirmation, it writes the file to .olaf/staging/generated-prompts/ . Output Location \u00b6 .olaf/staging/generated-prompts/{timestamp}-{prompt_name}.md Tip \u00b6 If you want to convert a staged prompt into a full skill, use create-skill or convert-prompt-to-skill depending on your workflow.","title":"Create Prompt - Tutorial"},{"location":"skills/create-prompt/tutorial/#create-prompt-tutorial","text":"","title":"Create Prompt - Tutorial"},{"location":"skills/create-prompt/tutorial/#goal","text":"Draft a prompt from an idea and stage it for later use.","title":"Goal"},{"location":"skills/create-prompt/tutorial/#example","text":"User: - \"I need a prompt that reviews a PR diff for security issues\" Flow: 1. The skill asks for missing context/constraints. 2. It rewrites your request into clear US English and asks you to approve it. 3. It generates the final OLAF prompt markdown. 4. After your confirmation, it writes the file to .olaf/staging/generated-prompts/ .","title":"Example"},{"location":"skills/create-prompt/tutorial/#output-location","text":".olaf/staging/generated-prompts/{timestamp}-{prompt_name}.md","title":"Output Location"},{"location":"skills/create-prompt/tutorial/#tip","text":"If you want to convert a staged prompt into a full skill, use create-skill or convert-prompt-to-skill depending on your workflow.","title":"Tip"},{"location":"skills/create-skill/description/","text":"Create Skill \u00b6 Source : skills/create-skill/prompts/create-skill.md Overview \u00b6 Create Skill is a comprehensive skill that generates new structured skills following OLAF's established skills architecture and best practices. It guides you through the entire skill creation lifecycle, from initial requirements gathering to proper directory structure setup. Purpose \u00b6 Creating high-quality, consistent skills is essential for maintaining OLAF's effectiveness and reliability in the skills-based architecture. This skill solves the challenge of ensuring all skills follow the proper structure, include clear input parameters and success criteria, and integrate seamlessly with the OLAF framework. Usage \u00b6 Command : create skill Protocol : Propose-Confirm-Act When to Use : Use this skill whenever you need to create a new skill in the OLAF skills architecture. It's particularly valuable when you want to ensure your skill follows all OLAF standards, includes proper error handling, has complete metadata, and integrates correctly with the skills registry. Parameters \u00b6 Required Inputs \u00b6 user_request : The requirement or task description that the new skill should address skill_name : Desired name for the skill (max 4 words, kebab-case format) skill_type : Type of skill being created: \"orchestrator\", \"workflow\", or \"prompt\" Optional Inputs \u00b6 None - all parameters are required for proper skill creation Context Requirements \u00b6 Access to OLAF skills directory structure Read access to skill templates and prompting principles Write access to the repository for new skill creation Terminal access for timestamp generation Output \u00b6 Deliverables : - Complete skill directory structure at repo root under [skill_name]/ - Main skill prompt file following OLAF template - Documentation files (description.md, tutorial.md) - Validation checklist confirming structure and conventions Format : Complete skill package with proper directory structure and manifest Examples \u00b6 Example 1: Creating a Code Analysis Skill \u00b6 Input : - user_request: \"Create a skill to analyze code quality and suggest improvements\" - skill_name: \"analyze-code-quality\" - skill_type: \"prompt\" Output : Complete skill at analyze-code-quality/ with: - skill.md - Main skill prompt - docs/description.md - Skill documentation - docs/tutorial.md - Step-by-step usage guide Example 2: Creating an Orchestrator Skill \u00b6 Input : - user_request: \"Create an orchestrator skill to manage a complete development workflow\" - skill_name: \"dev-workflow-manager\" - skill_type: \"orchestrator\" Output : Complete orchestrator skill with workflow coordination capabilities Related Skills \u00b6 convert-prompt : Convert existing prompts to skills format check-prompt-compliance : Validate created skills against standards generate-step-by-step-tutorial : Create detailed tutorials for skills Tips \u00b6 Choose descriptive names : Use clear, action-oriented names that describe what the skill does Select appropriate type : Use \"prompt\" for simple, standalone skills Use \"orchestrator\" for complex skills that coordinate multiple operations Use \"workflow\" for step-by-step process skills Provide clear requirements : The more detailed your user_request, the better the generated skill Review generated structure : Always review the complete skill structure before approval Test your skill : After creation, test the skill to ensure it works as expected Limitations \u00b6 Requires proper OLAF framework setup and access to skills directory Cannot automatically migrate dependencies from other systems Generated skills require manual testing and refinement Complex orchestrator skills may need additional workflow coordination setup Best Practices \u00b6 Follow naming conventions : Always use kebab-case, max 4 words Define clear objectives : Include specific, measurable objectives in your user request Consider dependencies : Think about what templates, tools, or knowledge base articles your skill will need Plan for error handling : Consider edge cases and failure scenarios in your requirements Document thoroughly : Provide comprehensive documentation for skill usage and maintenance","title":"Create Skill"},{"location":"skills/create-skill/description/#create-skill","text":"Source : skills/create-skill/prompts/create-skill.md","title":"Create Skill"},{"location":"skills/create-skill/description/#overview","text":"Create Skill is a comprehensive skill that generates new structured skills following OLAF's established skills architecture and best practices. It guides you through the entire skill creation lifecycle, from initial requirements gathering to proper directory structure setup.","title":"Overview"},{"location":"skills/create-skill/description/#purpose","text":"Creating high-quality, consistent skills is essential for maintaining OLAF's effectiveness and reliability in the skills-based architecture. This skill solves the challenge of ensuring all skills follow the proper structure, include clear input parameters and success criteria, and integrate seamlessly with the OLAF framework.","title":"Purpose"},{"location":"skills/create-skill/description/#usage","text":"Command : create skill Protocol : Propose-Confirm-Act When to Use : Use this skill whenever you need to create a new skill in the OLAF skills architecture. It's particularly valuable when you want to ensure your skill follows all OLAF standards, includes proper error handling, has complete metadata, and integrates correctly with the skills registry.","title":"Usage"},{"location":"skills/create-skill/description/#parameters","text":"","title":"Parameters"},{"location":"skills/create-skill/description/#required-inputs","text":"user_request : The requirement or task description that the new skill should address skill_name : Desired name for the skill (max 4 words, kebab-case format) skill_type : Type of skill being created: \"orchestrator\", \"workflow\", or \"prompt\"","title":"Required Inputs"},{"location":"skills/create-skill/description/#optional-inputs","text":"None - all parameters are required for proper skill creation","title":"Optional Inputs"},{"location":"skills/create-skill/description/#context-requirements","text":"Access to OLAF skills directory structure Read access to skill templates and prompting principles Write access to the repository for new skill creation Terminal access for timestamp generation","title":"Context Requirements"},{"location":"skills/create-skill/description/#output","text":"Deliverables : - Complete skill directory structure at repo root under [skill_name]/ - Main skill prompt file following OLAF template - Documentation files (description.md, tutorial.md) - Validation checklist confirming structure and conventions Format : Complete skill package with proper directory structure and manifest","title":"Output"},{"location":"skills/create-skill/description/#examples","text":"","title":"Examples"},{"location":"skills/create-skill/description/#example-1-creating-a-code-analysis-skill","text":"Input : - user_request: \"Create a skill to analyze code quality and suggest improvements\" - skill_name: \"analyze-code-quality\" - skill_type: \"prompt\" Output : Complete skill at analyze-code-quality/ with: - skill.md - Main skill prompt - docs/description.md - Skill documentation - docs/tutorial.md - Step-by-step usage guide","title":"Example 1: Creating a Code Analysis Skill"},{"location":"skills/create-skill/description/#example-2-creating-an-orchestrator-skill","text":"Input : - user_request: \"Create an orchestrator skill to manage a complete development workflow\" - skill_name: \"dev-workflow-manager\" - skill_type: \"orchestrator\" Output : Complete orchestrator skill with workflow coordination capabilities","title":"Example 2: Creating an Orchestrator Skill"},{"location":"skills/create-skill/description/#related-skills","text":"convert-prompt : Convert existing prompts to skills format check-prompt-compliance : Validate created skills against standards generate-step-by-step-tutorial : Create detailed tutorials for skills","title":"Related Skills"},{"location":"skills/create-skill/description/#tips","text":"Choose descriptive names : Use clear, action-oriented names that describe what the skill does Select appropriate type : Use \"prompt\" for simple, standalone skills Use \"orchestrator\" for complex skills that coordinate multiple operations Use \"workflow\" for step-by-step process skills Provide clear requirements : The more detailed your user_request, the better the generated skill Review generated structure : Always review the complete skill structure before approval Test your skill : After creation, test the skill to ensure it works as expected","title":"Tips"},{"location":"skills/create-skill/description/#limitations","text":"Requires proper OLAF framework setup and access to skills directory Cannot automatically migrate dependencies from other systems Generated skills require manual testing and refinement Complex orchestrator skills may need additional workflow coordination setup","title":"Limitations"},{"location":"skills/create-skill/description/#best-practices","text":"Follow naming conventions : Always use kebab-case, max 4 words Define clear objectives : Include specific, measurable objectives in your user request Consider dependencies : Think about what templates, tools, or knowledge base articles your skill will need Plan for error handling : Consider edge cases and failure scenarios in your requirements Document thoroughly : Provide comprehensive documentation for skill usage and maintenance","title":"Best Practices"},{"location":"skills/create-skill/tutorial/","text":"Tutorial: Create Skill \u00b6 Overview \u00b6 This tutorial guides you through creating a new structured skill for OLAF using the Create Skill skill. You'll learn how to generate skills that follow OLAF's skills architecture and integrate seamlessly with the framework. Prerequisites \u00b6 OLAF framework installed and configured Access to OLAF skills directory Understanding of the task your skill will address Terminal access for timestamp generation Basic knowledge of OLAF skills architecture Estimated Time \u00b6 45-60 minutes Steps \u00b6 Step 1: Invoke the Create Skill \u00b6 Open your IDE and invoke the skill: olaf create skill Expected Result : The skill activates and begins the skill creation workflow. Step 2: Provide User Request \u00b6 When prompted, describe what your new skill should do: Example: \"Create a skill that analyzes code quality metrics and generates improvement recommendations\" Expected Result : The skill acknowledges your request and proceeds to next parameter. Step 3: Specify Skill Name \u00b6 Provide a descriptive name in kebab-case (max 4 words): Example: \"analyze-code-quality\" Expected Result : Name is validated and checked for duplicates in skills directory. Step 4: Select Skill Type \u00b6 Choose the appropriate skill type: Options: 1. \"prompt\" - Simple, standalone skill 2. \"orchestrator\" - Complex skill coordinating multiple operations 3. \"workflow\" - Step-by-step process skill Example: \"prompt\" Expected Result : Skill type selection confirmed and skill architecture determined. Step 5: Review Generated Skill Structure \u00b6 The skill generates a complete directory structure: analyze-code-quality/ \u251c\u2500\u2500 skill.md \u251c\u2500\u2500 docs/ \u2502 \u251c\u2500\u2500 description.md \u2502 \u2514\u2500\u2500 tutorial.md \u251c\u2500\u2500 templates/ # optional \u251c\u2500\u2500 tools/ # optional \u251c\u2500\u2500 kb/ # optional \u2514\u2500\u2500 helpers/ # optional Expected Result : Complete skill structure created with proper organization. Step 6: Review Main Skill Prompt \u00b6 Examine the generated main prompt file: - Follows OLAF skill template structure - Uses imperative language consistently - Includes comprehensive error handling - Has measurable success criteria Expected Result : Skill prompt meets all OLAF standards. Step 7: Approve or Request Changes \u00b6 Use the Propose-Confirm-Act protocol: - Approve : Type \"approved\" to create the skill - Request Changes : Provide specific feedback for modifications Expected Result : Skill creation proceeds based on your response. Step 8: Verify Skill Creation \u00b6 After approval, verify the skill was created successfully: Check: analyze-code-quality/ exists with all files Expected Result : Complete skill package available for use. Step 9: Test Your New Skill \u00b6 Test the skill to ensure it works correctly: olaf analyze code quality Expected Result : Skill executes and performs as expected. Expected Outcomes \u00b6 Successful Completion \u00b6 Complete skill directory structure under [skill-name]/ Functional main skill prompt following OLAF standards Complete documentation package Skill discoverable through OLAF framework Files Created \u00b6 skill.md - Main skill prompt docs/description.md - Skill overview and usage docs/tutorial.md - Step-by-step guide Template files (if applicable) Tool files (if applicable) Validation Checklist \u00b6 [ ] Main prompt follows OLAF template structure [ ] Documentation is complete and accurate [ ] Skill can be invoked through OLAF framework [ ] No naming conflicts with existing skills Troubleshooting \u00b6 Common Issues \u00b6 Issue : \"Skill name already exists\" Solution : Choose a different, more specific name or review existing skill for potential merge Issue : \"Directory creation failed\" Solution : Check permissions and available disk space Issue : \"Template files not found\" Solution : Verify OLAF framework installation and template availability Best Practices \u00b6 Plan before creating : Think through your skill's purpose and dependencies Use descriptive names : Choose clear, action-oriented names Test thoroughly : Always test your skill after creation Document well : Provide comprehensive documentation for users Follow conventions : Stick to OLAF naming and structure conventions Next Steps \u00b6 After creating your skill: 1. Test functionality : Verify the skill works as expected 2. Refine prompt : Adjust the main prompt based on testing results 3. Add dependencies : Include any needed templates, tools, or knowledge base articles 4. Update documentation : Enhance docs based on actual usage 5. Share with team : Make the skill available to other team members","title":"Tutorial: Create Skill"},{"location":"skills/create-skill/tutorial/#tutorial-create-skill","text":"","title":"Tutorial: Create Skill"},{"location":"skills/create-skill/tutorial/#overview","text":"This tutorial guides you through creating a new structured skill for OLAF using the Create Skill skill. You'll learn how to generate skills that follow OLAF's skills architecture and integrate seamlessly with the framework.","title":"Overview"},{"location":"skills/create-skill/tutorial/#prerequisites","text":"OLAF framework installed and configured Access to OLAF skills directory Understanding of the task your skill will address Terminal access for timestamp generation Basic knowledge of OLAF skills architecture","title":"Prerequisites"},{"location":"skills/create-skill/tutorial/#estimated-time","text":"45-60 minutes","title":"Estimated Time"},{"location":"skills/create-skill/tutorial/#steps","text":"","title":"Steps"},{"location":"skills/create-skill/tutorial/#step-1-invoke-the-create-skill","text":"Open your IDE and invoke the skill: olaf create skill Expected Result : The skill activates and begins the skill creation workflow.","title":"Step 1: Invoke the Create Skill"},{"location":"skills/create-skill/tutorial/#step-2-provide-user-request","text":"When prompted, describe what your new skill should do: Example: \"Create a skill that analyzes code quality metrics and generates improvement recommendations\" Expected Result : The skill acknowledges your request and proceeds to next parameter.","title":"Step 2: Provide User Request"},{"location":"skills/create-skill/tutorial/#step-3-specify-skill-name","text":"Provide a descriptive name in kebab-case (max 4 words): Example: \"analyze-code-quality\" Expected Result : Name is validated and checked for duplicates in skills directory.","title":"Step 3: Specify Skill Name"},{"location":"skills/create-skill/tutorial/#step-4-select-skill-type","text":"Choose the appropriate skill type: Options: 1. \"prompt\" - Simple, standalone skill 2. \"orchestrator\" - Complex skill coordinating multiple operations 3. \"workflow\" - Step-by-step process skill Example: \"prompt\" Expected Result : Skill type selection confirmed and skill architecture determined.","title":"Step 4: Select Skill Type"},{"location":"skills/create-skill/tutorial/#step-5-review-generated-skill-structure","text":"The skill generates a complete directory structure: analyze-code-quality/ \u251c\u2500\u2500 skill.md \u251c\u2500\u2500 docs/ \u2502 \u251c\u2500\u2500 description.md \u2502 \u2514\u2500\u2500 tutorial.md \u251c\u2500\u2500 templates/ # optional \u251c\u2500\u2500 tools/ # optional \u251c\u2500\u2500 kb/ # optional \u2514\u2500\u2500 helpers/ # optional Expected Result : Complete skill structure created with proper organization.","title":"Step 5: Review Generated Skill Structure"},{"location":"skills/create-skill/tutorial/#step-6-review-main-skill-prompt","text":"Examine the generated main prompt file: - Follows OLAF skill template structure - Uses imperative language consistently - Includes comprehensive error handling - Has measurable success criteria Expected Result : Skill prompt meets all OLAF standards.","title":"Step 6: Review Main Skill Prompt"},{"location":"skills/create-skill/tutorial/#step-7-approve-or-request-changes","text":"Use the Propose-Confirm-Act protocol: - Approve : Type \"approved\" to create the skill - Request Changes : Provide specific feedback for modifications Expected Result : Skill creation proceeds based on your response.","title":"Step 7: Approve or Request Changes"},{"location":"skills/create-skill/tutorial/#step-8-verify-skill-creation","text":"After approval, verify the skill was created successfully: Check: analyze-code-quality/ exists with all files Expected Result : Complete skill package available for use.","title":"Step 8: Verify Skill Creation"},{"location":"skills/create-skill/tutorial/#step-9-test-your-new-skill","text":"Test the skill to ensure it works correctly: olaf analyze code quality Expected Result : Skill executes and performs as expected.","title":"Step 9: Test Your New Skill"},{"location":"skills/create-skill/tutorial/#expected-outcomes","text":"","title":"Expected Outcomes"},{"location":"skills/create-skill/tutorial/#successful-completion","text":"Complete skill directory structure under [skill-name]/ Functional main skill prompt following OLAF standards Complete documentation package Skill discoverable through OLAF framework","title":"Successful Completion"},{"location":"skills/create-skill/tutorial/#files-created","text":"skill.md - Main skill prompt docs/description.md - Skill overview and usage docs/tutorial.md - Step-by-step guide Template files (if applicable) Tool files (if applicable)","title":"Files Created"},{"location":"skills/create-skill/tutorial/#validation-checklist","text":"[ ] Main prompt follows OLAF template structure [ ] Documentation is complete and accurate [ ] Skill can be invoked through OLAF framework [ ] No naming conflicts with existing skills","title":"Validation Checklist"},{"location":"skills/create-skill/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/create-skill/tutorial/#common-issues","text":"Issue : \"Skill name already exists\" Solution : Choose a different, more specific name or review existing skill for potential merge Issue : \"Directory creation failed\" Solution : Check permissions and available disk space Issue : \"Template files not found\" Solution : Verify OLAF framework installation and template availability","title":"Common Issues"},{"location":"skills/create-skill/tutorial/#best-practices","text":"Plan before creating : Think through your skill's purpose and dependencies Use descriptive names : Choose clear, action-oriented names Test thoroughly : Always test your skill after creation Document well : Provide comprehensive documentation for users Follow conventions : Stick to OLAF naming and structure conventions","title":"Best Practices"},{"location":"skills/create-skill/tutorial/#next-steps","text":"After creating your skill: 1. Test functionality : Verify the skill works as expected 2. Refine prompt : Adjust the main prompt based on testing results 3. Add dependencies : Include any needed templates, tools, or knowledge base articles 4. Update documentation : Enhance docs based on actual usage 5. Share with team : Make the skill available to other team members","title":"Next Steps"},{"location":"skills/create-skill-description/description/","text":"Create Skill Description \u00b6 Overview \u00b6 The create-skill-description skill generates comprehensive docs/description.md documentation files for existing skills in the OLAF framework. Purpose \u00b6 This skill automates the documentation process for skills by analyzing their content and structure, then generating well-formatted description files that explain what the skill does, how to use it, and what parameters it requires. This ensures consistent, high-quality documentation across all skills. Key Features \u00b6 Interactive Skill Selection - Lists available skills if name not provided Automatic Content Analysis - Reads and extracts key information from skill files Structured Documentation - Generates comprehensive descriptions with standardized sections Safe Overwrite Protection - Warns before overwriting existing documentation User Review Process - Shows generated content before saving (Propose-Confirm-Act protocol) Usage \u00b6 Invocation \u00b6 You can trigger this skill using any of these commands: - olaf create-skill-description - olaf document skill - olaf generate skill docs - olaf add skill description - olaf create description file Basic Usage \u00b6 Invoke the skill with one of the commands above Provide the skill name when asked (or select from list) Review the generated description.md content Confirm to save or request edits Parameters \u00b6 Required Parameters \u00b6 skill_name (string) - The name/ID of the skill to document Must match an existing skill directory in skills/ If not provided, skill will list available skills for selection Optional Parameters \u00b6 skill_path (string) - Absolute path to the skill directory Auto-detected if not provided Only needed for skills in non-standard locations Process Flow \u00b6 Validation - Verify skill exists and locate its files Analysis - Read the skill file to extract metadata, parameters, process, outputs, and rules Generation - Create description.md with comprehensive documentation sections Proposal - Present generated content to user for review Confirmation - Wait for user approval or edit requests Save - Write description.md to the skill's /docs/ folder Output \u00b6 The skill generates a description.md file saved to: skills/[skill-name]/docs/description.md Description Sections \u00b6 Overview - Brief summary of skill functionality Purpose - Why the skill exists and when to use it Key Features - Main capabilities and highlights Usage - Invocation commands and basic workflow Parameters - Required and optional parameters with descriptions Process Flow - High-level execution steps Output - What the skill produces Examples - Common use cases Error Handling - Common errors and solutions Related Skills - Dependencies or complementary skills Examples \u00b6 Example 1: Document a Specific Skill \u00b6 User: olaf create-skill-description Assistant: Which skill would you like to document? User: review-code-quality Assistant: [Analyzes skill and generates description] [Shows generated content] Ready to save this documentation? (yes/no/edit) User: yes Assistant: \u2705 Documentation saved to skills/review-code-quality/docs/description.md Example 2: Using Skill Name Parameter \u00b6 User: olaf create-skill-description for generate-test-cases Assistant: [Analyzes skill] [Generates and shows description] Ready to save? (yes/no/edit) User: edit Assistant: What changes would you like? User: Add more examples Assistant: [Regenerates with additional examples] Ready to save? (yes/no/edit) User: yes Error Handling \u00b6 Common Errors \u00b6 Skill Not Found - Symptom : Specified skill doesn't exist - Resolution : Skill lists available skills for selection Missing Skill File - Symptom : Skill directory exists but main skill file missing - Resolution : Alert user to incomplete skill structure description.md Already Exists - Symptom : Target file already exists - Resolution : Warn user and request confirmation to overwrite File Save Failure - Symptom : Cannot write to /docs/ folder - Resolution : Check permissions, suggest alternative locations Related Skills \u00b6 create-skill - Creates new skills (which this skill documents) convert-prompt-to-skill - Converts prompt content into a skill structure Notes \u00b6 This skill uses the Propose-Confirm-Act protocol for safety Documentation is auto-generated but can be edited after saving Existing description.md files are preserved unless user confirms overwrite The skill analyzes the target skill's skill.md to generate accurate documentation","title":"Create Skill Description"},{"location":"skills/create-skill-description/description/#create-skill-description","text":"","title":"Create Skill Description"},{"location":"skills/create-skill-description/description/#overview","text":"The create-skill-description skill generates comprehensive docs/description.md documentation files for existing skills in the OLAF framework.","title":"Overview"},{"location":"skills/create-skill-description/description/#purpose","text":"This skill automates the documentation process for skills by analyzing their content and structure, then generating well-formatted description files that explain what the skill does, how to use it, and what parameters it requires. This ensures consistent, high-quality documentation across all skills.","title":"Purpose"},{"location":"skills/create-skill-description/description/#key-features","text":"Interactive Skill Selection - Lists available skills if name not provided Automatic Content Analysis - Reads and extracts key information from skill files Structured Documentation - Generates comprehensive descriptions with standardized sections Safe Overwrite Protection - Warns before overwriting existing documentation User Review Process - Shows generated content before saving (Propose-Confirm-Act protocol)","title":"Key Features"},{"location":"skills/create-skill-description/description/#usage","text":"","title":"Usage"},{"location":"skills/create-skill-description/description/#invocation","text":"You can trigger this skill using any of these commands: - olaf create-skill-description - olaf document skill - olaf generate skill docs - olaf add skill description - olaf create description file","title":"Invocation"},{"location":"skills/create-skill-description/description/#basic-usage","text":"Invoke the skill with one of the commands above Provide the skill name when asked (or select from list) Review the generated description.md content Confirm to save or request edits","title":"Basic Usage"},{"location":"skills/create-skill-description/description/#parameters","text":"","title":"Parameters"},{"location":"skills/create-skill-description/description/#required-parameters","text":"skill_name (string) - The name/ID of the skill to document Must match an existing skill directory in skills/ If not provided, skill will list available skills for selection","title":"Required Parameters"},{"location":"skills/create-skill-description/description/#optional-parameters","text":"skill_path (string) - Absolute path to the skill directory Auto-detected if not provided Only needed for skills in non-standard locations","title":"Optional Parameters"},{"location":"skills/create-skill-description/description/#process-flow","text":"Validation - Verify skill exists and locate its files Analysis - Read the skill file to extract metadata, parameters, process, outputs, and rules Generation - Create description.md with comprehensive documentation sections Proposal - Present generated content to user for review Confirmation - Wait for user approval or edit requests Save - Write description.md to the skill's /docs/ folder","title":"Process Flow"},{"location":"skills/create-skill-description/description/#output","text":"The skill generates a description.md file saved to: skills/[skill-name]/docs/description.md","title":"Output"},{"location":"skills/create-skill-description/description/#description-sections","text":"Overview - Brief summary of skill functionality Purpose - Why the skill exists and when to use it Key Features - Main capabilities and highlights Usage - Invocation commands and basic workflow Parameters - Required and optional parameters with descriptions Process Flow - High-level execution steps Output - What the skill produces Examples - Common use cases Error Handling - Common errors and solutions Related Skills - Dependencies or complementary skills","title":"Description Sections"},{"location":"skills/create-skill-description/description/#examples","text":"","title":"Examples"},{"location":"skills/create-skill-description/description/#example-1-document-a-specific-skill","text":"User: olaf create-skill-description Assistant: Which skill would you like to document? User: review-code-quality Assistant: [Analyzes skill and generates description] [Shows generated content] Ready to save this documentation? (yes/no/edit) User: yes Assistant: \u2705 Documentation saved to skills/review-code-quality/docs/description.md","title":"Example 1: Document a Specific Skill"},{"location":"skills/create-skill-description/description/#example-2-using-skill-name-parameter","text":"User: olaf create-skill-description for generate-test-cases Assistant: [Analyzes skill] [Generates and shows description] Ready to save? (yes/no/edit) User: edit Assistant: What changes would you like? User: Add more examples Assistant: [Regenerates with additional examples] Ready to save? (yes/no/edit) User: yes","title":"Example 2: Using Skill Name Parameter"},{"location":"skills/create-skill-description/description/#error-handling","text":"","title":"Error Handling"},{"location":"skills/create-skill-description/description/#common-errors","text":"Skill Not Found - Symptom : Specified skill doesn't exist - Resolution : Skill lists available skills for selection Missing Skill File - Symptom : Skill directory exists but main skill file missing - Resolution : Alert user to incomplete skill structure description.md Already Exists - Symptom : Target file already exists - Resolution : Warn user and request confirmation to overwrite File Save Failure - Symptom : Cannot write to /docs/ folder - Resolution : Check permissions, suggest alternative locations","title":"Common Errors"},{"location":"skills/create-skill-description/description/#related-skills","text":"create-skill - Creates new skills (which this skill documents) convert-prompt-to-skill - Converts prompt content into a skill structure","title":"Related Skills"},{"location":"skills/create-skill-description/description/#notes","text":"This skill uses the Propose-Confirm-Act protocol for safety Documentation is auto-generated but can be edited after saving Existing description.md files are preserved unless user confirms overwrite The skill analyzes the target skill's skill.md to generate accurate documentation","title":"Notes"},{"location":"skills/create-skill-description/tutorial/","text":"Tutorial: Creating Skill Documentation with create-skill-description \u00b6 This tutorial walks you through using the create-skill-description skill to generate documentation for your skills. Prerequisites \u00b6 An existing skill in skills/ that needs documentation Basic familiarity with OLAF framework skills Step-by-Step Guide \u00b6 Step 1: Invoke the Skill \u00b6 Start by calling the skill with any of its aliases: olaf create-skill-description Or use alternative commands: olaf document skill olaf generate skill docs Step 2: Select the Skill \u00b6 If you didn't specify a skill name, the skill will ask: Which skill would you like to document? You can either: - Provide the skill name directly : review-code-quality - Select from the list if the skill displays available skills Example: Available skills: 1. create-skill 2. review-code-quality 3. generate-test-cases 4. format-email-response Which skill would you like to document? 2 Step 3: Review Generated Documentation \u00b6 The skill will: 1. Read your skill file 2. Analyze its structure and content 3. Extract parameters, process flow, and features 4. Generate a comprehensive description.md You'll see the generated content displayed for review: # Review Code Quality ## Overview Analyzes code files for quality issues and suggests improvements... ## Purpose This skill helps developers identify code quality issues... [... full generated content ...] Step 4: Approve or Request Changes \u00b6 After reviewing, you have three options: Option A: Approve and Save Ready to save this documentation? (yes/no/edit) > yes \u2705 Documentation saved to skills/review-code-quality/docs/description.md Option B: Request Edits Ready to save this documentation? (yes/no/edit) > edit What changes would you like? > Add more examples in the Examples section [Skill regenerates with requested changes] Ready to save this documentation? (yes/no/edit) > yes Option C: Cancel Ready to save this documentation? (yes/no/edit) > no Would you like to cancel or provide different requirements? > cancel Operation cancelled. Step 5: Verify the Documentation \u00b6 After saving, verify the file was created: Location: skills/[your-skill-name]/docs/description.md Check the file: - Open it in your editor - Verify all sections are populated - Make any manual refinements if needed Advanced Usage \u00b6 Documenting Multiple Skills \u00b6 To document several skills efficiently: # Document first skill olaf document skill > create-user-story # Document second skill olaf document skill > format-commit-message # Document third skill olaf document skill > analyze-dependencies Handling Existing Documentation \u00b6 If description.md already exists, the skill will warn you: \u26a0\ufe0f description.md already exists at: skills/review-code-quality/docs/description.md Do you want to overwrite it? (yes/no) > yes Best Practice: Review the existing file first to preserve any manual customizations. Providing Custom Skill Path \u00b6 For skills in non-standard locations: olaf create-skill-description Skill name: my-custom-skill Skill path: /custom/location/my-custom-skill Common Scenarios \u00b6 Scenario 1: New Skill Without Documentation \u00b6 Situation: You just created a skill using create-skill but want better documentation. Solution: olaf document skill > [your-new-skill-name] > yes Scenario 2: Updating Outdated Documentation \u00b6 Situation: Your skill changed significantly and documentation is outdated. Solution: 1. Delete or backup existing description.md 2. Run olaf create-skill-description 3. Review and save the regenerated documentation Scenario 3: Documenting Legacy Skills \u00b6 Situation: Old skills lack proper documentation. Solution: # List all skills needing documentation ls skills/*/docs/ # Document each one olaf document skill > [legacy-skill-name] Tips and Best Practices \u00b6 Tip 1: Review Before Saving \u00b6 Always review the generated documentation. The skill is smart, but manual review ensures accuracy. Tip 2: Edit After Generation \u00b6 The generated description.md is a starting point. Feel free to enhance it with: - Additional examples - Screenshots or diagrams - Advanced usage patterns - Known limitations Tip 3: Keep Skills Up-to-Date \u00b6 When you modify a skill significantly, regenerate its documentation: olaf document skill > [modified-skill] Tip 4: Standardize Documentation \u00b6 Use this skill for all skills to maintain consistent documentation structure. Troubleshooting \u00b6 Issue: \"Skill not found\" \u00b6 Cause: Skill name doesn't match any existing skill Solution: Check available skills in skills/ or let the skill list them Issue: \"Cannot read skill file\" \u00b6 Cause: Skill structure is incomplete or corrupted Solution: Verify the skill has a valid file at skill.md Issue: \"File save failed\" \u00b6 Cause: Permission issues or disk full Solution: Check file permissions on the /docs/ directory Issue: Documentation is incomplete \u00b6 Cause: Skill file has minimal content Solution: Enhance your skill file first, then regenerate documentation Next Steps \u00b6 After creating documentation: 1. Review and refine the generated description.md 2. Create tutorial.md for step-by-step usage guides (can be done manually or with another skill) 3. Update skill metadata if you added new features to the skill 4. Share your documented skill with team members Summary \u00b6 You've learned how to: - \u2705 Invoke the create-skill-description skill - \u2705 Select skills for documentation - \u2705 Review and approve generated content - \u2705 Handle existing documentation - \u2705 Troubleshoot common issues Remember: Good documentation makes your skills more discoverable and easier to use!","title":"Tutorial: Creating Skill Documentation with create-skill-description"},{"location":"skills/create-skill-description/tutorial/#tutorial-creating-skill-documentation-with-create-skill-description","text":"This tutorial walks you through using the create-skill-description skill to generate documentation for your skills.","title":"Tutorial: Creating Skill Documentation with create-skill-description"},{"location":"skills/create-skill-description/tutorial/#prerequisites","text":"An existing skill in skills/ that needs documentation Basic familiarity with OLAF framework skills","title":"Prerequisites"},{"location":"skills/create-skill-description/tutorial/#step-by-step-guide","text":"","title":"Step-by-Step Guide"},{"location":"skills/create-skill-description/tutorial/#step-1-invoke-the-skill","text":"Start by calling the skill with any of its aliases: olaf create-skill-description Or use alternative commands: olaf document skill olaf generate skill docs","title":"Step 1: Invoke the Skill"},{"location":"skills/create-skill-description/tutorial/#step-2-select-the-skill","text":"If you didn't specify a skill name, the skill will ask: Which skill would you like to document? You can either: - Provide the skill name directly : review-code-quality - Select from the list if the skill displays available skills Example: Available skills: 1. create-skill 2. review-code-quality 3. generate-test-cases 4. format-email-response Which skill would you like to document? 2","title":"Step 2: Select the Skill"},{"location":"skills/create-skill-description/tutorial/#step-3-review-generated-documentation","text":"The skill will: 1. Read your skill file 2. Analyze its structure and content 3. Extract parameters, process flow, and features 4. Generate a comprehensive description.md You'll see the generated content displayed for review: # Review Code Quality ## Overview Analyzes code files for quality issues and suggests improvements... ## Purpose This skill helps developers identify code quality issues... [... full generated content ...]","title":"Step 3: Review Generated Documentation"},{"location":"skills/create-skill-description/tutorial/#step-4-approve-or-request-changes","text":"After reviewing, you have three options: Option A: Approve and Save Ready to save this documentation? (yes/no/edit) > yes \u2705 Documentation saved to skills/review-code-quality/docs/description.md Option B: Request Edits Ready to save this documentation? (yes/no/edit) > edit What changes would you like? > Add more examples in the Examples section [Skill regenerates with requested changes] Ready to save this documentation? (yes/no/edit) > yes Option C: Cancel Ready to save this documentation? (yes/no/edit) > no Would you like to cancel or provide different requirements? > cancel Operation cancelled.","title":"Step 4: Approve or Request Changes"},{"location":"skills/create-skill-description/tutorial/#step-5-verify-the-documentation","text":"After saving, verify the file was created: Location: skills/[your-skill-name]/docs/description.md Check the file: - Open it in your editor - Verify all sections are populated - Make any manual refinements if needed","title":"Step 5: Verify the Documentation"},{"location":"skills/create-skill-description/tutorial/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/create-skill-description/tutorial/#documenting-multiple-skills","text":"To document several skills efficiently: # Document first skill olaf document skill > create-user-story # Document second skill olaf document skill > format-commit-message # Document third skill olaf document skill > analyze-dependencies","title":"Documenting Multiple Skills"},{"location":"skills/create-skill-description/tutorial/#handling-existing-documentation","text":"If description.md already exists, the skill will warn you: \u26a0\ufe0f description.md already exists at: skills/review-code-quality/docs/description.md Do you want to overwrite it? (yes/no) > yes Best Practice: Review the existing file first to preserve any manual customizations.","title":"Handling Existing Documentation"},{"location":"skills/create-skill-description/tutorial/#providing-custom-skill-path","text":"For skills in non-standard locations: olaf create-skill-description Skill name: my-custom-skill Skill path: /custom/location/my-custom-skill","title":"Providing Custom Skill Path"},{"location":"skills/create-skill-description/tutorial/#common-scenarios","text":"","title":"Common Scenarios"},{"location":"skills/create-skill-description/tutorial/#scenario-1-new-skill-without-documentation","text":"Situation: You just created a skill using create-skill but want better documentation. Solution: olaf document skill > [your-new-skill-name] > yes","title":"Scenario 1: New Skill Without Documentation"},{"location":"skills/create-skill-description/tutorial/#scenario-2-updating-outdated-documentation","text":"Situation: Your skill changed significantly and documentation is outdated. Solution: 1. Delete or backup existing description.md 2. Run olaf create-skill-description 3. Review and save the regenerated documentation","title":"Scenario 2: Updating Outdated Documentation"},{"location":"skills/create-skill-description/tutorial/#scenario-3-documenting-legacy-skills","text":"Situation: Old skills lack proper documentation. Solution: # List all skills needing documentation ls skills/*/docs/ # Document each one olaf document skill > [legacy-skill-name]","title":"Scenario 3: Documenting Legacy Skills"},{"location":"skills/create-skill-description/tutorial/#tips-and-best-practices","text":"","title":"Tips and Best Practices"},{"location":"skills/create-skill-description/tutorial/#tip-1-review-before-saving","text":"Always review the generated documentation. The skill is smart, but manual review ensures accuracy.","title":"Tip 1: Review Before Saving"},{"location":"skills/create-skill-description/tutorial/#tip-2-edit-after-generation","text":"The generated description.md is a starting point. Feel free to enhance it with: - Additional examples - Screenshots or diagrams - Advanced usage patterns - Known limitations","title":"Tip 2: Edit After Generation"},{"location":"skills/create-skill-description/tutorial/#tip-3-keep-skills-up-to-date","text":"When you modify a skill significantly, regenerate its documentation: olaf document skill > [modified-skill]","title":"Tip 3: Keep Skills Up-to-Date"},{"location":"skills/create-skill-description/tutorial/#tip-4-standardize-documentation","text":"Use this skill for all skills to maintain consistent documentation structure.","title":"Tip 4: Standardize Documentation"},{"location":"skills/create-skill-description/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/create-skill-description/tutorial/#issue-skill-not-found","text":"Cause: Skill name doesn't match any existing skill Solution: Check available skills in skills/ or let the skill list them","title":"Issue: \"Skill not found\""},{"location":"skills/create-skill-description/tutorial/#issue-cannot-read-skill-file","text":"Cause: Skill structure is incomplete or corrupted Solution: Verify the skill has a valid file at skill.md","title":"Issue: \"Cannot read skill file\""},{"location":"skills/create-skill-description/tutorial/#issue-file-save-failed","text":"Cause: Permission issues or disk full Solution: Check file permissions on the /docs/ directory","title":"Issue: \"File save failed\""},{"location":"skills/create-skill-description/tutorial/#issue-documentation-is-incomplete","text":"Cause: Skill file has minimal content Solution: Enhance your skill file first, then regenerate documentation","title":"Issue: Documentation is incomplete"},{"location":"skills/create-skill-description/tutorial/#next-steps","text":"After creating documentation: 1. Review and refine the generated description.md 2. Create tutorial.md for step-by-step usage guides (can be done manually or with another skill) 3. Update skill metadata if you added new features to the skill 4. Share your documented skill with team members","title":"Next Steps"},{"location":"skills/create-skill-description/tutorial/#summary","text":"You've learned how to: - \u2705 Invoke the create-skill-description skill - \u2705 Select skills for documentation - \u2705 Review and approve generated content - \u2705 Handle existing documentation - \u2705 Troubleshoot common issues Remember: Good documentation makes your skills more discoverable and easier to use!","title":"Summary"},{"location":"skills/deepen-tech-spec-developer/description/","text":"Deepen Tech Spec Developer \u00b6 Enhanced skill migrated from developer competency. Usage \u00b6 This skill provides deepen tech spec developer functionality with self-contained dependencies and enhanced error handling.","title":"Deepen Tech Spec Developer"},{"location":"skills/deepen-tech-spec-developer/description/#deepen-tech-spec-developer","text":"Enhanced skill migrated from developer competency.","title":"Deepen Tech Spec Developer"},{"location":"skills/deepen-tech-spec-developer/description/#usage","text":"This skill provides deepen tech spec developer functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/deepen-tech-spec-developer/tutorial/","text":"Deepen Tech Spec Developer Tutorial \u00b6 Step-by-step guide for using the deepen-tech-spec-developer skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Deepen Tech Spec Developer Tutorial"},{"location":"skills/deepen-tech-spec-developer/tutorial/#deepen-tech-spec-developer-tutorial","text":"Step-by-step guide for using the deepen-tech-spec-developer skill.","title":"Deepen Tech Spec Developer Tutorial"},{"location":"skills/deepen-tech-spec-developer/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/deepen-tech-spec-developer/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/detect-schema-drift/description/","text":"Detect Schema Drift \u00b6 Enhanced skill migrated from olaf-specific-tools competency. Usage \u00b6 This skill provides detect schema drift functionality with self-contained dependencies and enhanced error handling.","title":"Detect Schema Drift"},{"location":"skills/detect-schema-drift/description/#detect-schema-drift","text":"Enhanced skill migrated from olaf-specific-tools competency.","title":"Detect Schema Drift"},{"location":"skills/detect-schema-drift/description/#usage","text":"This skill provides detect schema drift functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/detect-schema-drift/tutorial/","text":"Detect Schema Drift Tutorial \u00b6 Step-by-step guide for using the detect-schema-drift skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Detect Schema Drift Tutorial"},{"location":"skills/detect-schema-drift/tutorial/#detect-schema-drift-tutorial","text":"Step-by-step guide for using the detect-schema-drift skill.","title":"Detect Schema Drift Tutorial"},{"location":"skills/detect-schema-drift/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/detect-schema-drift/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/detect-test-directives/description/","text":"Detect Test Directives \u00b6 Enhanced skill migrated from developer competency. Usage \u00b6 This skill provides detect test directives functionality with self-contained dependencies and enhanced error handling.","title":"Detect Test Directives"},{"location":"skills/detect-test-directives/description/#detect-test-directives","text":"Enhanced skill migrated from developer competency.","title":"Detect Test Directives"},{"location":"skills/detect-test-directives/description/#usage","text":"This skill provides detect test directives functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/detect-test-directives/tutorial/","text":"Detect Test Directives Tutorial \u00b6 Step-by-step guide for using the detect-test-directives skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Detect Test Directives Tutorial"},{"location":"skills/detect-test-directives/tutorial/#detect-test-directives-tutorial","text":"Step-by-step guide for using the detect-test-directives skill.","title":"Detect Test Directives Tutorial"},{"location":"skills/detect-test-directives/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/detect-test-directives/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/evaluate-prompt-for-adoption/description/","text":"Evaluate Prompt for Adoption \u00b6 Overview \u00b6 The evaluate-prompt-for-adoption skill helps you systematically assess external prompts (from GitHub, awesome lists, registries, or the web) to determine if they're worth adopting into your OLAF framework. Purpose \u00b6 Before importing every interesting prompt you find, you need to evaluate: - Is it similar to what we already have? - Is it high quality? - Will anyone actually use it? - Does it add real value? - Is it worth the maintenance burden? This skill provides a structured evaluation framework to make informed adoption decisions. Key Features \u00b6 1. Multi-Source Fetching \u00b6 Retrieve prompts from various sources: - GitHub repositories - Raw files or repo browse - GitHub gists - Public prompt collections - Awesome lists - Curated prompt libraries - Web pages - Blog posts, documentation - Direct paste - Copy/paste prompt text 2. Similarity Detection \u00b6 Avoid duplicates by checking against existing OLAF skills: - Semantic search across workspace - Overlap percentage calculation - Unique feature identification - Merge vs adopt decision support 3. Multi-Dimensional Quality Assessment \u00b6 Evaluate prompts across 5 quality dimensions : Clarity \u00b6 Clear objective? Well-structured? Unambiguous instructions? Examples provided? Genericity \u00b6 Applicable to multiple use cases? Reusable across projects? Domain-agnostic or valuable niche? Parameterizability \u00b6 Can be configured? Supports inputs/outputs? Flexible for different contexts? LLM Independence \u00b6 Works across LLMs (Claude, GPT, Gemini)? Not platform-locked? Standard prompt patterns? Structure Quality \u00b6 Logical flow? Proper sections? Error handling? Validation steps? 4. Persona & Use Case Analysis \u00b6 Identify who would use this prompt: - Developer personas (junior, senior, architect) - Domain experts (data scientist, designer) - Expertise levels (beginner, intermediate, advanced) - Use case frequency (daily, weekly, rare) 5. Value-Add Estimation \u00b6 Frequency \u00d7 Specificity Matrix : \u2502 High Frequency \u2502 Low Frequency \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Generic \u2502 HIGH VALUE \u2b50\u2b50\u2b50 \u2502 MEDIUM VALUE \u2b50\u2b50 \u2502 (everyday tool) \u2502 (useful helper) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Specific \u2502 MEDIUM VALUE \u2b50\u2b50 \u2502 LOW VALUE \u2b50 \u2502 (niche but frequent) \u2502 (very situational) AI Necessity Assessment : - \u2705 Requires AI (reasoning, creativity) - \u26a0\ufe0f Benefits from AI but could script - \u274c Better as script/tool Value Score (0-50 points): - 40-50: EXCELLENT - Adopt immediately - 30-39: GOOD - Strong candidate - 20-29: MODERATE - Consider with improvements - 10-19: LOW - Skip or extract parts - 0-9: POOR - Not worth it 6. Actionable Recommendations \u00b6 Clear recommendation with rationale: - ADOPT - Import as-is or with minor tweaks - ADOPT WITH MODIFICATIONS - Needs improvements first - EXTRACT PARTS - Take specific patterns, not whole prompt - SKIP - Not valuable or duplicative Use Cases \u00b6 Scenario 1: GitHub Awesome List Discovery \u00b6 You find a promising prompt in awesome-chatgpt-prompts: User: \"evaluate this prompt: https://github.com/awesome/prompts/blob/main/code-reviewer.md\" \u2192 Fetches prompt from GitHub \u2192 Checks: Do we have code review skills? \u2192 Compares to existing review-code, review-diff skills \u2192 Finds 60% overlap but unique features \u2192 Rates: Clarity \u2705, Genericity \u2705, AI-required \u2705 \u2192 Value score: 38/50 (GOOD) \u2192 Recommends: ADOPT WITH MODIFICATIONS (extract unique review criteria, merge into review-code) Scenario 2: Blog Post Prompt \u00b6 You see an interesting prompt in a blog: User: \"evaluate prompt from https://example.com/blog/amazing-prompt\" \u2192 Fetches from webpage \u2192 Extracts prompt from article \u2192 Checks similarity: LOW (15% overlap) \u2192 Rates quality across 5 dimensions \u2192 Analyzes: High frequency + Generic = HIGH VALUE \u2192 Value score: 42/50 (EXCELLENT) \u2192 Recommends: ADOPT - create as new skill \u2192 Suggests: Use create-skill, competency: productivity Scenario 3: Direct Paste Evaluation \u00b6 You copied a prompt from Slack: User: \"evaluate this prompt: [pastes content]\" \u2192 Analyzes pasted text \u2192 Finds: Very specific to one use case \u2192 Rates: Genericity \u274c (Too Narrow) \u2192 Frequency: Rare \u2192 Value score: 12/50 (LOW) \u2192 Recommends: SKIP - too specific, low reuse potential Scenario 4: Gist Collection \u00b6 You found a gist with multiple prompts: User: \"evaluate prompts from https://gist.github.com/user/abc123\" \u2192 Fetches gist \u2192 Finds 5 prompts in gist \u2192 Evaluates each separately \u2192 Results: - Prompt 1: ADOPT (45/50) - Prompt 2: SKIP (duplicate of existing) - Prompt 3: EXTRACT PARTS (good pattern, merge into existing) - Prompt 4: ADOPT WITH MODIFICATIONS (needs parameterization) - Prompt 5: SKIP (better as script) Evaluation Report Example \u00b6 ## Evaluation Report ### Source Information - **URL**: https://github.com/f/awesome-chatgpt-prompts/blob/main/prompts.csv#L42 - **Description**: Act as a Linux Terminal - **Author**: Fatih Kadir Ak\u0131n - **License**: CC0-1.0 ### Similarity Analysis - **Similar OLAF Skills**: None found (0% overlap) - **Unique Features**: Interactive terminal simulation, command execution feedback - **Similarity Verdict**: LOW - New capability ### Quality Assessment | Dimension | Rating | Notes | |-----------|--------|-------| | Clarity | Clear | Well-defined objective and behavior | | Genericity | Domain-Specific | Specific to Linux terminal simulation | | Parameterizability | Moderate | Could add shell type parameter | | LLM Independence | Agnostic | Works across all LLMs | | Structure | Acceptable | Clear but could add error handling | ### Persona & Use Cases - **Target Personas**: Developers (junior to senior), System administrators, DevOps engineers - **Primary Use Case**: Learning/practicing Linux commands safely - **Frequency**: Weekly (learning contexts) ### Value-Add Analysis - **Frequency \u00d7 Specificity**: MEDIUM VALUE \u2b50\u2b50 (domain-specific but useful) - **AI Necessity**: Required (needs understanding of Linux commands) - **Value Score**: 32/50 points - GOOD ### Final Recommendation **\ud83c\udfaf RECOMMENDATION**: ADOPT WITH MODIFICATIONS **Rationale**: Unique capability not in OLAF. Good quality but could be enhanced with error handling. Value score indicates strong adoption candidate. **Modifications needed**: 1. Add error handling capabilities 2. Add error handling section 3. Add examples of common command interactions 4. Structure as OLAF skill with proper manifest **Estimated effort**: Medium (2-3 hours to properly structure) ### Next Steps 1. Use `create-skill` to build OLAF-native version with modifications 2. Add to `learning-tools` or `development` competency 3. Include parameterization for different shells 4. Add comprehensive examples and error handling Benefits \u00b6 For Teams \u00b6 Curated Library : Only high-quality prompts enter OLAF No Duplicates : Systematic similarity checking Clear Criteria : Objective evaluation framework Value Focus : Prioritize high-impact prompts For Individuals \u00b6 Save Time : Quick evaluation vs lengthy trial-and-error Better Decisions : Data-driven adoption choices Learn Patterns : Understand what makes prompts valuable Avoid Clutter : Don't import low-value prompts For Projects \u00b6 Quality Standards : Maintain high bar for prompts Strategic Growth : Grow library intentionally Resource Efficiency : Focus on high-ROI prompts Maintenance Burden : Avoid adopting hard-to-maintain prompts Integration with Other Skills \u00b6 Evaluation \u2192 Import Flow \u00b6 1. evaluate-prompt-for-adoption (this skill) \u2193 [if ADOPT recommendation] 2. convert-prompt-to-skill (package into OLAF skill) OR 3. convert-prompt (modernize to OLAF standards) OR 4. create-skill (build OLAF-native version) Evaluation \u2192 Enhancement Flow \u00b6 1. evaluate-prompt-for-adoption \u2193 [if EXTRACT PARTS recommendation] 2. Identify target OLAF skill \u2193 3. Extract valuable patterns/techniques \u2193 4. Enhance existing skill with extracted parts Best Practices \u00b6 When to Evaluate \u00b6 \u2705 Before importing any external prompt \u2705 When exploring awesome lists or registries \u2705 After seeing interesting blog post prompts \u2705 When team member suggests new prompt \u2705 During periodic prompt library audits What to Look For \u00b6 \u2705 High value score (30+) \u2705 Low similarity to existing (<40%) \u2705 Clear quality ratings \u2705 AI necessity (not scriptable) \u2705 Realistic use frequency Red Flags \u00b6 \u274c High similarity (>80%) without significant improvements \u274c Platform-locked (only works on one LLM/agent) \u274c Unclear or poorly structured \u274c Too specific (one-time use) \u274c Better as script/tool than prompt Advanced Usage \u00b6 Batch Evaluation \u00b6 Evaluate multiple prompts from a collection: User: \"evaluate all prompts from https://github.com/awesome/prompts/\" \u2192 Fetches repository \u2192 Identifies prompt files \u2192 Evaluates each individually \u2192 Provides summary report with recommendations Comparative Evaluation \u00b6 Compare two similar prompts: User: \"evaluate and compare: - https://github.com/user1/code-review-prompt - https://github.com/user2/better-code-review\" \u2192 Evaluates both \u2192 Compares quality scores \u2192 Recommends best one or hybrid approach Periodic Re-evaluation \u00b6 Re-evaluate adopted prompts periodically: User: \"re-evaluate my-imported-skill against current OLAF standards\" \u2192 Checks if better alternatives now exist in OLAF \u2192 Assesses if still valuable \u2192 Recommends: keep, enhance, or deprecate Metrics Tracked \u00b6 The evaluation provides quantifiable metrics: - Similarity Score : 0-100% overlap with existing skills - Quality Ratings : 5 dimensions (Clear/Acceptable/Poor scale) - Value Score : 0-50 points weighted formula - AI Necessity : Required/Beneficial/Optional - Frequency : Daily/Weekly/Monthly/Rare - Effort Estimate : Low/Medium/High for modifications Common Evaluation Outcomes \u00b6 Outcome Distribution (typical) \u00b6 ADOPT - 20% (truly new, high-value prompts) ADOPT WITH MODIFICATIONS - 30% (good but needs work) EXTRACT PARTS - 25% (valuable patterns to merge) SKIP - 25% (duplicates or low value) This distribution helps maintain a curated, high-quality OLAF library while avoiding prompt bloat.","title":"Evaluate Prompt for Adoption"},{"location":"skills/evaluate-prompt-for-adoption/description/#evaluate-prompt-for-adoption","text":"","title":"Evaluate Prompt for Adoption"},{"location":"skills/evaluate-prompt-for-adoption/description/#overview","text":"The evaluate-prompt-for-adoption skill helps you systematically assess external prompts (from GitHub, awesome lists, registries, or the web) to determine if they're worth adopting into your OLAF framework.","title":"Overview"},{"location":"skills/evaluate-prompt-for-adoption/description/#purpose","text":"Before importing every interesting prompt you find, you need to evaluate: - Is it similar to what we already have? - Is it high quality? - Will anyone actually use it? - Does it add real value? - Is it worth the maintenance burden? This skill provides a structured evaluation framework to make informed adoption decisions.","title":"Purpose"},{"location":"skills/evaluate-prompt-for-adoption/description/#key-features","text":"","title":"Key Features"},{"location":"skills/evaluate-prompt-for-adoption/description/#1-multi-source-fetching","text":"Retrieve prompts from various sources: - GitHub repositories - Raw files or repo browse - GitHub gists - Public prompt collections - Awesome lists - Curated prompt libraries - Web pages - Blog posts, documentation - Direct paste - Copy/paste prompt text","title":"1. Multi-Source Fetching"},{"location":"skills/evaluate-prompt-for-adoption/description/#2-similarity-detection","text":"Avoid duplicates by checking against existing OLAF skills: - Semantic search across workspace - Overlap percentage calculation - Unique feature identification - Merge vs adopt decision support","title":"2. Similarity Detection"},{"location":"skills/evaluate-prompt-for-adoption/description/#3-multi-dimensional-quality-assessment","text":"Evaluate prompts across 5 quality dimensions :","title":"3. Multi-Dimensional Quality Assessment"},{"location":"skills/evaluate-prompt-for-adoption/description/#clarity","text":"Clear objective? Well-structured? Unambiguous instructions? Examples provided?","title":"Clarity"},{"location":"skills/evaluate-prompt-for-adoption/description/#genericity","text":"Applicable to multiple use cases? Reusable across projects? Domain-agnostic or valuable niche?","title":"Genericity"},{"location":"skills/evaluate-prompt-for-adoption/description/#parameterizability","text":"Can be configured? Supports inputs/outputs? Flexible for different contexts?","title":"Parameterizability"},{"location":"skills/evaluate-prompt-for-adoption/description/#llm-independence","text":"Works across LLMs (Claude, GPT, Gemini)? Not platform-locked? Standard prompt patterns?","title":"LLM Independence"},{"location":"skills/evaluate-prompt-for-adoption/description/#structure-quality","text":"Logical flow? Proper sections? Error handling? Validation steps?","title":"Structure Quality"},{"location":"skills/evaluate-prompt-for-adoption/description/#4-persona-use-case-analysis","text":"Identify who would use this prompt: - Developer personas (junior, senior, architect) - Domain experts (data scientist, designer) - Expertise levels (beginner, intermediate, advanced) - Use case frequency (daily, weekly, rare)","title":"4. Persona &amp; Use Case Analysis"},{"location":"skills/evaluate-prompt-for-adoption/description/#5-value-add-estimation","text":"Frequency \u00d7 Specificity Matrix : \u2502 High Frequency \u2502 Low Frequency \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Generic \u2502 HIGH VALUE \u2b50\u2b50\u2b50 \u2502 MEDIUM VALUE \u2b50\u2b50 \u2502 (everyday tool) \u2502 (useful helper) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Specific \u2502 MEDIUM VALUE \u2b50\u2b50 \u2502 LOW VALUE \u2b50 \u2502 (niche but frequent) \u2502 (very situational) AI Necessity Assessment : - \u2705 Requires AI (reasoning, creativity) - \u26a0\ufe0f Benefits from AI but could script - \u274c Better as script/tool Value Score (0-50 points): - 40-50: EXCELLENT - Adopt immediately - 30-39: GOOD - Strong candidate - 20-29: MODERATE - Consider with improvements - 10-19: LOW - Skip or extract parts - 0-9: POOR - Not worth it","title":"5. Value-Add Estimation"},{"location":"skills/evaluate-prompt-for-adoption/description/#6-actionable-recommendations","text":"Clear recommendation with rationale: - ADOPT - Import as-is or with minor tweaks - ADOPT WITH MODIFICATIONS - Needs improvements first - EXTRACT PARTS - Take specific patterns, not whole prompt - SKIP - Not valuable or duplicative","title":"6. Actionable Recommendations"},{"location":"skills/evaluate-prompt-for-adoption/description/#use-cases","text":"","title":"Use Cases"},{"location":"skills/evaluate-prompt-for-adoption/description/#scenario-1-github-awesome-list-discovery","text":"You find a promising prompt in awesome-chatgpt-prompts: User: \"evaluate this prompt: https://github.com/awesome/prompts/blob/main/code-reviewer.md\" \u2192 Fetches prompt from GitHub \u2192 Checks: Do we have code review skills? \u2192 Compares to existing review-code, review-diff skills \u2192 Finds 60% overlap but unique features \u2192 Rates: Clarity \u2705, Genericity \u2705, AI-required \u2705 \u2192 Value score: 38/50 (GOOD) \u2192 Recommends: ADOPT WITH MODIFICATIONS (extract unique review criteria, merge into review-code)","title":"Scenario 1: GitHub Awesome List Discovery"},{"location":"skills/evaluate-prompt-for-adoption/description/#scenario-2-blog-post-prompt","text":"You see an interesting prompt in a blog: User: \"evaluate prompt from https://example.com/blog/amazing-prompt\" \u2192 Fetches from webpage \u2192 Extracts prompt from article \u2192 Checks similarity: LOW (15% overlap) \u2192 Rates quality across 5 dimensions \u2192 Analyzes: High frequency + Generic = HIGH VALUE \u2192 Value score: 42/50 (EXCELLENT) \u2192 Recommends: ADOPT - create as new skill \u2192 Suggests: Use create-skill, competency: productivity","title":"Scenario 2: Blog Post Prompt"},{"location":"skills/evaluate-prompt-for-adoption/description/#scenario-3-direct-paste-evaluation","text":"You copied a prompt from Slack: User: \"evaluate this prompt: [pastes content]\" \u2192 Analyzes pasted text \u2192 Finds: Very specific to one use case \u2192 Rates: Genericity \u274c (Too Narrow) \u2192 Frequency: Rare \u2192 Value score: 12/50 (LOW) \u2192 Recommends: SKIP - too specific, low reuse potential","title":"Scenario 3: Direct Paste Evaluation"},{"location":"skills/evaluate-prompt-for-adoption/description/#scenario-4-gist-collection","text":"You found a gist with multiple prompts: User: \"evaluate prompts from https://gist.github.com/user/abc123\" \u2192 Fetches gist \u2192 Finds 5 prompts in gist \u2192 Evaluates each separately \u2192 Results: - Prompt 1: ADOPT (45/50) - Prompt 2: SKIP (duplicate of existing) - Prompt 3: EXTRACT PARTS (good pattern, merge into existing) - Prompt 4: ADOPT WITH MODIFICATIONS (needs parameterization) - Prompt 5: SKIP (better as script)","title":"Scenario 4: Gist Collection"},{"location":"skills/evaluate-prompt-for-adoption/description/#evaluation-report-example","text":"## Evaluation Report ### Source Information - **URL**: https://github.com/f/awesome-chatgpt-prompts/blob/main/prompts.csv#L42 - **Description**: Act as a Linux Terminal - **Author**: Fatih Kadir Ak\u0131n - **License**: CC0-1.0 ### Similarity Analysis - **Similar OLAF Skills**: None found (0% overlap) - **Unique Features**: Interactive terminal simulation, command execution feedback - **Similarity Verdict**: LOW - New capability ### Quality Assessment | Dimension | Rating | Notes | |-----------|--------|-------| | Clarity | Clear | Well-defined objective and behavior | | Genericity | Domain-Specific | Specific to Linux terminal simulation | | Parameterizability | Moderate | Could add shell type parameter | | LLM Independence | Agnostic | Works across all LLMs | | Structure | Acceptable | Clear but could add error handling | ### Persona & Use Cases - **Target Personas**: Developers (junior to senior), System administrators, DevOps engineers - **Primary Use Case**: Learning/practicing Linux commands safely - **Frequency**: Weekly (learning contexts) ### Value-Add Analysis - **Frequency \u00d7 Specificity**: MEDIUM VALUE \u2b50\u2b50 (domain-specific but useful) - **AI Necessity**: Required (needs understanding of Linux commands) - **Value Score**: 32/50 points - GOOD ### Final Recommendation **\ud83c\udfaf RECOMMENDATION**: ADOPT WITH MODIFICATIONS **Rationale**: Unique capability not in OLAF. Good quality but could be enhanced with error handling. Value score indicates strong adoption candidate. **Modifications needed**: 1. Add error handling capabilities 2. Add error handling section 3. Add examples of common command interactions 4. Structure as OLAF skill with proper manifest **Estimated effort**: Medium (2-3 hours to properly structure) ### Next Steps 1. Use `create-skill` to build OLAF-native version with modifications 2. Add to `learning-tools` or `development` competency 3. Include parameterization for different shells 4. Add comprehensive examples and error handling","title":"Evaluation Report Example"},{"location":"skills/evaluate-prompt-for-adoption/description/#benefits","text":"","title":"Benefits"},{"location":"skills/evaluate-prompt-for-adoption/description/#for-teams","text":"Curated Library : Only high-quality prompts enter OLAF No Duplicates : Systematic similarity checking Clear Criteria : Objective evaluation framework Value Focus : Prioritize high-impact prompts","title":"For Teams"},{"location":"skills/evaluate-prompt-for-adoption/description/#for-individuals","text":"Save Time : Quick evaluation vs lengthy trial-and-error Better Decisions : Data-driven adoption choices Learn Patterns : Understand what makes prompts valuable Avoid Clutter : Don't import low-value prompts","title":"For Individuals"},{"location":"skills/evaluate-prompt-for-adoption/description/#for-projects","text":"Quality Standards : Maintain high bar for prompts Strategic Growth : Grow library intentionally Resource Efficiency : Focus on high-ROI prompts Maintenance Burden : Avoid adopting hard-to-maintain prompts","title":"For Projects"},{"location":"skills/evaluate-prompt-for-adoption/description/#integration-with-other-skills","text":"","title":"Integration with Other Skills"},{"location":"skills/evaluate-prompt-for-adoption/description/#evaluation-import-flow","text":"1. evaluate-prompt-for-adoption (this skill) \u2193 [if ADOPT recommendation] 2. convert-prompt-to-skill (package into OLAF skill) OR 3. convert-prompt (modernize to OLAF standards) OR 4. create-skill (build OLAF-native version)","title":"Evaluation \u2192 Import Flow"},{"location":"skills/evaluate-prompt-for-adoption/description/#evaluation-enhancement-flow","text":"1. evaluate-prompt-for-adoption \u2193 [if EXTRACT PARTS recommendation] 2. Identify target OLAF skill \u2193 3. Extract valuable patterns/techniques \u2193 4. Enhance existing skill with extracted parts","title":"Evaluation \u2192 Enhancement Flow"},{"location":"skills/evaluate-prompt-for-adoption/description/#best-practices","text":"","title":"Best Practices"},{"location":"skills/evaluate-prompt-for-adoption/description/#when-to-evaluate","text":"\u2705 Before importing any external prompt \u2705 When exploring awesome lists or registries \u2705 After seeing interesting blog post prompts \u2705 When team member suggests new prompt \u2705 During periodic prompt library audits","title":"When to Evaluate"},{"location":"skills/evaluate-prompt-for-adoption/description/#what-to-look-for","text":"\u2705 High value score (30+) \u2705 Low similarity to existing (<40%) \u2705 Clear quality ratings \u2705 AI necessity (not scriptable) \u2705 Realistic use frequency","title":"What to Look For"},{"location":"skills/evaluate-prompt-for-adoption/description/#red-flags","text":"\u274c High similarity (>80%) without significant improvements \u274c Platform-locked (only works on one LLM/agent) \u274c Unclear or poorly structured \u274c Too specific (one-time use) \u274c Better as script/tool than prompt","title":"Red Flags"},{"location":"skills/evaluate-prompt-for-adoption/description/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/evaluate-prompt-for-adoption/description/#batch-evaluation","text":"Evaluate multiple prompts from a collection: User: \"evaluate all prompts from https://github.com/awesome/prompts/\" \u2192 Fetches repository \u2192 Identifies prompt files \u2192 Evaluates each individually \u2192 Provides summary report with recommendations","title":"Batch Evaluation"},{"location":"skills/evaluate-prompt-for-adoption/description/#comparative-evaluation","text":"Compare two similar prompts: User: \"evaluate and compare: - https://github.com/user1/code-review-prompt - https://github.com/user2/better-code-review\" \u2192 Evaluates both \u2192 Compares quality scores \u2192 Recommends best one or hybrid approach","title":"Comparative Evaluation"},{"location":"skills/evaluate-prompt-for-adoption/description/#periodic-re-evaluation","text":"Re-evaluate adopted prompts periodically: User: \"re-evaluate my-imported-skill against current OLAF standards\" \u2192 Checks if better alternatives now exist in OLAF \u2192 Assesses if still valuable \u2192 Recommends: keep, enhance, or deprecate","title":"Periodic Re-evaluation"},{"location":"skills/evaluate-prompt-for-adoption/description/#metrics-tracked","text":"The evaluation provides quantifiable metrics: - Similarity Score : 0-100% overlap with existing skills - Quality Ratings : 5 dimensions (Clear/Acceptable/Poor scale) - Value Score : 0-50 points weighted formula - AI Necessity : Required/Beneficial/Optional - Frequency : Daily/Weekly/Monthly/Rare - Effort Estimate : Low/Medium/High for modifications","title":"Metrics Tracked"},{"location":"skills/evaluate-prompt-for-adoption/description/#common-evaluation-outcomes","text":"","title":"Common Evaluation Outcomes"},{"location":"skills/evaluate-prompt-for-adoption/description/#outcome-distribution-typical","text":"ADOPT - 20% (truly new, high-value prompts) ADOPT WITH MODIFICATIONS - 30% (good but needs work) EXTRACT PARTS - 25% (valuable patterns to merge) SKIP - 25% (duplicates or low value) This distribution helps maintain a curated, high-quality OLAF library while avoiding prompt bloat.","title":"Outcome Distribution (typical)"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/","text":"Evaluate Prompt for Adoption - Tutorial \u00b6 This tutorial demonstrates how to evaluate external prompts for potential adoption into your OLAF framework. Prerequisites \u00b6 OLAF framework installed Internet connection (for fetching from URLs) Access to evaluate-prompt-for-adoption skill Tutorial Scenarios \u00b6 Scenario 1: Evaluate from GitHub URL \u00b6 Situation : You found an interesting prompt in an awesome-chatgpt-prompts repository. Steps : Invoke the skill with URL : olaf evaluate prompt from https://raw.githubusercontent.com/f/awesome-chatgpt-prompts/main/prompts/linux-terminal.txt Skill fetches and analyzes : ``` Fetching prompt from URL... \u2713 Retrieved 245 characters \u2713 Detected prompt type: Interactive simulation Checking similarity to existing OLAF skills... \u2713 Searched 96 skills \u2713 Found 0 similar skills (0% overlap) Evaluating quality... ``` Review the evaluation report : ``` ## Evaluation Report ### Source Information - URL: https://raw.githubusercontent.com/.../linux-terminal.txt - Description: Act as a Linux Terminal - Author: Community contribution ### Similarity Analysis - Similar OLAF Skills: None (0% overlap) - Unique Features: Terminal simulation, command execution - Similarity Verdict: LOW - New capability \u2705 ### Quality Assessment | Dimension | Rating | Notes | |-----------|--------|-------| | Clarity | Clear | Well-defined behavior | | Genericity | Domain-Specific | Linux-specific | | Parameterizability | Moderate | Could add shell types | | LLM Independence | Agnostic | Works anywhere | | Structure | Acceptable | Could add error handling | ### Persona & Use Cases - Target Personas: Developers, sysadmins, DevOps - Primary Use Case: Safe Linux command practice - Frequency: Weekly ### Value-Add Analysis - Frequency \u00d7 Specificity: MEDIUM VALUE \u2b50\u2b50 - AI Necessity: Required (needs command understanding) - Value Score: 32/50 - GOOD ### Final Recommendation \ud83c\udfaf RECOMMENDATION: ADOPT WITH MODIFICATIONS Rationale: Unique capability not in OLAF. Good quality but needs parameterization and error handling. Value score indicates strong candidate. Modifications needed: 1. Add shell_type parameter (bash/zsh/fish) 2. Add error handling section 3. Structure as proper OLAF skill Estimated effort: Medium (2-3 hours) ``` Skill asks for next step : ``` Would you like me to proceed with ADOPT WITH MODIFICATIONS? I can: a) Create OLAF-native version with create-skill b) Import as-is then improve with convert-prompt c) Skip for now ``` You decide : Option a - create OLAF-native version Result : Skill creates improved version Scenario 2: Evaluate from Direct Paste \u00b6 Situation : Your colleague shared a prompt via Slack that they found useful. Steps : Copy the prompt text Invoke with pasted content : ``` olaf evaluate this prompt: [paste content] You are an expert code reviewer. Review the provided code for: 1. Security vulnerabilities 2. Performance issues 3. Code style violations 4. Best practice adherence Provide specific, actionable feedback. ``` Skill analyzes without fetching : ``` Analyzing provided prompt text... \u2713 Extracted 87 characters \u2713 Detected type: Code review assistant Checking similarity to existing OLAF skills... \u2713 Found 2 similar skills: - review-code (75% overlap) - review-diff (45% overlap) Evaluating quality and unique features... ``` Review report focusing on similarity : ``` ### Similarity Analysis Similar OLAF Skills: \u2022 review-code (75% overlap) - Already has security, performance checks \u2022 review-diff (45% overlap) - Focuses on git diffs Unique Features in External Prompt: \u2022 \"Best practice adherence\" explicitly mentioned \u2022 Numbered checklist approach Similarity Verdict: HIGH (75%) - Mostly duplicate \u26a0\ufe0f ### Final Recommendation \ud83c\udfaf RECOMMENDATION: EXTRACT PARTS Rationale: High overlap with existing review-code skill. However, the explicit \"best practice adherence\" callout and numbered checklist format could enhance our existing skill. Parts worth extracting: 1. Best practice adherence check (add to review-code) 2. Numbered checklist format (improve output structure) Integration approach: Enhance review-code skill with these elements ``` Next steps provided : ``` Recommended action: Open skills/review-code/prompts/review-code.md Add \"Best practice adherence\" to objectives Update output format to use numbered checklist Would you like me to make these enhancements now? ``` Scenario 3: Low-Value Prompt Rejection \u00b6 Situation : You see a very specific prompt that seems narrow. Steps : Invoke evaluation : olaf evaluate prompt: https://example.com/my-very-specific-prompt Skill fetches and evaluates : ``` Fetching prompt... \u2713 Retrieved content Prompt description: \"Generate TypeScript interfaces for AWS Lambda handlers that process S3 events triggered by CloudWatch using CDK\" Analyzing... ``` Report shows low scores : ``` ### Quality Assessment | Dimension | Rating | Notes | |-----------|--------|-------| | Clarity | Clear | Well-defined but narrow | | Genericity | Too Narrow | \u274c Very specific stack | | Parameterizability | Hardcoded | Locked to AWS/TypeScript | | LLM Independence | Agnostic | Works across LLMs | | Structure | Acceptable | Basic structure | ### Persona & Use Cases - Target Personas: AWS developers using TypeScript + CDK - Primary Use Case: Specific S3\u2192Lambda\u2192CloudWatch setup - Frequency: Rare (only when setting up this exact pattern) ### Value-Add Analysis - Frequency \u00d7 Specificity: LOW VALUE \u2b50 (very narrow + rare) - AI Necessity: Optional (code generator could handle) - Value Score: 14/50 - LOW ### Final Recommendation \ud83c\udfaf RECOMMENDATION: SKIP Rationale: Too specific to one tech stack combination. Rare use case. Could be replaced with code generator or CDK construct. Low reuse potential across team. Not generic enough for OLAF library. Alternative: Use general create-typescript-interfaces skill and adapt output for specific AWS needs. ``` Clear guidance : ``` This prompt is not recommended for adoption. If you frequently need AWS/TypeScript/CDK work, consider instead: 1. Creating a generic \"generate-aws-cdk-constructs\" skill 2. Parameterizing for different AWS services 3. Making it reusable beyond S3\u2192Lambda pattern ``` Scenario 4: Excellent High-Value Find \u00b6 Situation : You discover a prompt that looks perfect. Steps : Evaluate : olaf evaluate https://github.com/awesome/prompts/api-design-reviewer.md Report shows high scores : ``` ### Quality Assessment | Dimension | Rating | Notes | |-----------|--------|-------| | Clarity | Clear | \u2705 Excellent structure | | Genericity | Generic | \u2705 Works for any API | | Parameterizability | High | \u2705 REST/GraphQL/gRPC support | | LLM Independence | Agnostic | \u2705 Standard patterns | | Structure | Well-Structured | \u2705 Comprehensive flow | ### Value-Add Analysis - Frequency \u00d7 Specificity: HIGH VALUE \u2b50\u2b50\u2b50 (generic + frequent) - AI Necessity: Required (needs design judgment) - Value Score: 45/50 - EXCELLENT ### Final Recommendation \ud83c\udfaf RECOMMENDATION: ADOPT Rationale: Exceptional quality across all dimensions. Fills gap in OLAF (no API design review skill currently). High reuse potential. Frequent use case. Well-structured and parameterized. No modifications needed. Suggested skill name: review-api-design Suggested competency: code-quality or api-development Priority: HIGH ``` Immediate adoption : ``` Would you like me to import this excellent prompt now? I recommend: convert-prompt-to-skill (wrap it into OLAF) ``` You confirm : Yes, import it Skill proceeds : ``` \u2713 Packaging via convert-prompt-to-skill... \u2713 Created skill: review-api-design \u2713 Added to api-development competency \u2713 Ready to use! Try it: olaf review-api-design ``` Understanding the Value Score \u00b6 The value score formula combines multiple factors: Value Score = (Frequency \u00d7 3) + (Genericity \u00d7 2) + (AI_Necessity \u00d7 3) + (Quality \u00d7 2) Example calculation : For \"Linux Terminal\" prompt: - Frequency: 3/5 (weekly) \u2192 3 \u00d7 3 = 9 points - Genericity: 3/5 (domain-specific) \u2192 3 \u00d7 2 = 6 points - AI_Necessity: 5/5 (requires understanding) \u2192 5 \u00d7 3 = 15 points - Quality: 4/5 (acceptable) \u2192 4 \u00d7 2 = 8 points Total : 9 + 6 + 15 + 8 = 38/50 (GOOD) Decision Matrix \u00b6 Use this to quickly interpret recommendations: Recommendation Similarity Value Score Action ADOPT <40% 40-50 Import as-is or with minor tweaks ADOPT WITH MODIFICATIONS <60% 30-39 Improve then import EXTRACT PARTS 40-80% 20-29 Merge into existing skill SKIP >80% or <20% <20 Don't import Common Evaluation Patterns \u00b6 Pattern 1: The Duplicate \u00b6 High similarity (>80%) No unique features Action : SKIP, use existing Pattern 2: The Enhancement \u00b6 Medium similarity (40-70%) Some unique features Action : EXTRACT PARTS, merge Pattern 3: The Hidden Gem \u00b6 Low similarity (<40%) High value score (>35) Good quality across dimensions Action : ADOPT Pattern 4: The Niche Special \u00b6 Very specific use case High quality but rare use Action : ADOPT WITH MODIFICATIONS (make more generic) Pattern 5: The Almost-There \u00b6 Good concept, poor execution Low quality scores Action : ADOPT WITH MODIFICATIONS or rebuild with create-skill Tips for Effective Evaluation \u00b6 Before Evaluation \u00b6 Quick scan : Read the prompt briefly first Check source : Is it from reputable source? Check license : Can you legally use it? During Evaluation \u00b6 Trust the metrics : Don't override scores without good reason Consider context : Your team's needs may differ from general assessment Look for patterns : Does it teach you something valuable even if you skip it? After Evaluation \u00b6 Act on recommendation : Don't just evaluate, execute Track outcomes : Note which adopted prompts get used Iterate : Re-evaluate periodically Next Steps \u00b6 After completing this tutorial: Find prompts : Browse GitHub awesome lists, blogs, registries Evaluate systematically : Use this skill for all external prompts Build curated library : Only adopt high-value prompts Share evaluations : Help team make informed decisions Measure value : Track which adopted prompts get actual use Related Skills \u00b6 convert-prompt-to-skill - Package adopted prompts into a skill convert-prompt - Modernize adopted prompts to OLAF standards create-skill - Build OLAF-native version of adopted prompts validate-prompt-value - Re-evaluate existing OLAF prompts","title":"Evaluate Prompt for Adoption - Tutorial"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#evaluate-prompt-for-adoption-tutorial","text":"This tutorial demonstrates how to evaluate external prompts for potential adoption into your OLAF framework.","title":"Evaluate Prompt for Adoption - Tutorial"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#prerequisites","text":"OLAF framework installed Internet connection (for fetching from URLs) Access to evaluate-prompt-for-adoption skill","title":"Prerequisites"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#tutorial-scenarios","text":"","title":"Tutorial Scenarios"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#scenario-1-evaluate-from-github-url","text":"Situation : You found an interesting prompt in an awesome-chatgpt-prompts repository. Steps : Invoke the skill with URL : olaf evaluate prompt from https://raw.githubusercontent.com/f/awesome-chatgpt-prompts/main/prompts/linux-terminal.txt Skill fetches and analyzes : ``` Fetching prompt from URL... \u2713 Retrieved 245 characters \u2713 Detected prompt type: Interactive simulation Checking similarity to existing OLAF skills... \u2713 Searched 96 skills \u2713 Found 0 similar skills (0% overlap) Evaluating quality... ``` Review the evaluation report : ``` ## Evaluation Report ### Source Information - URL: https://raw.githubusercontent.com/.../linux-terminal.txt - Description: Act as a Linux Terminal - Author: Community contribution ### Similarity Analysis - Similar OLAF Skills: None (0% overlap) - Unique Features: Terminal simulation, command execution - Similarity Verdict: LOW - New capability \u2705 ### Quality Assessment | Dimension | Rating | Notes | |-----------|--------|-------| | Clarity | Clear | Well-defined behavior | | Genericity | Domain-Specific | Linux-specific | | Parameterizability | Moderate | Could add shell types | | LLM Independence | Agnostic | Works anywhere | | Structure | Acceptable | Could add error handling | ### Persona & Use Cases - Target Personas: Developers, sysadmins, DevOps - Primary Use Case: Safe Linux command practice - Frequency: Weekly ### Value-Add Analysis - Frequency \u00d7 Specificity: MEDIUM VALUE \u2b50\u2b50 - AI Necessity: Required (needs command understanding) - Value Score: 32/50 - GOOD ### Final Recommendation \ud83c\udfaf RECOMMENDATION: ADOPT WITH MODIFICATIONS Rationale: Unique capability not in OLAF. Good quality but needs parameterization and error handling. Value score indicates strong candidate. Modifications needed: 1. Add shell_type parameter (bash/zsh/fish) 2. Add error handling section 3. Structure as proper OLAF skill Estimated effort: Medium (2-3 hours) ``` Skill asks for next step : ``` Would you like me to proceed with ADOPT WITH MODIFICATIONS? I can: a) Create OLAF-native version with create-skill b) Import as-is then improve with convert-prompt c) Skip for now ``` You decide : Option a - create OLAF-native version Result : Skill creates improved version","title":"Scenario 1: Evaluate from GitHub URL"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#scenario-2-evaluate-from-direct-paste","text":"Situation : Your colleague shared a prompt via Slack that they found useful. Steps : Copy the prompt text Invoke with pasted content : ``` olaf evaluate this prompt: [paste content] You are an expert code reviewer. Review the provided code for: 1. Security vulnerabilities 2. Performance issues 3. Code style violations 4. Best practice adherence Provide specific, actionable feedback. ``` Skill analyzes without fetching : ``` Analyzing provided prompt text... \u2713 Extracted 87 characters \u2713 Detected type: Code review assistant Checking similarity to existing OLAF skills... \u2713 Found 2 similar skills: - review-code (75% overlap) - review-diff (45% overlap) Evaluating quality and unique features... ``` Review report focusing on similarity : ``` ### Similarity Analysis Similar OLAF Skills: \u2022 review-code (75% overlap) - Already has security, performance checks \u2022 review-diff (45% overlap) - Focuses on git diffs Unique Features in External Prompt: \u2022 \"Best practice adherence\" explicitly mentioned \u2022 Numbered checklist approach Similarity Verdict: HIGH (75%) - Mostly duplicate \u26a0\ufe0f ### Final Recommendation \ud83c\udfaf RECOMMENDATION: EXTRACT PARTS Rationale: High overlap with existing review-code skill. However, the explicit \"best practice adherence\" callout and numbered checklist format could enhance our existing skill. Parts worth extracting: 1. Best practice adherence check (add to review-code) 2. Numbered checklist format (improve output structure) Integration approach: Enhance review-code skill with these elements ``` Next steps provided : ``` Recommended action: Open skills/review-code/prompts/review-code.md Add \"Best practice adherence\" to objectives Update output format to use numbered checklist Would you like me to make these enhancements now? ```","title":"Scenario 2: Evaluate from Direct Paste"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#scenario-3-low-value-prompt-rejection","text":"Situation : You see a very specific prompt that seems narrow. Steps : Invoke evaluation : olaf evaluate prompt: https://example.com/my-very-specific-prompt Skill fetches and evaluates : ``` Fetching prompt... \u2713 Retrieved content Prompt description: \"Generate TypeScript interfaces for AWS Lambda handlers that process S3 events triggered by CloudWatch using CDK\" Analyzing... ``` Report shows low scores : ``` ### Quality Assessment | Dimension | Rating | Notes | |-----------|--------|-------| | Clarity | Clear | Well-defined but narrow | | Genericity | Too Narrow | \u274c Very specific stack | | Parameterizability | Hardcoded | Locked to AWS/TypeScript | | LLM Independence | Agnostic | Works across LLMs | | Structure | Acceptable | Basic structure | ### Persona & Use Cases - Target Personas: AWS developers using TypeScript + CDK - Primary Use Case: Specific S3\u2192Lambda\u2192CloudWatch setup - Frequency: Rare (only when setting up this exact pattern) ### Value-Add Analysis - Frequency \u00d7 Specificity: LOW VALUE \u2b50 (very narrow + rare) - AI Necessity: Optional (code generator could handle) - Value Score: 14/50 - LOW ### Final Recommendation \ud83c\udfaf RECOMMENDATION: SKIP Rationale: Too specific to one tech stack combination. Rare use case. Could be replaced with code generator or CDK construct. Low reuse potential across team. Not generic enough for OLAF library. Alternative: Use general create-typescript-interfaces skill and adapt output for specific AWS needs. ``` Clear guidance : ``` This prompt is not recommended for adoption. If you frequently need AWS/TypeScript/CDK work, consider instead: 1. Creating a generic \"generate-aws-cdk-constructs\" skill 2. Parameterizing for different AWS services 3. Making it reusable beyond S3\u2192Lambda pattern ```","title":"Scenario 3: Low-Value Prompt Rejection"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#scenario-4-excellent-high-value-find","text":"Situation : You discover a prompt that looks perfect. Steps : Evaluate : olaf evaluate https://github.com/awesome/prompts/api-design-reviewer.md Report shows high scores : ``` ### Quality Assessment | Dimension | Rating | Notes | |-----------|--------|-------| | Clarity | Clear | \u2705 Excellent structure | | Genericity | Generic | \u2705 Works for any API | | Parameterizability | High | \u2705 REST/GraphQL/gRPC support | | LLM Independence | Agnostic | \u2705 Standard patterns | | Structure | Well-Structured | \u2705 Comprehensive flow | ### Value-Add Analysis - Frequency \u00d7 Specificity: HIGH VALUE \u2b50\u2b50\u2b50 (generic + frequent) - AI Necessity: Required (needs design judgment) - Value Score: 45/50 - EXCELLENT ### Final Recommendation \ud83c\udfaf RECOMMENDATION: ADOPT Rationale: Exceptional quality across all dimensions. Fills gap in OLAF (no API design review skill currently). High reuse potential. Frequent use case. Well-structured and parameterized. No modifications needed. Suggested skill name: review-api-design Suggested competency: code-quality or api-development Priority: HIGH ``` Immediate adoption : ``` Would you like me to import this excellent prompt now? I recommend: convert-prompt-to-skill (wrap it into OLAF) ``` You confirm : Yes, import it Skill proceeds : ``` \u2713 Packaging via convert-prompt-to-skill... \u2713 Created skill: review-api-design \u2713 Added to api-development competency \u2713 Ready to use! Try it: olaf review-api-design ```","title":"Scenario 4: Excellent High-Value Find"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#understanding-the-value-score","text":"The value score formula combines multiple factors: Value Score = (Frequency \u00d7 3) + (Genericity \u00d7 2) + (AI_Necessity \u00d7 3) + (Quality \u00d7 2) Example calculation : For \"Linux Terminal\" prompt: - Frequency: 3/5 (weekly) \u2192 3 \u00d7 3 = 9 points - Genericity: 3/5 (domain-specific) \u2192 3 \u00d7 2 = 6 points - AI_Necessity: 5/5 (requires understanding) \u2192 5 \u00d7 3 = 15 points - Quality: 4/5 (acceptable) \u2192 4 \u00d7 2 = 8 points Total : 9 + 6 + 15 + 8 = 38/50 (GOOD)","title":"Understanding the Value Score"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#decision-matrix","text":"Use this to quickly interpret recommendations: Recommendation Similarity Value Score Action ADOPT <40% 40-50 Import as-is or with minor tweaks ADOPT WITH MODIFICATIONS <60% 30-39 Improve then import EXTRACT PARTS 40-80% 20-29 Merge into existing skill SKIP >80% or <20% <20 Don't import","title":"Decision Matrix"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#common-evaluation-patterns","text":"","title":"Common Evaluation Patterns"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#pattern-1-the-duplicate","text":"High similarity (>80%) No unique features Action : SKIP, use existing","title":"Pattern 1: The Duplicate"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#pattern-2-the-enhancement","text":"Medium similarity (40-70%) Some unique features Action : EXTRACT PARTS, merge","title":"Pattern 2: The Enhancement"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#pattern-3-the-hidden-gem","text":"Low similarity (<40%) High value score (>35) Good quality across dimensions Action : ADOPT","title":"Pattern 3: The Hidden Gem"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#pattern-4-the-niche-special","text":"Very specific use case High quality but rare use Action : ADOPT WITH MODIFICATIONS (make more generic)","title":"Pattern 4: The Niche Special"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#pattern-5-the-almost-there","text":"Good concept, poor execution Low quality scores Action : ADOPT WITH MODIFICATIONS or rebuild with create-skill","title":"Pattern 5: The Almost-There"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#tips-for-effective-evaluation","text":"","title":"Tips for Effective Evaluation"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#before-evaluation","text":"Quick scan : Read the prompt briefly first Check source : Is it from reputable source? Check license : Can you legally use it?","title":"Before Evaluation"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#during-evaluation","text":"Trust the metrics : Don't override scores without good reason Consider context : Your team's needs may differ from general assessment Look for patterns : Does it teach you something valuable even if you skip it?","title":"During Evaluation"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#after-evaluation","text":"Act on recommendation : Don't just evaluate, execute Track outcomes : Note which adopted prompts get used Iterate : Re-evaluate periodically","title":"After Evaluation"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#next-steps","text":"After completing this tutorial: Find prompts : Browse GitHub awesome lists, blogs, registries Evaluate systematically : Use this skill for all external prompts Build curated library : Only adopt high-value prompts Share evaluations : Help team make informed decisions Measure value : Track which adopted prompts get actual use","title":"Next Steps"},{"location":"skills/evaluate-prompt-for-adoption/tutorial/#related-skills","text":"convert-prompt-to-skill - Package adopted prompts into a skill convert-prompt - Modernize adopted prompts to OLAF standards create-skill - Build OLAF-native version of adopted prompts validate-prompt-value - Re-evaluate existing OLAF prompts","title":"Related Skills"},{"location":"skills/evolve-code-iteratively/description/","text":"Evolve Code Iteratively \u00b6 Enhanced skill migrated from developer competency. Usage \u00b6 This skill provides evolve code iteratively functionality with self-contained dependencies and enhanced error handling.","title":"Evolve Code Iteratively"},{"location":"skills/evolve-code-iteratively/description/#evolve-code-iteratively","text":"Enhanced skill migrated from developer competency.","title":"Evolve Code Iteratively"},{"location":"skills/evolve-code-iteratively/description/#usage","text":"This skill provides evolve code iteratively functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/evolve-code-iteratively/tutorial/","text":"Evolve Code Iteratively Tutorial \u00b6 Step-by-step guide for using the evolve-code-iteratively skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Evolve Code Iteratively Tutorial"},{"location":"skills/evolve-code-iteratively/tutorial/#evolve-code-iteratively-tutorial","text":"Step-by-step guide for using the evolve-code-iteratively skill.","title":"Evolve Code Iteratively Tutorial"},{"location":"skills/evolve-code-iteratively/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/evolve-code-iteratively/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/extend-specification/description/","text":"Extend Specification \u00b6 Enhanced skill migrated from business-analyst competency. Usage \u00b6 This skill provides extend specification functionality with self-contained dependencies and enhanced error handling.","title":"Extend Specification"},{"location":"skills/extend-specification/description/#extend-specification","text":"Enhanced skill migrated from business-analyst competency.","title":"Extend Specification"},{"location":"skills/extend-specification/description/#usage","text":"This skill provides extend specification functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/extend-specification/tutorial/","text":"Extend Specification Tutorial \u00b6 Step-by-step guide for using the extend-specification skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Extend Specification Tutorial"},{"location":"skills/extend-specification/tutorial/#extend-specification-tutorial","text":"Step-by-step guide for using the extend-specification skill.","title":"Extend Specification Tutorial"},{"location":"skills/extend-specification/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/extend-specification/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/extract-notes-from-skube-site/description/","text":"skube-doc-synthesis \u00b6 Creates chapter-by-chapter synthesis notes that clearly separate: - SKube-specific content (what SKube adds/changes) - Quarkus-baseline content (what is standard Quarkus) It is designed for: - Large documentation that must be processed across multiple sessions. - Multi-agent execution via a shared TODO/WIP/DONE tracker. Inputs \u00b6 input_url (required) chapter_selection ( next / all / list) agent_name (recommended) Outputs \u00b6 Progress tracker: .olaf/work/skube/progress.md Notes folder: .olaf/work/skube/syntheise-YYYYMMDD-HHmm/ 00-global-synthesis.md One file per chapter completed Usage \u00b6 Invoke the skill and provide the URL. Then run with chapter_selection=next repeatedly to process one chapter at a time.","title":"skube-doc-synthesis"},{"location":"skills/extract-notes-from-skube-site/description/#skube-doc-synthesis","text":"Creates chapter-by-chapter synthesis notes that clearly separate: - SKube-specific content (what SKube adds/changes) - Quarkus-baseline content (what is standard Quarkus) It is designed for: - Large documentation that must be processed across multiple sessions. - Multi-agent execution via a shared TODO/WIP/DONE tracker.","title":"skube-doc-synthesis"},{"location":"skills/extract-notes-from-skube-site/description/#inputs","text":"input_url (required) chapter_selection ( next / all / list) agent_name (recommended)","title":"Inputs"},{"location":"skills/extract-notes-from-skube-site/description/#outputs","text":"Progress tracker: .olaf/work/skube/progress.md Notes folder: .olaf/work/skube/syntheise-YYYYMMDD-HHmm/ 00-global-synthesis.md One file per chapter completed","title":"Outputs"},{"location":"skills/extract-notes-from-skube-site/description/#usage","text":"Invoke the skill and provide the URL. Then run with chapter_selection=next repeatedly to process one chapter at a time.","title":"Usage"},{"location":"skills/find-expert-contact/description/","text":"Find Expert Contact \u00b6 Overview \u00b6 Locates and provides contact information for subject matter experts within your organization or professional network. Purpose \u00b6 Quickly identifies the right person to contact for specific expertise, technical questions, or domain knowledge, saving time searching through organizational charts or directories. Usage \u00b6 Command : find expert contact Protocol : Act When to Use : When you need to find someone with specific expertise, technical knowledge, or domain experience. Parameters \u00b6 Required Inputs \u00b6 Expertise Area : The domain, technology, or subject matter you need help with Optional Inputs \u00b6 Organization/Team : Narrow search to specific org or team Location : Geographic or timezone preferences Context : Why you need the expert (helps refine search) Context Requirements \u00b6 Access to organizational directory or contact information Clear description of the expertise needed Output \u00b6 Deliverables : - Expert contact information (name, email, role) - Expertise areas and background - Availability or best contact method - Alternative contacts if primary is unavailable Format : Structured list with contact details and expertise summary Examples \u00b6 Example 1: Technical Expertise \u00b6 Scenario : Need help with Kubernetes deployment issues Command : find expert contact Input : \"I need someone who knows Kubernetes and container orchestration\" Result : Contact information for DevOps engineers or SREs with Kubernetes expertise Example 2: Domain Knowledge \u00b6 Scenario : Questions about regulatory compliance Command : find expert contact Input : \"Who can help with GDPR compliance requirements?\" Result : Contact for compliance officer or legal team member with GDPR expertise Related Competencies \u00b6 assess-genai-initiative : Use this first to evaluate initiatives, then find experts to implement use-skill : Can route to this skill when expert finding is needed olaf-help : General help discovery for OLAF capabilities Tips & Best Practices \u00b6 Be specific about the expertise area for better matches Mention the context or problem you're trying to solve Ask for alternative contacts in case primary is unavailable Consider timezone and availability when provided Limitations \u00b6 Requires access to organizational contact information Cannot guarantee expert availability May not have information for external experts Contact information may be outdated","title":"Find Expert Contact"},{"location":"skills/find-expert-contact/description/#find-expert-contact","text":"","title":"Find Expert Contact"},{"location":"skills/find-expert-contact/description/#overview","text":"Locates and provides contact information for subject matter experts within your organization or professional network.","title":"Overview"},{"location":"skills/find-expert-contact/description/#purpose","text":"Quickly identifies the right person to contact for specific expertise, technical questions, or domain knowledge, saving time searching through organizational charts or directories.","title":"Purpose"},{"location":"skills/find-expert-contact/description/#usage","text":"Command : find expert contact Protocol : Act When to Use : When you need to find someone with specific expertise, technical knowledge, or domain experience.","title":"Usage"},{"location":"skills/find-expert-contact/description/#parameters","text":"","title":"Parameters"},{"location":"skills/find-expert-contact/description/#required-inputs","text":"Expertise Area : The domain, technology, or subject matter you need help with","title":"Required Inputs"},{"location":"skills/find-expert-contact/description/#optional-inputs","text":"Organization/Team : Narrow search to specific org or team Location : Geographic or timezone preferences Context : Why you need the expert (helps refine search)","title":"Optional Inputs"},{"location":"skills/find-expert-contact/description/#context-requirements","text":"Access to organizational directory or contact information Clear description of the expertise needed","title":"Context Requirements"},{"location":"skills/find-expert-contact/description/#output","text":"Deliverables : - Expert contact information (name, email, role) - Expertise areas and background - Availability or best contact method - Alternative contacts if primary is unavailable Format : Structured list with contact details and expertise summary","title":"Output"},{"location":"skills/find-expert-contact/description/#examples","text":"","title":"Examples"},{"location":"skills/find-expert-contact/description/#example-1-technical-expertise","text":"Scenario : Need help with Kubernetes deployment issues Command : find expert contact Input : \"I need someone who knows Kubernetes and container orchestration\" Result : Contact information for DevOps engineers or SREs with Kubernetes expertise","title":"Example 1: Technical Expertise"},{"location":"skills/find-expert-contact/description/#example-2-domain-knowledge","text":"Scenario : Questions about regulatory compliance Command : find expert contact Input : \"Who can help with GDPR compliance requirements?\" Result : Contact for compliance officer or legal team member with GDPR expertise","title":"Example 2: Domain Knowledge"},{"location":"skills/find-expert-contact/description/#related-competencies","text":"assess-genai-initiative : Use this first to evaluate initiatives, then find experts to implement use-skill : Can route to this skill when expert finding is needed olaf-help : General help discovery for OLAF capabilities","title":"Related Competencies"},{"location":"skills/find-expert-contact/description/#tips-best-practices","text":"Be specific about the expertise area for better matches Mention the context or problem you're trying to solve Ask for alternative contacts in case primary is unavailable Consider timezone and availability when provided","title":"Tips &amp; Best Practices"},{"location":"skills/find-expert-contact/description/#limitations","text":"Requires access to organizational contact information Cannot guarantee expert availability May not have information for external experts Contact information may be outdated","title":"Limitations"},{"location":"skills/find-expert-contact/tutorial/","text":"Find Expert Contact: Step-by-Step Tutorial \u00b6 How to Execute the \"Find Expert Contact\" Workflow This tutorial shows how to locate subject matter experts within your organization. Prerequisites \u00b6 Clear understanding of the expertise you need Access to organizational directory or contact information Context about why you need the expert (optional but helpful) Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 Initiate the expert search User Action: 1. Type the command: find expert contact 2. Describe the expertise area you need OLAF Response: OLAF will acknowledge the request and begin searching for relevant experts Step 2: Provide Expertise Details \u00b6 User Action: Describe what expertise you need I need someone who can help with PostgreSQL database performance optimization and query tuning for a high-traffic application Provide Context (Optional): - Problem : Slow query performance affecting user experience - Team : Backend engineering - Urgency : Need help this week Step 3: Expert Search \u00b6 What OLAF Does: - Searches organizational directory - Identifies people with matching expertise - Reviews roles, teams, and backgrounds - Ranks by relevance and availability You Should See: Search in progress confirmation Step 4: Review Expert Contacts \u00b6 What OLAF Provides: - Primary expert contact with details - Alternative contacts if available - Expertise areas and background - Best contact method or availability notes You Should See: Structured list of expert contacts with relevant information Step 5: Follow Up \u00b6 User Action: Use the contact information - Reach out to the identified expert - Mention the specific expertise area - Provide context about your need - Ask follow-up questions if needed Verification Checklist \u00b6 \u2705 Expert contact information is complete (name, email, role) \u2705 Expertise areas match your needs \u2705 Alternative contacts provided if available \u2705 Contact method or availability notes included Troubleshooting \u00b6 If no experts found: - Broaden the expertise area description - Try related or adjacent expertise areas - Ask for external resources or documentation If multiple experts returned: - Ask OLAF to recommend the best match for your specific situation - Request ranking by availability or expertise depth If contact information seems outdated: - Verify through organizational directory - Ask for alternative contacts - Request most recent information available Key Learning Points \u00b6 Specific Descriptions : More specific expertise descriptions yield better matches Context Matters : Providing context helps identify the right expert Alternatives : Always good to have backup contacts Organizational Knowledge : Leverages org structure and role information Next Steps to Try \u00b6 Contact the identified expert If implementing an initiative, use assess genai initiative first Save expert contacts for future reference Build your network of go-to experts Expected Timeline \u00b6 Total search time: 2-3 minutes User input required: Expertise description (1 minute) OLAF execution time: Search and ranking (1-2 minutes)","title":"Find Expert Contact: Step-by-Step Tutorial"},{"location":"skills/find-expert-contact/tutorial/#find-expert-contact-step-by-step-tutorial","text":"How to Execute the \"Find Expert Contact\" Workflow This tutorial shows how to locate subject matter experts within your organization.","title":"Find Expert Contact: Step-by-Step Tutorial"},{"location":"skills/find-expert-contact/tutorial/#prerequisites","text":"Clear understanding of the expertise you need Access to organizational directory or contact information Context about why you need the expert (optional but helpful)","title":"Prerequisites"},{"location":"skills/find-expert-contact/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/find-expert-contact/tutorial/#step-1-invoke-the-competency","text":"Initiate the expert search User Action: 1. Type the command: find expert contact 2. Describe the expertise area you need OLAF Response: OLAF will acknowledge the request and begin searching for relevant experts","title":"Step 1: Invoke the Competency"},{"location":"skills/find-expert-contact/tutorial/#step-2-provide-expertise-details","text":"User Action: Describe what expertise you need I need someone who can help with PostgreSQL database performance optimization and query tuning for a high-traffic application Provide Context (Optional): - Problem : Slow query performance affecting user experience - Team : Backend engineering - Urgency : Need help this week","title":"Step 2: Provide Expertise Details"},{"location":"skills/find-expert-contact/tutorial/#step-3-expert-search","text":"What OLAF Does: - Searches organizational directory - Identifies people with matching expertise - Reviews roles, teams, and backgrounds - Ranks by relevance and availability You Should See: Search in progress confirmation","title":"Step 3: Expert Search"},{"location":"skills/find-expert-contact/tutorial/#step-4-review-expert-contacts","text":"What OLAF Provides: - Primary expert contact with details - Alternative contacts if available - Expertise areas and background - Best contact method or availability notes You Should See: Structured list of expert contacts with relevant information","title":"Step 4: Review Expert Contacts"},{"location":"skills/find-expert-contact/tutorial/#step-5-follow-up","text":"User Action: Use the contact information - Reach out to the identified expert - Mention the specific expertise area - Provide context about your need - Ask follow-up questions if needed","title":"Step 5: Follow Up"},{"location":"skills/find-expert-contact/tutorial/#verification-checklist","text":"\u2705 Expert contact information is complete (name, email, role) \u2705 Expertise areas match your needs \u2705 Alternative contacts provided if available \u2705 Contact method or availability notes included","title":"Verification Checklist"},{"location":"skills/find-expert-contact/tutorial/#troubleshooting","text":"If no experts found: - Broaden the expertise area description - Try related or adjacent expertise areas - Ask for external resources or documentation If multiple experts returned: - Ask OLAF to recommend the best match for your specific situation - Request ranking by availability or expertise depth If contact information seems outdated: - Verify through organizational directory - Ask for alternative contacts - Request most recent information available","title":"Troubleshooting"},{"location":"skills/find-expert-contact/tutorial/#key-learning-points","text":"Specific Descriptions : More specific expertise descriptions yield better matches Context Matters : Providing context helps identify the right expert Alternatives : Always good to have backup contacts Organizational Knowledge : Leverages org structure and role information","title":"Key Learning Points"},{"location":"skills/find-expert-contact/tutorial/#next-steps-to-try","text":"Contact the identified expert If implementing an initiative, use assess genai initiative first Save expert contacts for future reference Build your network of go-to experts","title":"Next Steps to Try"},{"location":"skills/find-expert-contact/tutorial/#expected-timeline","text":"Total search time: 2-3 minutes User input required: Expertise description (1 minute) OLAF execution time: Search and ranking (1-2 minutes)","title":"Expected Timeline"},{"location":"skills/fix-code-smells/description/","text":"Fix Code Smells \u00b6 Enhanced skill migrated from developer competency. Usage \u00b6 This skill provides fix code smells functionality with self-contained dependencies and enhanced error handling.","title":"Fix Code Smells"},{"location":"skills/fix-code-smells/description/#fix-code-smells","text":"Enhanced skill migrated from developer competency.","title":"Fix Code Smells"},{"location":"skills/fix-code-smells/description/#usage","text":"This skill provides fix code smells functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/fix-code-smells/tutorial/","text":"Fix Code Smells Tutorial \u00b6 Step-by-step guide for using the fix-code-smells skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Fix Code Smells Tutorial"},{"location":"skills/fix-code-smells/tutorial/#fix-code-smells-tutorial","text":"Step-by-step guide for using the fix-code-smells skill.","title":"Fix Code Smells Tutorial"},{"location":"skills/fix-code-smells/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/fix-code-smells/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/generate-ai-agent-instructions/description/","text":"Generate AI Agent Instructions \u00b6 Analyze codebase to generate platform-agnostic AI agent instruction files for any coding assistant. What It Does \u00b6 This skill analyzes your codebase and generates comprehensive instruction files that help AI coding assistants (GitHub Copilot, Cursor, Windsurf, Cline, Kiro, etc.) understand your project's: Architecture and design decisions Critical patterns and conventions Build and development workflows Common tasks and scenarios Project-specific best practices Key Features \u00b6 \ud83d\udd0d Multi-Platform Support \u00b6 Automatically detects and generates instructions for: - GitHub Copilot : .github/copilot-instructions.md - Cursor : .cursorrules , .cursor/rules/ - Windsurf : .windsurfrules , .windsurf/rules/ - Cline : .clinerules , .cline/rules/ - Kiro : .kiro/steering/ - Generic : AGENTS.md (works with any assistant) \ud83d\udcca Intelligent Analysis \u00b6 Scans project structure and identifies patterns Detects languages, frameworks, and build tools Finds integration points and dependencies Extracts critical workflows and conventions Focuses on project-specific knowledge (not generic advice) \ud83d\udd04 Merge Existing Content \u00b6 Discovers existing AI instruction files Preserves valuable existing guidance Updates outdated sections Consolidates multiple platform files \u2705 Quality Assurance \u00b6 150-250 line target (concise but comprehensive) References actual files and directories Includes real commands and workflows Explains \"why\" behind decisions Validates completeness before creation When to Use \u00b6 Setting up a new project for AI-assisted development Onboarding team members using different AI coding tools Documenting project-specific patterns for AI assistants Migrating between AI coding platforms Improving AI assistant effectiveness in your codebase How It Works \u00b6 Platform Discovery - Detects which AI tools you use Codebase Analysis - Examines structure, patterns, workflows Proposal - Shows analysis summary and proposed output Generation - Creates platform-appropriate instruction file Validation - Ensures quality and completeness Output \u00b6 Creates one or more files like: AGENTS.md (generic): # AI Assistant Instructions for MyProject ## \ud83d\udea8 CRITICAL RULES FOR AI BEHAVIOR [Project-specific guidelines] ## Repository Overview [Architecture, tech stack, components] ## File Structure Guidelines [Directory purposes and conventions] ## Development Workflows [Build, test, run commands] ## Common User Scenarios [Step-by-step guidance for common tasks] ## AI Assistant Guidelines [Topic-specific guidance with file references] Comparison to Other Skills \u00b6 vs onboard-me \u00b6 onboard-me : Human-focused repository guide (300-1500 lines, setup/build/test commands) generate-ai-agent-instructions : AI-focused guidance (150-250 lines, patterns/conventions/\"why\") Use both : onboard-me for humans, this skill for AI agents. vs generate-tech-spec-from-code \u00b6 generate-tech-spec-from-code : Detailed technical specification generate-ai-agent-instructions : Practical guidance for AI assistants Example Usage \u00b6 # Auto-detect platform and generate olaf generate ai agent instructions # Explicit platform olaf generate ai agent instructions --platform cursor # For generic AGENTS.md olaf generate ai agent instructions --platform generic Quality Standards \u00b6 Generated instructions must: - \u2705 Reference actual files/directories from your codebase - \u2705 Include real commands that work in your project - \u2705 Explain project-specific patterns (not generic best practices) - \u2705 Document the \"why\" behind architectural decisions - \u2705 Stay concise (150-250 lines) while being comprehensive - \u2705 Be actionable (what to DO, not just theory) Related Skills \u00b6 onboard-me - Human-focused repository guide generate-tech-spec-from-code - Technical specification from code bootstrap-functional-spec-from-code - Functional spec generation","title":"Generate AI Agent Instructions"},{"location":"skills/generate-ai-agent-instructions/description/#generate-ai-agent-instructions","text":"Analyze codebase to generate platform-agnostic AI agent instruction files for any coding assistant.","title":"Generate AI Agent Instructions"},{"location":"skills/generate-ai-agent-instructions/description/#what-it-does","text":"This skill analyzes your codebase and generates comprehensive instruction files that help AI coding assistants (GitHub Copilot, Cursor, Windsurf, Cline, Kiro, etc.) understand your project's: Architecture and design decisions Critical patterns and conventions Build and development workflows Common tasks and scenarios Project-specific best practices","title":"What It Does"},{"location":"skills/generate-ai-agent-instructions/description/#key-features","text":"","title":"Key Features"},{"location":"skills/generate-ai-agent-instructions/description/#multi-platform-support","text":"Automatically detects and generates instructions for: - GitHub Copilot : .github/copilot-instructions.md - Cursor : .cursorrules , .cursor/rules/ - Windsurf : .windsurfrules , .windsurf/rules/ - Cline : .clinerules , .cline/rules/ - Kiro : .kiro/steering/ - Generic : AGENTS.md (works with any assistant)","title":"\ud83d\udd0d Multi-Platform Support"},{"location":"skills/generate-ai-agent-instructions/description/#intelligent-analysis","text":"Scans project structure and identifies patterns Detects languages, frameworks, and build tools Finds integration points and dependencies Extracts critical workflows and conventions Focuses on project-specific knowledge (not generic advice)","title":"\ud83d\udcca Intelligent Analysis"},{"location":"skills/generate-ai-agent-instructions/description/#merge-existing-content","text":"Discovers existing AI instruction files Preserves valuable existing guidance Updates outdated sections Consolidates multiple platform files","title":"\ud83d\udd04 Merge Existing Content"},{"location":"skills/generate-ai-agent-instructions/description/#quality-assurance","text":"150-250 line target (concise but comprehensive) References actual files and directories Includes real commands and workflows Explains \"why\" behind decisions Validates completeness before creation","title":"\u2705 Quality Assurance"},{"location":"skills/generate-ai-agent-instructions/description/#when-to-use","text":"Setting up a new project for AI-assisted development Onboarding team members using different AI coding tools Documenting project-specific patterns for AI assistants Migrating between AI coding platforms Improving AI assistant effectiveness in your codebase","title":"When to Use"},{"location":"skills/generate-ai-agent-instructions/description/#how-it-works","text":"Platform Discovery - Detects which AI tools you use Codebase Analysis - Examines structure, patterns, workflows Proposal - Shows analysis summary and proposed output Generation - Creates platform-appropriate instruction file Validation - Ensures quality and completeness","title":"How It Works"},{"location":"skills/generate-ai-agent-instructions/description/#output","text":"Creates one or more files like: AGENTS.md (generic): # AI Assistant Instructions for MyProject ## \ud83d\udea8 CRITICAL RULES FOR AI BEHAVIOR [Project-specific guidelines] ## Repository Overview [Architecture, tech stack, components] ## File Structure Guidelines [Directory purposes and conventions] ## Development Workflows [Build, test, run commands] ## Common User Scenarios [Step-by-step guidance for common tasks] ## AI Assistant Guidelines [Topic-specific guidance with file references]","title":"Output"},{"location":"skills/generate-ai-agent-instructions/description/#comparison-to-other-skills","text":"","title":"Comparison to Other Skills"},{"location":"skills/generate-ai-agent-instructions/description/#vs-onboard-me","text":"onboard-me : Human-focused repository guide (300-1500 lines, setup/build/test commands) generate-ai-agent-instructions : AI-focused guidance (150-250 lines, patterns/conventions/\"why\") Use both : onboard-me for humans, this skill for AI agents.","title":"vs onboard-me"},{"location":"skills/generate-ai-agent-instructions/description/#vs-generate-tech-spec-from-code","text":"generate-tech-spec-from-code : Detailed technical specification generate-ai-agent-instructions : Practical guidance for AI assistants","title":"vs generate-tech-spec-from-code"},{"location":"skills/generate-ai-agent-instructions/description/#example-usage","text":"# Auto-detect platform and generate olaf generate ai agent instructions # Explicit platform olaf generate ai agent instructions --platform cursor # For generic AGENTS.md olaf generate ai agent instructions --platform generic","title":"Example Usage"},{"location":"skills/generate-ai-agent-instructions/description/#quality-standards","text":"Generated instructions must: - \u2705 Reference actual files/directories from your codebase - \u2705 Include real commands that work in your project - \u2705 Explain project-specific patterns (not generic best practices) - \u2705 Document the \"why\" behind architectural decisions - \u2705 Stay concise (150-250 lines) while being comprehensive - \u2705 Be actionable (what to DO, not just theory)","title":"Quality Standards"},{"location":"skills/generate-ai-agent-instructions/description/#related-skills","text":"onboard-me - Human-focused repository guide generate-tech-spec-from-code - Technical specification from code bootstrap-functional-spec-from-code - Functional spec generation","title":"Related Skills"},{"location":"skills/generate-ai-agent-instructions/tutorial/","text":"Generate AI Agent Instructions - Tutorial \u00b6 Learn how to create comprehensive instruction files for AI coding assistants across different platforms. Prerequisites \u00b6 OLAF framework installed Access to generate-ai-agent-instructions skill A codebase to analyze Basic Usage \u00b6 Scenario 1: Auto-Detect Platform \u00b6 Your Situation : You have a project and want AI instructions generated automatically. olaf generate ai agent instructions What Happens : 1. Skill scans for existing AI instruction files ( .cursorrules , .github/copilot-instructions.md , etc.) 2. Auto-detects which platform(s) you use 3. Analyzes your codebase structure 4. Proposes output location and content 5. Generates appropriate instruction file Example Output : Platform: Cursor (detected .cursorrules) File: .cursorrules Lines: 187 Sections: 7 Key Coverage: \u2713 Architecture: NestJS microservice with PostgreSQL \u2713 Workflows: npm run build, npm test, docker-compose up \u2713 Patterns: 12 project-specific patterns documented \u2713 Integration Points: 3 external APIs, Redis cache Scenario 2: Specify Target Platform \u00b6 Your Situation : You want to create instructions for a specific platform. olaf generate ai agent instructions When prompted : Select platform or provide --platform cursor Supported Platforms : - copilot - GitHub Copilot ( .github/copilot-instructions.md ) - cursor - Cursor ( .cursorrules ) - windsurf - Windsurf ( .windsurfrules ) - cline - Cline ( .clinerules ) - kiro - Kiro ( .kiro/steering/ ) - generic - Platform-agnostic ( AGENTS.md ) Scenario 3: Merge Existing Instructions \u00b6 Your Situation : You have existing .github/copilot-instructions.md and want to consolidate to AGENTS.md . olaf generate ai agent instructions Prompt Response : I found existing AI instructions in .github/copilot-instructions.md. Would you like me to: 1. Merge content into AGENTS.md (recommended) 2. Update .github/copilot-instructions.md in place 3. Create new file without merging 4. Create both with synced content Choose 1 to merge valuable guidance into platform-agnostic format. Result : - Preserves project-specific patterns from existing file - Updates outdated sections with current codebase analysis - Creates AGENTS.md with consolidated guidance Advanced Usage \u00b6 Scenario 4: Multi-Platform Projects \u00b6 Your Situation : Team uses multiple AI tools (Copilot + Cursor). Approach : 1. Generate generic AGENTS.md first: bash olaf generate ai agent instructions --platform generic Create platform-specific symlinks or copies: ```bash # Cursor cp AGENTS.md .cursorrules # Copilot cp AGENTS.md .github/copilot-instructions.md ``` Maintain single source of truth ( AGENTS.md ) Scenario 5: Existing Project Onboarding \u00b6 Your Situation : Large legacy codebase with complex patterns. Steps : Run the skill : bash olaf generate ai agent instructions Review analysis proposal : ``` Analysis Summary: Detected Platform: None (will use generic) Primary Language: Java Frameworks: Spring Boot 3.2, Hibernate Build Tool: Maven Proposed Output: - Create: AGENTS.md - Estimated size: 220 lines Sections to Include: 1. Critical Rules (security, data handling) 2. Repository Overview (microservices architecture) 3. Architecture & Key Concepts (DDD patterns) 4. File Structure (module organization) 5. Development Workflows (Maven, Docker) 6. Common Scenarios (adding endpoints, DB migrations) 7. AI Guidelines (topic-specific guidance) ``` Confirm or adjust Review generated file and provide feedback: ``` Please review: Clarity: Are all sections clear? Completeness: Missing workflows? Accuracy: Commands correct? Specificity: Enough project-specific examples? ``` Iterate if needed Understanding the Output \u00b6 What's Included \u00b6 Critical Rules - Project-specific do's and don'ts: ## \ud83d\udea8 CRITICAL RULES FOR AI BEHAVIOR - Never modify database migration files directly - All API changes require OpenAPI spec updates - Authentication uses OAuth2 - don't suggest Basic Auth Architecture Explanation - The \"why\" behind decisions: ## Understanding the Architecture Microservices architecture with event-driven communication. Each service owns its database (no shared DB). WHY: Enables independent scaling and deployment. File Structure - Where things go and why: ### `/services/` Purpose: Individual microservice implementations Conventions: Each service in own directory with Dockerfile Key Files: - `auth-service/` - JWT token management - `user-service/` - User CRUD operations Development Workflows - Actual commands: ### Building the Project ```bash mvn clean install -DskipTests docker-compose build **Common Scenarios** - Step-by-step with file references: ```markdown ### Adding New REST Endpoint 1. Create controller in `src/main/java/controllers/` 2. Add service method in `src/main/java/services/` 3. Update OpenAPI spec in `api/openapi.yml` 4. Write integration test in `src/test/java/integration/` AI Guidelines - Topic-specific guidance: ### When Users Ask About: **Database**: PostgreSQL with Flyway migrations in `db/migrations/`. Never modify existing migrations - create new ones. Best Practices \u00b6 1. Keep It Current \u00b6 Re-run when major changes occur: - New framework or library adoption - Architecture refactoring - New deployment process - Changed conventions 2. Be Specific \u00b6 Good \u2705: **Error Handling**: Custom exceptions in `src/errors/`, centralized handler in `middleware/error.handler.ts` Bad \u274c: **Error Handling**: Use try-catch blocks and handle errors properly 3. Reference Real Files \u00b6 Good \u2705: **Logging**: Winston logger configured in `src/utils/logger.ts` Bad \u274c: **Logging**: Use a logging library for better debugging 4. Explain Why \u00b6 Good \u2705: **Monorepo Structure**: Uses Nx for build optimization and dependency graph. WHY: Enables shared libraries and atomic commits across services. Bad \u274c: **Monorepo Structure**: Code organized in monorepo Comparison with onboard-me \u00b6 Aspect generate-ai-agent-instructions onboard-me Audience AI coding assistants Human developers Output AGENTS.md (150-250 lines) repo-guide.md (300-1500 lines) Focus Patterns, conventions, \"why\" Setup, build, test commands Depth Single comprehensive pass Progressive (quick/standard/deep) Content AI-optimized guidance Human-readable documentation Use Both : Generate repo-guide.md for humans, AGENTS.md for AI agents. Troubleshooting \u00b6 Issue: Generic Output \u00b6 Symptom : Instructions contain generic advice, not project-specific guidance. Solution : - Ensure codebase has clear patterns (not just getting started) - Provide feedback requesting more specific examples - Reference specific files you want documented Issue: Wrong Platform Detected \u00b6 Symptom : Skill chooses wrong platform. Solution : - Use --platform parameter to specify explicitly - Remove old platform files if migrating Issue: Missing Critical Info \u00b6 Symptom : Important workflows or patterns not documented. Solution : - Provide feedback listing missing items - Skill will iterate and add sections - Consider if pattern is discoverable in code Related Skills \u00b6 onboard-me - Generate human-focused repository guide evaluate-prompt-for-adoption - Assess external prompts for quality convert-prompt - Modernize prompts to OLAF standards","title":"Generate AI Agent Instructions - Tutorial"},{"location":"skills/generate-ai-agent-instructions/tutorial/#generate-ai-agent-instructions-tutorial","text":"Learn how to create comprehensive instruction files for AI coding assistants across different platforms.","title":"Generate AI Agent Instructions - Tutorial"},{"location":"skills/generate-ai-agent-instructions/tutorial/#prerequisites","text":"OLAF framework installed Access to generate-ai-agent-instructions skill A codebase to analyze","title":"Prerequisites"},{"location":"skills/generate-ai-agent-instructions/tutorial/#basic-usage","text":"","title":"Basic Usage"},{"location":"skills/generate-ai-agent-instructions/tutorial/#scenario-1-auto-detect-platform","text":"Your Situation : You have a project and want AI instructions generated automatically. olaf generate ai agent instructions What Happens : 1. Skill scans for existing AI instruction files ( .cursorrules , .github/copilot-instructions.md , etc.) 2. Auto-detects which platform(s) you use 3. Analyzes your codebase structure 4. Proposes output location and content 5. Generates appropriate instruction file Example Output : Platform: Cursor (detected .cursorrules) File: .cursorrules Lines: 187 Sections: 7 Key Coverage: \u2713 Architecture: NestJS microservice with PostgreSQL \u2713 Workflows: npm run build, npm test, docker-compose up \u2713 Patterns: 12 project-specific patterns documented \u2713 Integration Points: 3 external APIs, Redis cache","title":"Scenario 1: Auto-Detect Platform"},{"location":"skills/generate-ai-agent-instructions/tutorial/#scenario-2-specify-target-platform","text":"Your Situation : You want to create instructions for a specific platform. olaf generate ai agent instructions When prompted : Select platform or provide --platform cursor Supported Platforms : - copilot - GitHub Copilot ( .github/copilot-instructions.md ) - cursor - Cursor ( .cursorrules ) - windsurf - Windsurf ( .windsurfrules ) - cline - Cline ( .clinerules ) - kiro - Kiro ( .kiro/steering/ ) - generic - Platform-agnostic ( AGENTS.md )","title":"Scenario 2: Specify Target Platform"},{"location":"skills/generate-ai-agent-instructions/tutorial/#scenario-3-merge-existing-instructions","text":"Your Situation : You have existing .github/copilot-instructions.md and want to consolidate to AGENTS.md . olaf generate ai agent instructions Prompt Response : I found existing AI instructions in .github/copilot-instructions.md. Would you like me to: 1. Merge content into AGENTS.md (recommended) 2. Update .github/copilot-instructions.md in place 3. Create new file without merging 4. Create both with synced content Choose 1 to merge valuable guidance into platform-agnostic format. Result : - Preserves project-specific patterns from existing file - Updates outdated sections with current codebase analysis - Creates AGENTS.md with consolidated guidance","title":"Scenario 3: Merge Existing Instructions"},{"location":"skills/generate-ai-agent-instructions/tutorial/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/generate-ai-agent-instructions/tutorial/#scenario-4-multi-platform-projects","text":"Your Situation : Team uses multiple AI tools (Copilot + Cursor). Approach : 1. Generate generic AGENTS.md first: bash olaf generate ai agent instructions --platform generic Create platform-specific symlinks or copies: ```bash # Cursor cp AGENTS.md .cursorrules # Copilot cp AGENTS.md .github/copilot-instructions.md ``` Maintain single source of truth ( AGENTS.md )","title":"Scenario 4: Multi-Platform Projects"},{"location":"skills/generate-ai-agent-instructions/tutorial/#scenario-5-existing-project-onboarding","text":"Your Situation : Large legacy codebase with complex patterns. Steps : Run the skill : bash olaf generate ai agent instructions Review analysis proposal : ``` Analysis Summary: Detected Platform: None (will use generic) Primary Language: Java Frameworks: Spring Boot 3.2, Hibernate Build Tool: Maven Proposed Output: - Create: AGENTS.md - Estimated size: 220 lines Sections to Include: 1. Critical Rules (security, data handling) 2. Repository Overview (microservices architecture) 3. Architecture & Key Concepts (DDD patterns) 4. File Structure (module organization) 5. Development Workflows (Maven, Docker) 6. Common Scenarios (adding endpoints, DB migrations) 7. AI Guidelines (topic-specific guidance) ``` Confirm or adjust Review generated file and provide feedback: ``` Please review: Clarity: Are all sections clear? Completeness: Missing workflows? Accuracy: Commands correct? Specificity: Enough project-specific examples? ``` Iterate if needed","title":"Scenario 5: Existing Project Onboarding"},{"location":"skills/generate-ai-agent-instructions/tutorial/#understanding-the-output","text":"","title":"Understanding the Output"},{"location":"skills/generate-ai-agent-instructions/tutorial/#whats-included","text":"Critical Rules - Project-specific do's and don'ts: ## \ud83d\udea8 CRITICAL RULES FOR AI BEHAVIOR - Never modify database migration files directly - All API changes require OpenAPI spec updates - Authentication uses OAuth2 - don't suggest Basic Auth Architecture Explanation - The \"why\" behind decisions: ## Understanding the Architecture Microservices architecture with event-driven communication. Each service owns its database (no shared DB). WHY: Enables independent scaling and deployment. File Structure - Where things go and why: ### `/services/` Purpose: Individual microservice implementations Conventions: Each service in own directory with Dockerfile Key Files: - `auth-service/` - JWT token management - `user-service/` - User CRUD operations Development Workflows - Actual commands: ### Building the Project ```bash mvn clean install -DskipTests docker-compose build **Common Scenarios** - Step-by-step with file references: ```markdown ### Adding New REST Endpoint 1. Create controller in `src/main/java/controllers/` 2. Add service method in `src/main/java/services/` 3. Update OpenAPI spec in `api/openapi.yml` 4. Write integration test in `src/test/java/integration/` AI Guidelines - Topic-specific guidance: ### When Users Ask About: **Database**: PostgreSQL with Flyway migrations in `db/migrations/`. Never modify existing migrations - create new ones.","title":"What's Included"},{"location":"skills/generate-ai-agent-instructions/tutorial/#best-practices","text":"","title":"Best Practices"},{"location":"skills/generate-ai-agent-instructions/tutorial/#1-keep-it-current","text":"Re-run when major changes occur: - New framework or library adoption - Architecture refactoring - New deployment process - Changed conventions","title":"1. Keep It Current"},{"location":"skills/generate-ai-agent-instructions/tutorial/#2-be-specific","text":"Good \u2705: **Error Handling**: Custom exceptions in `src/errors/`, centralized handler in `middleware/error.handler.ts` Bad \u274c: **Error Handling**: Use try-catch blocks and handle errors properly","title":"2. Be Specific"},{"location":"skills/generate-ai-agent-instructions/tutorial/#3-reference-real-files","text":"Good \u2705: **Logging**: Winston logger configured in `src/utils/logger.ts` Bad \u274c: **Logging**: Use a logging library for better debugging","title":"3. Reference Real Files"},{"location":"skills/generate-ai-agent-instructions/tutorial/#4-explain-why","text":"Good \u2705: **Monorepo Structure**: Uses Nx for build optimization and dependency graph. WHY: Enables shared libraries and atomic commits across services. Bad \u274c: **Monorepo Structure**: Code organized in monorepo","title":"4. Explain Why"},{"location":"skills/generate-ai-agent-instructions/tutorial/#comparison-with-onboard-me","text":"Aspect generate-ai-agent-instructions onboard-me Audience AI coding assistants Human developers Output AGENTS.md (150-250 lines) repo-guide.md (300-1500 lines) Focus Patterns, conventions, \"why\" Setup, build, test commands Depth Single comprehensive pass Progressive (quick/standard/deep) Content AI-optimized guidance Human-readable documentation Use Both : Generate repo-guide.md for humans, AGENTS.md for AI agents.","title":"Comparison with onboard-me"},{"location":"skills/generate-ai-agent-instructions/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/generate-ai-agent-instructions/tutorial/#issue-generic-output","text":"Symptom : Instructions contain generic advice, not project-specific guidance. Solution : - Ensure codebase has clear patterns (not just getting started) - Provide feedback requesting more specific examples - Reference specific files you want documented","title":"Issue: Generic Output"},{"location":"skills/generate-ai-agent-instructions/tutorial/#issue-wrong-platform-detected","text":"Symptom : Skill chooses wrong platform. Solution : - Use --platform parameter to specify explicitly - Remove old platform files if migrating","title":"Issue: Wrong Platform Detected"},{"location":"skills/generate-ai-agent-instructions/tutorial/#issue-missing-critical-info","text":"Symptom : Important workflows or patterns not documented. Solution : - Provide feedback listing missing items - Skill will iterate and add sections - Consider if pattern is discoverable in code","title":"Issue: Missing Critical Info"},{"location":"skills/generate-ai-agent-instructions/tutorial/#related-skills","text":"onboard-me - Generate human-focused repository guide evaluate-prompt-for-adoption - Assess external prompts for quality convert-prompt - Modernize prompts to OLAF standards","title":"Related Skills"},{"location":"skills/generate-code-mapper-docs/description/","text":"Generate Code-Mapper Documentation \u00b6 This skill generates structured technical documentation for a codebase using the outputs of the OLAF code-mapper scripts. It guides you to: - Run the run.py --foundation-lite analysis on a target repository. - Inspect the structural, project-structure, and code-index artifacts under .olaf/work/staging/code-mapper/<repo-name>/ . - Perform contextual reads for key entry points in each application or tool. - Produce a consistent documentation artifact using the templates/project-documentation-structure.md template. The code-mapper Python scripts remain in their existing location; this skill only orchestrates how to use them and how to transform their outputs into documentation.","title":"Generate Code-Mapper Documentation"},{"location":"skills/generate-code-mapper-docs/description/#generate-code-mapper-documentation","text":"This skill generates structured technical documentation for a codebase using the outputs of the OLAF code-mapper scripts. It guides you to: - Run the run.py --foundation-lite analysis on a target repository. - Inspect the structural, project-structure, and code-index artifacts under .olaf/work/staging/code-mapper/<repo-name>/ . - Perform contextual reads for key entry points in each application or tool. - Produce a consistent documentation artifact using the templates/project-documentation-structure.md template. The code-mapper Python scripts remain in their existing location; this skill only orchestrates how to use them and how to transform their outputs into documentation.","title":"Generate Code-Mapper Documentation"},{"location":"skills/generate-code-mapper-docs/tutorial/","text":"Tutorial: Generate Code-Mapper Documentation \u00b6 This tutorial shows how to use the Generate Code-Mapper Documentation skill end to end. 1. Prerequisites \u00b6 A local clone of the target repository. OLAF code-mapper scripts available (by default under scripts/code-mapper ). Python environment capable of running run.py . 2. Run Foundation Analysis \u00b6 From your terminal: cd <project-path> python <code-mapper-path>/run.py --foundation-lite . Replace <project-path> with the repository root. Replace <code-mapper-path> with the path to the code-mapper scripts. The analysis will write outputs under: .olaf/work/staging/code-mapper/<repo-name>/ 3. Review Generated Files \u00b6 Open the following files in order: structural-files.md List all build files and map them to tools/applications. project-structure.md Understand the high-level directory and module layout. code-index.md Inspect key classes, functions, and imports per file. 4. Run Contextual Reads (Optional but Recommended) \u00b6 For each tool/application, identify the main entry file and main function if applicable, then run: python <code-mapper-path>/run.py --contextual-read \"path/to/main.py:main_function\" Use the contextual-read outputs to refine your understanding of startup flow and interactions. 5. Invoke the Skill \u00b6 In your OLAF-enabled environment, call the Generate Code-Mapper Documentation skill (for example via olaf create-skill -style wiring or direct skill invocation), then provide: project_path code_mapper_path The skill will guide you through using the existing artifacts and produce a documentation draft. 6. Use the Documentation Template \u00b6 The generated documentation will follow the structure defined in: /templates/project-documentation-structure.md You can copy the final markdown into your repository documentation (for example: docs/project-overview.md ) or internal knowledge base.","title":"Tutorial: Generate Code-Mapper Documentation"},{"location":"skills/generate-code-mapper-docs/tutorial/#tutorial-generate-code-mapper-documentation","text":"This tutorial shows how to use the Generate Code-Mapper Documentation skill end to end.","title":"Tutorial: Generate Code-Mapper Documentation"},{"location":"skills/generate-code-mapper-docs/tutorial/#1-prerequisites","text":"A local clone of the target repository. OLAF code-mapper scripts available (by default under scripts/code-mapper ). Python environment capable of running run.py .","title":"1. Prerequisites"},{"location":"skills/generate-code-mapper-docs/tutorial/#2-run-foundation-analysis","text":"From your terminal: cd <project-path> python <code-mapper-path>/run.py --foundation-lite . Replace <project-path> with the repository root. Replace <code-mapper-path> with the path to the code-mapper scripts. The analysis will write outputs under: .olaf/work/staging/code-mapper/<repo-name>/","title":"2. Run Foundation Analysis"},{"location":"skills/generate-code-mapper-docs/tutorial/#3-review-generated-files","text":"Open the following files in order: structural-files.md List all build files and map them to tools/applications. project-structure.md Understand the high-level directory and module layout. code-index.md Inspect key classes, functions, and imports per file.","title":"3. Review Generated Files"},{"location":"skills/generate-code-mapper-docs/tutorial/#4-run-contextual-reads-optional-but-recommended","text":"For each tool/application, identify the main entry file and main function if applicable, then run: python <code-mapper-path>/run.py --contextual-read \"path/to/main.py:main_function\" Use the contextual-read outputs to refine your understanding of startup flow and interactions.","title":"4. Run Contextual Reads (Optional but Recommended)"},{"location":"skills/generate-code-mapper-docs/tutorial/#5-invoke-the-skill","text":"In your OLAF-enabled environment, call the Generate Code-Mapper Documentation skill (for example via olaf create-skill -style wiring or direct skill invocation), then provide: project_path code_mapper_path The skill will guide you through using the existing artifacts and produce a documentation draft.","title":"5. Invoke the Skill"},{"location":"skills/generate-code-mapper-docs/tutorial/#6-use-the-documentation-template","text":"The generated documentation will follow the structure defined in: /templates/project-documentation-structure.md You can copy the final markdown into your repository documentation (for example: docs/project-overview.md ) or internal knowledge base.","title":"6. Use the Documentation Template"},{"location":"skills/generate-commits-from-changelog/description/","text":"Generate Commits From Changelog \u00b6 Enhanced skill migrated from project-manager competency. Usage \u00b6 This skill provides generate commits from changelog functionality with self-contained dependencies and enhanced error handling.","title":"Generate Commits From Changelog"},{"location":"skills/generate-commits-from-changelog/description/#generate-commits-from-changelog","text":"Enhanced skill migrated from project-manager competency.","title":"Generate Commits From Changelog"},{"location":"skills/generate-commits-from-changelog/description/#usage","text":"This skill provides generate commits from changelog functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/generate-commits-from-changelog/tutorial/","text":"Generate Commits From Changelog Tutorial \u00b6 Step-by-step guide for using the generate-commits-from-changelog skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Generate Commits From Changelog Tutorial"},{"location":"skills/generate-commits-from-changelog/tutorial/#generate-commits-from-changelog-tutorial","text":"Step-by-step guide for using the generate-commits-from-changelog skill.","title":"Generate Commits From Changelog Tutorial"},{"location":"skills/generate-commits-from-changelog/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/generate-commits-from-changelog/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/generate-contract-kit/description/","text":"Skill: Generate Contract Kit \u00b6 This skill produces a consumer-ready, self-contained contract-kit bundle for a demand folder by collecting the latest OpenAPI + specifications and snapshotting them into the kit. It includes copy/paste examples (curl + one additional language) and a scenario walkthrough with multiple endpoint calls.","title":"Skill: Generate Contract Kit"},{"location":"skills/generate-contract-kit/description/#skill-generate-contract-kit","text":"This skill produces a consumer-ready, self-contained contract-kit bundle for a demand folder by collecting the latest OpenAPI + specifications and snapshotting them into the kit. It includes copy/paste examples (curl + one additional language) and a scenario walkthrough with multiple endpoint calls.","title":"Skill: Generate Contract Kit"},{"location":"skills/generate-contract-kit/tutorial/","text":"Tutorial: Generate Contract Kit \u00b6 1) Prerequisites \u00b6 You should have a demand folder under docs/specifications/ containing: - 04-specifications/ (functional spec + OpenAPI) Optional (if present): - sdks/ (generated SDK) - tests/bruno/ (Bruno collections) 2) Run the skill \u00b6 @[/olaf-generate-contract-kit] demand_folder: <demand_folder> example_language: <typescript|python|java|csharp> The skill will: - Select the latest OpenAPI and specs - Snapshot/copy OpenAPI and specs into a bundle folder under docs/specifications/<demand_folder>/08-contract-kit/ - Snapshot/copy SDK and tests into the same bundle when they exist - Generate README.md inside the bundle folder - Ask for confirmation before writing","title":"Tutorial: Generate Contract Kit"},{"location":"skills/generate-contract-kit/tutorial/#tutorial-generate-contract-kit","text":"","title":"Tutorial: Generate Contract Kit"},{"location":"skills/generate-contract-kit/tutorial/#1-prerequisites","text":"You should have a demand folder under docs/specifications/ containing: - 04-specifications/ (functional spec + OpenAPI) Optional (if present): - sdks/ (generated SDK) - tests/bruno/ (Bruno collections)","title":"1) Prerequisites"},{"location":"skills/generate-contract-kit/tutorial/#2-run-the-skill","text":"@[/olaf-generate-contract-kit] demand_folder: <demand_folder> example_language: <typescript|python|java|csharp> The skill will: - Select the latest OpenAPI and specs - Snapshot/copy OpenAPI and specs into a bundle folder under docs/specifications/<demand_folder>/08-contract-kit/ - Snapshot/copy SDK and tests into the same bundle when they exist - Generate README.md inside the bundle folder - Ask for confirmation before writing","title":"2) Run the skill"},{"location":"skills/generate-ddl-and-seed/description/","text":"Generate DDL And Seed \u00b6 Purpose \u00b6 This skill helps API producers in greenfield scenarios where there is no existing database. It generates: - a relational schema (DDL) - deterministic seed/init data Inputs are taken from the latest: - OpenAPI contract in 04-specifications/ - DB\u2194API fit analysis in 05-data-fit-analysis/ Defaults \u00b6 Target DB: PostgreSQL Output folder: docs/specifications/{demand_folder}/07-db-artifacts/ What you get \u00b6 {timestamp}-{demand_folder}-db-schema.sql {timestamp}-{demand_folder}-db-seed.sql Notes \u00b6 This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Generate DDL And Seed"},{"location":"skills/generate-ddl-and-seed/description/#generate-ddl-and-seed","text":"","title":"Generate DDL And Seed"},{"location":"skills/generate-ddl-and-seed/description/#purpose","text":"This skill helps API producers in greenfield scenarios where there is no existing database. It generates: - a relational schema (DDL) - deterministic seed/init data Inputs are taken from the latest: - OpenAPI contract in 04-specifications/ - DB\u2194API fit analysis in 05-data-fit-analysis/","title":"Purpose"},{"location":"skills/generate-ddl-and-seed/description/#defaults","text":"Target DB: PostgreSQL Output folder: docs/specifications/{demand_folder}/07-db-artifacts/","title":"Defaults"},{"location":"skills/generate-ddl-and-seed/description/#what-you-get","text":"{timestamp}-{demand_folder}-db-schema.sql {timestamp}-{demand_folder}-db-seed.sql","title":"What you get"},{"location":"skills/generate-ddl-and-seed/description/#notes","text":"This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Notes"},{"location":"skills/generate-ddl-and-seed/tutorial/","text":"Tutorial: Generate DDL And Seed \u00b6 1) Provide the demand \u00b6 Invoke: - olaf generate-ddl-and-seed When asked, provide: - demand_folder (example: pet-clinic-01 ) 2) Approve schema + seed plan \u00b6 The skill will: - Locate the latest OpenAPI and DB\u2194API fit analysis - Propose a schema plan and the output file paths You MUST approve before files are written. 3) Use the outputs \u00b6 The result is two SQL files under: - docs/specifications/{demand_folder}/07-db-artifacts/ You can apply the DDL then load the seed data in a local database.","title":"Tutorial: Generate DDL And Seed"},{"location":"skills/generate-ddl-and-seed/tutorial/#tutorial-generate-ddl-and-seed","text":"","title":"Tutorial: Generate DDL And Seed"},{"location":"skills/generate-ddl-and-seed/tutorial/#1-provide-the-demand","text":"Invoke: - olaf generate-ddl-and-seed When asked, provide: - demand_folder (example: pet-clinic-01 )","title":"1) Provide the demand"},{"location":"skills/generate-ddl-and-seed/tutorial/#2-approve-schema-seed-plan","text":"The skill will: - Locate the latest OpenAPI and DB\u2194API fit analysis - Propose a schema plan and the output file paths You MUST approve before files are written.","title":"2) Approve schema + seed plan"},{"location":"skills/generate-ddl-and-seed/tutorial/#3-use-the-outputs","text":"The result is two SQL files under: - docs/specifications/{demand_folder}/07-db-artifacts/ You can apply the DDL then load the seed data in a local database.","title":"3) Use the outputs"},{"location":"skills/generate-jsdoc/description/","text":"Generate JSDoc Documentation \u00b6 Overview \u00b6 The generate-jsdoc skill generates comprehensive inline JSDoc comments for JavaScript and TypeScript source files using the AWS Strands multi-agent system. \u26a0\ufe0f CRITICAL : This skill MODIFIES SOURCE CODE by adding JSDoc documentation directly to your files. Key Features \u00b6 Inline Documentation : Adds comprehensive JSDoc comments to .js and .ts files High-Quality Output : Matches commit-d02da43 JSDoc standards with detailed @param, @returns, @throws, @example, and @remarks Spawn Mode : Runs in background, allowing you to continue working Git Safety : Creates git branch automatically (default) to protect against unwanted changes Two Modes : In-place modification or copy-to-folder Process Tracking : Monitor progress via .olaf/work/straf-locks/jsdoc-generation-processes.json Resume Support : Can resume interrupted operations Safety Features \u00b6 Automatic Git Branch Creation \u00b6 Default Behavior : The skill creates a git branch automatically before modifying any files. Branch name format: docs-jsdoc-gen-YYYYMMDD-HHMMSS Must explicitly use --no-branch flag to disable (NOT RECOMMENDED) Provides safety net to review and discard changes if needed Two Operating Modes \u00b6 In-Place Mode (default): Modifies source files directly in repository \u26a0\ufe0f Changes original files \u2705 Git branch creation enabled by default Use when you want to update your actual source code Copy-to-Folder Mode : Creates documented copies in separate directory \u2139\ufe0f Original files remain untouched Use when you want to preview changes first Usage \u00b6 Basic Usage (In-Place, Default) \u00b6 User: \"olaf generate jsdoc\" Processes entire workspace repository Creates git branch automatically Modifies source files with JSDoc comments Specific Folder \u00b6 User: \"olaf generate jsdoc for vscode-extension\" Processes only the vscode-extension subfolder Creates git branch Modifies files in that subfolder only Copy Mode (Safe Preview) \u00b6 User: \"olaf generate jsdoc to c:\\temp\\jsdoc-output\" Processes entire repository Saves documented copies to specified folder Original files untouched Without Git Branch (\u26a0\ufe0f NOT RECOMMENDED) \u00b6 User: \"olaf generate jsdoc --no-branch\" Modifies files without creating branch Changes applied to current branch No easy way to undo JSDoc Standards Applied \u00b6 The skill generates comprehensive JSDoc documentation including: @param : Detailed parameter descriptions with types @returns : Return value documentation with types @throws : Error conditions and exception types @example : Usage examples with code snippets @remarks : Implementation notes and context @see : Related references and links Quality Target : Matches commit-d02da43 JSDoc standards Process Monitoring \u00b6 Check Status \u00b6 python skills/generate-jsdoc/tools/check-jsdoc-processes.py Monitor Progress \u00b6 # Windows Get-Content .jsdoc-generation.log -Tail 20 # Unix/Linux tail -f .jsdoc-generation.log Process Registry \u00b6 Location: .olaf/work/straf-locks/jsdoc-generation-processes.json Contains: - Process ID and name - Repository and output paths - Operating mode (in-place | copy-to-folder) - Status (running | completed | failed | interrupted) - Timestamps - Log file location Performance \u00b6 Codebase Size Est. Time Files/Min Small (<100 files) 5-10 min 10-20 Medium (100-500 files) 10-30 min 10-20 Large (500+ files) 30-60 min 8-15 Note : Actual time depends on: - File size and complexity - Number of functions/classes per file - AWS Bedrock API response time - System resources Review and Commit Changes \u00b6 After Completion (In-Place Mode) \u00b6 Review changes : bash git diff git status Commit if satisfied : bash git add . git commit -m \"docs: add comprehensive JSDoc comments\" Discard if not satisfied : bash git checkout . git checkout main # Return to main branch git branch -D docs/jsdoc-gen-YYYYMMDD-HHMMSS # Delete branch Dependencies \u00b6 Python 3.x AWS credentials configured for Bedrock straf-cli installed at .olaf/core/agentic/straf-cli/ Git (optional but strongly recommended) Tags \u00b6 documentation , jsdoc , inline-docs , spawn , async , strands , code-modification","title":"Generate JSDoc Documentation"},{"location":"skills/generate-jsdoc/description/#generate-jsdoc-documentation","text":"","title":"Generate JSDoc Documentation"},{"location":"skills/generate-jsdoc/description/#overview","text":"The generate-jsdoc skill generates comprehensive inline JSDoc comments for JavaScript and TypeScript source files using the AWS Strands multi-agent system. \u26a0\ufe0f CRITICAL : This skill MODIFIES SOURCE CODE by adding JSDoc documentation directly to your files.","title":"Overview"},{"location":"skills/generate-jsdoc/description/#key-features","text":"Inline Documentation : Adds comprehensive JSDoc comments to .js and .ts files High-Quality Output : Matches commit-d02da43 JSDoc standards with detailed @param, @returns, @throws, @example, and @remarks Spawn Mode : Runs in background, allowing you to continue working Git Safety : Creates git branch automatically (default) to protect against unwanted changes Two Modes : In-place modification or copy-to-folder Process Tracking : Monitor progress via .olaf/work/straf-locks/jsdoc-generation-processes.json Resume Support : Can resume interrupted operations","title":"Key Features"},{"location":"skills/generate-jsdoc/description/#safety-features","text":"","title":"Safety Features"},{"location":"skills/generate-jsdoc/description/#automatic-git-branch-creation","text":"Default Behavior : The skill creates a git branch automatically before modifying any files. Branch name format: docs-jsdoc-gen-YYYYMMDD-HHMMSS Must explicitly use --no-branch flag to disable (NOT RECOMMENDED) Provides safety net to review and discard changes if needed","title":"Automatic Git Branch Creation"},{"location":"skills/generate-jsdoc/description/#two-operating-modes","text":"In-Place Mode (default): Modifies source files directly in repository \u26a0\ufe0f Changes original files \u2705 Git branch creation enabled by default Use when you want to update your actual source code Copy-to-Folder Mode : Creates documented copies in separate directory \u2139\ufe0f Original files remain untouched Use when you want to preview changes first","title":"Two Operating Modes"},{"location":"skills/generate-jsdoc/description/#usage","text":"","title":"Usage"},{"location":"skills/generate-jsdoc/description/#basic-usage-in-place-default","text":"User: \"olaf generate jsdoc\" Processes entire workspace repository Creates git branch automatically Modifies source files with JSDoc comments","title":"Basic Usage (In-Place, Default)"},{"location":"skills/generate-jsdoc/description/#specific-folder","text":"User: \"olaf generate jsdoc for vscode-extension\" Processes only the vscode-extension subfolder Creates git branch Modifies files in that subfolder only","title":"Specific Folder"},{"location":"skills/generate-jsdoc/description/#copy-mode-safe-preview","text":"User: \"olaf generate jsdoc to c:\\temp\\jsdoc-output\" Processes entire repository Saves documented copies to specified folder Original files untouched","title":"Copy Mode (Safe Preview)"},{"location":"skills/generate-jsdoc/description/#without-git-branch-not-recommended","text":"User: \"olaf generate jsdoc --no-branch\" Modifies files without creating branch Changes applied to current branch No easy way to undo","title":"Without Git Branch (\u26a0\ufe0f NOT RECOMMENDED)"},{"location":"skills/generate-jsdoc/description/#jsdoc-standards-applied","text":"The skill generates comprehensive JSDoc documentation including: @param : Detailed parameter descriptions with types @returns : Return value documentation with types @throws : Error conditions and exception types @example : Usage examples with code snippets @remarks : Implementation notes and context @see : Related references and links Quality Target : Matches commit-d02da43 JSDoc standards","title":"JSDoc Standards Applied"},{"location":"skills/generate-jsdoc/description/#process-monitoring","text":"","title":"Process Monitoring"},{"location":"skills/generate-jsdoc/description/#check-status","text":"python skills/generate-jsdoc/tools/check-jsdoc-processes.py","title":"Check Status"},{"location":"skills/generate-jsdoc/description/#monitor-progress","text":"# Windows Get-Content .jsdoc-generation.log -Tail 20 # Unix/Linux tail -f .jsdoc-generation.log","title":"Monitor Progress"},{"location":"skills/generate-jsdoc/description/#process-registry","text":"Location: .olaf/work/straf-locks/jsdoc-generation-processes.json Contains: - Process ID and name - Repository and output paths - Operating mode (in-place | copy-to-folder) - Status (running | completed | failed | interrupted) - Timestamps - Log file location","title":"Process Registry"},{"location":"skills/generate-jsdoc/description/#performance","text":"Codebase Size Est. Time Files/Min Small (<100 files) 5-10 min 10-20 Medium (100-500 files) 10-30 min 10-20 Large (500+ files) 30-60 min 8-15 Note : Actual time depends on: - File size and complexity - Number of functions/classes per file - AWS Bedrock API response time - System resources","title":"Performance"},{"location":"skills/generate-jsdoc/description/#review-and-commit-changes","text":"","title":"Review and Commit Changes"},{"location":"skills/generate-jsdoc/description/#after-completion-in-place-mode","text":"Review changes : bash git diff git status Commit if satisfied : bash git add . git commit -m \"docs: add comprehensive JSDoc comments\" Discard if not satisfied : bash git checkout . git checkout main # Return to main branch git branch -D docs/jsdoc-gen-YYYYMMDD-HHMMSS # Delete branch","title":"After Completion (In-Place Mode)"},{"location":"skills/generate-jsdoc/description/#dependencies","text":"Python 3.x AWS credentials configured for Bedrock straf-cli installed at .olaf/core/agentic/straf-cli/ Git (optional but strongly recommended)","title":"Dependencies"},{"location":"skills/generate-jsdoc/description/#tags","text":"documentation , jsdoc , inline-docs , spawn , async , strands , code-modification","title":"Tags"},{"location":"skills/generate-jsdoc/tutorial/","text":"Tutorial: Generate JSDoc Documentation \u00b6 This tutorial walks you through using the generate-jsdoc skill to add comprehensive inline JSDoc comments to your JavaScript and TypeScript codebase. Prerequisites \u00b6 OLAF framework loaded AWS credentials configured for Bedrock Git repository initialized (recommended) Source code committed (recommended) Tutorial Steps \u00b6 Step 1: Prepare Your Repository \u00b6 IMPORTANT : Before running JSDoc generation, ensure your current work is committed. # Check current status git status # If you have uncommitted changes, commit them git add . git commit -m \"feat: current work before JSDoc generation\" Why? The skill will create a new branch automatically, but it's safer to have a clean working directory first. Step 2: Invoke the Skill (Basic) \u00b6 Simply invoke OLAF with the generate jsdoc command: User: \"olaf generate jsdoc\" What happens: 1. OLAF validates the repository exists 2. Determines output mode: in-place (default) 3. Creates git branch: docs-jsdoc-gen-20251125-143022 4. Displays execution plan with warnings 5. Spawns background process 6. Returns control to you immediately Expected Output: \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 JSDOC INLINE DOCUMENTATION GENERATION (Spawn Mode) \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 Repository: c:\\Users\\you\\project Output Mode: in-place Git Branch: docs-jsdoc-gen-20251125-143022 (auto-created) Mode: Asynchronous (you can continue working) \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 \u26a0\ufe0f CRITICAL WARNINGS: \u26a0\ufe0f IN-PLACE MODE: Source files will be MODIFIED directly! \u26a0\ufe0f Git branch creation is ENABLED by default for safety \ud83d\ude80 JSDoc generation started in background! Process ID: abc-123-xyz Status: running Log: .jsdoc-generation.log Estimated time: 10-30 minutes Step 3: Continue Working \u00b6 You can continue working while JSDoc generation runs in the background: Edit other files Run tests Code review Any other VS Code activities The process runs independently at LOW priority to minimize impact. Step 4: Monitor Progress (Optional) \u00b6 Check current status: python skills/generate-jsdoc/tools/check-jsdoc-processes.py Monitor real-time progress: # Windows Get-Content .jsdoc-generation.log -Tail 20 -Wait # Unix/Linux tail -f .jsdoc-generation.log Step 5: Review Changes \u00b6 When the process completes, review the changes: # See what files were modified git status # Review actual changes git diff # Or review specific files git diff src/services/myService.ts What to look for: - JSDoc comments added above functions/classes - Comprehensive @param descriptions - Detailed @returns documentation - @throws for error cases - @example with code samples Step 6: Commit or Discard \u00b6 Option A: Commit the changes If you're satisfied with the JSDoc comments: git add . git commit -m \"docs: add comprehensive JSDoc comments to all source files\" # Optionally merge back to main git checkout main git merge docs-jsdoc-gen-20251125-143022 Option B: Discard the changes If you're not satisfied: # Discard all changes git checkout . # Return to main branch git checkout main # Delete the JSDoc branch git branch -D docs-jsdoc-gen-20251125-143022 Advanced Scenarios \u00b6 Scenario 1: Generate JSDoc for Specific Subfolder \u00b6 User: \"olaf generate jsdoc for src/services\" This processes only the src/services subfolder instead of the entire repository. Scenario 2: Preview Mode (Copy to Folder) \u00b6 User: \"olaf generate jsdoc to c:\\temp\\jsdoc-preview\" Benefits: - Original files untouched - Review output before applying to source - Compare side-by-side Workflow: 1. Generated files saved to c:\\temp\\jsdoc-preview 2. Review the documented files 3. If satisfied, copy desired files back to repository 4. Commit manually Scenario 3: Skip Git Branch (\u26a0\ufe0f Advanced Users Only) \u00b6 User: \"olaf generate jsdoc --no-branch\" \u26a0\ufe0f WARNING : This modifies files on your current branch without creating a safety branch. Only use this if: - You have uncommitted changes you want to preserve on current branch - You're working on a feature branch already - You understand the risk and want direct modification Common Issues and Solutions \u00b6 Issue 1: \"Not a git repository\" \u00b6 Solution : Initialize git first git init git add . git commit -m \"Initial commit before JSDoc\" Issue 2: Process seems stuck \u00b6 Check status: python skills/generate-jsdoc/tools/check-jsdoc-processes.py Check log file: Get-Content .jsdoc-generation.log -Tail 50 Issue 3: Want to interrupt process \u00b6 Press Ctrl+C in the terminal where process is running The process supports resume, so you can restart later: User: \"olaf generate jsdoc\" # It will resume from last processed file Tips and Best Practices \u00b6 Always commit first : Have a clean working directory before starting Use git branches : Let the skill create the branch automatically (default) Review changes : Don't blindly commit - review the JSDoc additions Start small : Test on a small subfolder first Monitor progress : Check logs periodically for large codebases Plan for time : Large codebases can take 30-60 minutes Next Steps \u00b6 After completing this tutorial, you can: Generate JSDoc for different parts of your codebase Customize JSDoc styles by editing source files after generation Generate external documentation with the generate-external-docs skill Integrate JSDoc into your CI/CD pipeline Related Skills \u00b6 generate-external-docs : Generate MkDocs external documentation propose-commit-thread : Create structured commit messages for JSDoc changes","title":"Tutorial: Generate JSDoc Documentation"},{"location":"skills/generate-jsdoc/tutorial/#tutorial-generate-jsdoc-documentation","text":"This tutorial walks you through using the generate-jsdoc skill to add comprehensive inline JSDoc comments to your JavaScript and TypeScript codebase.","title":"Tutorial: Generate JSDoc Documentation"},{"location":"skills/generate-jsdoc/tutorial/#prerequisites","text":"OLAF framework loaded AWS credentials configured for Bedrock Git repository initialized (recommended) Source code committed (recommended)","title":"Prerequisites"},{"location":"skills/generate-jsdoc/tutorial/#tutorial-steps","text":"","title":"Tutorial Steps"},{"location":"skills/generate-jsdoc/tutorial/#step-1-prepare-your-repository","text":"IMPORTANT : Before running JSDoc generation, ensure your current work is committed. # Check current status git status # If you have uncommitted changes, commit them git add . git commit -m \"feat: current work before JSDoc generation\" Why? The skill will create a new branch automatically, but it's safer to have a clean working directory first.","title":"Step 1: Prepare Your Repository"},{"location":"skills/generate-jsdoc/tutorial/#step-2-invoke-the-skill-basic","text":"Simply invoke OLAF with the generate jsdoc command: User: \"olaf generate jsdoc\" What happens: 1. OLAF validates the repository exists 2. Determines output mode: in-place (default) 3. Creates git branch: docs-jsdoc-gen-20251125-143022 4. Displays execution plan with warnings 5. Spawns background process 6. Returns control to you immediately Expected Output: \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 JSDOC INLINE DOCUMENTATION GENERATION (Spawn Mode) \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 Repository: c:\\Users\\you\\project Output Mode: in-place Git Branch: docs-jsdoc-gen-20251125-143022 (auto-created) Mode: Asynchronous (you can continue working) \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 \u26a0\ufe0f CRITICAL WARNINGS: \u26a0\ufe0f IN-PLACE MODE: Source files will be MODIFIED directly! \u26a0\ufe0f Git branch creation is ENABLED by default for safety \ud83d\ude80 JSDoc generation started in background! Process ID: abc-123-xyz Status: running Log: .jsdoc-generation.log Estimated time: 10-30 minutes","title":"Step 2: Invoke the Skill (Basic)"},{"location":"skills/generate-jsdoc/tutorial/#step-3-continue-working","text":"You can continue working while JSDoc generation runs in the background: Edit other files Run tests Code review Any other VS Code activities The process runs independently at LOW priority to minimize impact.","title":"Step 3: Continue Working"},{"location":"skills/generate-jsdoc/tutorial/#step-4-monitor-progress-optional","text":"Check current status: python skills/generate-jsdoc/tools/check-jsdoc-processes.py Monitor real-time progress: # Windows Get-Content .jsdoc-generation.log -Tail 20 -Wait # Unix/Linux tail -f .jsdoc-generation.log","title":"Step 4: Monitor Progress (Optional)"},{"location":"skills/generate-jsdoc/tutorial/#step-5-review-changes","text":"When the process completes, review the changes: # See what files were modified git status # Review actual changes git diff # Or review specific files git diff src/services/myService.ts What to look for: - JSDoc comments added above functions/classes - Comprehensive @param descriptions - Detailed @returns documentation - @throws for error cases - @example with code samples","title":"Step 5: Review Changes"},{"location":"skills/generate-jsdoc/tutorial/#step-6-commit-or-discard","text":"Option A: Commit the changes If you're satisfied with the JSDoc comments: git add . git commit -m \"docs: add comprehensive JSDoc comments to all source files\" # Optionally merge back to main git checkout main git merge docs-jsdoc-gen-20251125-143022 Option B: Discard the changes If you're not satisfied: # Discard all changes git checkout . # Return to main branch git checkout main # Delete the JSDoc branch git branch -D docs-jsdoc-gen-20251125-143022","title":"Step 6: Commit or Discard"},{"location":"skills/generate-jsdoc/tutorial/#advanced-scenarios","text":"","title":"Advanced Scenarios"},{"location":"skills/generate-jsdoc/tutorial/#scenario-1-generate-jsdoc-for-specific-subfolder","text":"User: \"olaf generate jsdoc for src/services\" This processes only the src/services subfolder instead of the entire repository.","title":"Scenario 1: Generate JSDoc for Specific Subfolder"},{"location":"skills/generate-jsdoc/tutorial/#scenario-2-preview-mode-copy-to-folder","text":"User: \"olaf generate jsdoc to c:\\temp\\jsdoc-preview\" Benefits: - Original files untouched - Review output before applying to source - Compare side-by-side Workflow: 1. Generated files saved to c:\\temp\\jsdoc-preview 2. Review the documented files 3. If satisfied, copy desired files back to repository 4. Commit manually","title":"Scenario 2: Preview Mode (Copy to Folder)"},{"location":"skills/generate-jsdoc/tutorial/#scenario-3-skip-git-branch-advanced-users-only","text":"User: \"olaf generate jsdoc --no-branch\" \u26a0\ufe0f WARNING : This modifies files on your current branch without creating a safety branch. Only use this if: - You have uncommitted changes you want to preserve on current branch - You're working on a feature branch already - You understand the risk and want direct modification","title":"Scenario 3: Skip Git Branch (\u26a0\ufe0f Advanced Users Only)"},{"location":"skills/generate-jsdoc/tutorial/#common-issues-and-solutions","text":"","title":"Common Issues and Solutions"},{"location":"skills/generate-jsdoc/tutorial/#issue-1-not-a-git-repository","text":"Solution : Initialize git first git init git add . git commit -m \"Initial commit before JSDoc\"","title":"Issue 1: \"Not a git repository\""},{"location":"skills/generate-jsdoc/tutorial/#issue-2-process-seems-stuck","text":"Check status: python skills/generate-jsdoc/tools/check-jsdoc-processes.py Check log file: Get-Content .jsdoc-generation.log -Tail 50","title":"Issue 2: Process seems stuck"},{"location":"skills/generate-jsdoc/tutorial/#issue-3-want-to-interrupt-process","text":"Press Ctrl+C in the terminal where process is running The process supports resume, so you can restart later: User: \"olaf generate jsdoc\" # It will resume from last processed file","title":"Issue 3: Want to interrupt process"},{"location":"skills/generate-jsdoc/tutorial/#tips-and-best-practices","text":"Always commit first : Have a clean working directory before starting Use git branches : Let the skill create the branch automatically (default) Review changes : Don't blindly commit - review the JSDoc additions Start small : Test on a small subfolder first Monitor progress : Check logs periodically for large codebases Plan for time : Large codebases can take 30-60 minutes","title":"Tips and Best Practices"},{"location":"skills/generate-jsdoc/tutorial/#next-steps","text":"After completing this tutorial, you can: Generate JSDoc for different parts of your codebase Customize JSDoc styles by editing source files after generation Generate external documentation with the generate-external-docs skill Integrate JSDoc into your CI/CD pipeline","title":"Next Steps"},{"location":"skills/generate-jsdoc/tutorial/#related-skills","text":"generate-external-docs : Generate MkDocs external documentation propose-commit-thread : Create structured commit messages for JSDoc changes","title":"Related Skills"},{"location":"skills/generate-orchestrator/description/","text":"Generate Orchestrator \u00b6 Generate-orchestrator creates a NEW orchestrator skill (a skill that uses other skills) under skills/ . Usage \u00b6 This skill generates orchestrator skills that orchestrate other skills. Outputs \u00b6 Generated orchestrator skill package: - skills/[orchestrator_name]/skill.md - skills/[orchestrator_name]/docs/description.md - skills/[orchestrator_name]/docs/tutorial.md Notes \u00b6 This repo no longer uses competency structures for new work. This repo no longer relies on skill manifests for generation. Prompting principles apply. This skill does NOT copy template/principles files into generated orchestrators.","title":"Generate Orchestrator"},{"location":"skills/generate-orchestrator/description/#generate-orchestrator","text":"Generate-orchestrator creates a NEW orchestrator skill (a skill that uses other skills) under skills/ .","title":"Generate Orchestrator"},{"location":"skills/generate-orchestrator/description/#usage","text":"This skill generates orchestrator skills that orchestrate other skills.","title":"Usage"},{"location":"skills/generate-orchestrator/description/#outputs","text":"Generated orchestrator skill package: - skills/[orchestrator_name]/skill.md - skills/[orchestrator_name]/docs/description.md - skills/[orchestrator_name]/docs/tutorial.md","title":"Outputs"},{"location":"skills/generate-orchestrator/description/#notes","text":"This repo no longer uses competency structures for new work. This repo no longer relies on skill manifests for generation. Prompting principles apply. This skill does NOT copy template/principles files into generated orchestrators.","title":"Notes"},{"location":"skills/generate-orchestrator/tutorial/","text":"Generate Orchestrator Tutorial \u00b6 Step-by-step guide for using the generate-orchestrator skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Run the skill. Provide required inputs: orchestrator_name (kebab-case) description skills_to_orchestrate[] (ordered) Optionally provide: review_gates[] stop_on_failure Review the proposed generated skill structure (Propose-Confirm-Act). Confirm creation. Review results under skills/[orchestrator_name]/ . Result \u00b6 You should see a new orchestrator skill package: - skills/[orchestrator_name]/skill.md - skills/[orchestrator_name]/docs/description.md - skills/[orchestrator_name]/docs/tutorial.md","title":"Generate Orchestrator Tutorial"},{"location":"skills/generate-orchestrator/tutorial/#generate-orchestrator-tutorial","text":"Step-by-step guide for using the generate-orchestrator skill.","title":"Generate Orchestrator Tutorial"},{"location":"skills/generate-orchestrator/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/generate-orchestrator/tutorial/#steps","text":"Run the skill. Provide required inputs: orchestrator_name (kebab-case) description skills_to_orchestrate[] (ordered) Optionally provide: review_gates[] stop_on_failure Review the proposed generated skill structure (Propose-Confirm-Act). Confirm creation. Review results under skills/[orchestrator_name]/ .","title":"Steps"},{"location":"skills/generate-orchestrator/tutorial/#result","text":"You should see a new orchestrator skill package: - skills/[orchestrator_name]/skill.md - skills/[orchestrator_name]/docs/description.md - skills/[orchestrator_name]/docs/tutorial.md","title":"Result"},{"location":"skills/generate-post-from-plan/description/","text":"Generate Post From Plan - Skill Description \u00b6 Overview \u00b6 The generate-post-from-plan skill transforms presentation content or technical documentation into engaging blog posts tailored for development teams and IT professionals. It offers two distinct writing styles - brochure (structured) and conversational (narrative) - to match different communication needs. Purpose \u00b6 This skill addresses the common challenge of converting technical presentations and documentation into accessible, engaging blog content that resonates with development teams, IT managers, and technical professionals. Key Capabilities \u00b6 Multi-Style Content Generation : Choose between brochure (structured) or conversational (narrative) styles, or generate both Source Material Flexibility : Process presentation plans, technical documentation, or project information Professional Quality Standards : Ensures factual accuracy, appropriate tone, and optimal reading length Template-Driven Consistency : Uses proven templates for reliable, professional output Multi-Language Support : Generates content in English, French, Spanish, or German Use Cases \u00b6 Ideal Scenarios \u00b6 Converting presentation plans into blog posts for team communication Transforming technical documentation into accessible content Creating multiple content versions (structured vs. narrative) from single source Generating team-focused content for IT announcements or updates Sample Input/Output \u00b6 Input: Presentation plan about new development framework Output: Professional blog post(s) with compelling title, structured content, and clear call-to-action, targeting under 2-minute reading time Technical Specifications \u00b6 Input Parameters : Source content, style preference, target audience, language, reading time target Output Format : Markdown files with professional blog post structure Word Count Target : 300-600 words for under 2-minute reading Templates : Dedicated templates for brochure and conversational styles Integration \u00b6 This skill works well in content creation workflows, particularly when combined with: - Presentation planning skills - Technical documentation generation - Multi-format content creation workflows - Team communication strategies Quality Standards \u00b6 Maintains factual accuracy from source material Ensures professional tone appropriate for IT audience Uses clear, concise language (max 20 words per sentence) Includes actionable next steps Avoids fictional testimonials or invented statistics Success Metrics \u00b6 Generated content stays within 300-600 word target Reading time under 2 minutes Professional tone maintained throughout Clear value proposition communicated Actionable call-to-action included","title":"Generate Post From Plan - Skill Description"},{"location":"skills/generate-post-from-plan/description/#generate-post-from-plan-skill-description","text":"","title":"Generate Post From Plan - Skill Description"},{"location":"skills/generate-post-from-plan/description/#overview","text":"The generate-post-from-plan skill transforms presentation content or technical documentation into engaging blog posts tailored for development teams and IT professionals. It offers two distinct writing styles - brochure (structured) and conversational (narrative) - to match different communication needs.","title":"Overview"},{"location":"skills/generate-post-from-plan/description/#purpose","text":"This skill addresses the common challenge of converting technical presentations and documentation into accessible, engaging blog content that resonates with development teams, IT managers, and technical professionals.","title":"Purpose"},{"location":"skills/generate-post-from-plan/description/#key-capabilities","text":"Multi-Style Content Generation : Choose between brochure (structured) or conversational (narrative) styles, or generate both Source Material Flexibility : Process presentation plans, technical documentation, or project information Professional Quality Standards : Ensures factual accuracy, appropriate tone, and optimal reading length Template-Driven Consistency : Uses proven templates for reliable, professional output Multi-Language Support : Generates content in English, French, Spanish, or German","title":"Key Capabilities"},{"location":"skills/generate-post-from-plan/description/#use-cases","text":"","title":"Use Cases"},{"location":"skills/generate-post-from-plan/description/#ideal-scenarios","text":"Converting presentation plans into blog posts for team communication Transforming technical documentation into accessible content Creating multiple content versions (structured vs. narrative) from single source Generating team-focused content for IT announcements or updates","title":"Ideal Scenarios"},{"location":"skills/generate-post-from-plan/description/#sample-inputoutput","text":"Input: Presentation plan about new development framework Output: Professional blog post(s) with compelling title, structured content, and clear call-to-action, targeting under 2-minute reading time","title":"Sample Input/Output"},{"location":"skills/generate-post-from-plan/description/#technical-specifications","text":"Input Parameters : Source content, style preference, target audience, language, reading time target Output Format : Markdown files with professional blog post structure Word Count Target : 300-600 words for under 2-minute reading Templates : Dedicated templates for brochure and conversational styles","title":"Technical Specifications"},{"location":"skills/generate-post-from-plan/description/#integration","text":"This skill works well in content creation workflows, particularly when combined with: - Presentation planning skills - Technical documentation generation - Multi-format content creation workflows - Team communication strategies","title":"Integration"},{"location":"skills/generate-post-from-plan/description/#quality-standards","text":"Maintains factual accuracy from source material Ensures professional tone appropriate for IT audience Uses clear, concise language (max 20 words per sentence) Includes actionable next steps Avoids fictional testimonials or invented statistics","title":"Quality Standards"},{"location":"skills/generate-post-from-plan/description/#success-metrics","text":"Generated content stays within 300-600 word target Reading time under 2 minutes Professional tone maintained throughout Clear value proposition communicated Actionable call-to-action included","title":"Success Metrics"},{"location":"skills/generate-post-from-plan/tutorial/","text":"Generate Post From Plan - Step-by-Step Tutorial \u00b6 How to Execute the \"Generate Blog Post from Presentation Plan\" Workflow This tutorial shows exactly how to transform presentation content or technical documentation into engaging blog posts using the generate-post-from-plan skill. Prerequisites \u00b6 Source material (presentation plan, technical documentation, or project information) Access to OLAF framework Clear understanding of target audience Basic knowledge of content style preferences Step-by-Step Instructions \u00b6 Step 1: Invoke the Skill \u00b6 Brief description: Start the blog post generation process User Action: 1. Use the command: olaf generate-post-from-plan 2. Prepare your source content (file path or direct text) 3. Decide on writing style preference OLAF Response: OLAF will request required parameters and begin content analysis Step 2: Provide Required Parameters \u00b6 User Action: Respond to OLAF's parameter requests Provide Requirements/Parameters: - source_content : [Example - \"presentation-plan-YYYYMMDD-HHmm.md\" or direct text paste] - style_preference : [Example - \"brochure\" for structured approach or \"conversational\" for narrative style or \"all\" for both versions] - target_audience : [Example - \"Development teams, IT managers, technical professionals\"] - language : [Example - \"english\" (default)] - reading_time : [Example - \"Under 2 minutes (300-600 words)\" (default)] Step 3: Content Analysis and Generation \u00b6 What OLAF Does: - Analyzes source material for key messages and value propositions - Selects appropriate template(s) based on style preference - Generates blog post content following template structure - Applies domain-specific writing standards - Creates compelling title, subtitle, and call-to-action You Should See: - Progress updates during content analysis - Style confirmation message - File generation completion with output locations Step 4: Review Generated Content \u00b6 User Action: 1. Navigate to staging directory to review generated blog post(s) 2. Check content quality and accuracy 3. Verify reading time meets target (under 2 minutes) File Locations: - Single style: [staging_dir]/blog-post-[style]-YYYYMMDD-HHmm.md - Both styles: [staging_dir]/blog-post-brochure-YYYYMMDD-HHmm.md and [staging_dir]/blog-post-conversational-YYYYMMDD-HHmm.md Verification Checklist \u00b6 \u2705 Source content successfully processed and key messages extracted \u2705 Appropriate writing style template applied consistently \u2705 Generated content meets word count target (300-600 words) \u2705 Reading time under 2 minutes achieved \u2705 Factual accuracy maintained throughout content \u2705 Clear call-to-action included with actionable next steps \u2705 Professional tone appropriate for IT/development audience Troubleshooting \u00b6 If source content analysis fails: Verify source file path is correct or ensure direct text input is complete If template not found: - Check template files exist in skill templates directory - Verify file permissions for template access - Use manual template specification as alternative If generated content is too long: - Review source material for key points only - Request focus on specific aspects of the topic - Consider breaking into multiple shorter posts Key Learning Points \u00b6 Style Selection Impact: Brochure style creates structured, feature-focused content while conversational style produces narrative, story-driven posts Source Quality Matters: Better source material with clear value propositions results in higher quality blog posts Audience Awareness: Tailoring content to specific audience (development teams, IT managers) improves relevance and engagement Next Steps to Try \u00b6 Experiment with different source materials (presentations, technical specs, project documentation) Test both writing styles to understand their distinct approaches Use generated posts as starting points for further customization Combine with other OLAF skills for comprehensive content creation workflows Expected Timeline \u00b6 Total generation time: 2-4 minutes User input required: Parameter specification and source content provision OLAF execution time: Content analysis and generation typically completes within 1-3 minutes Style Comparison Guide \u00b6 Brochure Style \u00b6 Structure: Clear sections with descriptive headings Best for: Feature announcements, product descriptions, technical specifications Format: Organized bullet points and structured information Tone: Professional, informative, direct Conversational Style \u00b6 Structure: Flowing narrative with natural transitions Best for: Problem-solution stories, team adoption scenarios, change management Format: Paragraphs with minimal bullet points Tone: Engaging, relatable, story-driven","title":"Generate Post From Plan - Step-by-Step Tutorial"},{"location":"skills/generate-post-from-plan/tutorial/#generate-post-from-plan-step-by-step-tutorial","text":"How to Execute the \"Generate Blog Post from Presentation Plan\" Workflow This tutorial shows exactly how to transform presentation content or technical documentation into engaging blog posts using the generate-post-from-plan skill.","title":"Generate Post From Plan - Step-by-Step Tutorial"},{"location":"skills/generate-post-from-plan/tutorial/#prerequisites","text":"Source material (presentation plan, technical documentation, or project information) Access to OLAF framework Clear understanding of target audience Basic knowledge of content style preferences","title":"Prerequisites"},{"location":"skills/generate-post-from-plan/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/generate-post-from-plan/tutorial/#step-1-invoke-the-skill","text":"Brief description: Start the blog post generation process User Action: 1. Use the command: olaf generate-post-from-plan 2. Prepare your source content (file path or direct text) 3. Decide on writing style preference OLAF Response: OLAF will request required parameters and begin content analysis","title":"Step 1: Invoke the Skill"},{"location":"skills/generate-post-from-plan/tutorial/#step-2-provide-required-parameters","text":"User Action: Respond to OLAF's parameter requests Provide Requirements/Parameters: - source_content : [Example - \"presentation-plan-YYYYMMDD-HHmm.md\" or direct text paste] - style_preference : [Example - \"brochure\" for structured approach or \"conversational\" for narrative style or \"all\" for both versions] - target_audience : [Example - \"Development teams, IT managers, technical professionals\"] - language : [Example - \"english\" (default)] - reading_time : [Example - \"Under 2 minutes (300-600 words)\" (default)]","title":"Step 2: Provide Required Parameters"},{"location":"skills/generate-post-from-plan/tutorial/#step-3-content-analysis-and-generation","text":"What OLAF Does: - Analyzes source material for key messages and value propositions - Selects appropriate template(s) based on style preference - Generates blog post content following template structure - Applies domain-specific writing standards - Creates compelling title, subtitle, and call-to-action You Should See: - Progress updates during content analysis - Style confirmation message - File generation completion with output locations","title":"Step 3: Content Analysis and Generation"},{"location":"skills/generate-post-from-plan/tutorial/#step-4-review-generated-content","text":"User Action: 1. Navigate to staging directory to review generated blog post(s) 2. Check content quality and accuracy 3. Verify reading time meets target (under 2 minutes) File Locations: - Single style: [staging_dir]/blog-post-[style]-YYYYMMDD-HHmm.md - Both styles: [staging_dir]/blog-post-brochure-YYYYMMDD-HHmm.md and [staging_dir]/blog-post-conversational-YYYYMMDD-HHmm.md","title":"Step 4: Review Generated Content"},{"location":"skills/generate-post-from-plan/tutorial/#verification-checklist","text":"\u2705 Source content successfully processed and key messages extracted \u2705 Appropriate writing style template applied consistently \u2705 Generated content meets word count target (300-600 words) \u2705 Reading time under 2 minutes achieved \u2705 Factual accuracy maintained throughout content \u2705 Clear call-to-action included with actionable next steps \u2705 Professional tone appropriate for IT/development audience","title":"Verification Checklist"},{"location":"skills/generate-post-from-plan/tutorial/#troubleshooting","text":"If source content analysis fails: Verify source file path is correct or ensure direct text input is complete If template not found: - Check template files exist in skill templates directory - Verify file permissions for template access - Use manual template specification as alternative If generated content is too long: - Review source material for key points only - Request focus on specific aspects of the topic - Consider breaking into multiple shorter posts","title":"Troubleshooting"},{"location":"skills/generate-post-from-plan/tutorial/#key-learning-points","text":"Style Selection Impact: Brochure style creates structured, feature-focused content while conversational style produces narrative, story-driven posts Source Quality Matters: Better source material with clear value propositions results in higher quality blog posts Audience Awareness: Tailoring content to specific audience (development teams, IT managers) improves relevance and engagement","title":"Key Learning Points"},{"location":"skills/generate-post-from-plan/tutorial/#next-steps-to-try","text":"Experiment with different source materials (presentations, technical specs, project documentation) Test both writing styles to understand their distinct approaches Use generated posts as starting points for further customization Combine with other OLAF skills for comprehensive content creation workflows","title":"Next Steps to Try"},{"location":"skills/generate-post-from-plan/tutorial/#expected-timeline","text":"Total generation time: 2-4 minutes User input required: Parameter specification and source content provision OLAF execution time: Content analysis and generation typically completes within 1-3 minutes","title":"Expected Timeline"},{"location":"skills/generate-post-from-plan/tutorial/#style-comparison-guide","text":"","title":"Style Comparison Guide"},{"location":"skills/generate-post-from-plan/tutorial/#brochure-style","text":"Structure: Clear sections with descriptive headings Best for: Feature announcements, product descriptions, technical specifications Format: Organized bullet points and structured information Tone: Professional, informative, direct","title":"Brochure Style"},{"location":"skills/generate-post-from-plan/tutorial/#conversational-style","text":"Structure: Flowing narrative with natural transitions Best for: Problem-solution stories, team adoption scenarios, change management Format: Paragraphs with minimal bullet points Tone: Engaging, relatable, story-driven","title":"Conversational Style"},{"location":"skills/generate-pptx-from-plan/tutorial/","text":"Generate PowerPoint from Plan: Step-by-Step Tutorial \u00b6 How to Execute the \"Generate PowerPoint from Plan\" Workflow This tutorial shows exactly how to reproduce the PowerPoint generation process from a presentation plan using OLAF automation tools. Prerequisites \u00b6 Python environment (3.10+ recommended) Existing presentation plan file (.md format) Access to OLAF skills directory Write permissions to staging directory Step-by-Step Instructions \u00b6 Step 1: Verify Your Presentation Plan File \u00b6 Ensure your presentation plan follows the correct format for PowerPoint generation. User Action: 1. Locate your presentation plan (.md file) 2. Verify it contains properly structured slides with titles 3. Check that content is formatted without bullet prefixes Expected Format: # Presentation Title ### Slide 1: Introduction **Layout**: Title Slide **Content**: Welcome to our presentation ### Slide 2: Main Content **Layout**: Content **Content**: Key points and information Step 2: Execute the Generate PowerPoint Skill \u00b6 User Action: Issue the OLAF command olaf generate-pptx-from-plan Provide Required Parameters: - Plan File Path : [Example - we used \"c:\\path\\to\\presentation-plan.md\"] - Output Directory : [Optional - defaults to staging/pptx-folder/] - Confirmation : Yes to proceed with generation Step 3: Dependency Check and Installation \u00b6 What OLAF Does: - Checks for python-pptx library installation - Installs python-pptx if not found using pip install python-pptx - Verifies Python environment compatibility - Confirms access to generation tool You Should See: \u2705 Python environment verified \u2705 python-pptx library available \u2705 PowerPoint generation tool accessible Step 4: Plan Validation \u00b6 What OLAF Does: - Reads and parses the presentation plan file - Validates markdown structure and slide format - Checks for proper content organization - Ensures compatibility with PowerPoint generation You Should See: \u2705 Presentation plan loaded successfully \u2705 [X] slides detected and validated \u2705 Content structure verified Step 5: PowerPoint Generation \u00b6 What OLAF Does: - Executes Python automation tool - Converts markdown slides to PowerPoint format - Applies proper formatting and layout - Saves timestamped .pptx file in staging directory You Should See: \ud83d\udd04 Generating PowerPoint presentation... \u2705 PowerPoint file created: [plan-name]-20251119-1456.pptx \u2705 [X] slides successfully generated \u2705 File saved in staging/pptx-folder/ Verification Checklist \u00b6 \u2705 Presentation plan file is properly formatted \u2705 Python environment and dependencies are ready \u2705 PowerPoint file is generated successfully \u2705 All slides from plan are included in presentation \u2705 Content formatting is preserved in PowerPoint \u2705 File is saved with correct timestamp naming Troubleshooting \u00b6 If python-pptx library is missing: pip install python-pptx If plan file format is incorrect: - Check that slides use \"### Slide X:\" format - Ensure Layout and Content sections are present - Remove bullet point prefixes from content If generation fails: - Verify file paths are correct and accessible - Check Python installation and version - Ensure write permissions to staging directory Key Learning Points \u00b6 Plan Structure Matters: PowerPoint generation requires specific markdown formatting with slide sections Automated Dependencies: OLAF handles python-pptx installation automatically if missing Staging Directory: All generated files are saved to staging for consistent organization Timestamped Output: Generated files include timestamps for version tracking Next Steps to Try \u00b6 Use generated PowerPoint as base for further customization Integrate with presentation planning workflows Automate multi-format content creation pipelines Combine with other technical writing skills Expected Timeline \u00b6 Total generation time: 1-3 minutes User input required: Plan file path and confirmation OLAF execution time: Automated dependency check, validation, and PowerPoint creation","title":"Generate PowerPoint from Plan: Step-by-Step Tutorial"},{"location":"skills/generate-pptx-from-plan/tutorial/#generate-powerpoint-from-plan-step-by-step-tutorial","text":"How to Execute the \"Generate PowerPoint from Plan\" Workflow This tutorial shows exactly how to reproduce the PowerPoint generation process from a presentation plan using OLAF automation tools.","title":"Generate PowerPoint from Plan: Step-by-Step Tutorial"},{"location":"skills/generate-pptx-from-plan/tutorial/#prerequisites","text":"Python environment (3.10+ recommended) Existing presentation plan file (.md format) Access to OLAF skills directory Write permissions to staging directory","title":"Prerequisites"},{"location":"skills/generate-pptx-from-plan/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/generate-pptx-from-plan/tutorial/#step-1-verify-your-presentation-plan-file","text":"Ensure your presentation plan follows the correct format for PowerPoint generation. User Action: 1. Locate your presentation plan (.md file) 2. Verify it contains properly structured slides with titles 3. Check that content is formatted without bullet prefixes Expected Format: # Presentation Title ### Slide 1: Introduction **Layout**: Title Slide **Content**: Welcome to our presentation ### Slide 2: Main Content **Layout**: Content **Content**: Key points and information","title":"Step 1: Verify Your Presentation Plan File"},{"location":"skills/generate-pptx-from-plan/tutorial/#step-2-execute-the-generate-powerpoint-skill","text":"User Action: Issue the OLAF command olaf generate-pptx-from-plan Provide Required Parameters: - Plan File Path : [Example - we used \"c:\\path\\to\\presentation-plan.md\"] - Output Directory : [Optional - defaults to staging/pptx-folder/] - Confirmation : Yes to proceed with generation","title":"Step 2: Execute the Generate PowerPoint Skill"},{"location":"skills/generate-pptx-from-plan/tutorial/#step-3-dependency-check-and-installation","text":"What OLAF Does: - Checks for python-pptx library installation - Installs python-pptx if not found using pip install python-pptx - Verifies Python environment compatibility - Confirms access to generation tool You Should See: \u2705 Python environment verified \u2705 python-pptx library available \u2705 PowerPoint generation tool accessible","title":"Step 3: Dependency Check and Installation"},{"location":"skills/generate-pptx-from-plan/tutorial/#step-4-plan-validation","text":"What OLAF Does: - Reads and parses the presentation plan file - Validates markdown structure and slide format - Checks for proper content organization - Ensures compatibility with PowerPoint generation You Should See: \u2705 Presentation plan loaded successfully \u2705 [X] slides detected and validated \u2705 Content structure verified","title":"Step 4: Plan Validation"},{"location":"skills/generate-pptx-from-plan/tutorial/#step-5-powerpoint-generation","text":"What OLAF Does: - Executes Python automation tool - Converts markdown slides to PowerPoint format - Applies proper formatting and layout - Saves timestamped .pptx file in staging directory You Should See: \ud83d\udd04 Generating PowerPoint presentation... \u2705 PowerPoint file created: [plan-name]-20251119-1456.pptx \u2705 [X] slides successfully generated \u2705 File saved in staging/pptx-folder/","title":"Step 5: PowerPoint Generation"},{"location":"skills/generate-pptx-from-plan/tutorial/#verification-checklist","text":"\u2705 Presentation plan file is properly formatted \u2705 Python environment and dependencies are ready \u2705 PowerPoint file is generated successfully \u2705 All slides from plan are included in presentation \u2705 Content formatting is preserved in PowerPoint \u2705 File is saved with correct timestamp naming","title":"Verification Checklist"},{"location":"skills/generate-pptx-from-plan/tutorial/#troubleshooting","text":"If python-pptx library is missing: pip install python-pptx If plan file format is incorrect: - Check that slides use \"### Slide X:\" format - Ensure Layout and Content sections are present - Remove bullet point prefixes from content If generation fails: - Verify file paths are correct and accessible - Check Python installation and version - Ensure write permissions to staging directory","title":"Troubleshooting"},{"location":"skills/generate-pptx-from-plan/tutorial/#key-learning-points","text":"Plan Structure Matters: PowerPoint generation requires specific markdown formatting with slide sections Automated Dependencies: OLAF handles python-pptx installation automatically if missing Staging Directory: All generated files are saved to staging for consistent organization Timestamped Output: Generated files include timestamps for version tracking","title":"Key Learning Points"},{"location":"skills/generate-pptx-from-plan/tutorial/#next-steps-to-try","text":"Use generated PowerPoint as base for further customization Integrate with presentation planning workflows Automate multi-format content creation pipelines Combine with other technical writing skills","title":"Next Steps to Try"},{"location":"skills/generate-pptx-from-plan/tutorial/#expected-timeline","text":"Total generation time: 1-3 minutes User input required: Plan file path and confirmation OLAF execution time: Automated dependency check, validation, and PowerPoint creation","title":"Expected Timeline"},{"location":"skills/generate-professional-release-notes/description/","text":"Generate Professional Release Notes \u00b6 Overview \u00b6 Generates professional, user-friendly release notes by analyzing git commit history between two version tags, categorizing changes, transforming technical messages into clear descriptions, and producing comprehensive release documentation. Purpose \u00b6 Software releases need clear communication about what changed, why it matters, and what users need to do. This competency solves the problem of technical, developer-focused commit messages by automatically analyzing git history, categorizing changes by type and impact, translating technical details into user benefits, and producing polished release notes suitable for various audiences. Usage \u00b6 Command : generate professional release notes Protocol : Propose-Act When to Use : Use this competency when preparing for a software release, creating release announcements, documenting version changes for stakeholders, or whenever you need to communicate what changed between two versions in a clear, professional, user-focused format. Parameters \u00b6 Required Inputs \u00b6 lower_tag : Starting version tag for the release notes (e.g., v1.0.0, v2.3.1) higher_tag : Ending version tag for the release notes (e.g., v1.1.0, v2.4.0) release_date : Release date in YYYY-MM-DD format project_name : Name of the project or product target_audience : Intended readers (e.g., developers, end-users, administrators, technical stakeholders) Optional Inputs \u00b6 release_theme : Main theme or focus of this release (e.g., \"Performance improvements\", \"Security hardening\") release_manager : Name of the person managing the release tag_link_base : Base URL for linking to tags (e.g., https://github.com/org/repo/tree/) Context Requirements \u00b6 Git repository with commit history between the specified tags Access to git commands for analyzing commits, files, and contributors Understanding of commit message conventions used in the project Knowledge of breaking changes and migration requirements Output \u00b6 Deliverables : - Professional release notes document with sections for features, fixes, improvements, breaking changes - User-friendly descriptions of changes with business value and impact - Contributor acknowledgments - Upgrade instructions and migration guidance - Links to commits, pull requests, and issues for traceability Format : Markdown document with emoji-enhanced sections, clear categorization, actionable upgrade instructions, and proper attribution. Examples \u00b6 Example 1: Minor Version Release \u00b6 Scenario : Releasing v1.5.0 with new features and bug fixes Command : generate professional release notes Input : Lower Tag: v1.4.0 Higher Tag: v1.5.0 Release Date: 2025-10-27 Project Name: Customer Portal Target Audience: end-users Release Theme: Enhanced user experience and performance Tag Link Base: https://github.com/company/customer-portal/tree/ Result : Generated release notes with 5 new features (dark mode, export functionality, etc.), 8 bug fixes, 3 performance improvements, contributor list, and simple upgrade instructions Example 2: Major Version with Breaking Changes \u00b6 Scenario : Releasing v2.0.0 with significant architectural changes Command : generate professional release notes Input : Lower Tag: v1.9.5 Higher Tag: v2.0.0 Release Date: 2025-11-01 Project Name: Analytics API Target Audience: developers Release Theme: Modern architecture and improved scalability Release Manager: Sarah Chen Result : Comprehensive release notes highlighting 12 new features, 15 improvements, 3 breaking changes with detailed migration guide, deprecation notices, and step-by-step upgrade instructions Example 3: Patch Release \u00b6 Scenario : Emergency patch release for security fix Command : generate professional release notes Input : Lower Tag: v1.4.2 Higher Tag: v1.4.3 Release Date: 2025-10-28 Project Name: Authentication Service Target Audience: administrators Release Theme: Security patch Result : Focused release notes emphasizing security fix, impact assessment, urgency of upgrade, and minimal changes to other functionality Related Competencies \u00b6 analyze-changelog-and-report : Provides changelog analysis that can supplement git history analysis generate-commits-from-changelog : Ensures commits reference changelog entries for richer release notes create-changelog-entry : Changelog entries provide additional context for release note generation create-decision-record : Major architectural decisions can be referenced in release notes Tips & Best Practices \u00b6 Use semantic versioning tags (v1.2.3) for clear version identification Run the competency before the actual release to allow time for review and refinement Tailor language and technical depth to your target audience - developers need different details than end-users Include specific issue/PR numbers for traceability and credibility Highlight breaking changes prominently with clear migration instructions Acknowledge all contributors to build community and recognition Test upgrade instructions before publishing to ensure they're accurate Include metrics or performance improvements with specific numbers when available Link to detailed documentation for complex changes Review generated notes for accuracy - automated categorization may need adjustment Limitations \u00b6 Quality depends on commit message quality - vague commits produce vague release notes Cannot automatically determine user impact - requires human judgment for business value assessment Categorization is based on commit prefixes - inconsistent conventions reduce accuracy Cannot access external context like issue descriptions or PR discussions automatically Does not validate that upgrade instructions are complete or accurate Cannot automatically identify all breaking changes - relies on commit message indicators Generated descriptions may need refinement for specific audience needs Source : core/competencies/project-manager/prompts/generate-professional-release-notes.md","title":"Generate Professional Release Notes"},{"location":"skills/generate-professional-release-notes/description/#generate-professional-release-notes","text":"","title":"Generate Professional Release Notes"},{"location":"skills/generate-professional-release-notes/description/#overview","text":"Generates professional, user-friendly release notes by analyzing git commit history between two version tags, categorizing changes, transforming technical messages into clear descriptions, and producing comprehensive release documentation.","title":"Overview"},{"location":"skills/generate-professional-release-notes/description/#purpose","text":"Software releases need clear communication about what changed, why it matters, and what users need to do. This competency solves the problem of technical, developer-focused commit messages by automatically analyzing git history, categorizing changes by type and impact, translating technical details into user benefits, and producing polished release notes suitable for various audiences.","title":"Purpose"},{"location":"skills/generate-professional-release-notes/description/#usage","text":"Command : generate professional release notes Protocol : Propose-Act When to Use : Use this competency when preparing for a software release, creating release announcements, documenting version changes for stakeholders, or whenever you need to communicate what changed between two versions in a clear, professional, user-focused format.","title":"Usage"},{"location":"skills/generate-professional-release-notes/description/#parameters","text":"","title":"Parameters"},{"location":"skills/generate-professional-release-notes/description/#required-inputs","text":"lower_tag : Starting version tag for the release notes (e.g., v1.0.0, v2.3.1) higher_tag : Ending version tag for the release notes (e.g., v1.1.0, v2.4.0) release_date : Release date in YYYY-MM-DD format project_name : Name of the project or product target_audience : Intended readers (e.g., developers, end-users, administrators, technical stakeholders)","title":"Required Inputs"},{"location":"skills/generate-professional-release-notes/description/#optional-inputs","text":"release_theme : Main theme or focus of this release (e.g., \"Performance improvements\", \"Security hardening\") release_manager : Name of the person managing the release tag_link_base : Base URL for linking to tags (e.g., https://github.com/org/repo/tree/)","title":"Optional Inputs"},{"location":"skills/generate-professional-release-notes/description/#context-requirements","text":"Git repository with commit history between the specified tags Access to git commands for analyzing commits, files, and contributors Understanding of commit message conventions used in the project Knowledge of breaking changes and migration requirements","title":"Context Requirements"},{"location":"skills/generate-professional-release-notes/description/#output","text":"Deliverables : - Professional release notes document with sections for features, fixes, improvements, breaking changes - User-friendly descriptions of changes with business value and impact - Contributor acknowledgments - Upgrade instructions and migration guidance - Links to commits, pull requests, and issues for traceability Format : Markdown document with emoji-enhanced sections, clear categorization, actionable upgrade instructions, and proper attribution.","title":"Output"},{"location":"skills/generate-professional-release-notes/description/#examples","text":"","title":"Examples"},{"location":"skills/generate-professional-release-notes/description/#example-1-minor-version-release","text":"Scenario : Releasing v1.5.0 with new features and bug fixes Command : generate professional release notes Input : Lower Tag: v1.4.0 Higher Tag: v1.5.0 Release Date: 2025-10-27 Project Name: Customer Portal Target Audience: end-users Release Theme: Enhanced user experience and performance Tag Link Base: https://github.com/company/customer-portal/tree/ Result : Generated release notes with 5 new features (dark mode, export functionality, etc.), 8 bug fixes, 3 performance improvements, contributor list, and simple upgrade instructions","title":"Example 1: Minor Version Release"},{"location":"skills/generate-professional-release-notes/description/#example-2-major-version-with-breaking-changes","text":"Scenario : Releasing v2.0.0 with significant architectural changes Command : generate professional release notes Input : Lower Tag: v1.9.5 Higher Tag: v2.0.0 Release Date: 2025-11-01 Project Name: Analytics API Target Audience: developers Release Theme: Modern architecture and improved scalability Release Manager: Sarah Chen Result : Comprehensive release notes highlighting 12 new features, 15 improvements, 3 breaking changes with detailed migration guide, deprecation notices, and step-by-step upgrade instructions","title":"Example 2: Major Version with Breaking Changes"},{"location":"skills/generate-professional-release-notes/description/#example-3-patch-release","text":"Scenario : Emergency patch release for security fix Command : generate professional release notes Input : Lower Tag: v1.4.2 Higher Tag: v1.4.3 Release Date: 2025-10-28 Project Name: Authentication Service Target Audience: administrators Release Theme: Security patch Result : Focused release notes emphasizing security fix, impact assessment, urgency of upgrade, and minimal changes to other functionality","title":"Example 3: Patch Release"},{"location":"skills/generate-professional-release-notes/description/#related-competencies","text":"analyze-changelog-and-report : Provides changelog analysis that can supplement git history analysis generate-commits-from-changelog : Ensures commits reference changelog entries for richer release notes create-changelog-entry : Changelog entries provide additional context for release note generation create-decision-record : Major architectural decisions can be referenced in release notes","title":"Related Competencies"},{"location":"skills/generate-professional-release-notes/description/#tips-best-practices","text":"Use semantic versioning tags (v1.2.3) for clear version identification Run the competency before the actual release to allow time for review and refinement Tailor language and technical depth to your target audience - developers need different details than end-users Include specific issue/PR numbers for traceability and credibility Highlight breaking changes prominently with clear migration instructions Acknowledge all contributors to build community and recognition Test upgrade instructions before publishing to ensure they're accurate Include metrics or performance improvements with specific numbers when available Link to detailed documentation for complex changes Review generated notes for accuracy - automated categorization may need adjustment","title":"Tips &amp; Best Practices"},{"location":"skills/generate-professional-release-notes/description/#limitations","text":"Quality depends on commit message quality - vague commits produce vague release notes Cannot automatically determine user impact - requires human judgment for business value assessment Categorization is based on commit prefixes - inconsistent conventions reduce accuracy Cannot access external context like issue descriptions or PR discussions automatically Does not validate that upgrade instructions are complete or accurate Cannot automatically identify all breaking changes - relies on commit message indicators Generated descriptions may need refinement for specific audience needs Source : core/competencies/project-manager/prompts/generate-professional-release-notes.md","title":"Limitations"},{"location":"skills/generate-professional-release-notes/tutorial/","text":"Generate Professional Release Notes: Step-by-Step Tutorial \u00b6 How to Execute the \"Generate Professional Release Notes\" Competency This tutorial shows exactly how to generate professional release notes by analyzing git commit history between two tags. Prerequisites \u00b6 OLAF framework loaded and active Git repository with tagged releases Access to git command line Understanding of semantic versioning Knowledge of target audience (developers, end-users, administrators) Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 User Action: 1. Type: olaf generate professional release notes 2. Or use aliases: olaf release notes , olaf create release notes 3. Press Enter AI Response: Acknowledges request and begins gathering release parameters using Propose-Act protocol. Step 2: Provide Release Parameters \u00b6 User Provides Required Information: - lower_tag : \"v1.0.0\" (starting tag, inclusive) - higher_tag : \"v1.1.0\" (ending tag, inclusive) - release_date : \"2025-10-27\" (YYYY-MM-DD format) - project_name : \"OAuth Authentication Service\" - target_audience : \"developers\" or \"end-users\" or \"administrators\" Optional Information: - release_theme : \"Enhanced Security and Performance\" - release_manager : \"Jane Smith\" - tag_link_base : \"https://github.com/org/repo/tree/\" Step 3: Gather Commit Information \u00b6 What AI Does: Executes git commands to collect data: # Get commit range git log --pretty=format:\"%h|%s|%an|%ad\" --date=short v1.0.0..v1.1.0 # Get detailed commits with bodies git log --pretty=format:\"%h|%s|%b|%an|%ad\" --date=short v1.0.0..v1.1.0 # Get changed files git diff --name-status v1.0.0..v1.1.0 # Get contributor stats git shortlog -sn v1.0.0..v1.1.0 You Should See: Progress updates as git data is collected. Step 4: Categorize Commits \u00b6 What AI Does: Analyzes commit messages and categorizes by type: Features : \"feat:\", \"feature:\", \"add:\" prefixes Enhancements : \"improve:\", \"enhance:\", \"optimize:\", \"update:\" Bug Fixes : \"fix:\", \"bug:\", \"resolve:\", \"correct:\" Technical : \"refactor:\", \"chore:\", \"build:\", \"ci:\" Documentation : \"docs:\", \"documentation:\" Security : \"security:\", \"vulnerability:\", CVE references Breaking : \"BREAKING CHANGE:\", major version bumps Deprecations : \"deprecate:\", \"remove:\", EOL notices Step 5: Transform Messages \u00b6 What AI Does: Converts technical commit messages into user-friendly descriptions: Before: fix: resolve auth timeout issue After: Fixed authentication timeout that was causing users to be logged out prematurely Transformation Rules: - Remove technical jargon for non-technical audiences - Focus on user benefits and impact - Add context and business value - Include specific details and metrics Step 6: Assess Impact \u00b6 What AI Does: For each change, identifies: - User impact and benefits - Business value delivered - Technical improvements made - Required user actions (if any) Step 7: Generate Release Notes \u00b6 What AI Does: Creates structured release notes document: # Release v1.1.0 - Enhanced Security and Performance **Release Date:** 2025-10-27 **Tag:** [v1.1.0](https://github.com/org/repo/tree/v1.1.0) ## Overview This release focuses on security enhancements and performance optimizations... ## \ud83d\ude80 New Features - **OAuth 2.0 Token Refresh**: Automatic token refresh prevents session expiration (#PR-156) - **Multi-Factor Authentication**: Added support for TOTP-based MFA (#PR-162) ## \ud83d\udc1b Bug Fixes - **Fixed Authentication Timeout**: Resolved issue causing premature logouts (#PR-145) - **Corrected Token Validation**: Fixed edge case in token expiry checking (#PR-151) ## \ud83d\udee0\ufe0f Technical Improvements - **Database Query Optimization**: Reduced auth query time by 40% (#PR-148) - **Caching Layer**: Implemented Redis caching for session data (#PR-153) ## \ud83d\udd04 Breaking Changes - **Token Format Change**: JWT tokens now include additional claims. Update client libraries to v2.0+ (#PR-160) - Migration: Update client library dependency - Run migration script: `npm run migrate-tokens` ## \ud83d\udc65 Contributors @jane-smith, @john-doe, @alice-dev ## \ud83d\udcdd Upgrade Instructions 1. Update client libraries to v2.0 or higher 2. Run database migrations: `npm run db:migrate` 3. Update environment variables (see UPGRADE.md) 4. Restart services in rolling fashion Step 8: Quality Validation \u00b6 What AI Does: - Verifies all commits accounted for - Ensures breaking changes include migration guidance - Confirms contributors properly acknowledged - Validates all links functional - Checks content appropriate for target audience You Should See: Complete release notes document with all sections populated. Verification Checklist \u00b6 \u2705 All commits categorized correctly \u2705 User-friendly descriptions for target audience \u2705 Breaking changes documented with migration steps \u2705 Contributors acknowledged properly \u2705 Links validated and functional \u2705 Impact assessment included for major changes \u2705 Upgrade instructions clear and actionable Troubleshooting \u00b6 If git commands fail: # Verify tags exist git tag -l # Check tag format git show v1.0.0 git show v1.1.0 If no commits found: - Verify tag range is correct - Check that higher_tag is after lower_tag - Ensure repository is up to date If categorization seems wrong: - Review commit message conventions - Manually adjust categories as needed - Update commit message patterns Key Learning Points \u00b6 Audience-Focused : Content adapts to target audience (technical vs. non-technical) Comprehensive : All commits accounted for with proper categorization Actionable : Breaking changes include clear migration guidance Traceable : Links to PRs and commits for detailed investigation Expected Timeline \u00b6 Total time: 10-15 minutes User input: 2-3 minutes for parameters AI execution: 8-12 minutes for git analysis and content generation Commits processed: ~100-200 commits per minute","title":"Generate Professional Release Notes: Step-by-Step Tutorial"},{"location":"skills/generate-professional-release-notes/tutorial/#generate-professional-release-notes-step-by-step-tutorial","text":"How to Execute the \"Generate Professional Release Notes\" Competency This tutorial shows exactly how to generate professional release notes by analyzing git commit history between two tags.","title":"Generate Professional Release Notes: Step-by-Step Tutorial"},{"location":"skills/generate-professional-release-notes/tutorial/#prerequisites","text":"OLAF framework loaded and active Git repository with tagged releases Access to git command line Understanding of semantic versioning Knowledge of target audience (developers, end-users, administrators)","title":"Prerequisites"},{"location":"skills/generate-professional-release-notes/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/generate-professional-release-notes/tutorial/#step-1-invoke-the-competency","text":"User Action: 1. Type: olaf generate professional release notes 2. Or use aliases: olaf release notes , olaf create release notes 3. Press Enter AI Response: Acknowledges request and begins gathering release parameters using Propose-Act protocol.","title":"Step 1: Invoke the Competency"},{"location":"skills/generate-professional-release-notes/tutorial/#step-2-provide-release-parameters","text":"User Provides Required Information: - lower_tag : \"v1.0.0\" (starting tag, inclusive) - higher_tag : \"v1.1.0\" (ending tag, inclusive) - release_date : \"2025-10-27\" (YYYY-MM-DD format) - project_name : \"OAuth Authentication Service\" - target_audience : \"developers\" or \"end-users\" or \"administrators\" Optional Information: - release_theme : \"Enhanced Security and Performance\" - release_manager : \"Jane Smith\" - tag_link_base : \"https://github.com/org/repo/tree/\"","title":"Step 2: Provide Release Parameters"},{"location":"skills/generate-professional-release-notes/tutorial/#step-3-gather-commit-information","text":"What AI Does: Executes git commands to collect data: # Get commit range git log --pretty=format:\"%h|%s|%an|%ad\" --date=short v1.0.0..v1.1.0 # Get detailed commits with bodies git log --pretty=format:\"%h|%s|%b|%an|%ad\" --date=short v1.0.0..v1.1.0 # Get changed files git diff --name-status v1.0.0..v1.1.0 # Get contributor stats git shortlog -sn v1.0.0..v1.1.0 You Should See: Progress updates as git data is collected.","title":"Step 3: Gather Commit Information"},{"location":"skills/generate-professional-release-notes/tutorial/#step-4-categorize-commits","text":"What AI Does: Analyzes commit messages and categorizes by type: Features : \"feat:\", \"feature:\", \"add:\" prefixes Enhancements : \"improve:\", \"enhance:\", \"optimize:\", \"update:\" Bug Fixes : \"fix:\", \"bug:\", \"resolve:\", \"correct:\" Technical : \"refactor:\", \"chore:\", \"build:\", \"ci:\" Documentation : \"docs:\", \"documentation:\" Security : \"security:\", \"vulnerability:\", CVE references Breaking : \"BREAKING CHANGE:\", major version bumps Deprecations : \"deprecate:\", \"remove:\", EOL notices","title":"Step 4: Categorize Commits"},{"location":"skills/generate-professional-release-notes/tutorial/#step-5-transform-messages","text":"What AI Does: Converts technical commit messages into user-friendly descriptions: Before: fix: resolve auth timeout issue After: Fixed authentication timeout that was causing users to be logged out prematurely Transformation Rules: - Remove technical jargon for non-technical audiences - Focus on user benefits and impact - Add context and business value - Include specific details and metrics","title":"Step 5: Transform Messages"},{"location":"skills/generate-professional-release-notes/tutorial/#step-6-assess-impact","text":"What AI Does: For each change, identifies: - User impact and benefits - Business value delivered - Technical improvements made - Required user actions (if any)","title":"Step 6: Assess Impact"},{"location":"skills/generate-professional-release-notes/tutorial/#step-7-generate-release-notes","text":"What AI Does: Creates structured release notes document: # Release v1.1.0 - Enhanced Security and Performance **Release Date:** 2025-10-27 **Tag:** [v1.1.0](https://github.com/org/repo/tree/v1.1.0) ## Overview This release focuses on security enhancements and performance optimizations... ## \ud83d\ude80 New Features - **OAuth 2.0 Token Refresh**: Automatic token refresh prevents session expiration (#PR-156) - **Multi-Factor Authentication**: Added support for TOTP-based MFA (#PR-162) ## \ud83d\udc1b Bug Fixes - **Fixed Authentication Timeout**: Resolved issue causing premature logouts (#PR-145) - **Corrected Token Validation**: Fixed edge case in token expiry checking (#PR-151) ## \ud83d\udee0\ufe0f Technical Improvements - **Database Query Optimization**: Reduced auth query time by 40% (#PR-148) - **Caching Layer**: Implemented Redis caching for session data (#PR-153) ## \ud83d\udd04 Breaking Changes - **Token Format Change**: JWT tokens now include additional claims. Update client libraries to v2.0+ (#PR-160) - Migration: Update client library dependency - Run migration script: `npm run migrate-tokens` ## \ud83d\udc65 Contributors @jane-smith, @john-doe, @alice-dev ## \ud83d\udcdd Upgrade Instructions 1. Update client libraries to v2.0 or higher 2. Run database migrations: `npm run db:migrate` 3. Update environment variables (see UPGRADE.md) 4. Restart services in rolling fashion","title":"Step 7: Generate Release Notes"},{"location":"skills/generate-professional-release-notes/tutorial/#step-8-quality-validation","text":"What AI Does: - Verifies all commits accounted for - Ensures breaking changes include migration guidance - Confirms contributors properly acknowledged - Validates all links functional - Checks content appropriate for target audience You Should See: Complete release notes document with all sections populated.","title":"Step 8: Quality Validation"},{"location":"skills/generate-professional-release-notes/tutorial/#verification-checklist","text":"\u2705 All commits categorized correctly \u2705 User-friendly descriptions for target audience \u2705 Breaking changes documented with migration steps \u2705 Contributors acknowledged properly \u2705 Links validated and functional \u2705 Impact assessment included for major changes \u2705 Upgrade instructions clear and actionable","title":"Verification Checklist"},{"location":"skills/generate-professional-release-notes/tutorial/#troubleshooting","text":"If git commands fail: # Verify tags exist git tag -l # Check tag format git show v1.0.0 git show v1.1.0 If no commits found: - Verify tag range is correct - Check that higher_tag is after lower_tag - Ensure repository is up to date If categorization seems wrong: - Review commit message conventions - Manually adjust categories as needed - Update commit message patterns","title":"Troubleshooting"},{"location":"skills/generate-professional-release-notes/tutorial/#key-learning-points","text":"Audience-Focused : Content adapts to target audience (technical vs. non-technical) Comprehensive : All commits accounted for with proper categorization Actionable : Breaking changes include clear migration guidance Traceable : Links to PRs and commits for detailed investigation","title":"Key Learning Points"},{"location":"skills/generate-professional-release-notes/tutorial/#expected-timeline","text":"Total time: 10-15 minutes User input: 2-3 minutes for parameters AI execution: 8-12 minutes for git analysis and content generation Commits processed: ~100-200 commits per minute","title":"Expected Timeline"},{"location":"skills/generate-questionnaire/description/","text":"Generate Questionnaire \u00b6 Enhanced skill migrated from business-analyst competency. Usage \u00b6 This skill provides generate questionnaire functionality with self-contained dependencies and enhanced error handling.","title":"Generate Questionnaire"},{"location":"skills/generate-questionnaire/description/#generate-questionnaire","text":"Enhanced skill migrated from business-analyst competency.","title":"Generate Questionnaire"},{"location":"skills/generate-questionnaire/description/#usage","text":"This skill provides generate questionnaire functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/generate-questionnaire/tutorial/","text":"Generate Questionnaire Tutorial \u00b6 Step-by-step guide for using the generate-questionnaire skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Generate Questionnaire Tutorial"},{"location":"skills/generate-questionnaire/tutorial/#generate-questionnaire-tutorial","text":"Step-by-step guide for using the generate-questionnaire skill.","title":"Generate Questionnaire Tutorial"},{"location":"skills/generate-questionnaire/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/generate-questionnaire/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/generate-tasklist/description/","text":"Generate Tasklist \u00b6 Enhanced skill migrated from project-manager competency. Usage \u00b6 This skill provides generate tasklist functionality with self-contained dependencies and enhanced error handling.","title":"Generate Tasklist"},{"location":"skills/generate-tasklist/description/#generate-tasklist","text":"Enhanced skill migrated from project-manager competency.","title":"Generate Tasklist"},{"location":"skills/generate-tasklist/description/#usage","text":"This skill provides generate tasklist functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/generate-tasklist/tutorial/","text":"Generate Tasklist Tutorial \u00b6 Step-by-step guide for using the generate-tasklist skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Generate Tasklist Tutorial"},{"location":"skills/generate-tasklist/tutorial/#generate-tasklist-tutorial","text":"Step-by-step guide for using the generate-tasklist skill.","title":"Generate Tasklist Tutorial"},{"location":"skills/generate-tasklist/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/generate-tasklist/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/generate-tech-spec-from-code/description/","text":"Generate Code from Spec \u00b6 Overview \u00b6 This competency transforms technical specifications into working code implementations, following best practices and design patterns while ensuring the generated code meets specified requirements and quality standards. Purpose \u00b6 Converting specifications into code is time-consuming and error-prone. This competency accelerates development by generating initial implementations from technical specifications, ensuring consistency with documented requirements, and applying appropriate design patterns and coding standards from the start. Usage \u00b6 Command : generate code from spec (or aliases: implement spec , code from specification , build from spec ) Protocol : Propose-Act When to Use : Use when you have detailed technical specifications and need to generate initial implementations, bootstrap new features, create proof-of-concepts, or ensure code matches documented requirements. Parameters \u00b6 Required Inputs \u00b6 specification : Technical specification document or detailed requirements target_language : Programming language for implementation framework : Framework or technology stack to use Optional Inputs \u00b6 coding_standards : Specific coding standards or style guides to follow design_patterns : Preferred design patterns to apply test_requirements : Testing approach and coverage expectations output_structure : Desired file and directory organization Context Requirements \u00b6 Clear, detailed technical specification Understanding of target technology stack Access to relevant coding standards and patterns Knowledge of project structure and conventions Output \u00b6 Generates working code implementation based on specifications. Deliverables : - Source code files implementing specified functionality - Supporting classes, interfaces, and utilities - Configuration files if needed - Basic unit tests (if specified) - Implementation notes documenting design decisions - README or documentation for generated code Format : Source code files in specified language and framework Examples \u00b6 Example 1: API Endpoint Implementation \u00b6 Scenario : Technical spec defines REST API endpoints, need implementation Command : generate code from spec Input : specification: API spec for user management endpoints target_language: TypeScript framework: Express.js coding_standards: Airbnb style guide Result : Generated Express routes, controller classes, service layer, data models, input validation, error handling, and basic unit tests following specified patterns. Example 2: Data Processing Module \u00b6 Scenario : Specification describes data transformation pipeline Command : implement spec Input : specification: Data processing pipeline spec target_language: Python framework: pandas design_patterns: Strategy pattern for transformations Result : Created pipeline classes, transformation strategies, error handling, logging, configuration management, and sample usage examples. Related Competencies \u00b6 generate-technical-specification : Architect competency that creates the specs this competency implements review-code : Should be used to review generated code before integration create-unit-tests : Can enhance generated code with comprehensive tests fix-code-smells : Can improve generated code quality after initial implementation Tips & Best Practices \u00b6 Ensure specifications are detailed and unambiguous before generating code Review and test generated code thoroughly before integration Specify coding standards and patterns upfront for consistency Use generated code as starting point, expect to refine and enhance Include test requirements in specification for better test coverage Provide examples in specification for more accurate implementation Iterate on generated code with feedback and refinements Document any deviations from specification in implementation notes Limitations \u00b6 Quality depends heavily on specification clarity and completeness Cannot make design decisions not specified in requirements May not capture all edge cases or error scenarios Generated code requires review and testing before production use Cannot infer business logic not explicitly documented May need adjustment for project-specific conventions Does not replace developer judgment and domain expertise Cannot optimize for performance without specific requirements","title":"Generate Code from Spec"},{"location":"skills/generate-tech-spec-from-code/description/#generate-code-from-spec","text":"","title":"Generate Code from Spec"},{"location":"skills/generate-tech-spec-from-code/description/#overview","text":"This competency transforms technical specifications into working code implementations, following best practices and design patterns while ensuring the generated code meets specified requirements and quality standards.","title":"Overview"},{"location":"skills/generate-tech-spec-from-code/description/#purpose","text":"Converting specifications into code is time-consuming and error-prone. This competency accelerates development by generating initial implementations from technical specifications, ensuring consistency with documented requirements, and applying appropriate design patterns and coding standards from the start.","title":"Purpose"},{"location":"skills/generate-tech-spec-from-code/description/#usage","text":"Command : generate code from spec (or aliases: implement spec , code from specification , build from spec ) Protocol : Propose-Act When to Use : Use when you have detailed technical specifications and need to generate initial implementations, bootstrap new features, create proof-of-concepts, or ensure code matches documented requirements.","title":"Usage"},{"location":"skills/generate-tech-spec-from-code/description/#parameters","text":"","title":"Parameters"},{"location":"skills/generate-tech-spec-from-code/description/#required-inputs","text":"specification : Technical specification document or detailed requirements target_language : Programming language for implementation framework : Framework or technology stack to use","title":"Required Inputs"},{"location":"skills/generate-tech-spec-from-code/description/#optional-inputs","text":"coding_standards : Specific coding standards or style guides to follow design_patterns : Preferred design patterns to apply test_requirements : Testing approach and coverage expectations output_structure : Desired file and directory organization","title":"Optional Inputs"},{"location":"skills/generate-tech-spec-from-code/description/#context-requirements","text":"Clear, detailed technical specification Understanding of target technology stack Access to relevant coding standards and patterns Knowledge of project structure and conventions","title":"Context Requirements"},{"location":"skills/generate-tech-spec-from-code/description/#output","text":"Generates working code implementation based on specifications. Deliverables : - Source code files implementing specified functionality - Supporting classes, interfaces, and utilities - Configuration files if needed - Basic unit tests (if specified) - Implementation notes documenting design decisions - README or documentation for generated code Format : Source code files in specified language and framework","title":"Output"},{"location":"skills/generate-tech-spec-from-code/description/#examples","text":"","title":"Examples"},{"location":"skills/generate-tech-spec-from-code/description/#example-1-api-endpoint-implementation","text":"Scenario : Technical spec defines REST API endpoints, need implementation Command : generate code from spec Input : specification: API spec for user management endpoints target_language: TypeScript framework: Express.js coding_standards: Airbnb style guide Result : Generated Express routes, controller classes, service layer, data models, input validation, error handling, and basic unit tests following specified patterns.","title":"Example 1: API Endpoint Implementation"},{"location":"skills/generate-tech-spec-from-code/description/#example-2-data-processing-module","text":"Scenario : Specification describes data transformation pipeline Command : implement spec Input : specification: Data processing pipeline spec target_language: Python framework: pandas design_patterns: Strategy pattern for transformations Result : Created pipeline classes, transformation strategies, error handling, logging, configuration management, and sample usage examples.","title":"Example 2: Data Processing Module"},{"location":"skills/generate-tech-spec-from-code/description/#related-competencies","text":"generate-technical-specification : Architect competency that creates the specs this competency implements review-code : Should be used to review generated code before integration create-unit-tests : Can enhance generated code with comprehensive tests fix-code-smells : Can improve generated code quality after initial implementation","title":"Related Competencies"},{"location":"skills/generate-tech-spec-from-code/description/#tips-best-practices","text":"Ensure specifications are detailed and unambiguous before generating code Review and test generated code thoroughly before integration Specify coding standards and patterns upfront for consistency Use generated code as starting point, expect to refine and enhance Include test requirements in specification for better test coverage Provide examples in specification for more accurate implementation Iterate on generated code with feedback and refinements Document any deviations from specification in implementation notes","title":"Tips &amp; Best Practices"},{"location":"skills/generate-tech-spec-from-code/description/#limitations","text":"Quality depends heavily on specification clarity and completeness Cannot make design decisions not specified in requirements May not capture all edge cases or error scenarios Generated code requires review and testing before production use Cannot infer business logic not explicitly documented May need adjustment for project-specific conventions Does not replace developer judgment and domain expertise Cannot optimize for performance without specific requirements","title":"Limitations"},{"location":"skills/generate-tech-spec-from-code/tutorial/","text":"Generate Tech Spec From Code: Step-by-Step Tutorial \u00b6 How to Execute the \"Generate Tech Spec From Code\" Workflow Extract and generate technical specifications directly from existing codebase. Prerequisites \u00b6 OLAF Framework with developer competency pack Codebase to analyze and extract specifications from Step-by-Step Instructions \u00b6 Step 1: Initialize Spec Generation \u00b6 User Action: Execute olaf tech spec from code or extract spec Step 2: Provide Code Parameters \u00b6 Specify: Code location, output format, specification depth Step 3: Code Analysis and Spec Generation \u00b6 System: Analyzes code structure, extracts patterns, generates technical documentation using Act protocol Expected Timeline: 20-35 minutes \u00b6","title":"Generate Tech Spec From Code: Step-by-Step Tutorial"},{"location":"skills/generate-tech-spec-from-code/tutorial/#generate-tech-spec-from-code-step-by-step-tutorial","text":"How to Execute the \"Generate Tech Spec From Code\" Workflow Extract and generate technical specifications directly from existing codebase.","title":"Generate Tech Spec From Code: Step-by-Step Tutorial"},{"location":"skills/generate-tech-spec-from-code/tutorial/#prerequisites","text":"OLAF Framework with developer competency pack Codebase to analyze and extract specifications from","title":"Prerequisites"},{"location":"skills/generate-tech-spec-from-code/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/generate-tech-spec-from-code/tutorial/#step-1-initialize-spec-generation","text":"User Action: Execute olaf tech spec from code or extract spec","title":"Step 1: Initialize Spec Generation"},{"location":"skills/generate-tech-spec-from-code/tutorial/#step-2-provide-code-parameters","text":"Specify: Code location, output format, specification depth","title":"Step 2: Provide Code Parameters"},{"location":"skills/generate-tech-spec-from-code/tutorial/#step-3-code-analysis-and-spec-generation","text":"System: Analyzes code structure, extracts patterns, generates technical documentation using Act protocol","title":"Step 3: Code Analysis and Spec Generation"},{"location":"skills/generate-tech-spec-from-code/tutorial/#expected-timeline-20-35-minutes","text":"","title":"Expected Timeline: 20-35 minutes"},{"location":"skills/generate-validation-report/description/","text":"Generate Validation Report \u00b6 Enhanced skill migrated from olaf-specific-tools competency. Usage \u00b6 This skill provides generate validation report functionality with self-contained dependencies and enhanced error handling.","title":"Generate Validation Report"},{"location":"skills/generate-validation-report/description/#generate-validation-report","text":"Enhanced skill migrated from olaf-specific-tools competency.","title":"Generate Validation Report"},{"location":"skills/generate-validation-report/description/#usage","text":"This skill provides generate validation report functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/generate-validation-report/tutorial/","text":"Generate Validation Report Tutorial \u00b6 Step-by-step guide for using the generate-validation-report skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Generate Validation Report Tutorial"},{"location":"skills/generate-validation-report/tutorial/#generate-validation-report-tutorial","text":"Step-by-step guide for using the generate-validation-report skill.","title":"Generate Validation Report Tutorial"},{"location":"skills/generate-validation-report/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/generate-validation-report/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/get-bms-expertise/description/","text":"Get BMS Expertise \u00b6 Load the BMS expert persona with comprehensive knowledge of Amadeus' enterprise-scale C/C++ build system. Purpose \u00b6 This skill transforms the AI into a Senior BMS Specialist with: - 10+ years of BMS experience - Deep knowledge of component-based architecture - Binary compatibility expertise - Build/test/delivery workflow mastery - Problem-solving methodology for common BMS scenarios Usage \u00b6 olaf get-bms-expertise After activation, ask BMS-related questions naturally: - \"How do I fix a binary incompatibility error?\" - \"What's the difference between external and internal dependencies?\" - \"How do I optimize parallel builds in a forest workspace?\" - \"My component delivery is failing, what should I check?\" What This Skill Provides \u00b6 Embedded Expertise \u00b6 Behavioral Guidelines : Problem-solving approach, communication style, quality standards Command Reference : Essential BMS commands for build, test, deliver, deps, configuration Troubleshooting Scenarios : Dependency issues, build problems, delivery failures, forest management Knowledge Snippets : Description.xml patterns, version management rules, plugin architecture Knowledge Base Integration \u00b6 For detailed technical information, the skill references: - .olaf/data/kb/bms-kb-index.md - Routing index to 18 BMS documentation files - Can use tell-me skill to search specific topics Example Session \u00b6 User: olaf get-bms-expertise AI: \u2705 BMS Expert Mode Activated I'm now operating as a Senior BMS Specialist with expertise in: - Component-based C/C++ architecture - Binary compatibility management - Build/test/delivery workflows - Dependency resolution and Forest workspaces How can I assist you with BMS today? User: My build is failing with \"undefined reference\" errors AI: [Diagnoses as link error, checks Description.xml sources, suggests solutions...] Benefits \u00b6 Fast activation : Single command loads complete BMS expertise Consistent guidance : Follows BMS best practices and axioms Structured problem-solving : Applies 5-step diagnostic methodology Safety-focused : Always warns about binary compatibility risks Knowledge-backed : Can reference detailed docs when needed Integration \u00b6 Works seamlessly with: - tell-me skill - Search BMS knowledge base - BMS documentation in .olaf/data/kb/bms/ - BMS knowledge base index for topic routing","title":"Get BMS Expertise"},{"location":"skills/get-bms-expertise/description/#get-bms-expertise","text":"Load the BMS expert persona with comprehensive knowledge of Amadeus' enterprise-scale C/C++ build system.","title":"Get BMS Expertise"},{"location":"skills/get-bms-expertise/description/#purpose","text":"This skill transforms the AI into a Senior BMS Specialist with: - 10+ years of BMS experience - Deep knowledge of component-based architecture - Binary compatibility expertise - Build/test/delivery workflow mastery - Problem-solving methodology for common BMS scenarios","title":"Purpose"},{"location":"skills/get-bms-expertise/description/#usage","text":"olaf get-bms-expertise After activation, ask BMS-related questions naturally: - \"How do I fix a binary incompatibility error?\" - \"What's the difference between external and internal dependencies?\" - \"How do I optimize parallel builds in a forest workspace?\" - \"My component delivery is failing, what should I check?\"","title":"Usage"},{"location":"skills/get-bms-expertise/description/#what-this-skill-provides","text":"","title":"What This Skill Provides"},{"location":"skills/get-bms-expertise/description/#embedded-expertise","text":"Behavioral Guidelines : Problem-solving approach, communication style, quality standards Command Reference : Essential BMS commands for build, test, deliver, deps, configuration Troubleshooting Scenarios : Dependency issues, build problems, delivery failures, forest management Knowledge Snippets : Description.xml patterns, version management rules, plugin architecture","title":"Embedded Expertise"},{"location":"skills/get-bms-expertise/description/#knowledge-base-integration","text":"For detailed technical information, the skill references: - .olaf/data/kb/bms-kb-index.md - Routing index to 18 BMS documentation files - Can use tell-me skill to search specific topics","title":"Knowledge Base Integration"},{"location":"skills/get-bms-expertise/description/#example-session","text":"User: olaf get-bms-expertise AI: \u2705 BMS Expert Mode Activated I'm now operating as a Senior BMS Specialist with expertise in: - Component-based C/C++ architecture - Binary compatibility management - Build/test/delivery workflows - Dependency resolution and Forest workspaces How can I assist you with BMS today? User: My build is failing with \"undefined reference\" errors AI: [Diagnoses as link error, checks Description.xml sources, suggests solutions...]","title":"Example Session"},{"location":"skills/get-bms-expertise/description/#benefits","text":"Fast activation : Single command loads complete BMS expertise Consistent guidance : Follows BMS best practices and axioms Structured problem-solving : Applies 5-step diagnostic methodology Safety-focused : Always warns about binary compatibility risks Knowledge-backed : Can reference detailed docs when needed","title":"Benefits"},{"location":"skills/get-bms-expertise/description/#integration","text":"Works seamlessly with: - tell-me skill - Search BMS knowledge base - BMS documentation in .olaf/data/kb/bms/ - BMS knowledge base index for topic routing","title":"Integration"},{"location":"skills/get-bms-expertise/tutorial/","text":"Get BMS Expertise - Tutorial \u00b6 Learn how to use the BMS expert persona to solve build system problems. Step 1: Activate BMS Expertise \u00b6 olaf get-bms-expertise You'll see confirmation: \u2705 BMS Expert Mode Activated I'm now operating as a Senior BMS Specialist... Step 2: Ask BMS Questions \u00b6 The AI now thinks like a BMS expert. Ask questions naturally: Example 1: Build Issues \u00b6 User: My component won't compile, I'm getting link errors AI: Let me help diagnose this link error using the BMS problem-solving approach. 1. Context First: What type of component are you building (library/binary)? 2. Check Description.xml: Are all .cpp files listed in <sources>? 3. Verify dependencies: Run `bms deps` to check your dependency graph [Provides structured troubleshooting steps...] Example 2: Dependency Management \u00b6 User: Should I use external or internal dependency for this library? AI: This depends on whether the library is part of your component's public API. External dependencies: - Transitively visible to components that depend on you - Use when: Library types appear in your public headers - Example: <dependency type=\"external\" name=\"mdw::Toolbox\"/> Internal dependencies: - Hidden from clients - Use when: Library only used in .cpp files - Example: <dependency type=\"internal\" name=\"mdw::Boost\"/> [Provides XML examples and best practices...] Example 3: Performance Optimization \u00b6 User: My forest builds are slow, how can I optimize? AI: Let's optimize your forest build performance: 1. Check current parallelism: `bms -s | grep parallel` 2. Balance forest.parallel vs build.parallel 3. Consider memory constraints [Provides specific tuning recommendations...] Step 3: Deep Dive with Knowledge Base \u00b6 For detailed documentation: User: I need the complete list of test plugins and their options AI: For comprehensive plugin documentation, use: `olaf tell me about BMS plugins` This will retrieve the complete plugin reference from the knowledge base, covering all 27+ plugins with configuration options. Or I can provide a quick overview of the main plugins: - build: Compilation with profiles - test: Orchestrates unittest, valgrind, callgrind, cppcheck - deliver: Full delivery pipeline [...] Step 4: Get Configuration Examples \u00b6 Ask for specific configurations: User: Show me how to configure a development profile with ccache AI: Here's a bmsrc configuration for a dev profile with ccache: ```bmsrc [default] profile = dev [dev] build.ccache = true build.parallel = 8 test.plugins = unittest,valgrind [repositories] [0] = ar://bms-release-public [Explains each setting...] ``` Common Use Cases \u00b6 1. Troubleshooting Build Failures \u00b6 Link errors \u2192 Check sources in Description.xml Compilation errors \u2192 Analyze cppFlags, cxxFlags Generator failures \u2192 Examine bms.log 2. Managing Dependencies \u00b6 Binary incompatibility \u2192 Manual version specification Missing dependencies \u2192 Check repositories config Circular dependencies \u2192 Architectural refactoring 3. Delivery Issues \u00b6 Version conflicts \u2192 Version bump strategy Test failures \u2192 Review test/logs/ SCM tagging \u2192 Verify uncommitted changes 4. Forest Workspace \u00b6 Setup multi-component workspace Resolve constraint conflicts Execute forest-level operations Tips \u00b6 \u2705 Be specific : \"My unittest plugin fails\" vs \"Tests don't work\" \u2705 Provide context : Component type, BMS version, error messages \u2705 Ask for examples : \"Show me an example Description.xml for...\" \u2705 Request validation : \"How do I verify this configuration?\" Exit Expertise Mode \u00b6 Simply start a new conversation or use another skill. The persona is session-specific. Need More Help? \u00b6 Detailed docs: olaf tell me about BMS <topic> Full documentation: .olaf/data/kb/bms/ Escalate to BMS team: NCE-BMS-Admin@amadeus.com","title":"Get BMS Expertise - Tutorial"},{"location":"skills/get-bms-expertise/tutorial/#get-bms-expertise-tutorial","text":"Learn how to use the BMS expert persona to solve build system problems.","title":"Get BMS Expertise - Tutorial"},{"location":"skills/get-bms-expertise/tutorial/#step-1-activate-bms-expertise","text":"olaf get-bms-expertise You'll see confirmation: \u2705 BMS Expert Mode Activated I'm now operating as a Senior BMS Specialist...","title":"Step 1: Activate BMS Expertise"},{"location":"skills/get-bms-expertise/tutorial/#step-2-ask-bms-questions","text":"The AI now thinks like a BMS expert. Ask questions naturally:","title":"Step 2: Ask BMS Questions"},{"location":"skills/get-bms-expertise/tutorial/#example-1-build-issues","text":"User: My component won't compile, I'm getting link errors AI: Let me help diagnose this link error using the BMS problem-solving approach. 1. Context First: What type of component are you building (library/binary)? 2. Check Description.xml: Are all .cpp files listed in <sources>? 3. Verify dependencies: Run `bms deps` to check your dependency graph [Provides structured troubleshooting steps...]","title":"Example 1: Build Issues"},{"location":"skills/get-bms-expertise/tutorial/#example-2-dependency-management","text":"User: Should I use external or internal dependency for this library? AI: This depends on whether the library is part of your component's public API. External dependencies: - Transitively visible to components that depend on you - Use when: Library types appear in your public headers - Example: <dependency type=\"external\" name=\"mdw::Toolbox\"/> Internal dependencies: - Hidden from clients - Use when: Library only used in .cpp files - Example: <dependency type=\"internal\" name=\"mdw::Boost\"/> [Provides XML examples and best practices...]","title":"Example 2: Dependency Management"},{"location":"skills/get-bms-expertise/tutorial/#example-3-performance-optimization","text":"User: My forest builds are slow, how can I optimize? AI: Let's optimize your forest build performance: 1. Check current parallelism: `bms -s | grep parallel` 2. Balance forest.parallel vs build.parallel 3. Consider memory constraints [Provides specific tuning recommendations...]","title":"Example 3: Performance Optimization"},{"location":"skills/get-bms-expertise/tutorial/#step-3-deep-dive-with-knowledge-base","text":"For detailed documentation: User: I need the complete list of test plugins and their options AI: For comprehensive plugin documentation, use: `olaf tell me about BMS plugins` This will retrieve the complete plugin reference from the knowledge base, covering all 27+ plugins with configuration options. Or I can provide a quick overview of the main plugins: - build: Compilation with profiles - test: Orchestrates unittest, valgrind, callgrind, cppcheck - deliver: Full delivery pipeline [...]","title":"Step 3: Deep Dive with Knowledge Base"},{"location":"skills/get-bms-expertise/tutorial/#step-4-get-configuration-examples","text":"Ask for specific configurations: User: Show me how to configure a development profile with ccache AI: Here's a bmsrc configuration for a dev profile with ccache: ```bmsrc [default] profile = dev [dev] build.ccache = true build.parallel = 8 test.plugins = unittest,valgrind [repositories] [0] = ar://bms-release-public [Explains each setting...] ```","title":"Step 4: Get Configuration Examples"},{"location":"skills/get-bms-expertise/tutorial/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"skills/get-bms-expertise/tutorial/#1-troubleshooting-build-failures","text":"Link errors \u2192 Check sources in Description.xml Compilation errors \u2192 Analyze cppFlags, cxxFlags Generator failures \u2192 Examine bms.log","title":"1. Troubleshooting Build Failures"},{"location":"skills/get-bms-expertise/tutorial/#2-managing-dependencies","text":"Binary incompatibility \u2192 Manual version specification Missing dependencies \u2192 Check repositories config Circular dependencies \u2192 Architectural refactoring","title":"2. Managing Dependencies"},{"location":"skills/get-bms-expertise/tutorial/#3-delivery-issues","text":"Version conflicts \u2192 Version bump strategy Test failures \u2192 Review test/logs/ SCM tagging \u2192 Verify uncommitted changes","title":"3. Delivery Issues"},{"location":"skills/get-bms-expertise/tutorial/#4-forest-workspace","text":"Setup multi-component workspace Resolve constraint conflicts Execute forest-level operations","title":"4. Forest Workspace"},{"location":"skills/get-bms-expertise/tutorial/#tips","text":"\u2705 Be specific : \"My unittest plugin fails\" vs \"Tests don't work\" \u2705 Provide context : Component type, BMS version, error messages \u2705 Ask for examples : \"Show me an example Description.xml for...\" \u2705 Request validation : \"How do I verify this configuration?\"","title":"Tips"},{"location":"skills/get-bms-expertise/tutorial/#exit-expertise-mode","text":"Simply start a new conversation or use another skill. The persona is session-specific.","title":"Exit Expertise Mode"},{"location":"skills/get-bms-expertise/tutorial/#need-more-help","text":"Detailed docs: olaf tell me about BMS <topic> Full documentation: .olaf/data/kb/bms/ Escalate to BMS team: NCE-BMS-Admin@amadeus.com","title":"Need More Help?"},{"location":"skills/git-add-commit/description/","text":"Git Add Commit \u00b6 Overview \u00b6 The git-add-commit skill provides an intelligent, LLM-driven approach to git commits by automatically discovering related files through dependency analysis and generating meaningful semantic commit messages. Purpose \u00b6 Traditional git workflows require manually tracking which files are related to a change. This skill automates that process by: Dependency Chasing : Starting from a scope (folder/file), it reads files to extract imports, references, and links Smart Discovery : Loops through git status to find all referenced files that have been modified Semantic Analysis : Deeply analyzes diffs to understand what actually changed and why Meaningful Commits : Generates conventional commit messages that explain the real intent Key Features \u00b6 Universal Language Support : Works with Python imports, TypeScript/JavaScript imports, markdown links, JSON paths Dependency-Aware : Finds connected files even if they're in different directories Semantic Understanding : Analyzes what changed (features, fixes, refactors) not just which files Safety Validation : Checks for large files, sensitive data, and common mistakes Conventional Commits : Follows standardized format with type, scope, subject, and body When to Use \u00b6 Use this skill when you: - Want to commit logically related changes together - Need help understanding what files are connected - Want meaningful commit messages without manual writing - Have changes spanning multiple files/directories - Want to ensure nothing related is missed How It Works \u00b6 1. Scope-Based Discovery \u00b6 You provide a scope (e.g., \"create-prompt\", \"vscode-extension/src\"), and the skill finds all matching files in git status. 2. Reference Chasing \u00b6 For each matched file, it: - Reads the content - Extracts imports ( import X from './Y' , from X import Y ) - Extracts links ( [link](../path) , [id:dir]path ) - Extracts JSON paths ( \"manifest\": \"path/to/file\" ) - Checks if those referenced files are in git status - Loops until no new references found 3. Semantic Analysis \u00b6 Analyzes all diffs to identify: - Structural changes (new sections, reorganization) - Functional changes (features, fixes, behavior) - Knowledge base changes (KB files, schemas, validation) - Terminology/UX changes (user messages, help text) - Dependencies (new imports, schema updates) 4. Commit Message Generation \u00b6 Creates conventional commit with: - Type : feat/fix/refactor/docs/chore/test - Scope : Affected area (from user's input) - Subject : One-line summary - Body : Detailed explanation of what, why, and major changes 5. Safe Execution \u00b6 Validates for large files (>10MB) Checks for sensitive data patterns Requires user confirmation Stages files with git add Commits with generated message Example \u00b6 User : \"commit create-prompt\" Skill discovers : Initial: create-prompt.md (modified) References found: kb/prompt-structure-schema.md (new) References found: kb/file-modification-rules.md (new) No more references \u2192 Stop Result: 3 connected files Generated commit : refactor(create-prompt): enforce KB-driven structure validation Added mandatory KB loading: - prompt-structure-schema.md: minimal BOM requirements - file-modification-rules.md: read-only file rules Ensures prompts follow canonical structure. Integration \u00b6 This skill integrates with: - Git : All standard git operations - File System : Reads files to extract references - LLM Context : Uses semantic understanding for analysis Limitations \u00b6 Requires files to be in git status (modified/new/staged) Reference extraction is pattern-based (may miss dynamic imports) Best for projects with clear dependency structures Cannot handle very large codebases (>1000 changed files) efficiently Version History \u00b6 2.0.0 (2025-11-25): Complete refactor to dependency-aware LLM approach 1.0.0 (2025-11-15): Initial version with task-based workflow","title":"Git Add Commit"},{"location":"skills/git-add-commit/description/#git-add-commit","text":"","title":"Git Add Commit"},{"location":"skills/git-add-commit/description/#overview","text":"The git-add-commit skill provides an intelligent, LLM-driven approach to git commits by automatically discovering related files through dependency analysis and generating meaningful semantic commit messages.","title":"Overview"},{"location":"skills/git-add-commit/description/#purpose","text":"Traditional git workflows require manually tracking which files are related to a change. This skill automates that process by: Dependency Chasing : Starting from a scope (folder/file), it reads files to extract imports, references, and links Smart Discovery : Loops through git status to find all referenced files that have been modified Semantic Analysis : Deeply analyzes diffs to understand what actually changed and why Meaningful Commits : Generates conventional commit messages that explain the real intent","title":"Purpose"},{"location":"skills/git-add-commit/description/#key-features","text":"Universal Language Support : Works with Python imports, TypeScript/JavaScript imports, markdown links, JSON paths Dependency-Aware : Finds connected files even if they're in different directories Semantic Understanding : Analyzes what changed (features, fixes, refactors) not just which files Safety Validation : Checks for large files, sensitive data, and common mistakes Conventional Commits : Follows standardized format with type, scope, subject, and body","title":"Key Features"},{"location":"skills/git-add-commit/description/#when-to-use","text":"Use this skill when you: - Want to commit logically related changes together - Need help understanding what files are connected - Want meaningful commit messages without manual writing - Have changes spanning multiple files/directories - Want to ensure nothing related is missed","title":"When to Use"},{"location":"skills/git-add-commit/description/#how-it-works","text":"","title":"How It Works"},{"location":"skills/git-add-commit/description/#1-scope-based-discovery","text":"You provide a scope (e.g., \"create-prompt\", \"vscode-extension/src\"), and the skill finds all matching files in git status.","title":"1. Scope-Based Discovery"},{"location":"skills/git-add-commit/description/#2-reference-chasing","text":"For each matched file, it: - Reads the content - Extracts imports ( import X from './Y' , from X import Y ) - Extracts links ( [link](../path) , [id:dir]path ) - Extracts JSON paths ( \"manifest\": \"path/to/file\" ) - Checks if those referenced files are in git status - Loops until no new references found","title":"2. Reference Chasing"},{"location":"skills/git-add-commit/description/#3-semantic-analysis","text":"Analyzes all diffs to identify: - Structural changes (new sections, reorganization) - Functional changes (features, fixes, behavior) - Knowledge base changes (KB files, schemas, validation) - Terminology/UX changes (user messages, help text) - Dependencies (new imports, schema updates)","title":"3. Semantic Analysis"},{"location":"skills/git-add-commit/description/#4-commit-message-generation","text":"Creates conventional commit with: - Type : feat/fix/refactor/docs/chore/test - Scope : Affected area (from user's input) - Subject : One-line summary - Body : Detailed explanation of what, why, and major changes","title":"4. Commit Message Generation"},{"location":"skills/git-add-commit/description/#5-safe-execution","text":"Validates for large files (>10MB) Checks for sensitive data patterns Requires user confirmation Stages files with git add Commits with generated message","title":"5. Safe Execution"},{"location":"skills/git-add-commit/description/#example","text":"User : \"commit create-prompt\" Skill discovers : Initial: create-prompt.md (modified) References found: kb/prompt-structure-schema.md (new) References found: kb/file-modification-rules.md (new) No more references \u2192 Stop Result: 3 connected files Generated commit : refactor(create-prompt): enforce KB-driven structure validation Added mandatory KB loading: - prompt-structure-schema.md: minimal BOM requirements - file-modification-rules.md: read-only file rules Ensures prompts follow canonical structure.","title":"Example"},{"location":"skills/git-add-commit/description/#integration","text":"This skill integrates with: - Git : All standard git operations - File System : Reads files to extract references - LLM Context : Uses semantic understanding for analysis","title":"Integration"},{"location":"skills/git-add-commit/description/#limitations","text":"Requires files to be in git status (modified/new/staged) Reference extraction is pattern-based (may miss dynamic imports) Best for projects with clear dependency structures Cannot handle very large codebases (>1000 changed files) efficiently","title":"Limitations"},{"location":"skills/git-add-commit/description/#version-history","text":"2.0.0 (2025-11-25): Complete refactor to dependency-aware LLM approach 1.0.0 (2025-11-15): Initial version with task-based workflow","title":"Version History"},{"location":"skills/git-add-commit/tutorial/","text":"Git Add Commit - Tutorial \u00b6 Getting Started \u00b6 This tutorial walks you through using the git-add-commit skill to intelligently commit related changes. Prerequisites \u00b6 Git repository initialized Files modified/added in your working directory Understanding of what you changed (general scope) Step-by-Step Guide \u00b6 Step 1: Make Your Changes \u00b6 Edit files in your project. For this example, let's say you updated a skill: # Modified files skills/create-prompt/prompts/create-prompt.md skills/create-prompt/skill-manifest.json # New files skills/create-prompt/kb/prompt-structure-schema.md skills/create-prompt/kb/file-modification-rules.md Step 2: Invoke the Skill \u00b6 Tell the LLM you want to commit with a scope: commit create-prompt Or more explicitly: Use git-add-commit skill to commit changes to create-prompt Step 3: Skill Discovers Related Files \u00b6 The skill will: Run git status to see all changes Filter by scope \"create-prompt\" Read matched files to find references Check git status for referenced files Loop until no new references found Output : \ud83d\udce6 Dependency Analysis for 'create-prompt': Initial matches (2): M create-prompt.md M skill-manifest.json Referenced files found (2): ?? kb/prompt-structure-schema.md \u2190 create-prompt.md:34 ?? kb/file-modification-rules.md \u2190 create-prompt.md:37 Total: 4 connected files Step 4: Review Dependency Graph \u00b6 The skill shows you WHY files are related: create-prompt.md \u251c\u2500 References: kb/prompt-structure-schema.md \u2514\u2500 References: kb/file-modification-rules.md skill-manifest.json \u2514\u2500 (no references) Step 5: Semantic Analysis \u00b6 The skill reads all diffs and identifies: \ud83d\udd0d Analysis Results: Structural changes: - Added KB loading section in create-prompt.md Functional changes: - Enforce structure validation before generation - Add file safety rules Knowledge base changes: - New file: prompt-structure-schema.md (BOM requirements) - New file: file-modification-rules.md (read-only rules) Step 6: Review Generated Commit Message \u00b6 \ud83d\udcdd Proposed Commit Message: \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 refactor(create-prompt): enforce KB-driven structure validation Added mandatory KB loading for canonical structure enforcement: - prompt-structure-schema.md: minimal BOM requirements - file-modification-rules.md: read-only vs editable file rules - JSON schema validation enforcement Strengthened validation: - Enforce minimal BOM (prompts + docs only) - Directory structure restrictions - Schema compliance checks Ensures prompts follow canonical structure and prevents corruption of auto-generated files. \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Files (4): M skills/create-prompt/prompts/create-prompt.md M skills/create-prompt/skill-manifest.json ?? skills/create-prompt/kb/prompt-structure-schema.md ?? skills/create-prompt/kb/file-modification-rules.md Step 7: Approve or Modify \u00b6 You have three options: Option 1: Approve (y) Proceed? (y/n/edit): y Option 2: Cancel (n) Proceed? (y/n/edit): n \u274c Commit cancelled Option 3: Edit (edit) Proceed? (y/n/edit): edit Provide your commit message: [type your own] Step 8: Execution \u00b6 If approved, the skill: # Stages all files git add skills/create-prompt/prompts/create-prompt.md \\ skills/create-prompt/skill-manifest.json \\ skills/create-prompt/kb/ # Commits with message git commit -m \"refactor(create-prompt): enforce KB-driven structure validation ...\" Result : \u2705 Commit successful Commit: abc1234 Branch: main Files: 4 changed (120 insertions, 10 deletions) Advanced Usage \u00b6 Commit Specific File \u00b6 commit vscode-extension/src/services/installationManager.ts Commit Entire Directory \u00b6 commit vscode-extension/src/commands Include Untracked Files \u00b6 commit create-prompt with new files Provide Custom Message \u00b6 commit create-prompt with message \"Add validation rules\" Tips \u00b6 Use descriptive scopes : \"create-prompt\" better than \"core\" Trust dependency chasing : It finds connections you might miss Review the graph : Understand why files are grouped Check the analysis : Make sure it understood your changes Edit if needed : The generated message is a starting point Troubleshooting \u00b6 Problem : No files found \u274c No files match scope 'xyz' Solution: Check spelling, try broader scope, or run git status manually Problem : Too many files included \u26a0\ufe0f Found 50 files - seems too broad Solution: Use more specific scope like \"folder/subfolder\" instead of \"folder\" Problem : Reference not resolved \u26a0\ufe0f Could not resolve: ../missing/file.md Solution: This is OK - reference might be to uncommitted file or incorrect path Next Steps \u00b6 Explore dependency graphs for your codebase Create conventional commits consistently Use for complex multi-file changes Integrate into your git workflow","title":"Git Add Commit - Tutorial"},{"location":"skills/git-add-commit/tutorial/#git-add-commit-tutorial","text":"","title":"Git Add Commit - Tutorial"},{"location":"skills/git-add-commit/tutorial/#getting-started","text":"This tutorial walks you through using the git-add-commit skill to intelligently commit related changes.","title":"Getting Started"},{"location":"skills/git-add-commit/tutorial/#prerequisites","text":"Git repository initialized Files modified/added in your working directory Understanding of what you changed (general scope)","title":"Prerequisites"},{"location":"skills/git-add-commit/tutorial/#step-by-step-guide","text":"","title":"Step-by-Step Guide"},{"location":"skills/git-add-commit/tutorial/#step-1-make-your-changes","text":"Edit files in your project. For this example, let's say you updated a skill: # Modified files skills/create-prompt/prompts/create-prompt.md skills/create-prompt/skill-manifest.json # New files skills/create-prompt/kb/prompt-structure-schema.md skills/create-prompt/kb/file-modification-rules.md","title":"Step 1: Make Your Changes"},{"location":"skills/git-add-commit/tutorial/#step-2-invoke-the-skill","text":"Tell the LLM you want to commit with a scope: commit create-prompt Or more explicitly: Use git-add-commit skill to commit changes to create-prompt","title":"Step 2: Invoke the Skill"},{"location":"skills/git-add-commit/tutorial/#step-3-skill-discovers-related-files","text":"The skill will: Run git status to see all changes Filter by scope \"create-prompt\" Read matched files to find references Check git status for referenced files Loop until no new references found Output : \ud83d\udce6 Dependency Analysis for 'create-prompt': Initial matches (2): M create-prompt.md M skill-manifest.json Referenced files found (2): ?? kb/prompt-structure-schema.md \u2190 create-prompt.md:34 ?? kb/file-modification-rules.md \u2190 create-prompt.md:37 Total: 4 connected files","title":"Step 3: Skill Discovers Related Files"},{"location":"skills/git-add-commit/tutorial/#step-4-review-dependency-graph","text":"The skill shows you WHY files are related: create-prompt.md \u251c\u2500 References: kb/prompt-structure-schema.md \u2514\u2500 References: kb/file-modification-rules.md skill-manifest.json \u2514\u2500 (no references)","title":"Step 4: Review Dependency Graph"},{"location":"skills/git-add-commit/tutorial/#step-5-semantic-analysis","text":"The skill reads all diffs and identifies: \ud83d\udd0d Analysis Results: Structural changes: - Added KB loading section in create-prompt.md Functional changes: - Enforce structure validation before generation - Add file safety rules Knowledge base changes: - New file: prompt-structure-schema.md (BOM requirements) - New file: file-modification-rules.md (read-only rules)","title":"Step 5: Semantic Analysis"},{"location":"skills/git-add-commit/tutorial/#step-6-review-generated-commit-message","text":"\ud83d\udcdd Proposed Commit Message: \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 refactor(create-prompt): enforce KB-driven structure validation Added mandatory KB loading for canonical structure enforcement: - prompt-structure-schema.md: minimal BOM requirements - file-modification-rules.md: read-only vs editable file rules - JSON schema validation enforcement Strengthened validation: - Enforce minimal BOM (prompts + docs only) - Directory structure restrictions - Schema compliance checks Ensures prompts follow canonical structure and prevents corruption of auto-generated files. \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Files (4): M skills/create-prompt/prompts/create-prompt.md M skills/create-prompt/skill-manifest.json ?? skills/create-prompt/kb/prompt-structure-schema.md ?? skills/create-prompt/kb/file-modification-rules.md","title":"Step 6: Review Generated Commit Message"},{"location":"skills/git-add-commit/tutorial/#step-7-approve-or-modify","text":"You have three options: Option 1: Approve (y) Proceed? (y/n/edit): y Option 2: Cancel (n) Proceed? (y/n/edit): n \u274c Commit cancelled Option 3: Edit (edit) Proceed? (y/n/edit): edit Provide your commit message: [type your own]","title":"Step 7: Approve or Modify"},{"location":"skills/git-add-commit/tutorial/#step-8-execution","text":"If approved, the skill: # Stages all files git add skills/create-prompt/prompts/create-prompt.md \\ skills/create-prompt/skill-manifest.json \\ skills/create-prompt/kb/ # Commits with message git commit -m \"refactor(create-prompt): enforce KB-driven structure validation ...\" Result : \u2705 Commit successful Commit: abc1234 Branch: main Files: 4 changed (120 insertions, 10 deletions)","title":"Step 8: Execution"},{"location":"skills/git-add-commit/tutorial/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/git-add-commit/tutorial/#commit-specific-file","text":"commit vscode-extension/src/services/installationManager.ts","title":"Commit Specific File"},{"location":"skills/git-add-commit/tutorial/#commit-entire-directory","text":"commit vscode-extension/src/commands","title":"Commit Entire Directory"},{"location":"skills/git-add-commit/tutorial/#include-untracked-files","text":"commit create-prompt with new files","title":"Include Untracked Files"},{"location":"skills/git-add-commit/tutorial/#provide-custom-message","text":"commit create-prompt with message \"Add validation rules\"","title":"Provide Custom Message"},{"location":"skills/git-add-commit/tutorial/#tips","text":"Use descriptive scopes : \"create-prompt\" better than \"core\" Trust dependency chasing : It finds connections you might miss Review the graph : Understand why files are grouped Check the analysis : Make sure it understood your changes Edit if needed : The generated message is a starting point","title":"Tips"},{"location":"skills/git-add-commit/tutorial/#troubleshooting","text":"Problem : No files found \u274c No files match scope 'xyz' Solution: Check spelling, try broader scope, or run git status manually Problem : Too many files included \u26a0\ufe0f Found 50 files - seems too broad Solution: Use more specific scope like \"folder/subfolder\" instead of \"folder\" Problem : Reference not resolved \u26a0\ufe0f Could not resolve: ../missing/file.md Solution: This is OK - reference might be to uncommitted file or incorrect path","title":"Troubleshooting"},{"location":"skills/git-add-commit/tutorial/#next-steps","text":"Explore dependency graphs for your codebase Create conventional commits consistently Use for complex multi-file changes Integrate into your git workflow","title":"Next Steps"},{"location":"skills/help-me-olaf/description/","text":"OLAF Help \u00b6 Overview \u00b6 Discovers available OLAF competencies and provides guidance on which competencies to use for specific needs. Purpose \u00b6 Helps users navigate the OLAF framework by discovering available competencies, understanding their purposes, and finding the right tool for their current task. Usage \u00b6 Command : help me | olaf help | olaf i need you Protocol : Act When to Use : When you're unsure what OLAF can do, need to find a specific competency, or want to explore available capabilities. Parameters \u00b6 Required Inputs \u00b6 None - can be invoked without parameters Optional Inputs \u00b6 Search Query : Keywords or description of what you need help with Persona Filter : Filter by role (developer, architect, etc.) Category : Filter by competency category Context Requirements \u00b6 None - works in any context Output \u00b6 Deliverables : - List of relevant competencies - Descriptions and use cases - Commands to execute each competency - Related competencies and alternatives Format : Organized list with descriptions and actionable commands Examples \u00b6 Example 1: General Help \u00b6 Scenario : New user wants to know what OLAF can do Command : olaf help Result : Overview of OLAF capabilities with major competency categories Example 2: Specific Need \u00b6 Scenario : Need help with code review Command : help me with code review Result : Lists code review related competencies with descriptions and commands Example 3: Persona-Based Discovery \u00b6 Scenario : Want to see all developer competencies Command : show me developer competencies Result : Filtered list of competencies relevant to developers Related Competencies \u00b6 use-skill : Intelligent routing to the right skill based on your goal assess-genai-initiative : Evaluate if AI/OLAF is right for your use case find-expert-contact : Find human experts when OLAF can't help Tips & Best Practices \u00b6 Start with general help to understand OLAF's capabilities Use specific keywords when searching for competencies Explore competencies by persona to find role-specific tools Bookmark or note frequently used competencies Use use competency when you know your goal but not which competency Limitations \u00b6 Cannot execute competencies, only discover them Requires some understanding of your need to provide relevant results May return many results for broad queries","title":"OLAF Help"},{"location":"skills/help-me-olaf/description/#olaf-help","text":"","title":"OLAF Help"},{"location":"skills/help-me-olaf/description/#overview","text":"Discovers available OLAF competencies and provides guidance on which competencies to use for specific needs.","title":"Overview"},{"location":"skills/help-me-olaf/description/#purpose","text":"Helps users navigate the OLAF framework by discovering available competencies, understanding their purposes, and finding the right tool for their current task.","title":"Purpose"},{"location":"skills/help-me-olaf/description/#usage","text":"Command : help me | olaf help | olaf i need you Protocol : Act When to Use : When you're unsure what OLAF can do, need to find a specific competency, or want to explore available capabilities.","title":"Usage"},{"location":"skills/help-me-olaf/description/#parameters","text":"","title":"Parameters"},{"location":"skills/help-me-olaf/description/#required-inputs","text":"None - can be invoked without parameters","title":"Required Inputs"},{"location":"skills/help-me-olaf/description/#optional-inputs","text":"Search Query : Keywords or description of what you need help with Persona Filter : Filter by role (developer, architect, etc.) Category : Filter by competency category","title":"Optional Inputs"},{"location":"skills/help-me-olaf/description/#context-requirements","text":"None - works in any context","title":"Context Requirements"},{"location":"skills/help-me-olaf/description/#output","text":"Deliverables : - List of relevant competencies - Descriptions and use cases - Commands to execute each competency - Related competencies and alternatives Format : Organized list with descriptions and actionable commands","title":"Output"},{"location":"skills/help-me-olaf/description/#examples","text":"","title":"Examples"},{"location":"skills/help-me-olaf/description/#example-1-general-help","text":"Scenario : New user wants to know what OLAF can do Command : olaf help Result : Overview of OLAF capabilities with major competency categories","title":"Example 1: General Help"},{"location":"skills/help-me-olaf/description/#example-2-specific-need","text":"Scenario : Need help with code review Command : help me with code review Result : Lists code review related competencies with descriptions and commands","title":"Example 2: Specific Need"},{"location":"skills/help-me-olaf/description/#example-3-persona-based-discovery","text":"Scenario : Want to see all developer competencies Command : show me developer competencies Result : Filtered list of competencies relevant to developers","title":"Example 3: Persona-Based Discovery"},{"location":"skills/help-me-olaf/description/#related-competencies","text":"use-skill : Intelligent routing to the right skill based on your goal assess-genai-initiative : Evaluate if AI/OLAF is right for your use case find-expert-contact : Find human experts when OLAF can't help","title":"Related Competencies"},{"location":"skills/help-me-olaf/description/#tips-best-practices","text":"Start with general help to understand OLAF's capabilities Use specific keywords when searching for competencies Explore competencies by persona to find role-specific tools Bookmark or note frequently used competencies Use use competency when you know your goal but not which competency","title":"Tips &amp; Best Practices"},{"location":"skills/help-me-olaf/description/#limitations","text":"Cannot execute competencies, only discover them Requires some understanding of your need to provide relevant results May return many results for broad queries","title":"Limitations"},{"location":"skills/help-me-olaf/tutorial/","text":"OLAF Help: Step-by-Step Tutorial \u00b6 How to Execute the \"OLAF Help\" Workflow This tutorial shows how to discover available OLAF competencies and get help. Prerequisites \u00b6 Active OLAF session Basic understanding that OLAF has multiple competencies Step-by-Step Instructions \u00b6 Step 1: Invoke Help \u00b6 Request help from OLAF User Action: 1. Type one of these commands: - help me - olaf help - olaf i need you OLAF Response: OLAF will begin the help discovery process Step 2: Specify Your Need (Optional) \u00b6 User Action: Describe what you need help with I need help with code review Or ask general questions: - \"What can you do?\" - \"Show me all competencies\" - \"What competencies are available for developers?\" Step 3: Competency Discovery \u00b6 What OLAF Does: - Searches available competencies - Filters by relevance to your request - Organizes by category or persona - Provides descriptions and use cases You Should See: List of relevant competencies with descriptions Step 4: Learn About Competencies \u00b6 What OLAF Provides: - Competency names and commands - Brief descriptions of what each does - When to use each competency - Related competencies You Should See: Organized list with actionable information Step 5: Execute or Learn More \u00b6 User Action: Choose next step - Execute a competency directly: \"use code review competency\" - Ask for more details: \"tell me more about the architect competency\" - Browse by category: \"show me all developer competencies\" Verification Checklist \u00b6 \u2705 Relevant competencies are listed \u2705 Descriptions are clear and actionable \u2705 Commands are provided for each competency \u2705 You understand which competency to use Troubleshooting \u00b6 If too many results: - Be more specific: \"help with database design\" - Filter by persona: \"show developer competencies\" - Ask for top recommendations: \"what's the best competency for my situation?\" If no relevant results: - Try broader terms: \"help with development\" instead of specific tech - Ask what's available: \"what categories of competencies exist?\" - Use use competency for intelligent routing If you're not sure which to use: - Describe your goal: \"I want to improve code quality\" - OLAF will recommend the most appropriate competency - Ask for comparisons: \"what's the difference between X and Y?\" Key Learning Points \u00b6 Multiple Entry Points : Several commands trigger help (help me, olaf help, etc.) Smart Discovery : Can search by keywords, persona, or category Actionable Results : Provides commands to execute competencies Contextual Help : Tailors results to your specific needs Next Steps to Try \u00b6 Execute a discovered competency Use use competency for intelligent routing to the right competency Explore competencies by persona (developer, architect, etc.) Bookmark frequently used competencies Expected Timeline \u00b6 Total help time: 1-2 minutes User input required: Command and optional description (30 seconds) OLAF execution time: Search and display results (30-60 seconds)","title":"OLAF Help: Step-by-Step Tutorial"},{"location":"skills/help-me-olaf/tutorial/#olaf-help-step-by-step-tutorial","text":"How to Execute the \"OLAF Help\" Workflow This tutorial shows how to discover available OLAF competencies and get help.","title":"OLAF Help: Step-by-Step Tutorial"},{"location":"skills/help-me-olaf/tutorial/#prerequisites","text":"Active OLAF session Basic understanding that OLAF has multiple competencies","title":"Prerequisites"},{"location":"skills/help-me-olaf/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/help-me-olaf/tutorial/#step-1-invoke-help","text":"Request help from OLAF User Action: 1. Type one of these commands: - help me - olaf help - olaf i need you OLAF Response: OLAF will begin the help discovery process","title":"Step 1: Invoke Help"},{"location":"skills/help-me-olaf/tutorial/#step-2-specify-your-need-optional","text":"User Action: Describe what you need help with I need help with code review Or ask general questions: - \"What can you do?\" - \"Show me all competencies\" - \"What competencies are available for developers?\"","title":"Step 2: Specify Your Need (Optional)"},{"location":"skills/help-me-olaf/tutorial/#step-3-competency-discovery","text":"What OLAF Does: - Searches available competencies - Filters by relevance to your request - Organizes by category or persona - Provides descriptions and use cases You Should See: List of relevant competencies with descriptions","title":"Step 3: Competency Discovery"},{"location":"skills/help-me-olaf/tutorial/#step-4-learn-about-competencies","text":"What OLAF Provides: - Competency names and commands - Brief descriptions of what each does - When to use each competency - Related competencies You Should See: Organized list with actionable information","title":"Step 4: Learn About Competencies"},{"location":"skills/help-me-olaf/tutorial/#step-5-execute-or-learn-more","text":"User Action: Choose next step - Execute a competency directly: \"use code review competency\" - Ask for more details: \"tell me more about the architect competency\" - Browse by category: \"show me all developer competencies\"","title":"Step 5: Execute or Learn More"},{"location":"skills/help-me-olaf/tutorial/#verification-checklist","text":"\u2705 Relevant competencies are listed \u2705 Descriptions are clear and actionable \u2705 Commands are provided for each competency \u2705 You understand which competency to use","title":"Verification Checklist"},{"location":"skills/help-me-olaf/tutorial/#troubleshooting","text":"If too many results: - Be more specific: \"help with database design\" - Filter by persona: \"show developer competencies\" - Ask for top recommendations: \"what's the best competency for my situation?\" If no relevant results: - Try broader terms: \"help with development\" instead of specific tech - Ask what's available: \"what categories of competencies exist?\" - Use use competency for intelligent routing If you're not sure which to use: - Describe your goal: \"I want to improve code quality\" - OLAF will recommend the most appropriate competency - Ask for comparisons: \"what's the difference between X and Y?\"","title":"Troubleshooting"},{"location":"skills/help-me-olaf/tutorial/#key-learning-points","text":"Multiple Entry Points : Several commands trigger help (help me, olaf help, etc.) Smart Discovery : Can search by keywords, persona, or category Actionable Results : Provides commands to execute competencies Contextual Help : Tailors results to your specific needs","title":"Key Learning Points"},{"location":"skills/help-me-olaf/tutorial/#next-steps-to-try","text":"Execute a discovered competency Use use competency for intelligent routing to the right competency Explore competencies by persona (developer, architect, etc.) Bookmark frequently used competencies","title":"Next Steps to Try"},{"location":"skills/help-me-olaf/tutorial/#expected-timeline","text":"Total help time: 1-2 minutes User input required: Command and optional description (30 seconds) OLAF execution time: Search and display results (30-60 seconds)","title":"Expected Timeline"},{"location":"skills/improve-cyclomatic-complexity/description/","text":"Improve Cyclomatic Complexity \u00b6 Source : core/competencies/developer/prompts/improve-cyclomatic-complexity.md Overview \u00b6 Systematically reduce cyclomatic complexity of code sections while preserving functionality and improving maintainability. Provides phased refactoring approach with complexity measurement. Purpose \u00b6 High cyclomatic complexity makes code difficult to understand, test, and maintain. This competency analyzes complex code, identifies root causes, and applies targeted refactoring techniques to reduce complexity while preserving behavior. It ensures changes are validated through testing and measured for improvement. Usage \u00b6 Command : improve complexity Protocol : Propose-Act When to Use : - When code complexity metrics exceed thresholds - During code review identifying complex methods - To improve code testability - When reducing technical debt - For making code more maintainable Parameters \u00b6 Required Inputs \u00b6 target_code : The method/function with high cyclomatic complexity (include containing class/module and file location) programming_language : The programming language of the code Optional Inputs \u00b6 test_information : Available test information and coverage details interface_restrictions : Restrictions on changing interfaces/signatures performance_requirements : Performance constraints to consider compatibility_needs : Backward compatibility requirements target_complexity : Target cyclomatic complexity score (default: <10) Context Requirements \u00b6 Code with high cyclomatic complexity Existing tests for validation Understanding of interface constraints Output \u00b6 Refactored code with reduced complexity and preserved functionality. Deliverables : - Current complexity assessment with score - Visual control flow representation - Root cause analysis of complexity - Phased refactoring strategy - Refactored code with reduced complexity - New complexity measurements - Test validation results Format : Code transformations with complexity analysis, saved to .olaf/work/staging/code-evolution/ Examples \u00b6 Example 1: Nested Conditionals Refactoring \u00b6 Scenario : Method with deeply nested if-else statements (complexity: 18) Command : improve complexity Input : - target_code: [processOrder method with nested conditionals] - programming_language: \"Java\" - target_complexity: 8 Result : Refactored using Extract Method and Guard Clauses, reduced complexity from 18 to 7 Example 2: State-Based Complexity Reduction \u00b6 Scenario : Complex state machine logic (complexity: 25) Command : improve complexity Input : - target_code: [handleEvent method with state transitions] - programming_language: \"TypeScript\" - target_complexity: 10 Result : Applied State Pattern, extracted state classes, reduced complexity from 25 to 6 per method Related Competencies \u00b6 analyze-function-complexity : Use first to identify complex functions fix-code-smells : Apply for broader code quality improvements evolve-code-iteratively : Use for multi-iteration complexity reduction review-code : Validate complexity improvements augment-code-unit-test : Improve test coverage after refactoring Tips & Best Practices \u00b6 Measure complexity before and after refactoring Start with highest complexity methods first Use Extract Method as primary technique Apply design patterns for state-based complexity Ensure tests pass after each refactoring step Consider Guard Clauses for early returns Replace conditionals with polymorphism when appropriate Keep target complexity realistic (<10 is good goal) Limitations \u00b6 Some complexity is inherent to business logic Refactoring may increase number of methods/classes Interface restrictions may limit refactoring options Performance requirements may constrain approaches Requires good test coverage for safe refactoring","title":"Improve Cyclomatic Complexity"},{"location":"skills/improve-cyclomatic-complexity/description/#improve-cyclomatic-complexity","text":"Source : core/competencies/developer/prompts/improve-cyclomatic-complexity.md","title":"Improve Cyclomatic Complexity"},{"location":"skills/improve-cyclomatic-complexity/description/#overview","text":"Systematically reduce cyclomatic complexity of code sections while preserving functionality and improving maintainability. Provides phased refactoring approach with complexity measurement.","title":"Overview"},{"location":"skills/improve-cyclomatic-complexity/description/#purpose","text":"High cyclomatic complexity makes code difficult to understand, test, and maintain. This competency analyzes complex code, identifies root causes, and applies targeted refactoring techniques to reduce complexity while preserving behavior. It ensures changes are validated through testing and measured for improvement.","title":"Purpose"},{"location":"skills/improve-cyclomatic-complexity/description/#usage","text":"Command : improve complexity Protocol : Propose-Act When to Use : - When code complexity metrics exceed thresholds - During code review identifying complex methods - To improve code testability - When reducing technical debt - For making code more maintainable","title":"Usage"},{"location":"skills/improve-cyclomatic-complexity/description/#parameters","text":"","title":"Parameters"},{"location":"skills/improve-cyclomatic-complexity/description/#required-inputs","text":"target_code : The method/function with high cyclomatic complexity (include containing class/module and file location) programming_language : The programming language of the code","title":"Required Inputs"},{"location":"skills/improve-cyclomatic-complexity/description/#optional-inputs","text":"test_information : Available test information and coverage details interface_restrictions : Restrictions on changing interfaces/signatures performance_requirements : Performance constraints to consider compatibility_needs : Backward compatibility requirements target_complexity : Target cyclomatic complexity score (default: <10)","title":"Optional Inputs"},{"location":"skills/improve-cyclomatic-complexity/description/#context-requirements","text":"Code with high cyclomatic complexity Existing tests for validation Understanding of interface constraints","title":"Context Requirements"},{"location":"skills/improve-cyclomatic-complexity/description/#output","text":"Refactored code with reduced complexity and preserved functionality. Deliverables : - Current complexity assessment with score - Visual control flow representation - Root cause analysis of complexity - Phased refactoring strategy - Refactored code with reduced complexity - New complexity measurements - Test validation results Format : Code transformations with complexity analysis, saved to .olaf/work/staging/code-evolution/","title":"Output"},{"location":"skills/improve-cyclomatic-complexity/description/#examples","text":"","title":"Examples"},{"location":"skills/improve-cyclomatic-complexity/description/#example-1-nested-conditionals-refactoring","text":"Scenario : Method with deeply nested if-else statements (complexity: 18) Command : improve complexity Input : - target_code: [processOrder method with nested conditionals] - programming_language: \"Java\" - target_complexity: 8 Result : Refactored using Extract Method and Guard Clauses, reduced complexity from 18 to 7","title":"Example 1: Nested Conditionals Refactoring"},{"location":"skills/improve-cyclomatic-complexity/description/#example-2-state-based-complexity-reduction","text":"Scenario : Complex state machine logic (complexity: 25) Command : improve complexity Input : - target_code: [handleEvent method with state transitions] - programming_language: \"TypeScript\" - target_complexity: 10 Result : Applied State Pattern, extracted state classes, reduced complexity from 25 to 6 per method","title":"Example 2: State-Based Complexity Reduction"},{"location":"skills/improve-cyclomatic-complexity/description/#related-competencies","text":"analyze-function-complexity : Use first to identify complex functions fix-code-smells : Apply for broader code quality improvements evolve-code-iteratively : Use for multi-iteration complexity reduction review-code : Validate complexity improvements augment-code-unit-test : Improve test coverage after refactoring","title":"Related Competencies"},{"location":"skills/improve-cyclomatic-complexity/description/#tips-best-practices","text":"Measure complexity before and after refactoring Start with highest complexity methods first Use Extract Method as primary technique Apply design patterns for state-based complexity Ensure tests pass after each refactoring step Consider Guard Clauses for early returns Replace conditionals with polymorphism when appropriate Keep target complexity realistic (<10 is good goal)","title":"Tips &amp; Best Practices"},{"location":"skills/improve-cyclomatic-complexity/description/#limitations","text":"Some complexity is inherent to business logic Refactoring may increase number of methods/classes Interface restrictions may limit refactoring options Performance requirements may constrain approaches Requires good test coverage for safe refactoring","title":"Limitations"},{"location":"skills/improve-cyclomatic-complexity/tutorial/","text":"Step-by-Step Tutorial \u00b6 Improve Cyclomatic Complexity: Step-by-Step Tutorial How to Execute the \"Systematic Cyclomatic Complexity Reduction\" Workflow This tutorial shows exactly how to systematically reduce cyclomatic complexity of code sections while preserving functionality and improving maintainability using the OLAF developer competency's improve-cyclomatic-complexity functionality. Prerequisites \u00b6 OLAF framework properly installed and configured Code with high cyclomatic complexity to refactor Existing test suite for the complex code (recommended) Basic understanding of refactoring principles and complexity metrics Access to project files and testing capabilities Step-by-Step Instructions \u00b6 Step 1: Initiate Complexity Improvement Analysis \u00b6 [Brief description: Start the complexity reduction process by invoking the OLAF improve-cyclomatic-complexity competency] User Action: Open your terminal or OLAF interface Navigate to your project directory containing the complex code Execute the OLAF improve-cyclomatic-complexity competency using one of these methods: Direct invocation: olaf improve-cyclomatic-complexity Via aliases: olaf improve complexity , olaf reduce complexity , olaf cyclomatic OLAF Response: The system will prompt you to provide the required parameters for complexity analysis and reduction. Step 2: Provide Target Code and Requirements \u00b6 User Action: Specify the complex code and constraints for refactoring Required Parameters: - target_code: The method/function with high cyclomatic complexity (include location) - programming_language: The programming language of the code - test_information: Available test information and coverage details - interface_restrictions: Restrictions on changing interfaces/signatures (optional) - performance_requirements: Performance constraints to consider (optional) - compatibility_needs: Backward compatibility requirements (optional) - target_complexity: Target cyclomatic complexity score (default: <10) Provide Requirements/Parameters: target_code : [Example - we used \"OrderProcessingService.calculateTotalCost() in src/services/OrderService.java\"] programming_language : [Example - we used \"Java\"] test_information : [Example - we used \"Unit tests exist with 85% coverage, missing edge cases\"] interface_restrictions : [Example - we used \"Cannot change public method signature\"] performance_requirements : [Example - we used \"Must maintain sub-100ms execution time\"] target_complexity : [Example - we used \"8\"] (optional) Step 3: Current Complexity Assessment \u00b6 What OLAF Does: Estimates current cyclomatic complexity score Identifies all decision points (conditionals, loops, switch statements) Creates visual representation of control flow Pinpoints the most complex code sections Gets current timestamp for analysis reports You Should See: Detailed complexity breakdown with decision point analysis and control flow visualization Step 4: Test Coverage Evaluation and Root Cause Analysis \u00b6 What OLAF Does: Analyzes existing unit tests for the complex code Identifies untested paths and edge cases Documents baseline behavior for validation Analyzes root causes of complexity: Mixed levels of abstraction Multiple responsibilities in single method Deep nesting structures Complex boolean logic State-based complexity Error handling mixed with business logic You Should See: Test coverage report and detailed root cause analysis of complexity patterns Step 5: Refactoring Strategy Design and Implementation \u00b6 User Action: Review and approve the proposed refactoring strategy What OLAF Does: Develops phased approach to reduce complexity Prioritizes changes for maximum impact Selects appropriate refactoring techniques: Extract Methods/Functions Replace conditionals with polymorphism Introduce design patterns (Strategy, State, Command) Simplify boolean expressions Extract specialized classes/objects Implements refactoring in small, incremental steps Preserves existing behavior exactly You Should See: Detailed refactoring plan and step-by-step implementation with preserved functionality Step 6: Verification and Measurement \u00b6 What OLAF Does: Confirms all tests pass after refactoring Measures new complexity metrics Validates behavior preservation Assesses readability and testability improvements Generates comprehensive complexity-reduction report Saves all reports to work/staging/code-evolution/ You Should See: Before/after comparison with improved complexity metrics and verification results Verification Checklist \u00b6 \u2705 Current complexity assessed with decision point breakdown \u2705 Test coverage evaluated and gaps identified \u2705 Root causes of complexity analyzed and documented \u2705 Phased refactoring strategy developed and approved \u2705 Refactoring implemented with behavior preservation \u2705 All existing tests pass after refactoring \u2705 New complexity metrics measured and improved Troubleshooting \u00b6 If tests fail after refactoring: # Run specific test suite mvn test -Dtest=OrderServiceTest npm test -- OrderService.test.js pytest tests/test_order_service.py If complexity doesn't improve as expected: Review if all decision points were addressed Check for hidden complexity in extracted methods Verify that design patterns were applied correctly Consider additional refactoring techniques If refactoring breaks external interfaces: Revert changes and review interface restrictions Apply adapter pattern to maintain compatibility Consider internal refactoring only without interface changes Key Learning Points \u00b6 Incremental Approach: Complexity reduction works best with small, testable changes rather than large refactoring efforts Behavior Preservation: All existing functionality must be preserved exactly; refactoring changes structure, not behavior Test-Driven Safety: Comprehensive test coverage is essential before attempting complexity reduction Next Steps to Try \u00b6 Apply the refactoring strategy in phases as recommended Add additional test cases for uncovered paths identified during analysis Monitor complexity metrics in future development to prevent regression Use extracted methods and patterns as templates for similar complexity issues Expected Timeline \u00b6 Total complexity improvement time: 30-90 minutes (depending on complexity and code size) User input required: Code identification and constraints specification (5-10 minutes) OLAF analysis time: Complexity assessment, root cause analysis, and strategy design (15-30 minutes) Implementation verification: Refactoring execution and testing validation (10-50 minutes)","title":"Step-by-Step Tutorial"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#step-by-step-tutorial","text":"Improve Cyclomatic Complexity: Step-by-Step Tutorial How to Execute the \"Systematic Cyclomatic Complexity Reduction\" Workflow This tutorial shows exactly how to systematically reduce cyclomatic complexity of code sections while preserving functionality and improving maintainability using the OLAF developer competency's improve-cyclomatic-complexity functionality.","title":"Step-by-Step Tutorial"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#prerequisites","text":"OLAF framework properly installed and configured Code with high cyclomatic complexity to refactor Existing test suite for the complex code (recommended) Basic understanding of refactoring principles and complexity metrics Access to project files and testing capabilities","title":"Prerequisites"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#step-1-initiate-complexity-improvement-analysis","text":"[Brief description: Start the complexity reduction process by invoking the OLAF improve-cyclomatic-complexity competency] User Action: Open your terminal or OLAF interface Navigate to your project directory containing the complex code Execute the OLAF improve-cyclomatic-complexity competency using one of these methods: Direct invocation: olaf improve-cyclomatic-complexity Via aliases: olaf improve complexity , olaf reduce complexity , olaf cyclomatic OLAF Response: The system will prompt you to provide the required parameters for complexity analysis and reduction.","title":"Step 1: Initiate Complexity Improvement Analysis"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#step-2-provide-target-code-and-requirements","text":"User Action: Specify the complex code and constraints for refactoring Required Parameters: - target_code: The method/function with high cyclomatic complexity (include location) - programming_language: The programming language of the code - test_information: Available test information and coverage details - interface_restrictions: Restrictions on changing interfaces/signatures (optional) - performance_requirements: Performance constraints to consider (optional) - compatibility_needs: Backward compatibility requirements (optional) - target_complexity: Target cyclomatic complexity score (default: <10) Provide Requirements/Parameters: target_code : [Example - we used \"OrderProcessingService.calculateTotalCost() in src/services/OrderService.java\"] programming_language : [Example - we used \"Java\"] test_information : [Example - we used \"Unit tests exist with 85% coverage, missing edge cases\"] interface_restrictions : [Example - we used \"Cannot change public method signature\"] performance_requirements : [Example - we used \"Must maintain sub-100ms execution time\"] target_complexity : [Example - we used \"8\"] (optional)","title":"Step 2: Provide Target Code and Requirements"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#step-3-current-complexity-assessment","text":"What OLAF Does: Estimates current cyclomatic complexity score Identifies all decision points (conditionals, loops, switch statements) Creates visual representation of control flow Pinpoints the most complex code sections Gets current timestamp for analysis reports You Should See: Detailed complexity breakdown with decision point analysis and control flow visualization","title":"Step 3: Current Complexity Assessment"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#step-4-test-coverage-evaluation-and-root-cause-analysis","text":"What OLAF Does: Analyzes existing unit tests for the complex code Identifies untested paths and edge cases Documents baseline behavior for validation Analyzes root causes of complexity: Mixed levels of abstraction Multiple responsibilities in single method Deep nesting structures Complex boolean logic State-based complexity Error handling mixed with business logic You Should See: Test coverage report and detailed root cause analysis of complexity patterns","title":"Step 4: Test Coverage Evaluation and Root Cause Analysis"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#step-5-refactoring-strategy-design-and-implementation","text":"User Action: Review and approve the proposed refactoring strategy What OLAF Does: Develops phased approach to reduce complexity Prioritizes changes for maximum impact Selects appropriate refactoring techniques: Extract Methods/Functions Replace conditionals with polymorphism Introduce design patterns (Strategy, State, Command) Simplify boolean expressions Extract specialized classes/objects Implements refactoring in small, incremental steps Preserves existing behavior exactly You Should See: Detailed refactoring plan and step-by-step implementation with preserved functionality","title":"Step 5: Refactoring Strategy Design and Implementation"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#step-6-verification-and-measurement","text":"What OLAF Does: Confirms all tests pass after refactoring Measures new complexity metrics Validates behavior preservation Assesses readability and testability improvements Generates comprehensive complexity-reduction report Saves all reports to work/staging/code-evolution/ You Should See: Before/after comparison with improved complexity metrics and verification results","title":"Step 6: Verification and Measurement"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#verification-checklist","text":"\u2705 Current complexity assessed with decision point breakdown \u2705 Test coverage evaluated and gaps identified \u2705 Root causes of complexity analyzed and documented \u2705 Phased refactoring strategy developed and approved \u2705 Refactoring implemented with behavior preservation \u2705 All existing tests pass after refactoring \u2705 New complexity metrics measured and improved","title":"Verification Checklist"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#troubleshooting","text":"If tests fail after refactoring: # Run specific test suite mvn test -Dtest=OrderServiceTest npm test -- OrderService.test.js pytest tests/test_order_service.py If complexity doesn't improve as expected: Review if all decision points were addressed Check for hidden complexity in extracted methods Verify that design patterns were applied correctly Consider additional refactoring techniques If refactoring breaks external interfaces: Revert changes and review interface restrictions Apply adapter pattern to maintain compatibility Consider internal refactoring only without interface changes","title":"Troubleshooting"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#key-learning-points","text":"Incremental Approach: Complexity reduction works best with small, testable changes rather than large refactoring efforts Behavior Preservation: All existing functionality must be preserved exactly; refactoring changes structure, not behavior Test-Driven Safety: Comprehensive test coverage is essential before attempting complexity reduction","title":"Key Learning Points"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#next-steps-to-try","text":"Apply the refactoring strategy in phases as recommended Add additional test cases for uncovered paths identified during analysis Monitor complexity metrics in future development to prevent regression Use extracted methods and patterns as templates for similar complexity issues","title":"Next Steps to Try"},{"location":"skills/improve-cyclomatic-complexity/tutorial/#expected-timeline","text":"Total complexity improvement time: 30-90 minutes (depending on complexity and code size) User input required: Code identification and constraints specification (5-10 minutes) OLAF analysis time: Complexity assessment, root cause analysis, and strategy design (15-30 minutes) Implementation verification: Refactoring execution and testing validation (10-50 minutes)","title":"Expected Timeline"},{"location":"skills/improve-spec/description/","text":"Improve Spec \u00b6 Enhanced skill migrated from business-analyst competency. Usage \u00b6 This skill provides improve spec functionality with self-contained dependencies and enhanced error handling.","title":"Improve Spec"},{"location":"skills/improve-spec/description/#improve-spec","text":"Enhanced skill migrated from business-analyst competency.","title":"Improve Spec"},{"location":"skills/improve-spec/description/#usage","text":"This skill provides improve spec functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/improve-spec/tutorial/","text":"Improve Spec Tutorial \u00b6 Step-by-step guide for using the improve-spec skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Improve Spec Tutorial"},{"location":"skills/improve-spec/tutorial/#improve-spec-tutorial","text":"Step-by-step guide for using the improve-spec skill.","title":"Improve Spec Tutorial"},{"location":"skills/improve-spec/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/improve-spec/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/measure-ai-impact/description/","text":"Measure AI Impact - Skill Description \u00b6 Overview \u00b6 The measure-ai-impact skill provides data-driven insights into how AI-assisted development affects your codebase quality and team productivity. It combines two powerful analysis approaches: File-Level AI Detection : Uses Halstead complexity metrics and Maintainability Index changes to detect AI-generated code improvements Quarterly Trend Analysis : Tracks team productivity patterns over time to measure the impact of AI adoption Why This Matters \u00b6 As teams adopt AI coding assistants (like GitHub Copilot), understanding the actual impact on code quality and developer productivity becomes critical: Validate ROI : Measure tangible improvements from AI tool investments Identify Patterns : Understand which files/areas benefit most from AI assistance Track Progress : Monitor productivity trends as AI adoption increases Optimize Usage : Learn which types of tasks AI handles best Key Capabilities \u00b6 1. AI Signature Detection \u00b6 Analyzes code metrics before and after changes to identify AI-assisted improvements: Maintainability Index (MI) jumps >20 points Cyclomatic Complexity reductions Halstead Difficulty drops >30% Effort reductions >50% Example Use Case : \"Did we use AI to refactor our authentication module?\" 2. Quarterly Productivity Snapshots \u00b6 Generates time-series data showing team productivity evolution: Commits per day/week Code churn (LOC changed) Contributor activity patterns Session gaps and work patterns Example Use Case : \"How has our productivity changed since adopting Copilot in Q1 2025?\" 3. Baseline Comparison \u00b6 Creates historical snapshots for accurate before/after comparisons: Snapshot repository state at any point in time Compare current metrics against historical baselines Track long-term quality trends Example Use Case : \"Create a baseline snapshot before we start using AI tools\" How It Works \u00b6 Detection Methodology \u00b6 The skill uses Halstead Complexity Metrics , a well-established software science approach that measures: Program Vocabulary : Unique operators and operands Program Length : Total operators and operands Difficulty : How hard is the code to understand? Effort : Mental effort required to comprehend/modify code When AI refactors code, these metrics typically show dramatic improvements: - Lower difficulty \u2192 Simpler logic - Reduced effort \u2192 Easier maintenance - Higher MI \u2192 Better overall quality Productivity Analysis \u00b6 The skill analyzes Git commit history to extract: Temporal Patterns : When are developers most active? Velocity Trends : Are commits increasing/decreasing? Team Dynamics : How does contributor count affect output? Code Efficiency : LOC per commit trends By comparing quarters, you can correlate AI tool adoption with productivity changes. Analysis Modes \u00b6 Mode: file-analysis \u00b6 Purpose : Detect AI signatures in specific files When to Use : - After refactoring specific modules - Validating AI-assisted code improvements - Identifying which files benefited from AI Outputs : - AI likelihood scores per file - Detected improvement patterns - Before/after metrics comparison - Confidence ratings Mode: quarterly-trends \u00b6 Purpose : Track team-wide productivity over time When to Use : - Quarterly reviews and retrospectives - Measuring AI adoption impact - Identifying productivity trends - Team performance analysis Outputs : - Quarterly comparison dashboard - Productivity trend graphs - Contributor analysis - AI impact estimation Mode: snapshot \u00b6 Purpose : Create baseline for future comparison When to Use : - Before starting AI tool adoption - Quarterly checkpoints - Major refactoring milestones - Release benchmarks Outputs : - JSON snapshot file with all metrics - Summary statistics - Timestamp and Git reference Integration with OLAF Ecosystem \u00b6 This skill complements other OLAF skills: onboard-me : Use measure-ai-impact after onboarding to track quality improvements review-code : Combine with AI detection to validate review suggestions report-my-daily : Include AI impact metrics in daily reports Requirements \u00b6 Python 3.10+ : Required for analyzer scripts Git Repository : Must be run in a Git-tracked repository Radon Library : Optional but recommended for full Halstead metrics (install: pip install radon ) Git History : At least 6 months of commit history recommended for accurate baselines Limitations \u00b6 What This Skill CAN Do: \u00b6 \u2705 Detect statistical patterns consistent with AI-generated improvements \u2705 Track productivity trends over time \u2705 Compare code quality before/after changes \u2705 Estimate AI impact based on metrics correlation What This Skill CANNOT Do: \u00b6 \u274c Definitively prove code was written by AI (no 100% certainty) \u274c Detect AI usage in non-Python files (limited language support) \u274c Attribute specific commits to AI vs human \u274c Measure developer satisfaction or code correctness Accuracy Considerations: \u00b6 False Positives : Manual refactoring can also improve metrics False Negatives : Not all AI assistance produces detectable patterns Baseline Quality : Requires sufficient historical data Language Support : Best results with Python; partial support for other languages Example Workflows \u00b6 Workflow 1: Validate AI-Assisted Refactoring \u00b6 Before Refactoring : Create baseline snapshot @olaf measure-ai-impact mode:snapshot name:\"pre-refactor\" Perform Refactoring : Use AI to improve code quality After Refactoring : Analyze specific files @olaf measure-ai-impact mode:file-analysis files:[\"src/auth.py\", \"src/validator.py\"] Review Report : Check AI likelihood scores and metric improvements Workflow 2: Quarterly Team Review \u00b6 Generate Quarterly Snapshots : @olaf measure-ai-impact mode:quarterly-trends since:\"2024-01-01\" Compare Quarters : @olaf measure-ai-impact mode:quarterly-trends compare:[\"2024-Q4\", \"2025-Q1\"] Review Trends : Analyze productivity changes and AI correlation Adjust Strategy : Optimize AI tool usage based on findings Workflow 3: Repository Health Check \u00b6 Create Baseline : Snapshot current state Quarterly Analysis : Run trends every 3 months File Targeting : Identify low-MI files for AI assistance Validate Impact : Re-run file-analysis after improvements Output Locations \u00b6 All reports are saved to olaf-data/ai-impact/ : File Analysis Reports : ai-impact-file-analysis-[YYYYMMDD-HHmm].md Quarterly Trends : ai-impact-quarterly-trends-[YYYYMMDD-HHmm].md Snapshots : snapshots/snapshot-{name}.json Support \u00b6 For issues, questions, or feature requests: - See tutorial.md for step-by-step examples - Check analyzer tool documentation in skills/onboard/tools/commons/project-onboarding/ - Review OLAF core documentation Skill Version : 1.0.0 Last Updated : 2025-01-24 Maintainer : OLAF Framework","title":"Measure AI Impact - Skill Description"},{"location":"skills/measure-ai-impact/description/#measure-ai-impact-skill-description","text":"","title":"Measure AI Impact - Skill Description"},{"location":"skills/measure-ai-impact/description/#overview","text":"The measure-ai-impact skill provides data-driven insights into how AI-assisted development affects your codebase quality and team productivity. It combines two powerful analysis approaches: File-Level AI Detection : Uses Halstead complexity metrics and Maintainability Index changes to detect AI-generated code improvements Quarterly Trend Analysis : Tracks team productivity patterns over time to measure the impact of AI adoption","title":"Overview"},{"location":"skills/measure-ai-impact/description/#why-this-matters","text":"As teams adopt AI coding assistants (like GitHub Copilot), understanding the actual impact on code quality and developer productivity becomes critical: Validate ROI : Measure tangible improvements from AI tool investments Identify Patterns : Understand which files/areas benefit most from AI assistance Track Progress : Monitor productivity trends as AI adoption increases Optimize Usage : Learn which types of tasks AI handles best","title":"Why This Matters"},{"location":"skills/measure-ai-impact/description/#key-capabilities","text":"","title":"Key Capabilities"},{"location":"skills/measure-ai-impact/description/#1-ai-signature-detection","text":"Analyzes code metrics before and after changes to identify AI-assisted improvements: Maintainability Index (MI) jumps >20 points Cyclomatic Complexity reductions Halstead Difficulty drops >30% Effort reductions >50% Example Use Case : \"Did we use AI to refactor our authentication module?\"","title":"1. AI Signature Detection"},{"location":"skills/measure-ai-impact/description/#2-quarterly-productivity-snapshots","text":"Generates time-series data showing team productivity evolution: Commits per day/week Code churn (LOC changed) Contributor activity patterns Session gaps and work patterns Example Use Case : \"How has our productivity changed since adopting Copilot in Q1 2025?\"","title":"2. Quarterly Productivity Snapshots"},{"location":"skills/measure-ai-impact/description/#3-baseline-comparison","text":"Creates historical snapshots for accurate before/after comparisons: Snapshot repository state at any point in time Compare current metrics against historical baselines Track long-term quality trends Example Use Case : \"Create a baseline snapshot before we start using AI tools\"","title":"3. Baseline Comparison"},{"location":"skills/measure-ai-impact/description/#how-it-works","text":"","title":"How It Works"},{"location":"skills/measure-ai-impact/description/#detection-methodology","text":"The skill uses Halstead Complexity Metrics , a well-established software science approach that measures: Program Vocabulary : Unique operators and operands Program Length : Total operators and operands Difficulty : How hard is the code to understand? Effort : Mental effort required to comprehend/modify code When AI refactors code, these metrics typically show dramatic improvements: - Lower difficulty \u2192 Simpler logic - Reduced effort \u2192 Easier maintenance - Higher MI \u2192 Better overall quality","title":"Detection Methodology"},{"location":"skills/measure-ai-impact/description/#productivity-analysis","text":"The skill analyzes Git commit history to extract: Temporal Patterns : When are developers most active? Velocity Trends : Are commits increasing/decreasing? Team Dynamics : How does contributor count affect output? Code Efficiency : LOC per commit trends By comparing quarters, you can correlate AI tool adoption with productivity changes.","title":"Productivity Analysis"},{"location":"skills/measure-ai-impact/description/#analysis-modes","text":"","title":"Analysis Modes"},{"location":"skills/measure-ai-impact/description/#mode-file-analysis","text":"Purpose : Detect AI signatures in specific files When to Use : - After refactoring specific modules - Validating AI-assisted code improvements - Identifying which files benefited from AI Outputs : - AI likelihood scores per file - Detected improvement patterns - Before/after metrics comparison - Confidence ratings","title":"Mode: file-analysis"},{"location":"skills/measure-ai-impact/description/#mode-quarterly-trends","text":"Purpose : Track team-wide productivity over time When to Use : - Quarterly reviews and retrospectives - Measuring AI adoption impact - Identifying productivity trends - Team performance analysis Outputs : - Quarterly comparison dashboard - Productivity trend graphs - Contributor analysis - AI impact estimation","title":"Mode: quarterly-trends"},{"location":"skills/measure-ai-impact/description/#mode-snapshot","text":"Purpose : Create baseline for future comparison When to Use : - Before starting AI tool adoption - Quarterly checkpoints - Major refactoring milestones - Release benchmarks Outputs : - JSON snapshot file with all metrics - Summary statistics - Timestamp and Git reference","title":"Mode: snapshot"},{"location":"skills/measure-ai-impact/description/#integration-with-olaf-ecosystem","text":"This skill complements other OLAF skills: onboard-me : Use measure-ai-impact after onboarding to track quality improvements review-code : Combine with AI detection to validate review suggestions report-my-daily : Include AI impact metrics in daily reports","title":"Integration with OLAF Ecosystem"},{"location":"skills/measure-ai-impact/description/#requirements","text":"Python 3.10+ : Required for analyzer scripts Git Repository : Must be run in a Git-tracked repository Radon Library : Optional but recommended for full Halstead metrics (install: pip install radon ) Git History : At least 6 months of commit history recommended for accurate baselines","title":"Requirements"},{"location":"skills/measure-ai-impact/description/#limitations","text":"","title":"Limitations"},{"location":"skills/measure-ai-impact/description/#what-this-skill-can-do","text":"\u2705 Detect statistical patterns consistent with AI-generated improvements \u2705 Track productivity trends over time \u2705 Compare code quality before/after changes \u2705 Estimate AI impact based on metrics correlation","title":"What This Skill CAN Do:"},{"location":"skills/measure-ai-impact/description/#what-this-skill-cannot-do","text":"\u274c Definitively prove code was written by AI (no 100% certainty) \u274c Detect AI usage in non-Python files (limited language support) \u274c Attribute specific commits to AI vs human \u274c Measure developer satisfaction or code correctness","title":"What This Skill CANNOT Do:"},{"location":"skills/measure-ai-impact/description/#accuracy-considerations","text":"False Positives : Manual refactoring can also improve metrics False Negatives : Not all AI assistance produces detectable patterns Baseline Quality : Requires sufficient historical data Language Support : Best results with Python; partial support for other languages","title":"Accuracy Considerations:"},{"location":"skills/measure-ai-impact/description/#example-workflows","text":"","title":"Example Workflows"},{"location":"skills/measure-ai-impact/description/#workflow-1-validate-ai-assisted-refactoring","text":"Before Refactoring : Create baseline snapshot @olaf measure-ai-impact mode:snapshot name:\"pre-refactor\" Perform Refactoring : Use AI to improve code quality After Refactoring : Analyze specific files @olaf measure-ai-impact mode:file-analysis files:[\"src/auth.py\", \"src/validator.py\"] Review Report : Check AI likelihood scores and metric improvements","title":"Workflow 1: Validate AI-Assisted Refactoring"},{"location":"skills/measure-ai-impact/description/#workflow-2-quarterly-team-review","text":"Generate Quarterly Snapshots : @olaf measure-ai-impact mode:quarterly-trends since:\"2024-01-01\" Compare Quarters : @olaf measure-ai-impact mode:quarterly-trends compare:[\"2024-Q4\", \"2025-Q1\"] Review Trends : Analyze productivity changes and AI correlation Adjust Strategy : Optimize AI tool usage based on findings","title":"Workflow 2: Quarterly Team Review"},{"location":"skills/measure-ai-impact/description/#workflow-3-repository-health-check","text":"Create Baseline : Snapshot current state Quarterly Analysis : Run trends every 3 months File Targeting : Identify low-MI files for AI assistance Validate Impact : Re-run file-analysis after improvements","title":"Workflow 3: Repository Health Check"},{"location":"skills/measure-ai-impact/description/#output-locations","text":"All reports are saved to olaf-data/ai-impact/ : File Analysis Reports : ai-impact-file-analysis-[YYYYMMDD-HHmm].md Quarterly Trends : ai-impact-quarterly-trends-[YYYYMMDD-HHmm].md Snapshots : snapshots/snapshot-{name}.json","title":"Output Locations"},{"location":"skills/measure-ai-impact/description/#support","text":"For issues, questions, or feature requests: - See tutorial.md for step-by-step examples - Check analyzer tool documentation in skills/onboard/tools/commons/project-onboarding/ - Review OLAF core documentation Skill Version : 1.0.0 Last Updated : 2025-01-24 Maintainer : OLAF Framework","title":"Support"},{"location":"skills/measure-ai-impact/tutorial/","text":"Measure AI Impact - Tutorial \u00b6 This tutorial walks you through practical examples of using the measure-ai-impact skill to analyze AI's impact on your codebase. Prerequisites \u00b6 Before starting, ensure: \u2705 You're in a Git repository \u2705 Python 3.10+ is installed \u2705 You have at least 6 months of commit history (recommended) \u2705 Radon library is installed (optional): pip install radon Tutorial 1: Detect AI Usage in Specific Files \u00b6 Scenario \u00b6 You used GitHub Copilot to refactor src/auth.py and src/validator.py last week. You want to confirm the AI actually improved code quality. Steps \u00b6 1. Invoke the Skill \u00b6 @olaf measure-ai-impact mode:file-analysis files:[\"src/auth.py\", \"src/validator.py\"] 2. What Happens \u00b6 The skill will: 1. \u2705 Validate repository and file paths 2. \u2705 Extract baseline metrics from 6 months ago 3. \u2705 Calculate current metrics from working directory 4. \u2705 Run AI signature detection 5. \u2705 Generate detailed comparison report 3. Review the Report \u00b6 Open the generated report at olaf-data/ai-impact/ai-impact-file-analysis-[timestamp].md : ### File: `src/auth.py` **AI Likelihood**: 0.87 (High) **Detection Indicators**: - \u2713 MI_JUMP_SIGNIFICANT: Maintainability Index increased by 35 points - \u2713 DIFFICULTY_DROP_MAJOR: Halstead Difficulty decreased by 42% - \u2713 EFFORT_REDUCTION: Halstead Effort reduced by 68% **Metrics Comparison**: | Metric | Before | After | Change | Impact | |--------|--------|-------|--------|--------| | Maintainability Index | 42 | 77 | +35 | \u2705 Excellent | | Cyclomatic Complexity | 18 | 9 | -50% | \u2705 Improved | | Halstead Difficulty | 28.4 | 16.5 | -42% | \u2705 Simplified | | Halstead Effort | 18500 | 5900 | -68% | \u2705 Optimized | 4. Interpretation \u00b6 High AI Likelihood (0.87) : Very confident AI was used All indicators present : Strong evidence of AI-assisted refactoring Metrics improved dramatically : Code is now easier to understand and maintain Key Takeaways \u00b6 \u2705 auth.py was likely improved using AI \u2705 Quality metrics show significant improvement \u2705 Code is now more maintainable Tutorial 2: Track Quarterly Productivity Trends \u00b6 Scenario \u00b6 Your team started using GitHub Copilot in January 2025 (Q1). It's now the end of Q1, and you want to measure productivity impact. Steps \u00b6 1. Generate Quarterly Snapshots \u00b6 @olaf measure-ai-impact mode:quarterly-trends since:\"2024-01-01\" 2. What Happens \u00b6 The skill will: 1. \u2705 Analyze Git commit history from 2024-01-01 to present 2. \u2705 Generate snapshots for each quarter (2024-Q1, Q2, Q3, Q4, 2025-Q1) 3. \u2705 Calculate productivity metrics per quarter 4. \u2705 Identify trends and AI correlation 3. Review the Report \u00b6 Open olaf-data/ai-impact/ai-impact-quarterly-trends-[timestamp].md : ## Productivity Overview | Quarter | Commits | Code Churn | Commits/Day | Contributors | |---------|---------|------------|-------------|--------------| | 2024-Q4 | 150 | 12,000 LOC | 2.3 | 5 | | 2025-Q1 | 210 | 18,500 LOC | 3.2 | 5 | ### Key Trends - \u2705 Commits increased by 40% in Q1 2025 - \u2705 Code churn up 54% (more code produced) - \u2705 Daily commit rate improved from 2.3 \u2192 3.2 (+39%) - \u26a0\ufe0f Contributor count stable (AI adoption, not team growth) ### Estimated AI Impact **Assessment**: High (Confident) Based on: - Productivity spike in Q1 2025 (AI adoption quarter) - Increased velocity without team size change - Commit patterns consistent with AI-assisted development 4. Compare Specific Quarters \u00b6 For deeper analysis: @olaf measure-ai-impact mode:quarterly-trends compare:[\"2024-Q4\", \"2025-Q1\"] This generates a detailed comparison: ### 2024-Q4 vs 2025-Q1 | Metric | 2024-Q4 | 2025-Q1 | Change | Trend | |--------|---------|---------|--------|-------| | Commits | 150 | 210 | +60 (+40%) | \u2197 | | Code Churn | 12K | 18.5K | +6.5K (+54%) | \u2197 | | Commits/Day | 2.3 | 3.2 | +0.9 (+39%) | \u2197 | | LOC/Commit | 80 | 88 | +8 (+10%) | \u2197 | Key Takeaways \u00b6 \u2705 Productivity increased significantly in Q1 2025 \u2705 AI adoption likely contributed to 39% improvement in daily commits \u2705 Code velocity up without team expansion Tutorial 3: Create Baseline for Future Comparison \u00b6 Scenario \u00b6 You're about to introduce AI tools to your team next month. You want a baseline snapshot to measure future impact. Steps \u00b6 1. Create Baseline Snapshot \u00b6 @olaf measure-ai-impact mode:snapshot name:\"baseline-pre-ai\" 2. What Happens \u00b6 The skill will: 1. \u2705 Collect current repository metrics 2. \u2705 Save snapshot JSON file 3. \u2705 Display summary Output: # Snapshot Created: baseline-pre-ai **Timestamp**: 2025-01-24 14:30:00 **Git Commit**: a3f7d9c **Total Files**: 125 **Total LOC**: 45,000 **Metrics Collected**: - Maintainability Index (avg): 58 - Cyclomatic Complexity (avg): 12 - Halstead Difficulty (avg): 22.5 - Commit activity (last 90 days): 85 commits **Snapshot saved**: olaf-data/ai-impact/snapshots/snapshot-baseline-pre-ai.json 3. Use Baseline Later \u00b6 Three months later, after AI adoption: @olaf measure-ai-impact mode:file-analysis baseline_date:\"baseline-pre-ai\" files:[\"src/**/*.py\"] The skill will compare current state against your pre-AI baseline. Key Takeaways \u00b6 \u2705 Baseline snapshot created for future comparison \u2705 Can measure AI impact accurately using historical data \u2705 JSON file preserves all metrics for long-term analysis Tutorial 4: Identify Files Needing AI Assistance \u00b6 Scenario \u00b6 You want to find files with low maintainability that could benefit from AI-assisted refactoring. Steps \u00b6 1. Run File Analysis on All Python Files \u00b6 @olaf measure-ai-impact mode:file-analysis files:[\"src/**/*.py\"] 2. Review Recommendations Section \u00b6 The report includes: ## Suggested Next Targets for AI Assistance - `src/legacy_parser.py` - Current MI: 32 - Complexity: 28 - `src/old_validator.py` - Current MI: 41 - Complexity: 22 - `src/data_processor.py` - Current MI: 38 - Complexity: 19 3. Refactor with AI \u00b6 Use GitHub Copilot or similar tools to refactor legacy_parser.py . 4. Validate Improvement \u00b6 @olaf measure-ai-impact mode:file-analysis files:[\"src/legacy_parser.py\"] Expected result: ### File: `src/legacy_parser.py` **AI Likelihood**: 0.92 (High) **Metrics Comparison**: | Metric | Before | After | Change | |--------|--------|-------|--------| | Maintainability Index | 32 | 68 | +36 \u2705 | | Cyclomatic Complexity | 28 | 12 | -57% \u2705 | Key Takeaways \u00b6 \u2705 Identified low-quality files systematically \u2705 Validated AI improvements with metrics \u2705 Iteratively improved codebase quality Tutorial 5: Quarterly Review Workflow \u00b6 Scenario \u00b6 Every quarter, you want to generate a standard AI impact report for leadership. Standard Workflow \u00b6 End of Each Quarter (e.g., March 31) \u00b6 Step 1 : Generate quarterly snapshot @olaf measure-ai-impact mode:quarterly-trends since:\"2024-01-01\" Step 2 : Compare current quarter vs previous @olaf measure-ai-impact mode:quarterly-trends compare:[\"2024-Q4\", \"2025-Q1\"] Step 3 : Create checkpoint snapshot @olaf measure-ai-impact mode:snapshot name:\"2025-Q1-checkpoint\" Step 4 : Review and share reports File analysis: olaf-data/ai-impact/ai-impact-quarterly-trends-[timestamp].md Snapshot: olaf-data/ai-impact/snapshots/snapshot-2025-Q1-checkpoint.json Automation (Optional) \u00b6 Add to your CI/CD or scheduled tasks: # End-of-quarter automation (PowerShell) $quarter = \"2025-Q1\" python skills/onboard/tools/commons/project-onboarding/git_productivity_analyzer.py snapshots --since 2024-01-01 python skills/onboard/tools/commons/project-onboarding/ai_impact_analyzer.py snapshot --name $quarter Common Patterns \u00b6 Pattern 1: Before/After Validation \u00b6 Use Case : Validate AI-assisted changes # Before refactoring @olaf measure-ai-impact mode:snapshot name:\"before-refactor\" # [Perform AI refactoring] # After refactoring @olaf measure-ai-impact mode:file-analysis baseline_date:\"before-refactor\" Pattern 2: Team Retrospective \u00b6 Use Case : Quarterly team review # Generate trends @olaf measure-ai-impact mode:quarterly-trends since:\"2024-01-01\" # Compare specific quarters @olaf measure-ai-impact mode:quarterly-trends compare:[\"2024-Q3\", \"2024-Q4\"] Pattern 3: Continuous Monitoring \u00b6 Use Case : Track ongoing AI impact # Monthly snapshots @olaf measure-ai-impact mode:snapshot name:\"2025-01-monthly\" # Quarterly full analysis @olaf measure-ai-impact mode:quarterly-trends Troubleshooting \u00b6 Issue: \"No baseline data available\" \u00b6 Solution : Create a snapshot first: @olaf measure-ai-impact mode:snapshot name:\"baseline\" Issue: \"Halstead metrics unavailable\" \u00b6 Solution : Install Radon library: pip install radon Or use limited mode: @olaf measure-ai-impact mode:snapshot include_halstead:false Issue: \"Invalid quarter format\" \u00b6 Solution : Use correct format: YYYY-QN (e.g., 2025-Q1 , 2024-Q4 ) Issue: \"Not a Git repository\" \u00b6 Solution : Run from repository root with .git folder Next Steps \u00b6 After completing these tutorials: \u2705 Create a baseline snapshot for your repository \u2705 Set up quarterly review schedule \u2705 Identify low-MI files for AI assistance \u2705 Track AI impact over time For advanced usage, see: - description.md - Full capability reference - Analyzer tool documentation - Technical details Tutorial Version : 1.0.0 Last Updated : 2025-01-24","title":"Measure AI Impact - Tutorial"},{"location":"skills/measure-ai-impact/tutorial/#measure-ai-impact-tutorial","text":"This tutorial walks you through practical examples of using the measure-ai-impact skill to analyze AI's impact on your codebase.","title":"Measure AI Impact - Tutorial"},{"location":"skills/measure-ai-impact/tutorial/#prerequisites","text":"Before starting, ensure: \u2705 You're in a Git repository \u2705 Python 3.10+ is installed \u2705 You have at least 6 months of commit history (recommended) \u2705 Radon library is installed (optional): pip install radon","title":"Prerequisites"},{"location":"skills/measure-ai-impact/tutorial/#tutorial-1-detect-ai-usage-in-specific-files","text":"","title":"Tutorial 1: Detect AI Usage in Specific Files"},{"location":"skills/measure-ai-impact/tutorial/#scenario","text":"You used GitHub Copilot to refactor src/auth.py and src/validator.py last week. You want to confirm the AI actually improved code quality.","title":"Scenario"},{"location":"skills/measure-ai-impact/tutorial/#steps","text":"","title":"Steps"},{"location":"skills/measure-ai-impact/tutorial/#1-invoke-the-skill","text":"@olaf measure-ai-impact mode:file-analysis files:[\"src/auth.py\", \"src/validator.py\"]","title":"1. Invoke the Skill"},{"location":"skills/measure-ai-impact/tutorial/#2-what-happens","text":"The skill will: 1. \u2705 Validate repository and file paths 2. \u2705 Extract baseline metrics from 6 months ago 3. \u2705 Calculate current metrics from working directory 4. \u2705 Run AI signature detection 5. \u2705 Generate detailed comparison report","title":"2. What Happens"},{"location":"skills/measure-ai-impact/tutorial/#3-review-the-report","text":"Open the generated report at olaf-data/ai-impact/ai-impact-file-analysis-[timestamp].md : ### File: `src/auth.py` **AI Likelihood**: 0.87 (High) **Detection Indicators**: - \u2713 MI_JUMP_SIGNIFICANT: Maintainability Index increased by 35 points - \u2713 DIFFICULTY_DROP_MAJOR: Halstead Difficulty decreased by 42% - \u2713 EFFORT_REDUCTION: Halstead Effort reduced by 68% **Metrics Comparison**: | Metric | Before | After | Change | Impact | |--------|--------|-------|--------|--------| | Maintainability Index | 42 | 77 | +35 | \u2705 Excellent | | Cyclomatic Complexity | 18 | 9 | -50% | \u2705 Improved | | Halstead Difficulty | 28.4 | 16.5 | -42% | \u2705 Simplified | | Halstead Effort | 18500 | 5900 | -68% | \u2705 Optimized |","title":"3. Review the Report"},{"location":"skills/measure-ai-impact/tutorial/#4-interpretation","text":"High AI Likelihood (0.87) : Very confident AI was used All indicators present : Strong evidence of AI-assisted refactoring Metrics improved dramatically : Code is now easier to understand and maintain","title":"4. Interpretation"},{"location":"skills/measure-ai-impact/tutorial/#key-takeaways","text":"\u2705 auth.py was likely improved using AI \u2705 Quality metrics show significant improvement \u2705 Code is now more maintainable","title":"Key Takeaways"},{"location":"skills/measure-ai-impact/tutorial/#tutorial-2-track-quarterly-productivity-trends","text":"","title":"Tutorial 2: Track Quarterly Productivity Trends"},{"location":"skills/measure-ai-impact/tutorial/#scenario_1","text":"Your team started using GitHub Copilot in January 2025 (Q1). It's now the end of Q1, and you want to measure productivity impact.","title":"Scenario"},{"location":"skills/measure-ai-impact/tutorial/#steps_1","text":"","title":"Steps"},{"location":"skills/measure-ai-impact/tutorial/#1-generate-quarterly-snapshots","text":"@olaf measure-ai-impact mode:quarterly-trends since:\"2024-01-01\"","title":"1. Generate Quarterly Snapshots"},{"location":"skills/measure-ai-impact/tutorial/#2-what-happens_1","text":"The skill will: 1. \u2705 Analyze Git commit history from 2024-01-01 to present 2. \u2705 Generate snapshots for each quarter (2024-Q1, Q2, Q3, Q4, 2025-Q1) 3. \u2705 Calculate productivity metrics per quarter 4. \u2705 Identify trends and AI correlation","title":"2. What Happens"},{"location":"skills/measure-ai-impact/tutorial/#3-review-the-report_1","text":"Open olaf-data/ai-impact/ai-impact-quarterly-trends-[timestamp].md : ## Productivity Overview | Quarter | Commits | Code Churn | Commits/Day | Contributors | |---------|---------|------------|-------------|--------------| | 2024-Q4 | 150 | 12,000 LOC | 2.3 | 5 | | 2025-Q1 | 210 | 18,500 LOC | 3.2 | 5 | ### Key Trends - \u2705 Commits increased by 40% in Q1 2025 - \u2705 Code churn up 54% (more code produced) - \u2705 Daily commit rate improved from 2.3 \u2192 3.2 (+39%) - \u26a0\ufe0f Contributor count stable (AI adoption, not team growth) ### Estimated AI Impact **Assessment**: High (Confident) Based on: - Productivity spike in Q1 2025 (AI adoption quarter) - Increased velocity without team size change - Commit patterns consistent with AI-assisted development","title":"3. Review the Report"},{"location":"skills/measure-ai-impact/tutorial/#4-compare-specific-quarters","text":"For deeper analysis: @olaf measure-ai-impact mode:quarterly-trends compare:[\"2024-Q4\", \"2025-Q1\"] This generates a detailed comparison: ### 2024-Q4 vs 2025-Q1 | Metric | 2024-Q4 | 2025-Q1 | Change | Trend | |--------|---------|---------|--------|-------| | Commits | 150 | 210 | +60 (+40%) | \u2197 | | Code Churn | 12K | 18.5K | +6.5K (+54%) | \u2197 | | Commits/Day | 2.3 | 3.2 | +0.9 (+39%) | \u2197 | | LOC/Commit | 80 | 88 | +8 (+10%) | \u2197 |","title":"4. Compare Specific Quarters"},{"location":"skills/measure-ai-impact/tutorial/#key-takeaways_1","text":"\u2705 Productivity increased significantly in Q1 2025 \u2705 AI adoption likely contributed to 39% improvement in daily commits \u2705 Code velocity up without team expansion","title":"Key Takeaways"},{"location":"skills/measure-ai-impact/tutorial/#tutorial-3-create-baseline-for-future-comparison","text":"","title":"Tutorial 3: Create Baseline for Future Comparison"},{"location":"skills/measure-ai-impact/tutorial/#scenario_2","text":"You're about to introduce AI tools to your team next month. You want a baseline snapshot to measure future impact.","title":"Scenario"},{"location":"skills/measure-ai-impact/tutorial/#steps_2","text":"","title":"Steps"},{"location":"skills/measure-ai-impact/tutorial/#1-create-baseline-snapshot","text":"@olaf measure-ai-impact mode:snapshot name:\"baseline-pre-ai\"","title":"1. Create Baseline Snapshot"},{"location":"skills/measure-ai-impact/tutorial/#2-what-happens_2","text":"The skill will: 1. \u2705 Collect current repository metrics 2. \u2705 Save snapshot JSON file 3. \u2705 Display summary Output: # Snapshot Created: baseline-pre-ai **Timestamp**: 2025-01-24 14:30:00 **Git Commit**: a3f7d9c **Total Files**: 125 **Total LOC**: 45,000 **Metrics Collected**: - Maintainability Index (avg): 58 - Cyclomatic Complexity (avg): 12 - Halstead Difficulty (avg): 22.5 - Commit activity (last 90 days): 85 commits **Snapshot saved**: olaf-data/ai-impact/snapshots/snapshot-baseline-pre-ai.json","title":"2. What Happens"},{"location":"skills/measure-ai-impact/tutorial/#3-use-baseline-later","text":"Three months later, after AI adoption: @olaf measure-ai-impact mode:file-analysis baseline_date:\"baseline-pre-ai\" files:[\"src/**/*.py\"] The skill will compare current state against your pre-AI baseline.","title":"3. Use Baseline Later"},{"location":"skills/measure-ai-impact/tutorial/#key-takeaways_2","text":"\u2705 Baseline snapshot created for future comparison \u2705 Can measure AI impact accurately using historical data \u2705 JSON file preserves all metrics for long-term analysis","title":"Key Takeaways"},{"location":"skills/measure-ai-impact/tutorial/#tutorial-4-identify-files-needing-ai-assistance","text":"","title":"Tutorial 4: Identify Files Needing AI Assistance"},{"location":"skills/measure-ai-impact/tutorial/#scenario_3","text":"You want to find files with low maintainability that could benefit from AI-assisted refactoring.","title":"Scenario"},{"location":"skills/measure-ai-impact/tutorial/#steps_3","text":"","title":"Steps"},{"location":"skills/measure-ai-impact/tutorial/#1-run-file-analysis-on-all-python-files","text":"@olaf measure-ai-impact mode:file-analysis files:[\"src/**/*.py\"]","title":"1. Run File Analysis on All Python Files"},{"location":"skills/measure-ai-impact/tutorial/#2-review-recommendations-section","text":"The report includes: ## Suggested Next Targets for AI Assistance - `src/legacy_parser.py` - Current MI: 32 - Complexity: 28 - `src/old_validator.py` - Current MI: 41 - Complexity: 22 - `src/data_processor.py` - Current MI: 38 - Complexity: 19","title":"2. Review Recommendations Section"},{"location":"skills/measure-ai-impact/tutorial/#3-refactor-with-ai","text":"Use GitHub Copilot or similar tools to refactor legacy_parser.py .","title":"3. Refactor with AI"},{"location":"skills/measure-ai-impact/tutorial/#4-validate-improvement","text":"@olaf measure-ai-impact mode:file-analysis files:[\"src/legacy_parser.py\"] Expected result: ### File: `src/legacy_parser.py` **AI Likelihood**: 0.92 (High) **Metrics Comparison**: | Metric | Before | After | Change | |--------|--------|-------|--------| | Maintainability Index | 32 | 68 | +36 \u2705 | | Cyclomatic Complexity | 28 | 12 | -57% \u2705 |","title":"4. Validate Improvement"},{"location":"skills/measure-ai-impact/tutorial/#key-takeaways_3","text":"\u2705 Identified low-quality files systematically \u2705 Validated AI improvements with metrics \u2705 Iteratively improved codebase quality","title":"Key Takeaways"},{"location":"skills/measure-ai-impact/tutorial/#tutorial-5-quarterly-review-workflow","text":"","title":"Tutorial 5: Quarterly Review Workflow"},{"location":"skills/measure-ai-impact/tutorial/#scenario_4","text":"Every quarter, you want to generate a standard AI impact report for leadership.","title":"Scenario"},{"location":"skills/measure-ai-impact/tutorial/#standard-workflow","text":"","title":"Standard Workflow"},{"location":"skills/measure-ai-impact/tutorial/#end-of-each-quarter-eg-march-31","text":"Step 1 : Generate quarterly snapshot @olaf measure-ai-impact mode:quarterly-trends since:\"2024-01-01\" Step 2 : Compare current quarter vs previous @olaf measure-ai-impact mode:quarterly-trends compare:[\"2024-Q4\", \"2025-Q1\"] Step 3 : Create checkpoint snapshot @olaf measure-ai-impact mode:snapshot name:\"2025-Q1-checkpoint\" Step 4 : Review and share reports File analysis: olaf-data/ai-impact/ai-impact-quarterly-trends-[timestamp].md Snapshot: olaf-data/ai-impact/snapshots/snapshot-2025-Q1-checkpoint.json","title":"End of Each Quarter (e.g., March 31)"},{"location":"skills/measure-ai-impact/tutorial/#automation-optional","text":"Add to your CI/CD or scheduled tasks: # End-of-quarter automation (PowerShell) $quarter = \"2025-Q1\" python skills/onboard/tools/commons/project-onboarding/git_productivity_analyzer.py snapshots --since 2024-01-01 python skills/onboard/tools/commons/project-onboarding/ai_impact_analyzer.py snapshot --name $quarter","title":"Automation (Optional)"},{"location":"skills/measure-ai-impact/tutorial/#common-patterns","text":"","title":"Common Patterns"},{"location":"skills/measure-ai-impact/tutorial/#pattern-1-beforeafter-validation","text":"Use Case : Validate AI-assisted changes # Before refactoring @olaf measure-ai-impact mode:snapshot name:\"before-refactor\" # [Perform AI refactoring] # After refactoring @olaf measure-ai-impact mode:file-analysis baseline_date:\"before-refactor\"","title":"Pattern 1: Before/After Validation"},{"location":"skills/measure-ai-impact/tutorial/#pattern-2-team-retrospective","text":"Use Case : Quarterly team review # Generate trends @olaf measure-ai-impact mode:quarterly-trends since:\"2024-01-01\" # Compare specific quarters @olaf measure-ai-impact mode:quarterly-trends compare:[\"2024-Q3\", \"2024-Q4\"]","title":"Pattern 2: Team Retrospective"},{"location":"skills/measure-ai-impact/tutorial/#pattern-3-continuous-monitoring","text":"Use Case : Track ongoing AI impact # Monthly snapshots @olaf measure-ai-impact mode:snapshot name:\"2025-01-monthly\" # Quarterly full analysis @olaf measure-ai-impact mode:quarterly-trends","title":"Pattern 3: Continuous Monitoring"},{"location":"skills/measure-ai-impact/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/measure-ai-impact/tutorial/#issue-no-baseline-data-available","text":"Solution : Create a snapshot first: @olaf measure-ai-impact mode:snapshot name:\"baseline\"","title":"Issue: \"No baseline data available\""},{"location":"skills/measure-ai-impact/tutorial/#issue-halstead-metrics-unavailable","text":"Solution : Install Radon library: pip install radon Or use limited mode: @olaf measure-ai-impact mode:snapshot include_halstead:false","title":"Issue: \"Halstead metrics unavailable\""},{"location":"skills/measure-ai-impact/tutorial/#issue-invalid-quarter-format","text":"Solution : Use correct format: YYYY-QN (e.g., 2025-Q1 , 2024-Q4 )","title":"Issue: \"Invalid quarter format\""},{"location":"skills/measure-ai-impact/tutorial/#issue-not-a-git-repository","text":"Solution : Run from repository root with .git folder","title":"Issue: \"Not a Git repository\""},{"location":"skills/measure-ai-impact/tutorial/#next-steps","text":"After completing these tutorials: \u2705 Create a baseline snapshot for your repository \u2705 Set up quarterly review schedule \u2705 Identify low-MI files for AI assistance \u2705 Track AI impact over time For advanced usage, see: - description.md - Full capability reference - Analyzer tool documentation - Technical details Tutorial Version : 1.0.0 Last Updated : 2025-01-24","title":"Next Steps"},{"location":"skills/merge-branch-with-safety/description/","text":"Merge Branch With Safety \u00b6 Enhanced skill migrated from git-assistant competency. Usage \u00b6 This skill provides merge branch with safety functionality with self-contained dependencies and enhanced error handling.","title":"Merge Branch With Safety"},{"location":"skills/merge-branch-with-safety/description/#merge-branch-with-safety","text":"Enhanced skill migrated from git-assistant competency.","title":"Merge Branch With Safety"},{"location":"skills/merge-branch-with-safety/description/#usage","text":"This skill provides merge branch with safety functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/merge-branch-with-safety/tutorial/","text":"Merge Branch With Safety Tutorial \u00b6 Step-by-step guide for using the merge-branch-with-safety skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Merge Branch With Safety Tutorial"},{"location":"skills/merge-branch-with-safety/tutorial/#merge-branch-with-safety-tutorial","text":"Step-by-step guide for using the merge-branch-with-safety skill.","title":"Merge Branch With Safety Tutorial"},{"location":"skills/merge-branch-with-safety/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/merge-branch-with-safety/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/onboard-me/description/","text":"Onboard Me - Skill Description \u00b6 Overview \u00b6 The onboard-me skill generates persona-focused quick start guides that help new team members become productive in 30 minutes. It analyzes any repository and creates tailored onboarding documentation for different developer roles (Frontend, Backend, QA, DevOps, etc.). Purpose \u00b6 New team members often face overwhelming documentation or none at all. This skill: - Analyzes repository structure, tech stack, and build systems automatically - Detects relevant developer personas based on technologies used - Generates focused, actionable quick start guides for each persona - Provides concrete \"first task\" examples to build confidence Key Features \u00b6 Automatic Analysis : Scans repository to extract languages, frameworks, entry points, and commands Persona Detection : Identifies 3-6 relevant developer roles based on tech stack 30-Minute Guides : Each guide is structured to get someone productive in half an hour Practical Focus : Includes setup, build, key files, and a first coding task Universal : Works with any programming language or framework When to Use \u00b6 Use this skill when: - Onboarding new team members to a codebase - Creating developer documentation for a new repository - Migrating teams to a new project - Improving existing onboarding materials - You need quick start guides for multiple developer personas Typical Output \u00b6 For a TypeScript/React + Python/FastAPI project, generates: - QUICKSTART-FRONTEND-DEVELOPER.md - QUICKSTART-BACKEND-DEVELOPER.md - QUICKSTART-QA-ENGINEER.md - QUICKSTART-DEVOPS-ENGINEER.md - QUICKSTART-ARCHITECT.md - QUICKSTART-OVERVIEW.md (linked index of all guides) Each guide contains: - What you'll build (concrete goal) - 5-min setup instructions - 5-min build & run verification - 10-min code walkthrough - 10-min first change exercise - Common tasks reference Benefits \u00b6 Reduces onboarding time from days to hours Persona-specific content eliminates irrelevant information Actionable tasks build confidence through immediate success Consistent format across all repositories Maintainable generated from code analysis, stays up-to-date Skill Type \u00b6 Protocol : Act Exposure : Export Status : Mainstream","title":"Onboard Me - Skill Description"},{"location":"skills/onboard-me/description/#onboard-me-skill-description","text":"","title":"Onboard Me - Skill Description"},{"location":"skills/onboard-me/description/#overview","text":"The onboard-me skill generates persona-focused quick start guides that help new team members become productive in 30 minutes. It analyzes any repository and creates tailored onboarding documentation for different developer roles (Frontend, Backend, QA, DevOps, etc.).","title":"Overview"},{"location":"skills/onboard-me/description/#purpose","text":"New team members often face overwhelming documentation or none at all. This skill: - Analyzes repository structure, tech stack, and build systems automatically - Detects relevant developer personas based on technologies used - Generates focused, actionable quick start guides for each persona - Provides concrete \"first task\" examples to build confidence","title":"Purpose"},{"location":"skills/onboard-me/description/#key-features","text":"Automatic Analysis : Scans repository to extract languages, frameworks, entry points, and commands Persona Detection : Identifies 3-6 relevant developer roles based on tech stack 30-Minute Guides : Each guide is structured to get someone productive in half an hour Practical Focus : Includes setup, build, key files, and a first coding task Universal : Works with any programming language or framework","title":"Key Features"},{"location":"skills/onboard-me/description/#when-to-use","text":"Use this skill when: - Onboarding new team members to a codebase - Creating developer documentation for a new repository - Migrating teams to a new project - Improving existing onboarding materials - You need quick start guides for multiple developer personas","title":"When to Use"},{"location":"skills/onboard-me/description/#typical-output","text":"For a TypeScript/React + Python/FastAPI project, generates: - QUICKSTART-FRONTEND-DEVELOPER.md - QUICKSTART-BACKEND-DEVELOPER.md - QUICKSTART-QA-ENGINEER.md - QUICKSTART-DEVOPS-ENGINEER.md - QUICKSTART-ARCHITECT.md - QUICKSTART-OVERVIEW.md (linked index of all guides) Each guide contains: - What you'll build (concrete goal) - 5-min setup instructions - 5-min build & run verification - 10-min code walkthrough - 10-min first change exercise - Common tasks reference","title":"Typical Output"},{"location":"skills/onboard-me/description/#benefits","text":"Reduces onboarding time from days to hours Persona-specific content eliminates irrelevant information Actionable tasks build confidence through immediate success Consistent format across all repositories Maintainable generated from code analysis, stays up-to-date","title":"Benefits"},{"location":"skills/onboard-me/description/#skill-type","text":"Protocol : Act Exposure : Export Status : Mainstream","title":"Skill Type"},{"location":"skills/onboard-me/tutorial/","text":"Onboard Me - Tutorial \u00b6 Quick Start \u00b6 Basic Usage \u00b6 olaf onboard me This will: 1. Analyze the current repository 2. Detect relevant developer personas 3. Generate persona-focused quick start guides 4. Create an overview index file Example Session \u00b6 You: olaf onboard me Copilot: [*] Analyzing repository... [*] Detected: TypeScript/React frontend + Python/FastAPI backend [*] Identified personas: Frontend Developer, Backend Developer, QA Engineer, Architect [*] Generating guides... \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-FRONTEND-DEVELOPER.md \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-BACKEND-DEVELOPER.md \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-QA-ENGINEER.md \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-ARCHITECT.md \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-OVERVIEW.md Onboarding guides ready! Share QUICKSTART-OVERVIEW.md with new team members. Step-by-Step Guide \u00b6 Step 1: Run Analysis \u00b6 The skill automatically runs the repository analyzer: # From anywhere (recommended): run the analyzer from where the skill is installed, # and write output into the target repo. python <path-to-onboard-me>/tools/analyze-repository.py <repo-path> --output <repo-path>/.olaf/work/onboard-me # If you are running from the haal-skills repo root, <path-to-onboard-me> is `onboard-me`: python onboard-me/tools/analyze-repository.py <repo-path> --output <repo-path>/.olaf/work/onboard-me This extracts: - Languages and frameworks - Build tools and commands - Entry points and key files - Project structure - Testing setup Step 2: Persona Detection \u00b6 Based on the analysis, the skill detects relevant personas: Always Included: - Architect (overview & patterns) - Business Analyst (features & workflows) - QA Engineer (if tests exist) - Docs Contributor Technology-Specific: - Frontend Developer (React/Vue/Angular/Next.js) - Backend Developer (FastAPI/Django/Flask/Go APIs) - Mobile Developer (Kotlin/Swift/React Native) - CLI Tool Developer (CLI frameworks) - DevOps Engineer (Docker/K8s/Terraform) - Data Engineer (pandas/Spark/ML frameworks) - VS Code Extension Developer Step 3: Guide Generation \u00b6 For each persona, generates a structured guide: 1. What You'll Build (Goal) - Concrete, achievable task relevant to persona 2. Setup (5 min) - Clone, install dependencies - Environment setup 3. Build & Run (5 min) - Build commands - Run/start commands - Verification steps 4. Understand the Code (10 min) - Key files for this persona - Relevant directories - Architecture diagrams (when needed) 5. Make Your First Change (10 min) - Specific file to modify - Exact changes to make - Test commands to verify 6. Common Tasks - Frequently needed commands - Development workflows - Troubleshooting tips Step 4: Output \u00b6 Guides are saved to: .olaf/data/product/context/<repo-name>/ \u251c\u2500\u2500 QUICKSTART-OVERVIEW.md \u251c\u2500\u2500 QUICKSTART-FRONTEND-DEVELOPER.md \u251c\u2500\u2500 QUICKSTART-BACKEND-DEVELOPER.md \u251c\u2500\u2500 QUICKSTART-QA-ENGINEER.md \u2514\u2500\u2500 ... Advanced Usage \u00b6 Analyze Specific Repository \u00b6 olaf onboard me /path/to/other/repo Customize Output Location \u00b6 Edit the prompt or analyzer script to change output directory (default: .olaf/data/product/context/<repo-name>/ ) Re-run Analysis \u00b6 Simply run olaf onboard me again - it will regenerate all guides with updated information (overwriting existing QUICKSTART-*.md files in place). Understanding the Output \u00b6 QUICKSTART-OVERVIEW.md \u00b6 Index file listing all generated guides with: - Quick links to each persona guide (Markdown links) - Repository overview - General setup instructions Each persona guide also includes a \"Back to Overview\" link at the top for easy navigation. Persona Guides \u00b6 Each QUICKSTART-<PERSONA>.md contains: - 30-minute structure : Designed for immediate productivity - Concrete examples : Actual file paths and commands from your repo - First task : Safe, testable modification to build confidence - Common tasks : Copy-paste ready commands for daily work Tips & Best Practices \u00b6 For Repository Owners \u00b6 Keep setup simple : Ensure install/build commands work on fresh clone Document entry points : Clear main files help the analyzer Include tests : Enables QA Engineer persona generation Use standard tools : Standard package managers detected automatically For New Team Members \u00b6 Start with OVERVIEW : Get the big picture first Pick your persona : Use the guide matching your role Follow the 30-min plan : Complete sections in order Do the first task : Builds confidence with a quick win Bookmark common tasks : Reference section saves time daily For Maintainers \u00b6 Regenerate periodically : Run when build process changes Validate guides : Test with actual new team members Customize if needed : Guides are markdown, easy to edit Share OVERVIEW link : Perfect for README or onboarding docs Common Scenarios \u00b6 Scenario 1: Monorepo \u00b6 The analyzer detects multiple modules and generates personas for each tech stack found. Scenario 2: Legacy Codebase \u00b6 Even without modern build tools, the skill extracts structure and creates guides based on detected patterns. Scenario 3: Multiple Languages \u00b6 Generates personas for each language ecosystem (e.g., Frontend + Backend + Data Pipeline). Scenario 4: Microservices \u00b6 Run on each service repository or on parent repo - adapts to structure. Troubleshooting \u00b6 No personas detected? - Ensure repository has source code files (not just config) - Check that .git directory exists (for analysis) Missing commands in guides? - Verify package.json , requirements.txt , go.mod , etc. exist - Standard build files help the analyzer find commands Guides too generic? - More structured code = better analysis - Clear entry points improve quality - Standard project layout helps detection Next Steps \u00b6 After generating guides: Review : Check accuracy of detected tech stack Test : Have a new team member try a guide Refine : Edit generated markdown if needed Share : Add link to OVERVIEW in your README Maintain : Regenerate when major changes occur","title":"Onboard Me - Tutorial"},{"location":"skills/onboard-me/tutorial/#onboard-me-tutorial","text":"","title":"Onboard Me - Tutorial"},{"location":"skills/onboard-me/tutorial/#quick-start","text":"","title":"Quick Start"},{"location":"skills/onboard-me/tutorial/#basic-usage","text":"olaf onboard me This will: 1. Analyze the current repository 2. Detect relevant developer personas 3. Generate persona-focused quick start guides 4. Create an overview index file","title":"Basic Usage"},{"location":"skills/onboard-me/tutorial/#example-session","text":"You: olaf onboard me Copilot: [*] Analyzing repository... [*] Detected: TypeScript/React frontend + Python/FastAPI backend [*] Identified personas: Frontend Developer, Backend Developer, QA Engineer, Architect [*] Generating guides... \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-FRONTEND-DEVELOPER.md \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-BACKEND-DEVELOPER.md \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-QA-ENGINEER.md \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-ARCHITECT.md \u2713 Created: .olaf/data/product/context/my-app/QUICKSTART-OVERVIEW.md Onboarding guides ready! Share QUICKSTART-OVERVIEW.md with new team members.","title":"Example Session"},{"location":"skills/onboard-me/tutorial/#step-by-step-guide","text":"","title":"Step-by-Step Guide"},{"location":"skills/onboard-me/tutorial/#step-1-run-analysis","text":"The skill automatically runs the repository analyzer: # From anywhere (recommended): run the analyzer from where the skill is installed, # and write output into the target repo. python <path-to-onboard-me>/tools/analyze-repository.py <repo-path> --output <repo-path>/.olaf/work/onboard-me # If you are running from the haal-skills repo root, <path-to-onboard-me> is `onboard-me`: python onboard-me/tools/analyze-repository.py <repo-path> --output <repo-path>/.olaf/work/onboard-me This extracts: - Languages and frameworks - Build tools and commands - Entry points and key files - Project structure - Testing setup","title":"Step 1: Run Analysis"},{"location":"skills/onboard-me/tutorial/#step-2-persona-detection","text":"Based on the analysis, the skill detects relevant personas: Always Included: - Architect (overview & patterns) - Business Analyst (features & workflows) - QA Engineer (if tests exist) - Docs Contributor Technology-Specific: - Frontend Developer (React/Vue/Angular/Next.js) - Backend Developer (FastAPI/Django/Flask/Go APIs) - Mobile Developer (Kotlin/Swift/React Native) - CLI Tool Developer (CLI frameworks) - DevOps Engineer (Docker/K8s/Terraform) - Data Engineer (pandas/Spark/ML frameworks) - VS Code Extension Developer","title":"Step 2: Persona Detection"},{"location":"skills/onboard-me/tutorial/#step-3-guide-generation","text":"For each persona, generates a structured guide: 1. What You'll Build (Goal) - Concrete, achievable task relevant to persona 2. Setup (5 min) - Clone, install dependencies - Environment setup 3. Build & Run (5 min) - Build commands - Run/start commands - Verification steps 4. Understand the Code (10 min) - Key files for this persona - Relevant directories - Architecture diagrams (when needed) 5. Make Your First Change (10 min) - Specific file to modify - Exact changes to make - Test commands to verify 6. Common Tasks - Frequently needed commands - Development workflows - Troubleshooting tips","title":"Step 3: Guide Generation"},{"location":"skills/onboard-me/tutorial/#step-4-output","text":"Guides are saved to: .olaf/data/product/context/<repo-name>/ \u251c\u2500\u2500 QUICKSTART-OVERVIEW.md \u251c\u2500\u2500 QUICKSTART-FRONTEND-DEVELOPER.md \u251c\u2500\u2500 QUICKSTART-BACKEND-DEVELOPER.md \u251c\u2500\u2500 QUICKSTART-QA-ENGINEER.md \u2514\u2500\u2500 ...","title":"Step 4: Output"},{"location":"skills/onboard-me/tutorial/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/onboard-me/tutorial/#analyze-specific-repository","text":"olaf onboard me /path/to/other/repo","title":"Analyze Specific Repository"},{"location":"skills/onboard-me/tutorial/#customize-output-location","text":"Edit the prompt or analyzer script to change output directory (default: .olaf/data/product/context/<repo-name>/ )","title":"Customize Output Location"},{"location":"skills/onboard-me/tutorial/#re-run-analysis","text":"Simply run olaf onboard me again - it will regenerate all guides with updated information (overwriting existing QUICKSTART-*.md files in place).","title":"Re-run Analysis"},{"location":"skills/onboard-me/tutorial/#understanding-the-output","text":"","title":"Understanding the Output"},{"location":"skills/onboard-me/tutorial/#quickstart-overviewmd","text":"Index file listing all generated guides with: - Quick links to each persona guide (Markdown links) - Repository overview - General setup instructions Each persona guide also includes a \"Back to Overview\" link at the top for easy navigation.","title":"QUICKSTART-OVERVIEW.md"},{"location":"skills/onboard-me/tutorial/#persona-guides","text":"Each QUICKSTART-<PERSONA>.md contains: - 30-minute structure : Designed for immediate productivity - Concrete examples : Actual file paths and commands from your repo - First task : Safe, testable modification to build confidence - Common tasks : Copy-paste ready commands for daily work","title":"Persona Guides"},{"location":"skills/onboard-me/tutorial/#tips-best-practices","text":"","title":"Tips &amp; Best Practices"},{"location":"skills/onboard-me/tutorial/#for-repository-owners","text":"Keep setup simple : Ensure install/build commands work on fresh clone Document entry points : Clear main files help the analyzer Include tests : Enables QA Engineer persona generation Use standard tools : Standard package managers detected automatically","title":"For Repository Owners"},{"location":"skills/onboard-me/tutorial/#for-new-team-members","text":"Start with OVERVIEW : Get the big picture first Pick your persona : Use the guide matching your role Follow the 30-min plan : Complete sections in order Do the first task : Builds confidence with a quick win Bookmark common tasks : Reference section saves time daily","title":"For New Team Members"},{"location":"skills/onboard-me/tutorial/#for-maintainers","text":"Regenerate periodically : Run when build process changes Validate guides : Test with actual new team members Customize if needed : Guides are markdown, easy to edit Share OVERVIEW link : Perfect for README or onboarding docs","title":"For Maintainers"},{"location":"skills/onboard-me/tutorial/#common-scenarios","text":"","title":"Common Scenarios"},{"location":"skills/onboard-me/tutorial/#scenario-1-monorepo","text":"The analyzer detects multiple modules and generates personas for each tech stack found.","title":"Scenario 1: Monorepo"},{"location":"skills/onboard-me/tutorial/#scenario-2-legacy-codebase","text":"Even without modern build tools, the skill extracts structure and creates guides based on detected patterns.","title":"Scenario 2: Legacy Codebase"},{"location":"skills/onboard-me/tutorial/#scenario-3-multiple-languages","text":"Generates personas for each language ecosystem (e.g., Frontend + Backend + Data Pipeline).","title":"Scenario 3: Multiple Languages"},{"location":"skills/onboard-me/tutorial/#scenario-4-microservices","text":"Run on each service repository or on parent repo - adapts to structure.","title":"Scenario 4: Microservices"},{"location":"skills/onboard-me/tutorial/#troubleshooting","text":"No personas detected? - Ensure repository has source code files (not just config) - Check that .git directory exists (for analysis) Missing commands in guides? - Verify package.json , requirements.txt , go.mod , etc. exist - Standard build files help the analyzer find commands Guides too generic? - More structured code = better analysis - Clear entry points improve quality - Standard project layout helps detection","title":"Troubleshooting"},{"location":"skills/onboard-me/tutorial/#next-steps","text":"After generating guides: Review : Check accuracy of detected tech stack Test : Have a new team member try a guide Refine : Edit generated markdown if needed Share : Add link to OVERVIEW in your README Maintain : Regenerate when major changes occur","title":"Next Steps"},{"location":"skills/plan-db-api-remediation/description/","text":"Skill: Plan DB API Remediation \u00b6 This skill translates a DB\u2194API fit analysis into a decision-driven delivery impact summary and (when needed) a phased remediation plan. It is intended to be used after analyze-db-api-fit , when mismatches are known but stakeholders need a clear decision path based on delivery constraints and impact to existing users.","title":"Skill: Plan DB API Remediation"},{"location":"skills/plan-db-api-remediation/description/#skill-plan-db-api-remediation","text":"This skill translates a DB\u2194API fit analysis into a decision-driven delivery impact summary and (when needed) a phased remediation plan. It is intended to be used after analyze-db-api-fit , when mismatches are known but stakeholders need a clear decision path based on delivery constraints and impact to existing users.","title":"Skill: Plan DB API Remediation"},{"location":"skills/plan-db-api-remediation/tutorial/","text":"Tutorial: Plan DB\u2194API Remediation \u00b6 1) Prerequisites \u00b6 You should have: - docs/specifications/<demand_folder>/04-specifications/ (functional spec + OpenAPI) - docs/specifications/<demand_folder>/05-data-fit-analysis/ (a DB\u2194API fit report) 2) Run the skill (first pass) \u00b6 @[/olaf-plan-db-api-remediation] demand_folder: <demand_folder> plan_mode: initial previous_data_fit_analysis_path: <path-to-data-fit-analysis> The skill will: - Summarize mismatches in delivery/user-impact terms - Ask SME/PO questions about must-have vs can-drop - Draft a phased remediation plan if scope is not reduced - Propose an output file under docs/specifications/<demand_folder>/06-delivery-impact/ 3) Run follow-up (after answers) \u00b6 @[/olaf-plan-db-api-remediation] demand_folder: <demand_folder> plan_mode: followup previous_data_fit_analysis_path: <path-to-data-fit-analysis> previous_plan_path: <path-to-previous-delivery-impact-plan>","title":"Tutorial: Plan DB\u2194API Remediation"},{"location":"skills/plan-db-api-remediation/tutorial/#tutorial-plan-dbapi-remediation","text":"","title":"Tutorial: Plan DB\u2194API Remediation"},{"location":"skills/plan-db-api-remediation/tutorial/#1-prerequisites","text":"You should have: - docs/specifications/<demand_folder>/04-specifications/ (functional spec + OpenAPI) - docs/specifications/<demand_folder>/05-data-fit-analysis/ (a DB\u2194API fit report)","title":"1) Prerequisites"},{"location":"skills/plan-db-api-remediation/tutorial/#2-run-the-skill-first-pass","text":"@[/olaf-plan-db-api-remediation] demand_folder: <demand_folder> plan_mode: initial previous_data_fit_analysis_path: <path-to-data-fit-analysis> The skill will: - Summarize mismatches in delivery/user-impact terms - Ask SME/PO questions about must-have vs can-drop - Draft a phased remediation plan if scope is not reduced - Propose an output file under docs/specifications/<demand_folder>/06-delivery-impact/","title":"2) Run the skill (first pass)"},{"location":"skills/plan-db-api-remediation/tutorial/#3-run-follow-up-after-answers","text":"@[/olaf-plan-db-api-remediation] demand_folder: <demand_folder> plan_mode: followup previous_data_fit_analysis_path: <path-to-data-fit-analysis> previous_plan_path: <path-to-previous-delivery-impact-plan>","title":"3) Run follow-up (after answers)"},{"location":"skills/propose-commit-thread/description/","text":"Propose Commit Thread \u00b6 Overview \u00b6 Analyzes your git changes, intelligently clusters them into logical commits, and executes a commit thread with interactive modification capabilities and GitHub issue integration. This competency transforms messy working directory changes into a clean, well-organized commit history. Purpose \u00b6 Developers often accumulate many changes across multiple files before committing, making it difficult to create a clean, logical commit history. This competency solves the problem by: - Automatically analyzing and categorizing all changes - Clustering related changes into coherent commits - Matching commits with relevant GitHub issues - Providing interactive modification before execution - Maintaining clean git history with detailed commit messages Usage \u00b6 Command : propose commit thread (or aliases: propose commit , commit thread , smart commit , cluster commits , interactive commit , staged commit , organize commits , commit workflow ) Protocol : Propose-Confirm-Act When to Use : Use this when you have multiple uncommitted changes that should be organized into separate logical commits rather than one large commit. Ideal for feature development sessions where you've modified multiple components, or when you want to maintain clean git history with focused commits. Parameters \u00b6 Required Inputs \u00b6 repository_path : Path to git repository (defaults to current working directory) Optional Inputs \u00b6 include_github_issues : Check for related GitHub issues (default: true) commit_strategy : \"granular\" or \"feature-based\" clustering (default: \"feature-based\") auto_execute : Execute commits automatically after approval (default: false) Context Requirements \u00b6 Valid git repository Uncommitted changes in working directory GitHub CLI installed (optional, for issue integration) Clean working directory (no merge conflicts) Commit permissions on repository Output \u00b6 Deliverables : - Structured commit proposal with interactive modification options - Executed commit sequence in logical order - Updated GitHub issues with commit references (if enabled) - Clean working directory after execution - Detailed git log with organized commit history Format : - Interactive markdown proposal with user commands - Git commits with detailed multi-line messages - GitHub issue updates with commit links Examples \u00b6 Example 1: Feature Development Session \u00b6 Scenario : You've spent the day building a new API endpoint, updating tests, and adding documentation. You have 15 modified files and want to organize them into logical commits. Command : olaf propose commit thread Analysis Result : Proposed Commit Thread: Commit 1: Add user profile API endpoint Files: src/api/profile.js, src/routes/profile.js Related Issue: #142 - User profile management Commit 2: Add profile endpoint tests Files: tests/api/profile.test.js, tests/fixtures/users.json Commit 3: Update API documentation Files: docs/api-reference.md, README.md Commit 4: Update configuration for new endpoint Files: config/routes.json, config/permissions.json Interactive Modification : User: merge 1,2 [Commits 1 and 2 combined into single commit] User: 3a [Commit 3 approved] User: execute [All approved commits executed] Result : - 3 well-organized commits created - Issue #142 updated with commit references - Clean git history ready for push Example 2: Bug Fix with Multiple Components \u00b6 Scenario : You fixed a validation bug that required changes to utility functions, middleware, and tests. Command : olaf propose commit thread Result : - Commit 1: Fix validation logic in utilities - Commit 2: Update middleware to use fixed validation - Commit 3: Add regression tests for validation bug - All commits linked to bug tracking issue Related Competencies \u00b6 create-feature-for-pr : Use this after organizing commits to extract feature for PR merge-branch-with-safety : Use this to safely merge organized commits to target branch developer/review-code : Use this to review changes before committing Tips & Best Practices \u00b6 Use \"feature-based\" clustering for most development work (groups related functionality) Use \"granular\" clustering when you need very detailed commit history Review the proposed commit sequence carefully before executing Modify commit messages to add context that the AI might miss Split large commits if they contain multiple logical changes Enable GitHub issue integration to maintain traceability Commit infrastructure changes separately from business logic Use descriptive commit messages following conventional commits format Limitations \u00b6 Requires clean working directory (no merge conflicts) GitHub issue integration requires GitHub CLI installation Cannot automatically resolve complex file dependencies Commit clustering is based on heuristics and may need manual adjustment Does not support interactive rebase of existing commits Cannot modify already committed history","title":"Propose Commit Thread"},{"location":"skills/propose-commit-thread/description/#propose-commit-thread","text":"","title":"Propose Commit Thread"},{"location":"skills/propose-commit-thread/description/#overview","text":"Analyzes your git changes, intelligently clusters them into logical commits, and executes a commit thread with interactive modification capabilities and GitHub issue integration. This competency transforms messy working directory changes into a clean, well-organized commit history.","title":"Overview"},{"location":"skills/propose-commit-thread/description/#purpose","text":"Developers often accumulate many changes across multiple files before committing, making it difficult to create a clean, logical commit history. This competency solves the problem by: - Automatically analyzing and categorizing all changes - Clustering related changes into coherent commits - Matching commits with relevant GitHub issues - Providing interactive modification before execution - Maintaining clean git history with detailed commit messages","title":"Purpose"},{"location":"skills/propose-commit-thread/description/#usage","text":"Command : propose commit thread (or aliases: propose commit , commit thread , smart commit , cluster commits , interactive commit , staged commit , organize commits , commit workflow ) Protocol : Propose-Confirm-Act When to Use : Use this when you have multiple uncommitted changes that should be organized into separate logical commits rather than one large commit. Ideal for feature development sessions where you've modified multiple components, or when you want to maintain clean git history with focused commits.","title":"Usage"},{"location":"skills/propose-commit-thread/description/#parameters","text":"","title":"Parameters"},{"location":"skills/propose-commit-thread/description/#required-inputs","text":"repository_path : Path to git repository (defaults to current working directory)","title":"Required Inputs"},{"location":"skills/propose-commit-thread/description/#optional-inputs","text":"include_github_issues : Check for related GitHub issues (default: true) commit_strategy : \"granular\" or \"feature-based\" clustering (default: \"feature-based\") auto_execute : Execute commits automatically after approval (default: false)","title":"Optional Inputs"},{"location":"skills/propose-commit-thread/description/#context-requirements","text":"Valid git repository Uncommitted changes in working directory GitHub CLI installed (optional, for issue integration) Clean working directory (no merge conflicts) Commit permissions on repository","title":"Context Requirements"},{"location":"skills/propose-commit-thread/description/#output","text":"Deliverables : - Structured commit proposal with interactive modification options - Executed commit sequence in logical order - Updated GitHub issues with commit references (if enabled) - Clean working directory after execution - Detailed git log with organized commit history Format : - Interactive markdown proposal with user commands - Git commits with detailed multi-line messages - GitHub issue updates with commit links","title":"Output"},{"location":"skills/propose-commit-thread/description/#examples","text":"","title":"Examples"},{"location":"skills/propose-commit-thread/description/#example-1-feature-development-session","text":"Scenario : You've spent the day building a new API endpoint, updating tests, and adding documentation. You have 15 modified files and want to organize them into logical commits. Command : olaf propose commit thread Analysis Result : Proposed Commit Thread: Commit 1: Add user profile API endpoint Files: src/api/profile.js, src/routes/profile.js Related Issue: #142 - User profile management Commit 2: Add profile endpoint tests Files: tests/api/profile.test.js, tests/fixtures/users.json Commit 3: Update API documentation Files: docs/api-reference.md, README.md Commit 4: Update configuration for new endpoint Files: config/routes.json, config/permissions.json Interactive Modification : User: merge 1,2 [Commits 1 and 2 combined into single commit] User: 3a [Commit 3 approved] User: execute [All approved commits executed] Result : - 3 well-organized commits created - Issue #142 updated with commit references - Clean git history ready for push","title":"Example 1: Feature Development Session"},{"location":"skills/propose-commit-thread/description/#example-2-bug-fix-with-multiple-components","text":"Scenario : You fixed a validation bug that required changes to utility functions, middleware, and tests. Command : olaf propose commit thread Result : - Commit 1: Fix validation logic in utilities - Commit 2: Update middleware to use fixed validation - Commit 3: Add regression tests for validation bug - All commits linked to bug tracking issue","title":"Example 2: Bug Fix with Multiple Components"},{"location":"skills/propose-commit-thread/description/#related-competencies","text":"create-feature-for-pr : Use this after organizing commits to extract feature for PR merge-branch-with-safety : Use this to safely merge organized commits to target branch developer/review-code : Use this to review changes before committing","title":"Related Competencies"},{"location":"skills/propose-commit-thread/description/#tips-best-practices","text":"Use \"feature-based\" clustering for most development work (groups related functionality) Use \"granular\" clustering when you need very detailed commit history Review the proposed commit sequence carefully before executing Modify commit messages to add context that the AI might miss Split large commits if they contain multiple logical changes Enable GitHub issue integration to maintain traceability Commit infrastructure changes separately from business logic Use descriptive commit messages following conventional commits format","title":"Tips &amp; Best Practices"},{"location":"skills/propose-commit-thread/description/#limitations","text":"Requires clean working directory (no merge conflicts) GitHub issue integration requires GitHub CLI installation Cannot automatically resolve complex file dependencies Commit clustering is based on heuristics and may need manual adjustment Does not support interactive rebase of existing commits Cannot modify already committed history","title":"Limitations"},{"location":"skills/propose-commit-thread/tutorial/","text":"Propose Commit Thread: Step-by-Step Tutorial \u00b6 How to Execute the \"Analyze Git Changes and Create Smart Commit Sequences\" \u00b6 This tutorial shows exactly how to reproduce the intelligent commit clustering workflow for organizing changes into logical, coherent commits with GitHub issue integration. Prerequisites \u00b6 Git installed and configured on your system Repository with uncommitted changes ready for analysis GitHub CLI installed (optional, for issue integration) Write permissions to the repository Understanding of your project's feature/component structure Step-by-Step Instructions \u00b6 Step 1: Initiate Commit Analysis \u00b6 [This step starts the OLAF commit analysis workflow] User Action: Invoke the propose-commit-thread competency in OLAF Navigate to your repository with pending changes Ensure git status shows files ready for commit organization OLAF Response: You should see OLAF validate the repository state and begin analyzing all uncommitted changes for intelligent clustering. Step 2: Provide Analysis Parameters \u00b6 User Action: Specify analysis preferences when prompted Repository path: [current directory or specify path] Include GitHub issues integration? (y/n): [your choice] Commit strategy (granular/feature-based): [your preference] Auto-execute after approval? (y/n): [recommended: no] Provide Analysis Configuration: Repository Path : Path to git repository (defaults to current directory) GitHub Issues : Enable to link commits with related open issues Commit Strategy : Choose between granular (file-by-file) or feature-based clustering Auto Execute : Keep false for safety - allows review before execution Step 3: Change Analysis and Categorization \u00b6 What OLAF Does: Executes git status --porcelain for machine-readable status Categorizes files by git status (Modified, Added, Deleted, Renamed, etc.) Analyzes git diff for each file to understand change scope Groups related files by functionality, dependencies, and components Scans for GitHub issues if integration enabled You Should See: Comprehensive analysis of all changes with file categorization and initial clustering proposals Step 4: GitHub Issues Integration \u00b6 What OLAF Does (if enabled): Retrieves open GitHub issues using gh issue list Extracts keywords from your changes (file names, functions, classes) Matches potential issues by title keywords and labels Correlates changes with bug reports, enhancements, or features You Should See: List of potentially related GitHub issues with relevance scores and suggested associations Step 5: Interactive Commit Proposal \u00b6 User Action: Review the structured commit thread proposal # \ud83d\udccb Proposed Commit Thread - YYYYMMDD-HHmm ## Repository Analysis **Repository**: your-repo-name **Branch**: current-branch **Files Changed**: X (Y untracked, Z modified, W staged) ## \ud83c\udfaf Proposed Commit Sequence ### Commit 1: Feature Implementation **Files** (3): - src/feature/main.js (Modified) - src/feature/helper.js (Added) **Commit Message**: feat: implement user authentication feature - Add main authentication logic - Create helper utilities for token validation **Related GitHub Issues**: #42 - User Login System **\ud83d\udc64 User Actions Available:** - \u2705 APPROVE: Accept this commit as proposed - \ud83d\udd04 MODIFY: Change commit message or file grouping - \u2795 SPLIT: Break into smaller commits - \u2796 MERGE: Combine with another commit - \u274c SKIP: Don't commit these changes now Available Interactive Commands: 1a = Approve commit 1 1m = Modify commit 1 1s = Split commit 1 merge 1,2 = Merge commits 1 and 2 skip 1 = Skip commit 1 execute = Execute all approved commits Step 6: Interactive Modification Phase \u00b6 User Action: Use commands to refine commit organization Modification Operations: Message Edit : Update commit title and description File Regrouping : Move files between commit clusters Commit Splitting : Break large commits into focused smaller ones Commit Merging : Combine related commits for cleaner history Issue Association : Link/unlink GitHub issues Real-time Updates: OLAF provides immediate feedback as you modify the commit structure, ensuring consistency and preventing conflicts. Step 7: Final Approval and Execution \u00b6 User Action: Execute the final commit sequence execute What OLAF Does: For each approved commit (in logical order): Stage specified files: git add [file_list] Create commit with detailed message: git commit -m \"[commit_message]\" Update related GitHub issues with commit reference Verify commit success before proceeding GitHub Integration: Add commit references to related issues Update issue labels based on commit types Close issues if commit messages include closing keywords You Should See: Step-by-step execution with confirmation of each successful commit and issue integration results Verification Checklist \u00b6 \u2705 All intended files committed (git log shows proper commit sequence) \u2705 Logical commit organization (each commit has coherent purpose and scope) \u2705 Detailed commit messages (follows conventional commits with bullet points) \u2705 GitHub issues updated (commits referenced in related issues) \u2705 Clean working directory (git status shows no remaining uncommitted changes) \u2705 Git history integrity (no conflicts or broken dependencies between commits) Troubleshooting \u00b6 If not a git repository: Error: Not a valid git repository Navigate to correct directory containing .git folder Initialize repository with git init if needed If merge conflicts present: OLAF will stop and require resolution before proceeding Resolve conflicts manually using git mergetool or editor Re-run the competency after conflicts are resolved If GitHub CLI not available: OLAF will skip GitHub integration and proceed with git-only workflow Install GitHub CLI with gh auth login for issue integration Alternative: manually reference issues in commit messages If commit permission denied: Verify you have write access to the repository Check if branch is protected and requires specific permissions Ensure proper Git configuration with valid author information Key Learning Points \u00b6 Intelligent Clustering: Changes are grouped by logical relationships rather than arbitrary file selection Interactive Refinement: Full control over commit organization with real-time modification capabilities GitHub Integration: Automatic linking between commits and project issues for better project tracking Safety First: Propose-Confirm-Act protocol prevents accidental commits and allows thorough review Next Steps to Try \u00b6 Review git log to see clean, logical commit sequence Check GitHub issues for automatic commit references and updates Push commits to remote repository for team collaboration Use similar approach for future change sets to maintain clean history Expected Timeline \u00b6 Total analysis and execution time: 5-15 minutes User input required: Analysis parameters, commit review and modification, final execution approval OLAF execution time: Git analysis, GitHub integration, automated commit execution with issue updates","title":"Propose Commit Thread: Step-by-Step Tutorial"},{"location":"skills/propose-commit-thread/tutorial/#propose-commit-thread-step-by-step-tutorial","text":"","title":"Propose Commit Thread: Step-by-Step Tutorial"},{"location":"skills/propose-commit-thread/tutorial/#how-to-execute-the-analyze-git-changes-and-create-smart-commit-sequences","text":"This tutorial shows exactly how to reproduce the intelligent commit clustering workflow for organizing changes into logical, coherent commits with GitHub issue integration.","title":"How to Execute the \"Analyze Git Changes and Create Smart Commit Sequences\""},{"location":"skills/propose-commit-thread/tutorial/#prerequisites","text":"Git installed and configured on your system Repository with uncommitted changes ready for analysis GitHub CLI installed (optional, for issue integration) Write permissions to the repository Understanding of your project's feature/component structure","title":"Prerequisites"},{"location":"skills/propose-commit-thread/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/propose-commit-thread/tutorial/#step-1-initiate-commit-analysis","text":"[This step starts the OLAF commit analysis workflow] User Action: Invoke the propose-commit-thread competency in OLAF Navigate to your repository with pending changes Ensure git status shows files ready for commit organization OLAF Response: You should see OLAF validate the repository state and begin analyzing all uncommitted changes for intelligent clustering.","title":"Step 1: Initiate Commit Analysis"},{"location":"skills/propose-commit-thread/tutorial/#step-2-provide-analysis-parameters","text":"User Action: Specify analysis preferences when prompted Repository path: [current directory or specify path] Include GitHub issues integration? (y/n): [your choice] Commit strategy (granular/feature-based): [your preference] Auto-execute after approval? (y/n): [recommended: no] Provide Analysis Configuration: Repository Path : Path to git repository (defaults to current directory) GitHub Issues : Enable to link commits with related open issues Commit Strategy : Choose between granular (file-by-file) or feature-based clustering Auto Execute : Keep false for safety - allows review before execution","title":"Step 2: Provide Analysis Parameters"},{"location":"skills/propose-commit-thread/tutorial/#step-3-change-analysis-and-categorization","text":"What OLAF Does: Executes git status --porcelain for machine-readable status Categorizes files by git status (Modified, Added, Deleted, Renamed, etc.) Analyzes git diff for each file to understand change scope Groups related files by functionality, dependencies, and components Scans for GitHub issues if integration enabled You Should See: Comprehensive analysis of all changes with file categorization and initial clustering proposals","title":"Step 3: Change Analysis and Categorization"},{"location":"skills/propose-commit-thread/tutorial/#step-4-github-issues-integration","text":"What OLAF Does (if enabled): Retrieves open GitHub issues using gh issue list Extracts keywords from your changes (file names, functions, classes) Matches potential issues by title keywords and labels Correlates changes with bug reports, enhancements, or features You Should See: List of potentially related GitHub issues with relevance scores and suggested associations","title":"Step 4: GitHub Issues Integration"},{"location":"skills/propose-commit-thread/tutorial/#step-5-interactive-commit-proposal","text":"User Action: Review the structured commit thread proposal # \ud83d\udccb Proposed Commit Thread - YYYYMMDD-HHmm ## Repository Analysis **Repository**: your-repo-name **Branch**: current-branch **Files Changed**: X (Y untracked, Z modified, W staged) ## \ud83c\udfaf Proposed Commit Sequence ### Commit 1: Feature Implementation **Files** (3): - src/feature/main.js (Modified) - src/feature/helper.js (Added) **Commit Message**: feat: implement user authentication feature - Add main authentication logic - Create helper utilities for token validation **Related GitHub Issues**: #42 - User Login System **\ud83d\udc64 User Actions Available:** - \u2705 APPROVE: Accept this commit as proposed - \ud83d\udd04 MODIFY: Change commit message or file grouping - \u2795 SPLIT: Break into smaller commits - \u2796 MERGE: Combine with another commit - \u274c SKIP: Don't commit these changes now Available Interactive Commands: 1a = Approve commit 1 1m = Modify commit 1 1s = Split commit 1 merge 1,2 = Merge commits 1 and 2 skip 1 = Skip commit 1 execute = Execute all approved commits","title":"Step 5: Interactive Commit Proposal"},{"location":"skills/propose-commit-thread/tutorial/#step-6-interactive-modification-phase","text":"User Action: Use commands to refine commit organization Modification Operations: Message Edit : Update commit title and description File Regrouping : Move files between commit clusters Commit Splitting : Break large commits into focused smaller ones Commit Merging : Combine related commits for cleaner history Issue Association : Link/unlink GitHub issues Real-time Updates: OLAF provides immediate feedback as you modify the commit structure, ensuring consistency and preventing conflicts.","title":"Step 6: Interactive Modification Phase"},{"location":"skills/propose-commit-thread/tutorial/#step-7-final-approval-and-execution","text":"User Action: Execute the final commit sequence execute What OLAF Does: For each approved commit (in logical order): Stage specified files: git add [file_list] Create commit with detailed message: git commit -m \"[commit_message]\" Update related GitHub issues with commit reference Verify commit success before proceeding GitHub Integration: Add commit references to related issues Update issue labels based on commit types Close issues if commit messages include closing keywords You Should See: Step-by-step execution with confirmation of each successful commit and issue integration results","title":"Step 7: Final Approval and Execution"},{"location":"skills/propose-commit-thread/tutorial/#verification-checklist","text":"\u2705 All intended files committed (git log shows proper commit sequence) \u2705 Logical commit organization (each commit has coherent purpose and scope) \u2705 Detailed commit messages (follows conventional commits with bullet points) \u2705 GitHub issues updated (commits referenced in related issues) \u2705 Clean working directory (git status shows no remaining uncommitted changes) \u2705 Git history integrity (no conflicts or broken dependencies between commits)","title":"Verification Checklist"},{"location":"skills/propose-commit-thread/tutorial/#troubleshooting","text":"If not a git repository: Error: Not a valid git repository Navigate to correct directory containing .git folder Initialize repository with git init if needed If merge conflicts present: OLAF will stop and require resolution before proceeding Resolve conflicts manually using git mergetool or editor Re-run the competency after conflicts are resolved If GitHub CLI not available: OLAF will skip GitHub integration and proceed with git-only workflow Install GitHub CLI with gh auth login for issue integration Alternative: manually reference issues in commit messages If commit permission denied: Verify you have write access to the repository Check if branch is protected and requires specific permissions Ensure proper Git configuration with valid author information","title":"Troubleshooting"},{"location":"skills/propose-commit-thread/tutorial/#key-learning-points","text":"Intelligent Clustering: Changes are grouped by logical relationships rather than arbitrary file selection Interactive Refinement: Full control over commit organization with real-time modification capabilities GitHub Integration: Automatic linking between commits and project issues for better project tracking Safety First: Propose-Confirm-Act protocol prevents accidental commits and allows thorough review","title":"Key Learning Points"},{"location":"skills/propose-commit-thread/tutorial/#next-steps-to-try","text":"Review git log to see clean, logical commit sequence Check GitHub issues for automatic commit references and updates Push commits to remote repository for team collaboration Use similar approach for future change sets to maintain clean history","title":"Next Steps to Try"},{"location":"skills/propose-commit-thread/tutorial/#expected-timeline","text":"Total analysis and execution time: 5-15 minutes User input required: Analysis parameters, commit review and modification, final execution approval OLAF execution time: Git analysis, GitHub integration, automated commit execution with issue updates","title":"Expected Timeline"},{"location":"skills/report-my-daily/description/","text":"Report My Daily \u00b6 Overview \u00b6 Generates a daily work report by analyzing git activity, file changes, PRs, and project artifacts. Purpose \u00b6 Automates the creation of daily status reports by analyzing your actual work output, saving time and ensuring accurate reporting of accomplishments, progress, and blockers. Usage \u00b6 Command : report my daily Protocol : Propose-Act When to Use : At end of day for status updates, standups, or personal work tracking. Parameters \u00b6 Required Inputs \u00b6 None - analyzes today's work by default Optional Inputs \u00b6 Date Range : Specify different date or range (yesterday, this week, etc.) Branch : Specific branch to analyze Format : Desired output format (bullets, narrative, etc.) Context Requirements \u00b6 Git repository with commit history Work done during the specified period Output \u00b6 Deliverables : - Summary of accomplishments - List of commits with descriptions - Files modified by category - Features completed or in progress - Blockers or issues - Next steps Format : Structured markdown report, customizable Examples \u00b6 Example 1: End of Day Report \u00b6 Scenario : Need to report on today's work for standup Command : report my daily Result : Report showing commits, features worked on, files modified, and progress made Example 2: Weekly Summary \u00b6 Scenario : Need weekly status for team meeting Command : report my work this week Result : Comprehensive weekly summary with major accomplishments and metrics Example 3: Specific Feature Report \u00b6 Scenario : Report on work for specific feature branch Command : report my daily on feature/user-authentication branch Result : Focused report on authentication feature work Related Competencies \u00b6 create-carry-over : Create session notes after reviewing daily report carry-on-work : Resume work based on report's next steps stash-work : Stash current work before switching based on report insights Tips & Best Practices \u00b6 Run at end of day for most accurate reporting Use for daily standups to save preparation time Customize format for different audiences (team vs management) Review report before sharing to add context if needed Combine with carry-over notes for continuity Limitations \u00b6 Requires git commits to analyze Cannot capture work not committed to git Quality depends on commit message quality May miss context not evident in code changes","title":"Report My Daily"},{"location":"skills/report-my-daily/description/#report-my-daily","text":"","title":"Report My Daily"},{"location":"skills/report-my-daily/description/#overview","text":"Generates a daily work report by analyzing git activity, file changes, PRs, and project artifacts.","title":"Overview"},{"location":"skills/report-my-daily/description/#purpose","text":"Automates the creation of daily status reports by analyzing your actual work output, saving time and ensuring accurate reporting of accomplishments, progress, and blockers.","title":"Purpose"},{"location":"skills/report-my-daily/description/#usage","text":"Command : report my daily Protocol : Propose-Act When to Use : At end of day for status updates, standups, or personal work tracking.","title":"Usage"},{"location":"skills/report-my-daily/description/#parameters","text":"","title":"Parameters"},{"location":"skills/report-my-daily/description/#required-inputs","text":"None - analyzes today's work by default","title":"Required Inputs"},{"location":"skills/report-my-daily/description/#optional-inputs","text":"Date Range : Specify different date or range (yesterday, this week, etc.) Branch : Specific branch to analyze Format : Desired output format (bullets, narrative, etc.)","title":"Optional Inputs"},{"location":"skills/report-my-daily/description/#context-requirements","text":"Git repository with commit history Work done during the specified period","title":"Context Requirements"},{"location":"skills/report-my-daily/description/#output","text":"Deliverables : - Summary of accomplishments - List of commits with descriptions - Files modified by category - Features completed or in progress - Blockers or issues - Next steps Format : Structured markdown report, customizable","title":"Output"},{"location":"skills/report-my-daily/description/#examples","text":"","title":"Examples"},{"location":"skills/report-my-daily/description/#example-1-end-of-day-report","text":"Scenario : Need to report on today's work for standup Command : report my daily Result : Report showing commits, features worked on, files modified, and progress made","title":"Example 1: End of Day Report"},{"location":"skills/report-my-daily/description/#example-2-weekly-summary","text":"Scenario : Need weekly status for team meeting Command : report my work this week Result : Comprehensive weekly summary with major accomplishments and metrics","title":"Example 2: Weekly Summary"},{"location":"skills/report-my-daily/description/#example-3-specific-feature-report","text":"Scenario : Report on work for specific feature branch Command : report my daily on feature/user-authentication branch Result : Focused report on authentication feature work","title":"Example 3: Specific Feature Report"},{"location":"skills/report-my-daily/description/#related-competencies","text":"create-carry-over : Create session notes after reviewing daily report carry-on-work : Resume work based on report's next steps stash-work : Stash current work before switching based on report insights","title":"Related Competencies"},{"location":"skills/report-my-daily/description/#tips-best-practices","text":"Run at end of day for most accurate reporting Use for daily standups to save preparation time Customize format for different audiences (team vs management) Review report before sharing to add context if needed Combine with carry-over notes for continuity","title":"Tips &amp; Best Practices"},{"location":"skills/report-my-daily/description/#limitations","text":"Requires git commits to analyze Cannot capture work not committed to git Quality depends on commit message quality May miss context not evident in code changes","title":"Limitations"},{"location":"skills/report-my-daily/tutorial/","text":"Report My Daily: Step-by-Step Tutorial \u00b6 How to Execute the \"Report My Daily\" Workflow This tutorial shows how to generate a daily work report by analyzing your git activity and project artifacts. Prerequisites \u00b6 Git repository with commit history Work done during the day (commits, file changes, etc.) Access to project files and git history Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 Generate your daily report User Action: 1. At end of day, type: report my daily 2. Optionally specify date range OLAF Response: OLAF will begin analyzing your git activity and project files Step 2: Git Activity Analysis \u00b6 What OLAF Does: - Runs git log to get today's commits - Analyzes commit messages and changes - Identifies files modified - Calculates lines added/removed - Groups changes by feature or area You Should See: Progress indication of git analysis Step 3: File and Artifact Analysis \u00b6 What OLAF Does: - Reviews modified files for context - Checks for PR descriptions or comments - Analyzes code changes for patterns - Identifies completed features or fixes - Notes any TODO items or blockers You Should See: Analysis of work artifacts Step 4: Report Generation \u00b6 What OLAF Provides: - Summary of accomplishments - List of commits with descriptions - Files modified by category - Features completed or in progress - Blockers or issues encountered - Next steps planned You Should See: Structured daily report Step 5: Review and Share \u00b6 User Action: Use the report - Review for accuracy - Request additions or clarifications - Copy for standup or status update - Save for personal records Verification Checklist \u00b6 \u2705 All commits from today are included \u2705 Work is accurately summarized \u2705 Features and accomplishments are highlighted \u2705 Blockers or issues are noted \u2705 Report is ready to share Troubleshooting \u00b6 If no commits found: No commits found for today Solution: Verify you have commits in the current repository, or specify a different date range If report seems incomplete: - Specify date range: \"report my daily for yesterday\" - Include specific branches: \"report my daily including feature branches\" - Add context: \"also include work on the API redesign\" If you want different format: - Request specific format: \"format as bullet points for standup\" - Ask for different grouping: \"group by feature instead of by file\" Key Learning Points \u00b6 Automated Analysis : Analyzes git history automatically Context-Aware : Understands code changes and their purpose Flexible Reporting : Can customize format and content Time-Saving : Eliminates manual report writing Next Steps to Try \u00b6 Use for daily standups or status updates Generate weekly summaries: \"report my work this week\" Compare with previous days: \"how does today compare to yesterday?\" Create carry-over notes: create carry-over after reviewing report Expected Timeline \u00b6 Total report time: 2-3 minutes User input required: Just the command (10 seconds) OLAF execution time: Git analysis and report generation (2-3 minutes)","title":"Report My Daily: Step-by-Step Tutorial"},{"location":"skills/report-my-daily/tutorial/#report-my-daily-step-by-step-tutorial","text":"How to Execute the \"Report My Daily\" Workflow This tutorial shows how to generate a daily work report by analyzing your git activity and project artifacts.","title":"Report My Daily: Step-by-Step Tutorial"},{"location":"skills/report-my-daily/tutorial/#prerequisites","text":"Git repository with commit history Work done during the day (commits, file changes, etc.) Access to project files and git history","title":"Prerequisites"},{"location":"skills/report-my-daily/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/report-my-daily/tutorial/#step-1-invoke-the-competency","text":"Generate your daily report User Action: 1. At end of day, type: report my daily 2. Optionally specify date range OLAF Response: OLAF will begin analyzing your git activity and project files","title":"Step 1: Invoke the Competency"},{"location":"skills/report-my-daily/tutorial/#step-2-git-activity-analysis","text":"What OLAF Does: - Runs git log to get today's commits - Analyzes commit messages and changes - Identifies files modified - Calculates lines added/removed - Groups changes by feature or area You Should See: Progress indication of git analysis","title":"Step 2: Git Activity Analysis"},{"location":"skills/report-my-daily/tutorial/#step-3-file-and-artifact-analysis","text":"What OLAF Does: - Reviews modified files for context - Checks for PR descriptions or comments - Analyzes code changes for patterns - Identifies completed features or fixes - Notes any TODO items or blockers You Should See: Analysis of work artifacts","title":"Step 3: File and Artifact Analysis"},{"location":"skills/report-my-daily/tutorial/#step-4-report-generation","text":"What OLAF Provides: - Summary of accomplishments - List of commits with descriptions - Files modified by category - Features completed or in progress - Blockers or issues encountered - Next steps planned You Should See: Structured daily report","title":"Step 4: Report Generation"},{"location":"skills/report-my-daily/tutorial/#step-5-review-and-share","text":"User Action: Use the report - Review for accuracy - Request additions or clarifications - Copy for standup or status update - Save for personal records","title":"Step 5: Review and Share"},{"location":"skills/report-my-daily/tutorial/#verification-checklist","text":"\u2705 All commits from today are included \u2705 Work is accurately summarized \u2705 Features and accomplishments are highlighted \u2705 Blockers or issues are noted \u2705 Report is ready to share","title":"Verification Checklist"},{"location":"skills/report-my-daily/tutorial/#troubleshooting","text":"If no commits found: No commits found for today Solution: Verify you have commits in the current repository, or specify a different date range If report seems incomplete: - Specify date range: \"report my daily for yesterday\" - Include specific branches: \"report my daily including feature branches\" - Add context: \"also include work on the API redesign\" If you want different format: - Request specific format: \"format as bullet points for standup\" - Ask for different grouping: \"group by feature instead of by file\"","title":"Troubleshooting"},{"location":"skills/report-my-daily/tutorial/#key-learning-points","text":"Automated Analysis : Analyzes git history automatically Context-Aware : Understands code changes and their purpose Flexible Reporting : Can customize format and content Time-Saving : Eliminates manual report writing","title":"Key Learning Points"},{"location":"skills/report-my-daily/tutorial/#next-steps-to-try","text":"Use for daily standups or status updates Generate weekly summaries: \"report my work this week\" Compare with previous days: \"how does today compare to yesterday?\" Create carry-over notes: create carry-over after reviewing report","title":"Next Steps to Try"},{"location":"skills/report-my-daily/tutorial/#expected-timeline","text":"Total report time: 2-3 minutes User input required: Just the command (10 seconds) OLAF execution time: Git analysis and report generation (2-3 minutes)","title":"Expected Timeline"},{"location":"skills/research-and-report/tutorial/","text":"Research and Report - Tutorial \u00b6 Overview \u00b6 The Research and Report skill provides structured research capabilities with comprehensive reporting and current information validation. This tutorial will guide you through using this skill effectively. What This Skill Does \u00b6 Structured Research : Systematic approach with planning, execution, and finalization phases Current Information Priority : Web search validation of training data with mandatory URL collection Chapter-by-chapter Workflow : User approval required for each chapter before proceeding Professional Reporting : Publication-ready reports with proper formatting and sourcing When to Use This Skill \u00b6 Use research-andreport when you need: - Comprehensive research on any topic with current information - Systematic investigation with professional documentation - Web-validated findings to supplement training data - Reports that require source verification and currency tracking Step-by-Step Tutorial \u00b6 Step 1: Invoke the Skill \u00b6 olaf research-andreport Step 2: Provide Research Parameters \u00b6 When prompted, provide: - research_topic : Specific topic or question to research - scope_boundaries : What is included and excluded from research - expected_outcomes : Expected deliverables and target audience - timeline : Optional research and writing timeline Example: research_topic: \"Modern containerization strategies for microservices\" scope_boundaries: \"Focus on Docker and Kubernetes, exclude legacy systems\" expected_outcomes: \"Technical guide for development teams\" timeline: \"2 weeks for completion\" Step 3: Review Research Plan \u00b6 The skill will create a detailed research plan including: - Scope statement with boundaries - Key research questions (primary and secondary) - Proposed chapter structure - Potential sources strategy - Timeline with phases Important : You must approve this plan before research begins. Step 4: Chapter-by-Chapter Approval \u00b6 For each chapter, the skill will: 1. Conduct web research for current information 2. Validate training data against recent sources 3. Draft the chapter content 4. Present it for your approval 5. Only proceed to the next chapter after approval Step 5: Final Report Delivery \u00b6 After all chapters are approved: - Complete report is compiled with table of contents - Professional formatting applied - Final file delivered to staging directory Output Files \u00b6 The skill creates these files in your staging directory: Research Plan \u00b6 File : research-plan-YYYYMMDD-HHmm.md Purpose : Detailed research roadmap requiring approval Template : Uses structured planning template Research Report \u00b6 File : research-report-YYYYMMDD-HHmm.md Purpose : Final comprehensive report with all findings Template : Professional report format with sourcing Key Features \u00b6 Current Information Priority \u00b6 Web searches prioritize 2024-2025 content Training data validated against recent sources All sources marked with currency indicators Mandatory URL collection (no generic references allowed) Source Validation Rules \u00b6 Every source must include full URL Sources categorized as \"Web 2025\", \"Training Data\", or \"Verified 2025\" Generic references without URLs are rejected Search dates documented for web sources Quality Standards \u00b6 Publication-ready formatting Professional structure and flow Accurate and current technical details Actionable recommendations Best Practices \u00b6 For Better Research Results \u00b6 Be Specific : Provide clear, focused research topics Define Boundaries : Clearly state what to include/exclude Set Expectations : Specify target audience and use cases Review Carefully : Approve each chapter thoughtfully For Source Quality \u00b6 Prefer official documentation and current vendor sites Value recent industry reports and technical blogs Use training data as supplementary, not primary source Verify conflicting information through multiple sources For Effective Workflow \u00b6 Allow time for thorough review of each chapter Provide feedback on chapter content before approval Consider timeline realistically for quality research Plan for iteration and refinement Common Use Cases \u00b6 Technical Research \u00b6 Technology stack analysis Architecture pattern research Tool comparison and evaluation Performance and scaling studies Market Analysis \u00b6 Industry trend investigation Competitive landscape research Technology adoption patterns Solution comparisons Educational Content \u00b6 Learning guides and tutorials Best practices documentation Implementation roadmaps Decision frameworks Tips for Success \u00b6 Start with Clear Goals : Define what you want to learn or decide Invest in Planning : Good research plans lead to better reports Value Current Sources : Prioritize recent information over training data Review Thoroughly : Each chapter builds on previous ones Think Publication-Ready : Reports should be professional and shareable Troubleshooting \u00b6 If Research Plan Needs Changes \u00b6 Provide specific feedback during approval phase Request modifications to scope, questions, or structure Clarify any ambiguous requirements If Sources Are Insufficient \u00b6 Request broader search strategies Ask for additional source types Specify particular sources to investigate If Chapters Need Revision \u00b6 Provide detailed feedback before approval Ask for additional research on specific points Request different analysis angles or depth Expected Timeline \u00b6 Planning Phase : 15-30 minutes for plan creation and approval Research Phase : 1-3 hours per chapter depending on complexity Finalization Phase : 15-30 minutes for compilation and formatting Total time varies based on topic complexity, number of chapters, and review cycles. This tutorial should help you get the most value from the Research and Report skill. Remember that the quality of your research inputs directly impacts the quality of your research outputs!","title":"Research and Report - Tutorial"},{"location":"skills/research-and-report/tutorial/#research-and-report-tutorial","text":"","title":"Research and Report - Tutorial"},{"location":"skills/research-and-report/tutorial/#overview","text":"The Research and Report skill provides structured research capabilities with comprehensive reporting and current information validation. This tutorial will guide you through using this skill effectively.","title":"Overview"},{"location":"skills/research-and-report/tutorial/#what-this-skill-does","text":"Structured Research : Systematic approach with planning, execution, and finalization phases Current Information Priority : Web search validation of training data with mandatory URL collection Chapter-by-chapter Workflow : User approval required for each chapter before proceeding Professional Reporting : Publication-ready reports with proper formatting and sourcing","title":"What This Skill Does"},{"location":"skills/research-and-report/tutorial/#when-to-use-this-skill","text":"Use research-andreport when you need: - Comprehensive research on any topic with current information - Systematic investigation with professional documentation - Web-validated findings to supplement training data - Reports that require source verification and currency tracking","title":"When to Use This Skill"},{"location":"skills/research-and-report/tutorial/#step-by-step-tutorial","text":"","title":"Step-by-Step Tutorial"},{"location":"skills/research-and-report/tutorial/#step-1-invoke-the-skill","text":"olaf research-andreport","title":"Step 1: Invoke the Skill"},{"location":"skills/research-and-report/tutorial/#step-2-provide-research-parameters","text":"When prompted, provide: - research_topic : Specific topic or question to research - scope_boundaries : What is included and excluded from research - expected_outcomes : Expected deliverables and target audience - timeline : Optional research and writing timeline Example: research_topic: \"Modern containerization strategies for microservices\" scope_boundaries: \"Focus on Docker and Kubernetes, exclude legacy systems\" expected_outcomes: \"Technical guide for development teams\" timeline: \"2 weeks for completion\"","title":"Step 2: Provide Research Parameters"},{"location":"skills/research-and-report/tutorial/#step-3-review-research-plan","text":"The skill will create a detailed research plan including: - Scope statement with boundaries - Key research questions (primary and secondary) - Proposed chapter structure - Potential sources strategy - Timeline with phases Important : You must approve this plan before research begins.","title":"Step 3: Review Research Plan"},{"location":"skills/research-and-report/tutorial/#step-4-chapter-by-chapter-approval","text":"For each chapter, the skill will: 1. Conduct web research for current information 2. Validate training data against recent sources 3. Draft the chapter content 4. Present it for your approval 5. Only proceed to the next chapter after approval","title":"Step 4: Chapter-by-Chapter Approval"},{"location":"skills/research-and-report/tutorial/#step-5-final-report-delivery","text":"After all chapters are approved: - Complete report is compiled with table of contents - Professional formatting applied - Final file delivered to staging directory","title":"Step 5: Final Report Delivery"},{"location":"skills/research-and-report/tutorial/#output-files","text":"The skill creates these files in your staging directory:","title":"Output Files"},{"location":"skills/research-and-report/tutorial/#research-plan","text":"File : research-plan-YYYYMMDD-HHmm.md Purpose : Detailed research roadmap requiring approval Template : Uses structured planning template","title":"Research Plan"},{"location":"skills/research-and-report/tutorial/#research-report","text":"File : research-report-YYYYMMDD-HHmm.md Purpose : Final comprehensive report with all findings Template : Professional report format with sourcing","title":"Research Report"},{"location":"skills/research-and-report/tutorial/#key-features","text":"","title":"Key Features"},{"location":"skills/research-and-report/tutorial/#current-information-priority","text":"Web searches prioritize 2024-2025 content Training data validated against recent sources All sources marked with currency indicators Mandatory URL collection (no generic references allowed)","title":"Current Information Priority"},{"location":"skills/research-and-report/tutorial/#source-validation-rules","text":"Every source must include full URL Sources categorized as \"Web 2025\", \"Training Data\", or \"Verified 2025\" Generic references without URLs are rejected Search dates documented for web sources","title":"Source Validation Rules"},{"location":"skills/research-and-report/tutorial/#quality-standards","text":"Publication-ready formatting Professional structure and flow Accurate and current technical details Actionable recommendations","title":"Quality Standards"},{"location":"skills/research-and-report/tutorial/#best-practices","text":"","title":"Best Practices"},{"location":"skills/research-and-report/tutorial/#for-better-research-results","text":"Be Specific : Provide clear, focused research topics Define Boundaries : Clearly state what to include/exclude Set Expectations : Specify target audience and use cases Review Carefully : Approve each chapter thoughtfully","title":"For Better Research Results"},{"location":"skills/research-and-report/tutorial/#for-source-quality","text":"Prefer official documentation and current vendor sites Value recent industry reports and technical blogs Use training data as supplementary, not primary source Verify conflicting information through multiple sources","title":"For Source Quality"},{"location":"skills/research-and-report/tutorial/#for-effective-workflow","text":"Allow time for thorough review of each chapter Provide feedback on chapter content before approval Consider timeline realistically for quality research Plan for iteration and refinement","title":"For Effective Workflow"},{"location":"skills/research-and-report/tutorial/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"skills/research-and-report/tutorial/#technical-research","text":"Technology stack analysis Architecture pattern research Tool comparison and evaluation Performance and scaling studies","title":"Technical Research"},{"location":"skills/research-and-report/tutorial/#market-analysis","text":"Industry trend investigation Competitive landscape research Technology adoption patterns Solution comparisons","title":"Market Analysis"},{"location":"skills/research-and-report/tutorial/#educational-content","text":"Learning guides and tutorials Best practices documentation Implementation roadmaps Decision frameworks","title":"Educational Content"},{"location":"skills/research-and-report/tutorial/#tips-for-success","text":"Start with Clear Goals : Define what you want to learn or decide Invest in Planning : Good research plans lead to better reports Value Current Sources : Prioritize recent information over training data Review Thoroughly : Each chapter builds on previous ones Think Publication-Ready : Reports should be professional and shareable","title":"Tips for Success"},{"location":"skills/research-and-report/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/research-and-report/tutorial/#if-research-plan-needs-changes","text":"Provide specific feedback during approval phase Request modifications to scope, questions, or structure Clarify any ambiguous requirements","title":"If Research Plan Needs Changes"},{"location":"skills/research-and-report/tutorial/#if-sources-are-insufficient","text":"Request broader search strategies Ask for additional source types Specify particular sources to investigate","title":"If Sources Are Insufficient"},{"location":"skills/research-and-report/tutorial/#if-chapters-need-revision","text":"Provide detailed feedback before approval Ask for additional research on specific points Request different analysis angles or depth","title":"If Chapters Need Revision"},{"location":"skills/research-and-report/tutorial/#expected-timeline","text":"Planning Phase : 15-30 minutes for plan creation and approval Research Phase : 1-3 hours per chapter depending on complexity Finalization Phase : 15-30 minutes for compilation and formatting Total time varies based on topic complexity, number of chapters, and review cycles. This tutorial should help you get the most value from the Research and Report skill. Remember that the quality of your research inputs directly impacts the quality of your research outputs!","title":"Expected Timeline"},{"location":"skills/review-code/description/","text":"Review Code \u00b6 Overview \u00b6 This competency performs comprehensive code reviews with multiple input modes - manual selection, git-modified files, or batch processing - focusing on quality, security, maintainability, and adherence to coding standards. Purpose \u00b6 Code reviews catch bugs early, ensure quality standards, share knowledge, and maintain codebase health. This competency provides thorough, consistent code reviews that check for security vulnerabilities, performance issues, code smells, and adherence to best practices, with support for both single-file and batch processing workflows. Usage \u00b6 Command : review code (or aliases: code review , examine code , check code , inspect code , review modified , review changes , modified files , changes review , git changes , review git , review branch ) Protocol : Propose-Act When to Use : Use for pre-commit reviews, pull request reviews, security audits, quality assessments, onboarding reviews, or periodic codebase health checks. Supports both targeted single-file reviews and comprehensive git-modified file batch processing. Parameters \u00b6 Required Inputs (Mode-Dependent) \u00b6 For Manual Mode: - code_source : What to review (copy-pasted code, file path, folder, or repository) - language : Programming language For Git-Modified Mode (Auto-Discovery): - branch_name : Optional specific branch (defaults to current) - file_filter : Optional file type filter (e.g., \" .cs, .js, .py\") - batch_size *: Files per batch (default: 10) Optional Inputs (All Modes) \u00b6 focus_areas : Specific areas to emphasize (security, performance, style) review_standards : Custom coding standards or style guides team_conventions : Team-specific patterns or guidelines compliance_requirements : Specific compliance standards (OWASP, NIST) Context Requirements \u00b6 Access to code to be reviewed Relevant coding standards and team conventions Understanding of project context and requirements For git mode: working git repository Output \u00b6 Generates comprehensive code review reports with staging and recommendations. Deliverables : Single File/Manual Mode: - Critical issues (security, bugs, performance) - Recommendations for improvements - Positive feedback on good practices - Code review report: code-review-YYYYMMDD-HHmm.md - Curative action plan: action-plan-YYYYMMDD-HHmm.md Git-Modified Mode (Batch): - Individual review files for each analyzed file - Summary report: code-review-summary-YYYYMMDD-NNN.md - Aggregated staging by severity - Common patterns across files - Team-wide improvement recommendations Format : Structured markdown following code-review template Examples \u00b6 Example 1: Pre-Commit Review \u00b6 Scenario : Developer wants to review changes before committing Command : review code Input : code_source: src/services/payment-service.ts language: TypeScript focus_areas: [\"security\", \"error-handling\"] Result : Identified SQL injection vulnerability, missing error handling for network failures, recommended input validation improvements, generated action plan with specific fixes. Example 2: Git-Modified Files Batch Review \u00b6 Scenario : Review all changes in current branch before pull request Command : review modified files Input : branch_name: feature/user-authentication file_filter: *.ts,*.tsx Result : Processed 15 modified files in batches, generated individual reviews for each, created summary report showing 3 critical security issues, 8 code quality improvements, and 5 positive patterns to replicate. Example 3: Security Audit \u00b6 Scenario : Security review of authentication module Command : review code Input : code_source: src/auth/ language: Java focus_areas: [\"security\"] compliance_requirements: [\"OWASP Top 10\"] Result : Comprehensive security review identifying authentication bypass risk, weak password hashing, missing rate limiting, with detailed remediation steps and OWASP references. Related Competencies \u00b6 fix-code-smells : Implements improvements identified during review improve-cyclomatic-complexity : Addresses complexity issues found in review review-github-pr : Specialized review for pull requests with integration analysis create-unit-tests : Adds tests for code lacking coverage identified in review Tips & Best Practices \u00b6 Load universal and team-specific coding standards before reviewing Use git-modified mode for efficient branch reviews Specify focus areas for targeted reviews Always review generated action plans and prioritize fixes Run reviews before committing to catch issues early Use batch processing for large changesets Combine with automated testing for comprehensive quality checks Document and share common patterns found across reviews Review positive patterns to encourage good practices Limitations \u00b6 Cannot execute code or validate runtime behavior Effectiveness depends on coding standards clarity May miss context-dependent issues Cannot assess business logic correctness without domain knowledge Batch processing may hit session limits on very large changesets Cannot detect all security vulnerabilities (use specialized security tools) Review quality depends on specification completeness Cannot replace human judgment for architectural decisions","title":"Review Code"},{"location":"skills/review-code/description/#review-code","text":"","title":"Review Code"},{"location":"skills/review-code/description/#overview","text":"This competency performs comprehensive code reviews with multiple input modes - manual selection, git-modified files, or batch processing - focusing on quality, security, maintainability, and adherence to coding standards.","title":"Overview"},{"location":"skills/review-code/description/#purpose","text":"Code reviews catch bugs early, ensure quality standards, share knowledge, and maintain codebase health. This competency provides thorough, consistent code reviews that check for security vulnerabilities, performance issues, code smells, and adherence to best practices, with support for both single-file and batch processing workflows.","title":"Purpose"},{"location":"skills/review-code/description/#usage","text":"Command : review code (or aliases: code review , examine code , check code , inspect code , review modified , review changes , modified files , changes review , git changes , review git , review branch ) Protocol : Propose-Act When to Use : Use for pre-commit reviews, pull request reviews, security audits, quality assessments, onboarding reviews, or periodic codebase health checks. Supports both targeted single-file reviews and comprehensive git-modified file batch processing.","title":"Usage"},{"location":"skills/review-code/description/#parameters","text":"","title":"Parameters"},{"location":"skills/review-code/description/#required-inputs-mode-dependent","text":"For Manual Mode: - code_source : What to review (copy-pasted code, file path, folder, or repository) - language : Programming language For Git-Modified Mode (Auto-Discovery): - branch_name : Optional specific branch (defaults to current) - file_filter : Optional file type filter (e.g., \" .cs, .js, .py\") - batch_size *: Files per batch (default: 10)","title":"Required Inputs (Mode-Dependent)"},{"location":"skills/review-code/description/#optional-inputs-all-modes","text":"focus_areas : Specific areas to emphasize (security, performance, style) review_standards : Custom coding standards or style guides team_conventions : Team-specific patterns or guidelines compliance_requirements : Specific compliance standards (OWASP, NIST)","title":"Optional Inputs (All Modes)"},{"location":"skills/review-code/description/#context-requirements","text":"Access to code to be reviewed Relevant coding standards and team conventions Understanding of project context and requirements For git mode: working git repository","title":"Context Requirements"},{"location":"skills/review-code/description/#output","text":"Generates comprehensive code review reports with staging and recommendations. Deliverables : Single File/Manual Mode: - Critical issues (security, bugs, performance) - Recommendations for improvements - Positive feedback on good practices - Code review report: code-review-YYYYMMDD-HHmm.md - Curative action plan: action-plan-YYYYMMDD-HHmm.md Git-Modified Mode (Batch): - Individual review files for each analyzed file - Summary report: code-review-summary-YYYYMMDD-NNN.md - Aggregated staging by severity - Common patterns across files - Team-wide improvement recommendations Format : Structured markdown following code-review template","title":"Output"},{"location":"skills/review-code/description/#examples","text":"","title":"Examples"},{"location":"skills/review-code/description/#example-1-pre-commit-review","text":"Scenario : Developer wants to review changes before committing Command : review code Input : code_source: src/services/payment-service.ts language: TypeScript focus_areas: [\"security\", \"error-handling\"] Result : Identified SQL injection vulnerability, missing error handling for network failures, recommended input validation improvements, generated action plan with specific fixes.","title":"Example 1: Pre-Commit Review"},{"location":"skills/review-code/description/#example-2-git-modified-files-batch-review","text":"Scenario : Review all changes in current branch before pull request Command : review modified files Input : branch_name: feature/user-authentication file_filter: *.ts,*.tsx Result : Processed 15 modified files in batches, generated individual reviews for each, created summary report showing 3 critical security issues, 8 code quality improvements, and 5 positive patterns to replicate.","title":"Example 2: Git-Modified Files Batch Review"},{"location":"skills/review-code/description/#example-3-security-audit","text":"Scenario : Security review of authentication module Command : review code Input : code_source: src/auth/ language: Java focus_areas: [\"security\"] compliance_requirements: [\"OWASP Top 10\"] Result : Comprehensive security review identifying authentication bypass risk, weak password hashing, missing rate limiting, with detailed remediation steps and OWASP references.","title":"Example 3: Security Audit"},{"location":"skills/review-code/description/#related-competencies","text":"fix-code-smells : Implements improvements identified during review improve-cyclomatic-complexity : Addresses complexity issues found in review review-github-pr : Specialized review for pull requests with integration analysis create-unit-tests : Adds tests for code lacking coverage identified in review","title":"Related Competencies"},{"location":"skills/review-code/description/#tips-best-practices","text":"Load universal and team-specific coding standards before reviewing Use git-modified mode for efficient branch reviews Specify focus areas for targeted reviews Always review generated action plans and prioritize fixes Run reviews before committing to catch issues early Use batch processing for large changesets Combine with automated testing for comprehensive quality checks Document and share common patterns found across reviews Review positive patterns to encourage good practices","title":"Tips &amp; Best Practices"},{"location":"skills/review-code/description/#limitations","text":"Cannot execute code or validate runtime behavior Effectiveness depends on coding standards clarity May miss context-dependent issues Cannot assess business logic correctness without domain knowledge Batch processing may hit session limits on very large changesets Cannot detect all security vulnerabilities (use specialized security tools) Review quality depends on specification completeness Cannot replace human judgment for architectural decisions","title":"Limitations"},{"location":"skills/review-code/tutorial/","text":"Review Code: Step-by-Step Tutorial \u00b6 How to Execute the \"Review Code\" Workflow This tutorial shows exactly how to use the Developer competency's comprehensive code review workflow with multiple input modes for quality, security, and maintainability analysis. Prerequisites \u00b6 Access to OLAF Framework with developer competency pack Code to review (files, git repository, or copy-paste) Basic understanding of code quality principles Git repository (optional, for git-modified mode) Step-by-Step Instructions \u00b6 Step 1: Initialize Code Review \u00b6 Brief description: Start the comprehensive code review workflow by invoking the developer competency with the review code command. User Action: Navigate to your project workspace Execute one of the commands: olaf review code , code review , examine code , check code , or review modified Prepare to specify review mode and parameters System Response: The system will prompt for review mode selection and gather appropriate parameters using Propose-Act protocol. Step 2: Select Review Mode and Provide Parameters \u00b6 User Action: Choose review mode and provide required parameters when prompted Option A - Manual Mode: Source Mode: manual Code Source: [file-path-folder-or-copy-paste] Language: [programming-language] Context: [optional-additional-context] Focus Areas: [optional-security-performance-style] Option B - Git-Modified Mode: Source Mode: git-modified Branch Name: [optional-specific-branch] File Filter: [optional-file-types] Batch Size: [optional-batch-size] Focus Areas: [optional-focus-areas] Provide Requirements/Parameters: source_mode : Review approach - we used \"git-modified\" for automatic discovery branch_name : Optional branch - we used \"\" (current branch) file_filter : Optional file types - we used \" .js, .ts\" for JavaScript/TypeScript batch_size : Optional batch size - we used \"10\" (default) focus_areas : Optional focus - we used [\"security\", \"performance\"] Step 3: Code Discovery and Preparation \u00b6 What System Does: For Git-Modified Mode: - Automatically discovers modified files in git repository - Filters files based on specified file types - Organizes files into batches for systematic review - Identifies file changes and modification scope For Manual Mode: - Reads specified files or processes copy-pasted code - Validates code syntax and structure - Prepares code for comprehensive analysis You Should See: Code discovery results showing files to be reviewed and batch organization Step 4: Systematic Code Analysis \u00b6 What System Does: Performs comprehensive quality analysis on each file/batch Evaluates code against best practices and standards Identifies security vulnerabilities and potential issues Assesses maintainability and readability factors Checks for performance optimization opportunities You Should See: Detailed analysis results for each reviewed file with specific staging Step 5: Security and Quality Assessment \u00b6 What System Does: Conducts security-focused review for vulnerabilities Identifies potential injection attacks and data exposure Reviews authentication and authorization patterns Evaluates input validation and sanitization Assesses error handling and logging practices You Should See: Security assessment results with risk levels and specific recommendations Step 6: Maintainability and Style Review \u00b6 What System Does: Reviews code structure and organization Evaluates naming conventions and documentation Assesses code complexity and readability Identifies potential refactoring opportunities Checks adherence to coding standards You Should See: Maintainability assessment with code quality metrics and improvement suggestions Step 7: Aggregated Report Generation \u00b6 What System Does: Compiles staging from all reviewed files Creates prioritized list of issues by severity Generates actionable recommendations for improvements Provides summary statistics and quality metrics Saves comprehensive review report to staging directory You Should See: Complete code review report with prioritized staging and actionable recommendations Step 8: Follow-up Action Planning \u00b6 What System Does: Suggests next steps for addressing identified issues Provides implementation guidance for improvements Recommends tools and processes for ongoing quality Creates tracking mechanism for improvement progress Offers integration suggestions with development workflow You Should See: Action plan with specific steps for code quality improvement and workflow integration Verification Checklist \u00b6 \u2705 Review mode selected : Appropriate input mode chosen and configured \u2705 Code discovered : Files or code identified and prepared for review \u2705 Quality analysis completed : Comprehensive evaluation against best practices \u2705 Security assessment done : Vulnerability and security pattern review completed \u2705 Maintainability evaluated : Code structure and readability assessed \u2705 Issues prioritized : staging organized by severity and impact \u2705 Report generated : Comprehensive review documentation created \u2705 Action plan provided : Clear next steps for improvement identified Troubleshooting \u00b6 If git-modified mode fails: # Verify git repository status and modified files git status git diff --name-only # Check branch and ensure there are modified files to review If code analysis seems incomplete: Verify file paths are accessible and readable Check that specified programming language is supported Ensure focus areas match actual code characteristics Consider adjusting batch size for large repositories If security assessment misses issues: Review focus areas to include specific security concerns Provide additional context about application security requirements Consider manual mode for sensitive code sections Supplement with specialized security tools if needed Key Learning Points \u00b6 Multiple input modes : Review supports manual selection, git discovery, and batch processing Comprehensive analysis : Covers quality, security, maintainability, and performance Batch processing : Large codebases handled systematically through batching Actionable output : Results include specific recommendations and implementation guidance Workflow integration : Designed to fit into existing development and review processes Next Steps to Try \u00b6 Implement prioritized improvements from review staging Integrate code review workflow into development process Use git-modified mode for regular change reviews Apply focus areas for specialized review needs (security, performance) Establish regular review cycles for ongoing code quality Expected Timeline \u00b6 Total review time: 15-45 minutes depending on code volume and complexity User input required: Mode selection and parameter setup (3-5 minutes) Code discovery: File identification and preparation (2-5 minutes) Analysis execution: Comprehensive review and assessment (10-30 minutes) Report generation: staging compilation and action planning (5-10 minutes)","title":"Review Code: Step-by-Step Tutorial"},{"location":"skills/review-code/tutorial/#review-code-step-by-step-tutorial","text":"How to Execute the \"Review Code\" Workflow This tutorial shows exactly how to use the Developer competency's comprehensive code review workflow with multiple input modes for quality, security, and maintainability analysis.","title":"Review Code: Step-by-Step Tutorial"},{"location":"skills/review-code/tutorial/#prerequisites","text":"Access to OLAF Framework with developer competency pack Code to review (files, git repository, or copy-paste) Basic understanding of code quality principles Git repository (optional, for git-modified mode)","title":"Prerequisites"},{"location":"skills/review-code/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/review-code/tutorial/#step-1-initialize-code-review","text":"Brief description: Start the comprehensive code review workflow by invoking the developer competency with the review code command. User Action: Navigate to your project workspace Execute one of the commands: olaf review code , code review , examine code , check code , or review modified Prepare to specify review mode and parameters System Response: The system will prompt for review mode selection and gather appropriate parameters using Propose-Act protocol.","title":"Step 1: Initialize Code Review"},{"location":"skills/review-code/tutorial/#step-2-select-review-mode-and-provide-parameters","text":"User Action: Choose review mode and provide required parameters when prompted Option A - Manual Mode: Source Mode: manual Code Source: [file-path-folder-or-copy-paste] Language: [programming-language] Context: [optional-additional-context] Focus Areas: [optional-security-performance-style] Option B - Git-Modified Mode: Source Mode: git-modified Branch Name: [optional-specific-branch] File Filter: [optional-file-types] Batch Size: [optional-batch-size] Focus Areas: [optional-focus-areas] Provide Requirements/Parameters: source_mode : Review approach - we used \"git-modified\" for automatic discovery branch_name : Optional branch - we used \"\" (current branch) file_filter : Optional file types - we used \" .js, .ts\" for JavaScript/TypeScript batch_size : Optional batch size - we used \"10\" (default) focus_areas : Optional focus - we used [\"security\", \"performance\"]","title":"Step 2: Select Review Mode and Provide Parameters"},{"location":"skills/review-code/tutorial/#step-3-code-discovery-and-preparation","text":"What System Does: For Git-Modified Mode: - Automatically discovers modified files in git repository - Filters files based on specified file types - Organizes files into batches for systematic review - Identifies file changes and modification scope For Manual Mode: - Reads specified files or processes copy-pasted code - Validates code syntax and structure - Prepares code for comprehensive analysis You Should See: Code discovery results showing files to be reviewed and batch organization","title":"Step 3: Code Discovery and Preparation"},{"location":"skills/review-code/tutorial/#step-4-systematic-code-analysis","text":"What System Does: Performs comprehensive quality analysis on each file/batch Evaluates code against best practices and standards Identifies security vulnerabilities and potential issues Assesses maintainability and readability factors Checks for performance optimization opportunities You Should See: Detailed analysis results for each reviewed file with specific staging","title":"Step 4: Systematic Code Analysis"},{"location":"skills/review-code/tutorial/#step-5-security-and-quality-assessment","text":"What System Does: Conducts security-focused review for vulnerabilities Identifies potential injection attacks and data exposure Reviews authentication and authorization patterns Evaluates input validation and sanitization Assesses error handling and logging practices You Should See: Security assessment results with risk levels and specific recommendations","title":"Step 5: Security and Quality Assessment"},{"location":"skills/review-code/tutorial/#step-6-maintainability-and-style-review","text":"What System Does: Reviews code structure and organization Evaluates naming conventions and documentation Assesses code complexity and readability Identifies potential refactoring opportunities Checks adherence to coding standards You Should See: Maintainability assessment with code quality metrics and improvement suggestions","title":"Step 6: Maintainability and Style Review"},{"location":"skills/review-code/tutorial/#step-7-aggregated-report-generation","text":"What System Does: Compiles staging from all reviewed files Creates prioritized list of issues by severity Generates actionable recommendations for improvements Provides summary statistics and quality metrics Saves comprehensive review report to staging directory You Should See: Complete code review report with prioritized staging and actionable recommendations","title":"Step 7: Aggregated Report Generation"},{"location":"skills/review-code/tutorial/#step-8-follow-up-action-planning","text":"What System Does: Suggests next steps for addressing identified issues Provides implementation guidance for improvements Recommends tools and processes for ongoing quality Creates tracking mechanism for improvement progress Offers integration suggestions with development workflow You Should See: Action plan with specific steps for code quality improvement and workflow integration","title":"Step 8: Follow-up Action Planning"},{"location":"skills/review-code/tutorial/#verification-checklist","text":"\u2705 Review mode selected : Appropriate input mode chosen and configured \u2705 Code discovered : Files or code identified and prepared for review \u2705 Quality analysis completed : Comprehensive evaluation against best practices \u2705 Security assessment done : Vulnerability and security pattern review completed \u2705 Maintainability evaluated : Code structure and readability assessed \u2705 Issues prioritized : staging organized by severity and impact \u2705 Report generated : Comprehensive review documentation created \u2705 Action plan provided : Clear next steps for improvement identified","title":"Verification Checklist"},{"location":"skills/review-code/tutorial/#troubleshooting","text":"If git-modified mode fails: # Verify git repository status and modified files git status git diff --name-only # Check branch and ensure there are modified files to review If code analysis seems incomplete: Verify file paths are accessible and readable Check that specified programming language is supported Ensure focus areas match actual code characteristics Consider adjusting batch size for large repositories If security assessment misses issues: Review focus areas to include specific security concerns Provide additional context about application security requirements Consider manual mode for sensitive code sections Supplement with specialized security tools if needed","title":"Troubleshooting"},{"location":"skills/review-code/tutorial/#key-learning-points","text":"Multiple input modes : Review supports manual selection, git discovery, and batch processing Comprehensive analysis : Covers quality, security, maintainability, and performance Batch processing : Large codebases handled systematically through batching Actionable output : Results include specific recommendations and implementation guidance Workflow integration : Designed to fit into existing development and review processes","title":"Key Learning Points"},{"location":"skills/review-code/tutorial/#next-steps-to-try","text":"Implement prioritized improvements from review staging Integrate code review workflow into development process Use git-modified mode for regular change reviews Apply focus areas for specialized review needs (security, performance) Establish regular review cycles for ongoing code quality","title":"Next Steps to Try"},{"location":"skills/review-code/tutorial/#expected-timeline","text":"Total review time: 15-45 minutes depending on code volume and complexity User input required: Mode selection and parameter setup (3-5 minutes) Code discovery: File identification and preparation (2-5 minutes) Analysis execution: Comprehensive review and assessment (10-30 minutes) Report generation: staging compilation and action planning (5-10 minutes)","title":"Expected Timeline"},{"location":"skills/review-code-accessibility/description/","text":"Review Code Accessibility \u00b6 Enhanced skill migrated from developer competency. Usage \u00b6 This skill provides review code accessibility functionality with self-contained dependencies and enhanced error handling.","title":"Review Code Accessibility"},{"location":"skills/review-code-accessibility/description/#review-code-accessibility","text":"Enhanced skill migrated from developer competency.","title":"Review Code Accessibility"},{"location":"skills/review-code-accessibility/description/#usage","text":"This skill provides review code accessibility functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/review-code-accessibility/tutorial/","text":"Review Code Accessibility Tutorial \u00b6 Step-by-step guide for using the review-code-accessibility skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Review Code Accessibility Tutorial"},{"location":"skills/review-code-accessibility/tutorial/#review-code-accessibility-tutorial","text":"Step-by-step guide for using the review-code-accessibility skill.","title":"Review Code Accessibility Tutorial"},{"location":"skills/review-code-accessibility/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/review-code-accessibility/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/review-diff/description/","text":"Review-Diff Skill Description \u00b6 Overview \u00b6 The review-diff skill provides comprehensive code review capabilities for git diffs using language-specific review standards and practices. It automatically detects programming languages, applies appropriate review criteria, and generates structured severity-based feedback reports. Purpose \u00b6 This skill automates the code review process by: - Analyzing git diff output for changed files - Detecting programming languages from file extensions - Applying language-specific review standards from the knowledge base - Generating structured review reports with actionable feedback - Providing file and line number references for all findings Key Features \u00b6 Language Detection \u00b6 Automatically identifies programming languages (.py, .cpp, .h, .java, .go, .js, etc.) Routes each file to appropriate review standards Supports Python, C++, Java, and Go specific review criteria Fallback to general review principles for other languages Severity Classification \u00b6 HIGH : Security vulnerabilities, memory safety, runtime errors MEDIUM : Code quality, best practices, testing gaps LOW : Minor style issues, optimization opportunities Actionable Commands \u00b6 Generates specific fix commands for each finding Provides verification commands to confirm fixes Categorizes actions by immediate vs manual fixes Language-specific tooling recommendations Report Persistence \u00b6 Optional saving to [staging_dir]/diff-reviews/ Timestamped report files for tracking over time Separate actionable commands file for easy execution Organized directory structure for review history Comprehensive Coverage \u00b6 Security vulnerability scanning (hardcoded secrets, credentials) Code quality assessment (duplication, complexity, organization) Best practices validation (type hints, documentation, testing) Formatting and style compliance checking Naming convention consistency verification Structured Output \u00b6 Mandatory file and line number references for every finding Markdown-formatted reports with clickable file links Organized by severity levels for prioritized action Summary statistics and next steps guidance Integration \u00b6 This skill integrates with: - Git : Requires git repository in workspace - OLAF Framework : Follows established protocols and templates - Shared Practices : References central language-specific review standards in data/practices/code-reviews/ - Templates : Uses structured report formats - Language Router : Uses helpers/review-diff-router.md for language detection and routing - Other Review Skills : Shares review standards with review-github-pr , review-commit , and other review tools Use Cases \u00b6 Pre-commit Review : Review changes before committing to repository Pull Request Preparation : Generate comprehensive feedback for PR descriptions External Integration : Accept diff from other tools (GitHub PRs, external systems) Code Quality Assurance : Systematic evaluation of code changes Team Standards Enforcement : Consistent application of coding standards Security Scanning : Identification of potential security vulnerabilities Input Parameters \u00b6 diff_content : Pre-collected diff content for external integrations (OPTIONAL) review_scope : Scope of review - workspace, folder, or file (default: workspace) target_path : Specific folder or file path when scope is targeted save_report : Save report to staging directory (default: false) include_actions : Include actionable fix commands (default: true) Workflow Integration \u00b6 The skill follows the OLAF Act protocol for standard reviews: 1. Validates git repository availability 2. Discovers and verifies target paths 3. Executes appropriate git diff commands 4. Applies language-specific review standards 5. Generates structured severity-based reports 6. Provides actionable recommendations and next steps","title":"Review-Diff Skill Description"},{"location":"skills/review-diff/description/#review-diff-skill-description","text":"","title":"Review-Diff Skill Description"},{"location":"skills/review-diff/description/#overview","text":"The review-diff skill provides comprehensive code review capabilities for git diffs using language-specific review standards and practices. It automatically detects programming languages, applies appropriate review criteria, and generates structured severity-based feedback reports.","title":"Overview"},{"location":"skills/review-diff/description/#purpose","text":"This skill automates the code review process by: - Analyzing git diff output for changed files - Detecting programming languages from file extensions - Applying language-specific review standards from the knowledge base - Generating structured review reports with actionable feedback - Providing file and line number references for all findings","title":"Purpose"},{"location":"skills/review-diff/description/#key-features","text":"","title":"Key Features"},{"location":"skills/review-diff/description/#language-detection","text":"Automatically identifies programming languages (.py, .cpp, .h, .java, .go, .js, etc.) Routes each file to appropriate review standards Supports Python, C++, Java, and Go specific review criteria Fallback to general review principles for other languages","title":"Language Detection"},{"location":"skills/review-diff/description/#severity-classification","text":"HIGH : Security vulnerabilities, memory safety, runtime errors MEDIUM : Code quality, best practices, testing gaps LOW : Minor style issues, optimization opportunities","title":"Severity Classification"},{"location":"skills/review-diff/description/#actionable-commands","text":"Generates specific fix commands for each finding Provides verification commands to confirm fixes Categorizes actions by immediate vs manual fixes Language-specific tooling recommendations","title":"Actionable Commands"},{"location":"skills/review-diff/description/#report-persistence","text":"Optional saving to [staging_dir]/diff-reviews/ Timestamped report files for tracking over time Separate actionable commands file for easy execution Organized directory structure for review history","title":"Report Persistence"},{"location":"skills/review-diff/description/#comprehensive-coverage","text":"Security vulnerability scanning (hardcoded secrets, credentials) Code quality assessment (duplication, complexity, organization) Best practices validation (type hints, documentation, testing) Formatting and style compliance checking Naming convention consistency verification","title":"Comprehensive Coverage"},{"location":"skills/review-diff/description/#structured-output","text":"Mandatory file and line number references for every finding Markdown-formatted reports with clickable file links Organized by severity levels for prioritized action Summary statistics and next steps guidance","title":"Structured Output"},{"location":"skills/review-diff/description/#integration","text":"This skill integrates with: - Git : Requires git repository in workspace - OLAF Framework : Follows established protocols and templates - Shared Practices : References central language-specific review standards in data/practices/code-reviews/ - Templates : Uses structured report formats - Language Router : Uses helpers/review-diff-router.md for language detection and routing - Other Review Skills : Shares review standards with review-github-pr , review-commit , and other review tools","title":"Integration"},{"location":"skills/review-diff/description/#use-cases","text":"Pre-commit Review : Review changes before committing to repository Pull Request Preparation : Generate comprehensive feedback for PR descriptions External Integration : Accept diff from other tools (GitHub PRs, external systems) Code Quality Assurance : Systematic evaluation of code changes Team Standards Enforcement : Consistent application of coding standards Security Scanning : Identification of potential security vulnerabilities","title":"Use Cases"},{"location":"skills/review-diff/description/#input-parameters","text":"diff_content : Pre-collected diff content for external integrations (OPTIONAL) review_scope : Scope of review - workspace, folder, or file (default: workspace) target_path : Specific folder or file path when scope is targeted save_report : Save report to staging directory (default: false) include_actions : Include actionable fix commands (default: true)","title":"Input Parameters"},{"location":"skills/review-diff/description/#workflow-integration","text":"The skill follows the OLAF Act protocol for standard reviews: 1. Validates git repository availability 2. Discovers and verifies target paths 3. Executes appropriate git diff commands 4. Applies language-specific review standards 5. Generates structured severity-based reports 6. Provides actionable recommendations and next steps","title":"Workflow Integration"},{"location":"skills/review-diff/tutorial/","text":"Review-Diff Skill Tutorial \u00b6 Step-by-Step Guide \u00b6 This tutorial walks you through using the review-diff skill to perform comprehensive code reviews on git diffs. Prerequisites \u00b6 Before using this skill: - Ensure you have a git repository in your workspace - Make some code changes (but don't commit them yet) - Have the OLAF framework loaded Basic Usage \u00b6 Step 1: Review All Changes in Workspace \u00b6 /review-diff This will: - Analyze all unstaged changes in the workspace - Apply appropriate language-specific standards - Generate a comprehensive review report Step 2: Review Specific Folder \u00b6 /review-diff folder /path/to/specific/folder This will: - Limit review to changes within the specified folder - Verify the folder path exists - Focus review scope on targeted changes Step 3: Review Specific File \u00b6 /review-diff file /path/to/specific/file.py This will: - Review changes only in the specified file - Apply language-specific standards for that file type - Provide focused feedback on single file changes Understanding the Output \u00b6 Report Structure \u00b6 The skill generates reports with this structure: # Code Review Report - 20251120-1445 **Files Reviewed:** 3 files **Languages Detected:** Python, C++ **Review Scope:** Full workspace #### HIGH - [src/auth.py](src/auth.py), line 42 \u2014 Hardcoded API key detected. Use environment variable instead. #### MEDIUM - [src/utils.cpp](src/utils.cpp), lines 15-20 \u2014 Missing type hints for function parameters. Add type annotations. #### LOW - [src/main.py](src/main.py), line 8 \u2014 Import organization could be improved for readability. --- **Review Summary:** - HIGH: 1 issues - MEDIUM: 1 issues - LOW: 1 issues **Next Steps:** - Address HIGH severity issues before push - Consider MEDIUM issues for code quality - Apply LOW suggestions when convenient Severity Levels \u00b6 HIGH Priority - Address before committing: - Security vulnerabilities - Memory safety issues - Runtime errors - Critical performance problems MEDIUM Priority - Consider for code quality: - Best practices violations - Missing documentation - Test coverage gaps - Formatting inconsistencies LOW Priority - Apply when convenient: - Minor style improvements - Optimization opportunities - Code organization suggestions Language-Specific Reviews \u00b6 Python Files (.py) \u00b6 The skill automatically applies Python-specific standards from the central practices: - Source : .olaf/data/practices/guidances/review/code-reviews/review-guidelines-python.md - Standards : Type hints validation, PEP compliance checking, import organization - Tools : Docstring requirements, memory management patterns C++ Files (.cpp, .h, .hpp) \u00b6 For C++ files, it applies standards from: - Source : .olaf/data/practices/guidances/review/code-reviews/review-guidelines-cplusplus.md - Standards : Memory safety checks, modern C++ standards, smart pointer usage - Tools : Thread safety validation, performance considerations Java Files (.java) \u00b6 For Java files, it applies enterprise-grade standards: - Source : .olaf/data/practices/guidances/review/code-reviews/review-guidelines-java.md - Standards : Modern Java features, Spring framework patterns, exception handling - Tools : JVM performance, security practices, testing patterns Go Files (.go) \u00b6 For Go files, it applies Go-specific idioms and practices: - Source : .olaf/data/practices/guidances/review/code-reviews/review-guidelines-go.md - Standards : Go idioms, error handling, concurrency patterns - Tools : Goroutine management, channel usage, memory efficiency Mixed Language Projects \u00b6 When your changes include multiple languages: - Each file is reviewed with its appropriate standards - Findings are organized by language in the report - Cross-language interface concerns are noted Advanced Usage \u00b6 Working with Large Diffs \u00b6 For projects with many changes: 1. Start with a full workspace review to get overview 2. Address HIGH severity issues first 3. Use folder-specific reviews to focus on areas 4. Use file-specific reviews for detailed analysis Integration with Git Workflow \u00b6 Before Committing: /review-diff Review all changes and address HIGH/MEDIUM issues Before Push: /review-diff Final check to ensure quality standards Pull Request Preparation: Use the generated report to write comprehensive PR descriptions Troubleshooting \u00b6 No Changes Detected \u00b6 If the skill reports no changes: - Verify you have unstaged changes: git status - Ensure you're in the correct directory - Check that files are tracked by git Path Not Found \u00b6 If specified paths aren't found: - Verify the path exists in your workspace - Use absolute paths or workspace-relative paths - Check for typos in the path specification Missing Language Standards \u00b6 If a language isn't specifically supported: - The skill applies general code review principles - Consider adding language-specific standards to the knowledge base - Focus on universal quality aspects (security, organization, documentation) Best Practices \u00b6 Regular Reviews : Run reviews frequently during development Incremental Fixes : Address issues as they're identified Team Standards : Use consistent review criteria across team Documentation : Keep review findings for future reference Continuous Improvement : Update review standards based on findings Next Steps \u00b6 After completing your review: - Address HIGH severity findings before committing - Consider MEDIUM severity improvements - Apply LOW severity suggestions incrementally - Update your commit message based on review findings - Share review insights with your team","title":"Review-Diff Skill Tutorial"},{"location":"skills/review-diff/tutorial/#review-diff-skill-tutorial","text":"","title":"Review-Diff Skill Tutorial"},{"location":"skills/review-diff/tutorial/#step-by-step-guide","text":"This tutorial walks you through using the review-diff skill to perform comprehensive code reviews on git diffs.","title":"Step-by-Step Guide"},{"location":"skills/review-diff/tutorial/#prerequisites","text":"Before using this skill: - Ensure you have a git repository in your workspace - Make some code changes (but don't commit them yet) - Have the OLAF framework loaded","title":"Prerequisites"},{"location":"skills/review-diff/tutorial/#basic-usage","text":"","title":"Basic Usage"},{"location":"skills/review-diff/tutorial/#step-1-review-all-changes-in-workspace","text":"/review-diff This will: - Analyze all unstaged changes in the workspace - Apply appropriate language-specific standards - Generate a comprehensive review report","title":"Step 1: Review All Changes in Workspace"},{"location":"skills/review-diff/tutorial/#step-2-review-specific-folder","text":"/review-diff folder /path/to/specific/folder This will: - Limit review to changes within the specified folder - Verify the folder path exists - Focus review scope on targeted changes","title":"Step 2: Review Specific Folder"},{"location":"skills/review-diff/tutorial/#step-3-review-specific-file","text":"/review-diff file /path/to/specific/file.py This will: - Review changes only in the specified file - Apply language-specific standards for that file type - Provide focused feedback on single file changes","title":"Step 3: Review Specific File"},{"location":"skills/review-diff/tutorial/#understanding-the-output","text":"","title":"Understanding the Output"},{"location":"skills/review-diff/tutorial/#report-structure","text":"The skill generates reports with this structure: # Code Review Report - 20251120-1445 **Files Reviewed:** 3 files **Languages Detected:** Python, C++ **Review Scope:** Full workspace #### HIGH - [src/auth.py](src/auth.py), line 42 \u2014 Hardcoded API key detected. Use environment variable instead. #### MEDIUM - [src/utils.cpp](src/utils.cpp), lines 15-20 \u2014 Missing type hints for function parameters. Add type annotations. #### LOW - [src/main.py](src/main.py), line 8 \u2014 Import organization could be improved for readability. --- **Review Summary:** - HIGH: 1 issues - MEDIUM: 1 issues - LOW: 1 issues **Next Steps:** - Address HIGH severity issues before push - Consider MEDIUM issues for code quality - Apply LOW suggestions when convenient","title":"Report Structure"},{"location":"skills/review-diff/tutorial/#severity-levels","text":"HIGH Priority - Address before committing: - Security vulnerabilities - Memory safety issues - Runtime errors - Critical performance problems MEDIUM Priority - Consider for code quality: - Best practices violations - Missing documentation - Test coverage gaps - Formatting inconsistencies LOW Priority - Apply when convenient: - Minor style improvements - Optimization opportunities - Code organization suggestions","title":"Severity Levels"},{"location":"skills/review-diff/tutorial/#language-specific-reviews","text":"","title":"Language-Specific Reviews"},{"location":"skills/review-diff/tutorial/#python-files-py","text":"The skill automatically applies Python-specific standards from the central practices: - Source : .olaf/data/practices/guidances/review/code-reviews/review-guidelines-python.md - Standards : Type hints validation, PEP compliance checking, import organization - Tools : Docstring requirements, memory management patterns","title":"Python Files (.py)"},{"location":"skills/review-diff/tutorial/#c-files-cpp-h-hpp","text":"For C++ files, it applies standards from: - Source : .olaf/data/practices/guidances/review/code-reviews/review-guidelines-cplusplus.md - Standards : Memory safety checks, modern C++ standards, smart pointer usage - Tools : Thread safety validation, performance considerations","title":"C++ Files (.cpp, .h, .hpp)"},{"location":"skills/review-diff/tutorial/#java-files-java","text":"For Java files, it applies enterprise-grade standards: - Source : .olaf/data/practices/guidances/review/code-reviews/review-guidelines-java.md - Standards : Modern Java features, Spring framework patterns, exception handling - Tools : JVM performance, security practices, testing patterns","title":"Java Files (.java)"},{"location":"skills/review-diff/tutorial/#go-files-go","text":"For Go files, it applies Go-specific idioms and practices: - Source : .olaf/data/practices/guidances/review/code-reviews/review-guidelines-go.md - Standards : Go idioms, error handling, concurrency patterns - Tools : Goroutine management, channel usage, memory efficiency","title":"Go Files (.go)"},{"location":"skills/review-diff/tutorial/#mixed-language-projects","text":"When your changes include multiple languages: - Each file is reviewed with its appropriate standards - Findings are organized by language in the report - Cross-language interface concerns are noted","title":"Mixed Language Projects"},{"location":"skills/review-diff/tutorial/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/review-diff/tutorial/#working-with-large-diffs","text":"For projects with many changes: 1. Start with a full workspace review to get overview 2. Address HIGH severity issues first 3. Use folder-specific reviews to focus on areas 4. Use file-specific reviews for detailed analysis","title":"Working with Large Diffs"},{"location":"skills/review-diff/tutorial/#integration-with-git-workflow","text":"Before Committing: /review-diff Review all changes and address HIGH/MEDIUM issues Before Push: /review-diff Final check to ensure quality standards Pull Request Preparation: Use the generated report to write comprehensive PR descriptions","title":"Integration with Git Workflow"},{"location":"skills/review-diff/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/review-diff/tutorial/#no-changes-detected","text":"If the skill reports no changes: - Verify you have unstaged changes: git status - Ensure you're in the correct directory - Check that files are tracked by git","title":"No Changes Detected"},{"location":"skills/review-diff/tutorial/#path-not-found","text":"If specified paths aren't found: - Verify the path exists in your workspace - Use absolute paths or workspace-relative paths - Check for typos in the path specification","title":"Path Not Found"},{"location":"skills/review-diff/tutorial/#missing-language-standards","text":"If a language isn't specifically supported: - The skill applies general code review principles - Consider adding language-specific standards to the knowledge base - Focus on universal quality aspects (security, organization, documentation)","title":"Missing Language Standards"},{"location":"skills/review-diff/tutorial/#best-practices","text":"Regular Reviews : Run reviews frequently during development Incremental Fixes : Address issues as they're identified Team Standards : Use consistent review criteria across team Documentation : Keep review findings for future reference Continuous Improvement : Update review standards based on findings","title":"Best Practices"},{"location":"skills/review-diff/tutorial/#next-steps","text":"After completing your review: - Address HIGH severity findings before committing - Consider MEDIUM severity improvements - Apply LOW severity suggestions incrementally - Update your commit message based on review findings - Share review insights with your team","title":"Next Steps"},{"location":"skills/review-github-pr/description/","text":"Review GitHub PR \u00b6 Overview \u00b6 This competency performs comprehensive pull request reviews with user-guided file selection, integration analysis, and automated action plan generation, focusing on code quality, security, and system integration impact. Purpose \u00b6 Pull requests require thorough review to ensure code quality, prevent bugs, and maintain system integrity. This competency provides structured PR reviews that analyze not just individual changes but also integration impacts, cross-file dependencies, and overall system health, with actionable recommendations for improvement. Usage \u00b6 Command : review github pr (or aliases: review pr , pull request review , check pr , github pr ) Protocol : Propose-Act When to Use : Use for reviewing pull requests before merging, assessing integration risks, validating that changes meet requirements, ensuring code quality standards, and identifying potential issues that span multiple files. Parameters \u00b6 Required Inputs \u00b6 What to review : PR number, branch name, or \\\"latest open PR\\\" repository : Repository name (auto-detected if possible) Optional Inputs \u00b6 review_depth : quick : PR metadata only (description, CI, approvals) standard : PR metadata + optional code analysis comprehensive : PR metadata + automatic code analysis focus_areas : Standards-based focus (security, workflow, quality, compliance, all) Standards-Based Analysis \u00b6 Uses established guidance from .olaf/data/practices/guidances/pr-review/ : - PR Description Standards : Title quality, completeness, traceability - CI/CD Integration Standards : Build status, security scans, quality gates - Review Workflow Standards : Approval requirements, conflict resolution - Branch Workflow Standards : Naming conventions, merge strategies Output \u00b6 Generates comprehensive PR review with integration analysis and action plan. Deliverables : - PR overview with change summary - File-by-file review staging - Integration impact analysis - Cross-file dependency assessment - Security and quality concerns - Automated action plan with prioritized fixes - Merge recommendation (approve, request changes, reject) - Code review report: pr-review-{pr-number}-YYYYMMDD-HHmm.md - Action plan: pr-action-plan-{pr-number}-YYYYMMDD-HHmm.md Format : Structured markdown following code-review-action-plan template Examples \u00b6 Example 1: Feature PR Review \u00b6 Scenario : New authentication feature needs review before merge Command : review github pr Input : pr_url: https://github.com/org/repo/pull/123 focus_areas: [\"security\", \"integration\"] Result : Reviewed 8 files, identified security issue with token storage, found integration risk with existing session management, generated action plan with 5 prioritized fixes, recommended \"Request Changes\" with specific improvements. Example 2: Bug Fix PR Review \u00b6 Scenario : Critical bug fix needs quick but thorough review Command : review pr Input : pr_url: https://github.com/org/repo/pull/456 focus_areas: [\"correctness\", \"testing\"] file_selection: [changed files only] Result : Verified fix addresses root cause, identified missing edge case handling, recommended additional test cases, generated action plan with test improvements, approved with minor suggestions. Example 3: Refactoring PR Review \u00b6 Scenario : Large refactoring PR needs integration analysis Command : check pr Input : pr_url: https://github.com/org/repo/pull/789 focus_areas: [\"integration\", \"breaking-changes\"] integration_scope: deep Result : Analyzed 23 files, mapped all integration points, identified 3 breaking changes, found 2 files with incomplete refactoring, generated comprehensive action plan with migration steps, recommended \"Request Changes\" with detailed integration fixes. Related Competencies \u00b6 review-code : General code review that can be used for individual files in PR analyze-function-complexity : Deep-dive into complex functions changed in PR fix-code-smells : Implements improvements identified during PR review create-unit-tests : Adds tests for PR changes lacking coverage Tips & Best Practices \u00b6 Review PR description and linked issues first for context Use user-guided file selection to focus on critical changes Pay special attention to integration points and dependencies Check for breaking changes and backward compatibility Verify test coverage for new functionality Look for security implications of changes Consider performance impact of modifications Review action plan and prioritize critical fixes Provide constructive feedback with specific examples Acknowledge good practices and clean code Limitations \u00b6 Cannot execute code or run tests May miss runtime behavior issues Cannot validate business logic correctness without domain knowledge Integration analysis limited to static code analysis Cannot detect all security vulnerabilities Effectiveness depends on PR description quality May not catch issues requiring system-wide context Cannot assess user experience or UI/UX changes Limited to code changes, doesn't review documentation or configuration","title":"Review GitHub PR"},{"location":"skills/review-github-pr/description/#review-github-pr","text":"","title":"Review GitHub PR"},{"location":"skills/review-github-pr/description/#overview","text":"This competency performs comprehensive pull request reviews with user-guided file selection, integration analysis, and automated action plan generation, focusing on code quality, security, and system integration impact.","title":"Overview"},{"location":"skills/review-github-pr/description/#purpose","text":"Pull requests require thorough review to ensure code quality, prevent bugs, and maintain system integrity. This competency provides structured PR reviews that analyze not just individual changes but also integration impacts, cross-file dependencies, and overall system health, with actionable recommendations for improvement.","title":"Purpose"},{"location":"skills/review-github-pr/description/#usage","text":"Command : review github pr (or aliases: review pr , pull request review , check pr , github pr ) Protocol : Propose-Act When to Use : Use for reviewing pull requests before merging, assessing integration risks, validating that changes meet requirements, ensuring code quality standards, and identifying potential issues that span multiple files.","title":"Usage"},{"location":"skills/review-github-pr/description/#parameters","text":"","title":"Parameters"},{"location":"skills/review-github-pr/description/#required-inputs","text":"What to review : PR number, branch name, or \\\"latest open PR\\\" repository : Repository name (auto-detected if possible)","title":"Required Inputs"},{"location":"skills/review-github-pr/description/#optional-inputs","text":"review_depth : quick : PR metadata only (description, CI, approvals) standard : PR metadata + optional code analysis comprehensive : PR metadata + automatic code analysis focus_areas : Standards-based focus (security, workflow, quality, compliance, all)","title":"Optional Inputs"},{"location":"skills/review-github-pr/description/#standards-based-analysis","text":"Uses established guidance from .olaf/data/practices/guidances/pr-review/ : - PR Description Standards : Title quality, completeness, traceability - CI/CD Integration Standards : Build status, security scans, quality gates - Review Workflow Standards : Approval requirements, conflict resolution - Branch Workflow Standards : Naming conventions, merge strategies","title":"Standards-Based Analysis"},{"location":"skills/review-github-pr/description/#output","text":"Generates comprehensive PR review with integration analysis and action plan. Deliverables : - PR overview with change summary - File-by-file review staging - Integration impact analysis - Cross-file dependency assessment - Security and quality concerns - Automated action plan with prioritized fixes - Merge recommendation (approve, request changes, reject) - Code review report: pr-review-{pr-number}-YYYYMMDD-HHmm.md - Action plan: pr-action-plan-{pr-number}-YYYYMMDD-HHmm.md Format : Structured markdown following code-review-action-plan template","title":"Output"},{"location":"skills/review-github-pr/description/#examples","text":"","title":"Examples"},{"location":"skills/review-github-pr/description/#example-1-feature-pr-review","text":"Scenario : New authentication feature needs review before merge Command : review github pr Input : pr_url: https://github.com/org/repo/pull/123 focus_areas: [\"security\", \"integration\"] Result : Reviewed 8 files, identified security issue with token storage, found integration risk with existing session management, generated action plan with 5 prioritized fixes, recommended \"Request Changes\" with specific improvements.","title":"Example 1: Feature PR Review"},{"location":"skills/review-github-pr/description/#example-2-bug-fix-pr-review","text":"Scenario : Critical bug fix needs quick but thorough review Command : review pr Input : pr_url: https://github.com/org/repo/pull/456 focus_areas: [\"correctness\", \"testing\"] file_selection: [changed files only] Result : Verified fix addresses root cause, identified missing edge case handling, recommended additional test cases, generated action plan with test improvements, approved with minor suggestions.","title":"Example 2: Bug Fix PR Review"},{"location":"skills/review-github-pr/description/#example-3-refactoring-pr-review","text":"Scenario : Large refactoring PR needs integration analysis Command : check pr Input : pr_url: https://github.com/org/repo/pull/789 focus_areas: [\"integration\", \"breaking-changes\"] integration_scope: deep Result : Analyzed 23 files, mapped all integration points, identified 3 breaking changes, found 2 files with incomplete refactoring, generated comprehensive action plan with migration steps, recommended \"Request Changes\" with detailed integration fixes.","title":"Example 3: Refactoring PR Review"},{"location":"skills/review-github-pr/description/#related-competencies","text":"review-code : General code review that can be used for individual files in PR analyze-function-complexity : Deep-dive into complex functions changed in PR fix-code-smells : Implements improvements identified during PR review create-unit-tests : Adds tests for PR changes lacking coverage","title":"Related Competencies"},{"location":"skills/review-github-pr/description/#tips-best-practices","text":"Review PR description and linked issues first for context Use user-guided file selection to focus on critical changes Pay special attention to integration points and dependencies Check for breaking changes and backward compatibility Verify test coverage for new functionality Look for security implications of changes Consider performance impact of modifications Review action plan and prioritize critical fixes Provide constructive feedback with specific examples Acknowledge good practices and clean code","title":"Tips &amp; Best Practices"},{"location":"skills/review-github-pr/description/#limitations","text":"Cannot execute code or run tests May miss runtime behavior issues Cannot validate business logic correctness without domain knowledge Integration analysis limited to static code analysis Cannot detect all security vulnerabilities Effectiveness depends on PR description quality May not catch issues requiring system-wide context Cannot assess user experience or UI/UX changes Limited to code changes, doesn't review documentation or configuration","title":"Limitations"},{"location":"skills/review-github-pr/tutorial/","text":"Review GitHub PR: Step-by-Step Tutorial \u00b6 How to Execute the \"Review GitHub PR\" Workflow Comprehensive pull request review with integration analysis and action planning. Prerequisites \u00b6 OLAF Framework with developer competency pack GitHub repository access Pull request to review Step-by-Step Instructions \u00b6 Step 1: Initialize PR Review \u00b6 User Action: Execute olaf review pr or github pr Step 2: Specify PR Details \u00b6 Provide: Repository, PR number, review focus areas Step 3: PR Analysis and Review \u00b6 System: Reviews changes, analyzes integration impact, generates action plan using Propose-Act protocol Expected Timeline: 15-25 minutes \u00b6","title":"Review GitHub PR: Step-by-Step Tutorial"},{"location":"skills/review-github-pr/tutorial/#review-github-pr-step-by-step-tutorial","text":"How to Execute the \"Review GitHub PR\" Workflow Comprehensive pull request review with integration analysis and action planning.","title":"Review GitHub PR: Step-by-Step Tutorial"},{"location":"skills/review-github-pr/tutorial/#prerequisites","text":"OLAF Framework with developer competency pack GitHub repository access Pull request to review","title":"Prerequisites"},{"location":"skills/review-github-pr/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/review-github-pr/tutorial/#step-1-initialize-pr-review","text":"User Action: Execute olaf review pr or github pr","title":"Step 1: Initialize PR Review"},{"location":"skills/review-github-pr/tutorial/#step-2-specify-pr-details","text":"Provide: Repository, PR number, review focus areas","title":"Step 2: Specify PR Details"},{"location":"skills/review-github-pr/tutorial/#step-3-pr-analysis-and-review","text":"System: Reviews changes, analyzes integration impact, generates action plan using Propose-Act protocol","title":"Step 3: PR Analysis and Review"},{"location":"skills/review-github-pr/tutorial/#expected-timeline-15-25-minutes","text":"","title":"Expected Timeline: 15-25 minutes"},{"location":"skills/review-human-written-spec/description/","text":"Review Human Written Spec \u00b6 What this skill does \u00b6 This skill guides a multi-phase review of a human-written specification in order to: - Challenge ambiguities and missing decisions - Produce a structured question set for a Subject Matter Expert (SME) - Prepare inputs that unblock API contract design (e.g., OpenAPI) In follow-up mode, the skill also drafts a business decision document from the SME answers. When to use \u00b6 Use this skill when you have a business-facing specification (often incomplete or ambiguous) and you need to design an API that serves the expressed needs. Outputs \u00b6 A markdown review document written under docs/specifications/<demand_folder>/02-ai-review/ (after user confirmation) If review_mode=followup , a business decisions draft written under docs/specifications/<demand_folder>/03-business-decisions/ (after user confirmation) After decisions are reviewed and approved by the user (approval phrase required), the workflow can generate: - docs/specifications/<demand_folder>/04-specifications/ (dev-ready functional spec overview + detailed functional spec (with Mermaid diagrams) + OpenAPI) How decisions are produced \u00b6 The SME/business owner provides answers directly in the AI review file. The skill synthesizes those answers into a draft decisions document (strict gating applies). Decisions approval gate \u00b6 Before generating 04-specifications , the user MUST review the decisions draft and reply with: - I approved this decision Input layout \u00b6 Demand folder: docs/specifications/<demand_folder>/ Human demand documents: docs/specifications/<demand_folder>/01-demand/ Follow-up invocation (copy/paste) \u00b6 @[/olaf-review-human-written-spec] demand_folder: <demand_folder> review_mode: followup previous_review_path: <path-to-previous-ai-review> Protocol \u00b6 This skill uses Propose-Confirm-Act because it writes files into the repository.","title":"Review Human Written Spec"},{"location":"skills/review-human-written-spec/description/#review-human-written-spec","text":"","title":"Review Human Written Spec"},{"location":"skills/review-human-written-spec/description/#what-this-skill-does","text":"This skill guides a multi-phase review of a human-written specification in order to: - Challenge ambiguities and missing decisions - Produce a structured question set for a Subject Matter Expert (SME) - Prepare inputs that unblock API contract design (e.g., OpenAPI) In follow-up mode, the skill also drafts a business decision document from the SME answers.","title":"What this skill does"},{"location":"skills/review-human-written-spec/description/#when-to-use","text":"Use this skill when you have a business-facing specification (often incomplete or ambiguous) and you need to design an API that serves the expressed needs.","title":"When to use"},{"location":"skills/review-human-written-spec/description/#outputs","text":"A markdown review document written under docs/specifications/<demand_folder>/02-ai-review/ (after user confirmation) If review_mode=followup , a business decisions draft written under docs/specifications/<demand_folder>/03-business-decisions/ (after user confirmation) After decisions are reviewed and approved by the user (approval phrase required), the workflow can generate: - docs/specifications/<demand_folder>/04-specifications/ (dev-ready functional spec overview + detailed functional spec (with Mermaid diagrams) + OpenAPI)","title":"Outputs"},{"location":"skills/review-human-written-spec/description/#how-decisions-are-produced","text":"The SME/business owner provides answers directly in the AI review file. The skill synthesizes those answers into a draft decisions document (strict gating applies).","title":"How decisions are produced"},{"location":"skills/review-human-written-spec/description/#decisions-approval-gate","text":"Before generating 04-specifications , the user MUST review the decisions draft and reply with: - I approved this decision","title":"Decisions approval gate"},{"location":"skills/review-human-written-spec/description/#input-layout","text":"Demand folder: docs/specifications/<demand_folder>/ Human demand documents: docs/specifications/<demand_folder>/01-demand/","title":"Input layout"},{"location":"skills/review-human-written-spec/description/#follow-up-invocation-copypaste","text":"@[/olaf-review-human-written-spec] demand_folder: <demand_folder> review_mode: followup previous_review_path: <path-to-previous-ai-review>","title":"Follow-up invocation (copy/paste)"},{"location":"skills/review-human-written-spec/description/#protocol","text":"This skill uses Propose-Confirm-Act because it writes files into the repository.","title":"Protocol"},{"location":"skills/review-human-written-spec/tutorial/","text":"Tutorial: Review a human specification for API design readiness \u00b6 1) Provide the input specification \u00b6 Create (or pick) a demand folder under docs/specifications/ (example: pet-clinic-01/ ) Place the demand documents under: docs/specifications/<demand_folder>/01-demand/ 2) Run the skill \u00b6 Invoke the skill and provide: - demand_folder (example: pet-clinic-01 ) - Optionally review_mode=followup and previous_review_path 3) Review and confirm file writing \u00b6 The skill will: - Produce the review content - Propose an output file path under docs/specifications/<demand_folder>/02-ai-review/ - Ask for confirmation before writing 4) SME answers (edit the AI review directly) \u00b6 The SME SHOULD edit the generated AI review file directly. Fill the SME answer worksheet (and/or SME answer column) for each question. 5) Follow-up review (generates business decisions + strict gating) \u00b6 After the SME answers are filled, run a follow-up review by copy/pasting: @[/olaf-review-human-written-spec] demand_folder: <demand_folder> review_mode: followup previous_review_path: <path-to-previous-ai-review> In follow-up mode the skill will: - Enforce strict gating on High-priority questions - Draft business decisions under docs/specifications/<demand_folder>/03-business-decisions/ After the decisions draft is written: - Review it - To approve and allow spec generation, reply with this exact sentence: - I approved this decision Only after approval, the workflow will generate docs/specifications/<demand_folder>/04-specifications/ : - A dev-ready functional specification (overview) - A dev-ready functional specification (detailed, including Mermaid diagrams) - An OpenAPI specification","title":"Tutorial: Review a human specification for API design readiness"},{"location":"skills/review-human-written-spec/tutorial/#tutorial-review-a-human-specification-for-api-design-readiness","text":"","title":"Tutorial: Review a human specification for API design readiness"},{"location":"skills/review-human-written-spec/tutorial/#1-provide-the-input-specification","text":"Create (or pick) a demand folder under docs/specifications/ (example: pet-clinic-01/ ) Place the demand documents under: docs/specifications/<demand_folder>/01-demand/","title":"1) Provide the input specification"},{"location":"skills/review-human-written-spec/tutorial/#2-run-the-skill","text":"Invoke the skill and provide: - demand_folder (example: pet-clinic-01 ) - Optionally review_mode=followup and previous_review_path","title":"2) Run the skill"},{"location":"skills/review-human-written-spec/tutorial/#3-review-and-confirm-file-writing","text":"The skill will: - Produce the review content - Propose an output file path under docs/specifications/<demand_folder>/02-ai-review/ - Ask for confirmation before writing","title":"3) Review and confirm file writing"},{"location":"skills/review-human-written-spec/tutorial/#4-sme-answers-edit-the-ai-review-directly","text":"The SME SHOULD edit the generated AI review file directly. Fill the SME answer worksheet (and/or SME answer column) for each question.","title":"4) SME answers (edit the AI review directly)"},{"location":"skills/review-human-written-spec/tutorial/#5-follow-up-review-generates-business-decisions-strict-gating","text":"After the SME answers are filled, run a follow-up review by copy/pasting: @[/olaf-review-human-written-spec] demand_folder: <demand_folder> review_mode: followup previous_review_path: <path-to-previous-ai-review> In follow-up mode the skill will: - Enforce strict gating on High-priority questions - Draft business decisions under docs/specifications/<demand_folder>/03-business-decisions/ After the decisions draft is written: - Review it - To approve and allow spec generation, reply with this exact sentence: - I approved this decision Only after approval, the workflow will generate docs/specifications/<demand_folder>/04-specifications/ : - A dev-ready functional specification (overview) - A dev-ready functional specification (detailed, including Mermaid diagrams) - An OpenAPI specification","title":"5) Follow-up review (generates business decisions + strict gating)"},{"location":"skills/review-prd-spec/description/","text":"Review PRD Spec \u00b6 Overview \u00b6 This competency performs comprehensive reviews of Product Requirements Documents (PRDs) and evolution requests to ensure completeness, identify gaps, and format them according to standardized templates. It analyzes content systematically, generates targeted improvement questions, and produces professionally formatted PRD documents ready for stakeholder review. Purpose \u00b6 PRDs often suffer from incomplete sections, missing success criteria, unclear requirements, or inconsistent formatting that lead to misaligned expectations and project delays. This competency addresses these issues by conducting thorough gap analysis, engaging users with specific improvement questions, and applying standardized templates to ensure all critical PRD elements are present and properly documented before stakeholder approval. Usage \u00b6 Command : review prd spec Protocol : Propose-Act (for review staging), Propose-Confirm-Act (for final document save) When to Use : Use this competency when you have a draft PRD or evolution request that needs validation before stakeholder review, when preparing requirements for technical team handoff, or when standardizing PRD format across your organization. Parameters \u00b6 Required Inputs \u00b6 prd_content : The evolution request/PRD content to review (string or file path) project_name : Name of the project/feature being evolved Optional Inputs \u00b6 review_depth : Level of review depth - basic, comprehensive, or detailed (default: comprehensive) save_format : Whether to save the reviewed document in template format (default: true) template_type : PRD template format to use - standard, agile, or enterprise (default: standard) Context Requirements \u00b6 Access to PRD template files in templates directory Current timestamp for document versioning Product documentation directory for saving formatted output Output \u00b6 This competency produces a comprehensive review analysis and a professionally formatted PRD document. Deliverables : - Review summary with completeness assessment and gap analysis - Categorized improvement questions (Critical, Important, Nice-to-have) - Formatted PRD document following selected template: [product_docs_dir]/[project_name]-prd-[timestamp].md - Quality checklist with validation results Format : Structured markdown documents following PRD template standards with proper section numbering, table of contents, and version control information. Examples \u00b6 Example 1: Pre-Stakeholder Review Validation \u00b6 Scenario : A product manager has drafted a PRD for a new customer portal feature and needs to ensure all critical sections are complete before presenting to executives. Command : olaf review prd spec Input : prd_content: [path to draft PRD] project_name: customer-portal-v2 review_depth: comprehensive Result : Identified 5 critical gaps (missing success metrics, incomplete risk assessment), 8 important gaps (unclear technical constraints), generated 15 targeted questions, and produced formatted PRD with 95% template compliance. Example 2: Evolution Request Standardization \u00b6 Scenario : Multiple teams submit evolution requests in different formats. Need to standardize a request for the approval process. Command : olaf review prd spec Input : prd_content: [evolution request content] project_name: payment-integration-enhancement template_type: enterprise Result : Analyzed informal request, identified missing business case and ROI sections, engaged user to fill gaps, and produced enterprise-standard PRD document ready for governance review. Related Competencies \u00b6 analyze-business-requirements : Use this for detailed requirements validation after PRD review identifies requirement gaps improve-spec : Complements this by adding technical diagrams and detailed specifications to the reviewed PRD extend-specification : Use after PRD approval to add implementation-level technical details generate-questionnaire : Use to create structured stakeholder interviews for filling identified PRD gaps Tips & Best Practices \u00b6 Run this review before scheduling stakeholder approval meetings to avoid last-minute gaps Focus on critical gaps first\u2014use the prioritized gap list to guide improvement efforts efficiently Engage subject matter experts for technical sections identified as incomplete Use the generated questions in collaborative sessions rather than as standalone surveys Save multiple review iterations to track PRD quality improvement over time Ensure success criteria are measurable and time-bound\u2014this is the most commonly missed element Include both technical and business risks in the risk assessment section Limitations \u00b6 Cannot validate business viability or market fit\u2014focuses on document completeness and structure Requires human judgment for strategic decisions and priority trade-offs Template compliance depends on availability of template files in the expected directory Does not replace stakeholder collaboration\u2014use as a preparation tool, not a replacement for discussion Quality of improvement questions depends on clarity of the input PRD content Source : core/competencies/business-analyst/prompts/review-prd-spec.md","title":"Review PRD Spec"},{"location":"skills/review-prd-spec/description/#review-prd-spec","text":"","title":"Review PRD Spec"},{"location":"skills/review-prd-spec/description/#overview","text":"This competency performs comprehensive reviews of Product Requirements Documents (PRDs) and evolution requests to ensure completeness, identify gaps, and format them according to standardized templates. It analyzes content systematically, generates targeted improvement questions, and produces professionally formatted PRD documents ready for stakeholder review.","title":"Overview"},{"location":"skills/review-prd-spec/description/#purpose","text":"PRDs often suffer from incomplete sections, missing success criteria, unclear requirements, or inconsistent formatting that lead to misaligned expectations and project delays. This competency addresses these issues by conducting thorough gap analysis, engaging users with specific improvement questions, and applying standardized templates to ensure all critical PRD elements are present and properly documented before stakeholder approval.","title":"Purpose"},{"location":"skills/review-prd-spec/description/#usage","text":"Command : review prd spec Protocol : Propose-Act (for review staging), Propose-Confirm-Act (for final document save) When to Use : Use this competency when you have a draft PRD or evolution request that needs validation before stakeholder review, when preparing requirements for technical team handoff, or when standardizing PRD format across your organization.","title":"Usage"},{"location":"skills/review-prd-spec/description/#parameters","text":"","title":"Parameters"},{"location":"skills/review-prd-spec/description/#required-inputs","text":"prd_content : The evolution request/PRD content to review (string or file path) project_name : Name of the project/feature being evolved","title":"Required Inputs"},{"location":"skills/review-prd-spec/description/#optional-inputs","text":"review_depth : Level of review depth - basic, comprehensive, or detailed (default: comprehensive) save_format : Whether to save the reviewed document in template format (default: true) template_type : PRD template format to use - standard, agile, or enterprise (default: standard)","title":"Optional Inputs"},{"location":"skills/review-prd-spec/description/#context-requirements","text":"Access to PRD template files in templates directory Current timestamp for document versioning Product documentation directory for saving formatted output","title":"Context Requirements"},{"location":"skills/review-prd-spec/description/#output","text":"This competency produces a comprehensive review analysis and a professionally formatted PRD document. Deliverables : - Review summary with completeness assessment and gap analysis - Categorized improvement questions (Critical, Important, Nice-to-have) - Formatted PRD document following selected template: [product_docs_dir]/[project_name]-prd-[timestamp].md - Quality checklist with validation results Format : Structured markdown documents following PRD template standards with proper section numbering, table of contents, and version control information.","title":"Output"},{"location":"skills/review-prd-spec/description/#examples","text":"","title":"Examples"},{"location":"skills/review-prd-spec/description/#example-1-pre-stakeholder-review-validation","text":"Scenario : A product manager has drafted a PRD for a new customer portal feature and needs to ensure all critical sections are complete before presenting to executives. Command : olaf review prd spec Input : prd_content: [path to draft PRD] project_name: customer-portal-v2 review_depth: comprehensive Result : Identified 5 critical gaps (missing success metrics, incomplete risk assessment), 8 important gaps (unclear technical constraints), generated 15 targeted questions, and produced formatted PRD with 95% template compliance.","title":"Example 1: Pre-Stakeholder Review Validation"},{"location":"skills/review-prd-spec/description/#example-2-evolution-request-standardization","text":"Scenario : Multiple teams submit evolution requests in different formats. Need to standardize a request for the approval process. Command : olaf review prd spec Input : prd_content: [evolution request content] project_name: payment-integration-enhancement template_type: enterprise Result : Analyzed informal request, identified missing business case and ROI sections, engaged user to fill gaps, and produced enterprise-standard PRD document ready for governance review.","title":"Example 2: Evolution Request Standardization"},{"location":"skills/review-prd-spec/description/#related-competencies","text":"analyze-business-requirements : Use this for detailed requirements validation after PRD review identifies requirement gaps improve-spec : Complements this by adding technical diagrams and detailed specifications to the reviewed PRD extend-specification : Use after PRD approval to add implementation-level technical details generate-questionnaire : Use to create structured stakeholder interviews for filling identified PRD gaps","title":"Related Competencies"},{"location":"skills/review-prd-spec/description/#tips-best-practices","text":"Run this review before scheduling stakeholder approval meetings to avoid last-minute gaps Focus on critical gaps first\u2014use the prioritized gap list to guide improvement efforts efficiently Engage subject matter experts for technical sections identified as incomplete Use the generated questions in collaborative sessions rather than as standalone surveys Save multiple review iterations to track PRD quality improvement over time Ensure success criteria are measurable and time-bound\u2014this is the most commonly missed element Include both technical and business risks in the risk assessment section","title":"Tips &amp; Best Practices"},{"location":"skills/review-prd-spec/description/#limitations","text":"Cannot validate business viability or market fit\u2014focuses on document completeness and structure Requires human judgment for strategic decisions and priority trade-offs Template compliance depends on availability of template files in the expected directory Does not replace stakeholder collaboration\u2014use as a preparation tool, not a replacement for discussion Quality of improvement questions depends on clarity of the input PRD content Source : core/competencies/business-analyst/prompts/review-prd-spec.md","title":"Limitations"},{"location":"skills/review-prd-spec/tutorial/","text":"Step-by-Step Tutorial \u00b6 Review PRD Spec: Step-by-Step Tutorial How to Execute the \"Review PRD Spec\" Workflow This tutorial shows exactly how to review Product Requirements Documents (PRDs) for completeness, identify gaps, and generate standardized formatted documents using the OLAF business-analyst competency. Prerequisites \u00b6 OLAF framework properly installed and configured Access to a PRD or evolution request document to review PRD template files available in the templates directory Understanding of PRD structure and standard sections Access to the business-analyst competency pack Step-by-Step Instructions \u00b6 Step 1: Prepare the PRD Content \u00b6 [Ensure you have the PRD document ready for review] User Action: 1. Locate the PRD or evolution request document you want to review 2. Ensure the document is accessible (file path or content string) 3. Identify the project name for proper document naming 4. Decide on review depth level (basic, comprehensive, or detailed) System Response: Document should be readable and accessible for processing. Step 2: Invoke the Review Command \u00b6 User Action: Execute the OLAF command to start PRD review olaf review prd spec Provide Parameters: - prd_content : [path/to/prd-document.md or content string] - The PRD to review - project_name : [your-project-name] - Name for output file naming - review_depth : [comprehensive] - Level of analysis (default: comprehensive) - save_format : [true] - Whether to save formatted output (default: true) - template_type : [standard] - Template format to use (default: standard) Step 3: Content Analysis Phase \u00b6 What OLAF Does: - Reads and parses the PRD content structure - Analyzes business objectives and success metrics - Reviews user stories and acceptance criteria - Evaluates technical requirements and constraints - Assesses risk management and mitigation strategies - Checks timeline and resource requirements - Validates stakeholder identification You Should See: Progress messages indicating content analysis is underway Step 4: Completeness Review and Gap Identification \u00b6 What OLAF Does: - Evaluates each PRD section against standard requirements: - Executive Summary (problem statement, solution overview) - Business Case (value proposition, ROI, strategic alignment) - User Requirements (personas, journeys, functional requirements) - Technical Specifications (architecture, integrations, performance) - Implementation Plan (phases, milestones, dependencies) - Success Criteria (measurable outcomes, KPIs) - Risk Management (identified risks, mitigation plans) - Creates prioritized gap list (Critical, Important, Nice-to-have) - Generates specific questions to address each gap - Provides examples of complete sections You Should See: Categorized list of gaps with priority levels and specific questions Step 5: User Interaction for Improvements \u00b6 What OLAF Does: - Presents staging using Propose-Act protocol - Asks targeted questions to fill identified gaps - Requests clarification on ambiguous requirements - Validates user responses iteratively - Ensures all critical gaps are addressed User Action: 1. Review the identified gaps and their priority levels 2. Answer the targeted improvement questions 3. Provide clarification for ambiguous sections 4. Confirm when critical gaps have been addressed You Should See: Interactive question-and-answer session with specific, actionable questions Step 6: Document Formatting \u00b6 What OLAF Does: - Applies selected PRD template structure (standard/agile/enterprise) - Ensures consistent formatting and style throughout - Adds proper section numbering and cross-references - Includes timestamp and version information - Generates table of contents and appendices - Validates internal consistency and clarity You Should See: Formatted document preview following template structure Step 7: Quality Validation and Final Output \u00b6 What OLAF Does: - Confirms all critical gaps have been addressed - Verifies document follows template structure completely - Checks for internal consistency and clarity - Validates that success criteria are measurable - Calculates quality score and template compliance percentage - Saves final document using Propose-Confirm-Act protocol User Action: Review and approve the final formatted document for saving You Should See: - Complete formatted PRD document - Quality checklist with validation results - Template compliance score (target: 95%+) - File save confirmation: [product_docs_dir]/[project_name]-prd-[timestamp].md Verification Checklist \u00b6 \u2705 PRD content thoroughly analyzed for completeness \u2705 All critical gaps identified and prioritized \u2705 Targeted improvement questions generated and answered \u2705 Document formatted according to selected template \u2705 Quality validation confirms 95%+ template compliance \u2705 Success criteria are measurable and time-bound \u2705 Risk assessment includes both technical and business risks \u2705 Final document saved with proper naming convention \u2705 User approval obtained for final formatted version Troubleshooting \u00b6 If PRD content cannot be read: - Verify the file path is correct and accessible - Ensure the document format is supported - Check file permissions If template files are not found: Check templates directory: [templates_dir]/business-analyst/ Verify template_type parameter matches available templates If critical gaps remain unaddressed: - Review the prioritized gap list systematically - Engage subject matter experts for technical sections - Consider scheduling stakeholder workshops for complex gaps If template compliance is below 95%: - Review sections flagged in quality validation - Ensure all required sections are present - Verify formatting consistency throughout document Key Learning Points \u00b6 Systematic Gap Analysis: The workflow uses a structured approach to identify missing or incomplete PRD sections across all standard categories Prioritized Improvements: Gaps are categorized by severity (Critical, Important, Nice-to-have) to focus efforts efficiently Interactive Refinement: The Propose-Act protocol ensures collaborative improvement rather than automated assumptions Template Standardization: Applying consistent templates ensures organizational alignment and reduces review friction Next Steps to Try \u00b6 Share the formatted PRD with stakeholders for approval Use analyze-business-requirements to validate detailed requirement sections Apply improve-spec to add technical diagrams and data models Schedule technical review with development team Track PRD quality metrics over multiple projects to improve process Expected Timeline \u00b6 Total review time: 10-20 minutes depending on PRD size and gap count User input required: Answering improvement questions, providing clarifications, approving final document OLAF execution time: Automated analysis, gap identification, formatting, and validation Interactive phases: Gap discussion and document approval require active user participation","title":"Step-by-Step Tutorial"},{"location":"skills/review-prd-spec/tutorial/#step-by-step-tutorial","text":"Review PRD Spec: Step-by-Step Tutorial How to Execute the \"Review PRD Spec\" Workflow This tutorial shows exactly how to review Product Requirements Documents (PRDs) for completeness, identify gaps, and generate standardized formatted documents using the OLAF business-analyst competency.","title":"Step-by-Step Tutorial"},{"location":"skills/review-prd-spec/tutorial/#prerequisites","text":"OLAF framework properly installed and configured Access to a PRD or evolution request document to review PRD template files available in the templates directory Understanding of PRD structure and standard sections Access to the business-analyst competency pack","title":"Prerequisites"},{"location":"skills/review-prd-spec/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/review-prd-spec/tutorial/#step-1-prepare-the-prd-content","text":"[Ensure you have the PRD document ready for review] User Action: 1. Locate the PRD or evolution request document you want to review 2. Ensure the document is accessible (file path or content string) 3. Identify the project name for proper document naming 4. Decide on review depth level (basic, comprehensive, or detailed) System Response: Document should be readable and accessible for processing.","title":"Step 1: Prepare the PRD Content"},{"location":"skills/review-prd-spec/tutorial/#step-2-invoke-the-review-command","text":"User Action: Execute the OLAF command to start PRD review olaf review prd spec Provide Parameters: - prd_content : [path/to/prd-document.md or content string] - The PRD to review - project_name : [your-project-name] - Name for output file naming - review_depth : [comprehensive] - Level of analysis (default: comprehensive) - save_format : [true] - Whether to save formatted output (default: true) - template_type : [standard] - Template format to use (default: standard)","title":"Step 2: Invoke the Review Command"},{"location":"skills/review-prd-spec/tutorial/#step-3-content-analysis-phase","text":"What OLAF Does: - Reads and parses the PRD content structure - Analyzes business objectives and success metrics - Reviews user stories and acceptance criteria - Evaluates technical requirements and constraints - Assesses risk management and mitigation strategies - Checks timeline and resource requirements - Validates stakeholder identification You Should See: Progress messages indicating content analysis is underway","title":"Step 3: Content Analysis Phase"},{"location":"skills/review-prd-spec/tutorial/#step-4-completeness-review-and-gap-identification","text":"What OLAF Does: - Evaluates each PRD section against standard requirements: - Executive Summary (problem statement, solution overview) - Business Case (value proposition, ROI, strategic alignment) - User Requirements (personas, journeys, functional requirements) - Technical Specifications (architecture, integrations, performance) - Implementation Plan (phases, milestones, dependencies) - Success Criteria (measurable outcomes, KPIs) - Risk Management (identified risks, mitigation plans) - Creates prioritized gap list (Critical, Important, Nice-to-have) - Generates specific questions to address each gap - Provides examples of complete sections You Should See: Categorized list of gaps with priority levels and specific questions","title":"Step 4: Completeness Review and Gap Identification"},{"location":"skills/review-prd-spec/tutorial/#step-5-user-interaction-for-improvements","text":"What OLAF Does: - Presents staging using Propose-Act protocol - Asks targeted questions to fill identified gaps - Requests clarification on ambiguous requirements - Validates user responses iteratively - Ensures all critical gaps are addressed User Action: 1. Review the identified gaps and their priority levels 2. Answer the targeted improvement questions 3. Provide clarification for ambiguous sections 4. Confirm when critical gaps have been addressed You Should See: Interactive question-and-answer session with specific, actionable questions","title":"Step 5: User Interaction for Improvements"},{"location":"skills/review-prd-spec/tutorial/#step-6-document-formatting","text":"What OLAF Does: - Applies selected PRD template structure (standard/agile/enterprise) - Ensures consistent formatting and style throughout - Adds proper section numbering and cross-references - Includes timestamp and version information - Generates table of contents and appendices - Validates internal consistency and clarity You Should See: Formatted document preview following template structure","title":"Step 6: Document Formatting"},{"location":"skills/review-prd-spec/tutorial/#step-7-quality-validation-and-final-output","text":"What OLAF Does: - Confirms all critical gaps have been addressed - Verifies document follows template structure completely - Checks for internal consistency and clarity - Validates that success criteria are measurable - Calculates quality score and template compliance percentage - Saves final document using Propose-Confirm-Act protocol User Action: Review and approve the final formatted document for saving You Should See: - Complete formatted PRD document - Quality checklist with validation results - Template compliance score (target: 95%+) - File save confirmation: [product_docs_dir]/[project_name]-prd-[timestamp].md","title":"Step 7: Quality Validation and Final Output"},{"location":"skills/review-prd-spec/tutorial/#verification-checklist","text":"\u2705 PRD content thoroughly analyzed for completeness \u2705 All critical gaps identified and prioritized \u2705 Targeted improvement questions generated and answered \u2705 Document formatted according to selected template \u2705 Quality validation confirms 95%+ template compliance \u2705 Success criteria are measurable and time-bound \u2705 Risk assessment includes both technical and business risks \u2705 Final document saved with proper naming convention \u2705 User approval obtained for final formatted version","title":"Verification Checklist"},{"location":"skills/review-prd-spec/tutorial/#troubleshooting","text":"If PRD content cannot be read: - Verify the file path is correct and accessible - Ensure the document format is supported - Check file permissions If template files are not found: Check templates directory: [templates_dir]/business-analyst/ Verify template_type parameter matches available templates If critical gaps remain unaddressed: - Review the prioritized gap list systematically - Engage subject matter experts for technical sections - Consider scheduling stakeholder workshops for complex gaps If template compliance is below 95%: - Review sections flagged in quality validation - Ensure all required sections are present - Verify formatting consistency throughout document","title":"Troubleshooting"},{"location":"skills/review-prd-spec/tutorial/#key-learning-points","text":"Systematic Gap Analysis: The workflow uses a structured approach to identify missing or incomplete PRD sections across all standard categories Prioritized Improvements: Gaps are categorized by severity (Critical, Important, Nice-to-have) to focus efforts efficiently Interactive Refinement: The Propose-Act protocol ensures collaborative improvement rather than automated assumptions Template Standardization: Applying consistent templates ensures organizational alignment and reduces review friction","title":"Key Learning Points"},{"location":"skills/review-prd-spec/tutorial/#next-steps-to-try","text":"Share the formatted PRD with stakeholders for approval Use analyze-business-requirements to validate detailed requirement sections Apply improve-spec to add technical diagrams and data models Schedule technical review with development team Track PRD quality metrics over multiple projects to improve process","title":"Next Steps to Try"},{"location":"skills/review-prd-spec/tutorial/#expected-timeline","text":"Total review time: 10-20 minutes depending on PRD size and gap count User input required: Answering improvement questions, providing clarifications, approving final document OLAF execution time: Automated analysis, gap identification, formatting, and validation Interactive phases: Gap discussion and document approval require active user participation","title":"Expected Timeline"},{"location":"skills/review-producer-api-as-consumer/description/","text":"Review Producer API As Consumer \u00b6 Purpose \u00b6 This skill reviews a producer functional specification and OpenAPI contract from a consumer perspective. It produces: - questions to ask the producer team - consumer implementation risks - early development priorities Default output \u00b6 docs/specifications/{demand_folder}/09-consumer-review/{timestamp}-{demand_folder}-consumer-review.md Notes \u00b6 This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Review Producer API As Consumer"},{"location":"skills/review-producer-api-as-consumer/description/#review-producer-api-as-consumer","text":"","title":"Review Producer API As Consumer"},{"location":"skills/review-producer-api-as-consumer/description/#purpose","text":"This skill reviews a producer functional specification and OpenAPI contract from a consumer perspective. It produces: - questions to ask the producer team - consumer implementation risks - early development priorities","title":"Purpose"},{"location":"skills/review-producer-api-as-consumer/description/#default-output","text":"docs/specifications/{demand_folder}/09-consumer-review/{timestamp}-{demand_folder}-consumer-review.md","title":"Default output"},{"location":"skills/review-producer-api-as-consumer/description/#notes","text":"This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Notes"},{"location":"skills/review-producer-api-as-consumer/tutorial/","text":"Review Producer API As Consumer \u00b6 Run: @[/review-producer-api-as-consumer] demand_folder: <demand_folder> You can optionally provide: - openapi_path - functional_spec_path - consumer_context The skill will: - select the latest spec artifacts by default - propose a review plan - after approval, write a consumer review report under 09-consumer-review/","title":"Review Producer API As Consumer"},{"location":"skills/review-producer-api-as-consumer/tutorial/#review-producer-api-as-consumer","text":"Run: @[/review-producer-api-as-consumer] demand_folder: <demand_folder> You can optionally provide: - openapi_path - functional_spec_path - consumer_context The skill will: - select the latest spec artifacts by default - propose a review plan - after approval, write a consumer review report under 09-consumer-review/","title":"Review Producer API As Consumer"},{"location":"skills/review-progress/description/","text":"Review Progress \u00b6 Enhanced skill migrated from project-manager competency. Usage \u00b6 This skill provides review progress functionality with self-contained dependencies and enhanced error handling.","title":"Review Progress"},{"location":"skills/review-progress/description/#review-progress","text":"Enhanced skill migrated from project-manager competency.","title":"Review Progress"},{"location":"skills/review-progress/description/#usage","text":"This skill provides review progress functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/review-progress/tutorial/","text":"Review Progress Tutorial \u00b6 Step-by-step guide for using the review-progress skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Review Progress Tutorial"},{"location":"skills/review-progress/tutorial/#review-progress-tutorial","text":"Step-by-step guide for using the review-progress skill.","title":"Review Progress Tutorial"},{"location":"skills/review-progress/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/review-progress/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/review-user-story/description/","text":"Review User Story \u00b6 Overview \u00b6 This competency reviews user stories against standard templates to ensure quality, clarity, and completeness. It systematically evaluates story components including title, description, acceptance criteria, and supporting details, then provides constructive feedback and clarifying questions to improve the story before development begins. Purpose \u00b6 User stories often suffer from ambiguity, incomplete acceptance criteria, or untestable requirements that lead to misunderstandings and rework during development. This competency addresses this by applying a structured evaluation framework to assess story quality, identify specific weaknesses, and generate actionable questions that guide story authors toward clearer, more implementable user stories. Usage \u00b6 Command : review user story Protocol : Act When to Use : Use this competency during backlog refinement sessions, before sprint planning to validate story readiness, when developers report unclear requirements, or as part of a quality gate before stories are approved for development. Parameters \u00b6 Required Inputs \u00b6 user_story_content : The user story text to be reviewed (can be provided inline or as file reference) Optional Inputs \u00b6 template_reference : Specific template to use for evaluation (uses default user story template if not specified) review_depth : Depth level for review (basic, thorough, or comprehensive; default: thorough) Context Requirements \u00b6 User story should follow standard format (title, description, acceptance criteria) User story review template is automatically loaded from competency templates Best results when story has at least basic structure defined Output \u00b6 This competency produces a structured review report with assessment and improvement recommendations. Deliverables : - User story review report saved to work/staging/user-story-reviews/user-story-review-YYYYMMDD-NNN.md - Overall quality assessment and rating - Identified strengths and areas requiring improvement - Specific clarifying questions for story author Format : Markdown document with standardized sections covering overall assessment, component-by-component evaluation, identified issues, and actionable recommendations for improvement. Examples \u00b6 Example 1: Sprint Planning Story Validation \u00b6 Scenario : During sprint planning, the team wants to validate that a user story about password reset functionality is ready for development. Command : olaf review user story Input : user_story_content: | As a user, I want to reset my password so I can access my account if I forget it. Acceptance Criteria: - User can request password reset - User receives email with reset link - User can set new password Result : Review identified that acceptance criteria lack specificity (no timeout for reset link, no password complexity requirements, no error handling scenarios). Generated 8 clarifying questions about edge cases, security requirements, and user feedback mechanisms. Recommended story not ready for development without enhancements. Example 2: Backlog Refinement Quality Check \u00b6 Scenario : Product owner has written several user stories for a new feature and wants quality feedback before backlog refinement meeting. Command : olaf review user story Input : user_story_content: [file reference to story document] review_depth: comprehensive Result : Comprehensive review highlighting strong business value statement and clear user persona, but identifying missing acceptance criteria for error states, unclear definition of \"done\", and testability concerns. Provided specific recommendations for improving each section. Related Competencies \u00b6 analyze-business-requirements : Use for reviewing complete requirements documents containing multiple stories extend-specification : Enhance specifications that user stories are derived from generate-questionnaire : Create questionnaires to gather missing information for incomplete stories create-unit-tests (developer): Validate that acceptance criteria are testable by attempting to write tests Tips & Best Practices \u00b6 Review stories early in the refinement process to allow time for improvements Use review staging as discussion points in refinement sessions, not as criticism Focus on testability\u2014if you can't write a test for it, the criteria needs clarification Ensure acceptance criteria are specific, measurable, and observable Check that the story follows INVEST principles (Independent, Negotiable, Valuable, Estimable, Small, Testable) Validate that the story includes the \"who, what, why\" (persona, capability, benefit) Look for missing error handling, edge cases, and non-functional requirements Ensure story size is appropriate\u2014large stories may need splitting Review related stories together to identify inconsistencies or gaps Limitations \u00b6 Cannot validate business value or priority\u2014focuses on story quality and clarity Does not assess technical feasibility or implementation complexity Cannot determine if story is appropriately sized without team context May identify issues that are acceptable trade-offs for the team's context Does not replace collaborative refinement discussions with the team Cannot verify that acceptance criteria match actual business needs without stakeholder input Review quality depends on the completeness of the provided story content Source : core/competencies/business-analyst/prompts/review-user-story.md","title":"Review User Story"},{"location":"skills/review-user-story/description/#review-user-story","text":"","title":"Review User Story"},{"location":"skills/review-user-story/description/#overview","text":"This competency reviews user stories against standard templates to ensure quality, clarity, and completeness. It systematically evaluates story components including title, description, acceptance criteria, and supporting details, then provides constructive feedback and clarifying questions to improve the story before development begins.","title":"Overview"},{"location":"skills/review-user-story/description/#purpose","text":"User stories often suffer from ambiguity, incomplete acceptance criteria, or untestable requirements that lead to misunderstandings and rework during development. This competency addresses this by applying a structured evaluation framework to assess story quality, identify specific weaknesses, and generate actionable questions that guide story authors toward clearer, more implementable user stories.","title":"Purpose"},{"location":"skills/review-user-story/description/#usage","text":"Command : review user story Protocol : Act When to Use : Use this competency during backlog refinement sessions, before sprint planning to validate story readiness, when developers report unclear requirements, or as part of a quality gate before stories are approved for development.","title":"Usage"},{"location":"skills/review-user-story/description/#parameters","text":"","title":"Parameters"},{"location":"skills/review-user-story/description/#required-inputs","text":"user_story_content : The user story text to be reviewed (can be provided inline or as file reference)","title":"Required Inputs"},{"location":"skills/review-user-story/description/#optional-inputs","text":"template_reference : Specific template to use for evaluation (uses default user story template if not specified) review_depth : Depth level for review (basic, thorough, or comprehensive; default: thorough)","title":"Optional Inputs"},{"location":"skills/review-user-story/description/#context-requirements","text":"User story should follow standard format (title, description, acceptance criteria) User story review template is automatically loaded from competency templates Best results when story has at least basic structure defined","title":"Context Requirements"},{"location":"skills/review-user-story/description/#output","text":"This competency produces a structured review report with assessment and improvement recommendations. Deliverables : - User story review report saved to work/staging/user-story-reviews/user-story-review-YYYYMMDD-NNN.md - Overall quality assessment and rating - Identified strengths and areas requiring improvement - Specific clarifying questions for story author Format : Markdown document with standardized sections covering overall assessment, component-by-component evaluation, identified issues, and actionable recommendations for improvement.","title":"Output"},{"location":"skills/review-user-story/description/#examples","text":"","title":"Examples"},{"location":"skills/review-user-story/description/#example-1-sprint-planning-story-validation","text":"Scenario : During sprint planning, the team wants to validate that a user story about password reset functionality is ready for development. Command : olaf review user story Input : user_story_content: | As a user, I want to reset my password so I can access my account if I forget it. Acceptance Criteria: - User can request password reset - User receives email with reset link - User can set new password Result : Review identified that acceptance criteria lack specificity (no timeout for reset link, no password complexity requirements, no error handling scenarios). Generated 8 clarifying questions about edge cases, security requirements, and user feedback mechanisms. Recommended story not ready for development without enhancements.","title":"Example 1: Sprint Planning Story Validation"},{"location":"skills/review-user-story/description/#example-2-backlog-refinement-quality-check","text":"Scenario : Product owner has written several user stories for a new feature and wants quality feedback before backlog refinement meeting. Command : olaf review user story Input : user_story_content: [file reference to story document] review_depth: comprehensive Result : Comprehensive review highlighting strong business value statement and clear user persona, but identifying missing acceptance criteria for error states, unclear definition of \"done\", and testability concerns. Provided specific recommendations for improving each section.","title":"Example 2: Backlog Refinement Quality Check"},{"location":"skills/review-user-story/description/#related-competencies","text":"analyze-business-requirements : Use for reviewing complete requirements documents containing multiple stories extend-specification : Enhance specifications that user stories are derived from generate-questionnaire : Create questionnaires to gather missing information for incomplete stories create-unit-tests (developer): Validate that acceptance criteria are testable by attempting to write tests","title":"Related Competencies"},{"location":"skills/review-user-story/description/#tips-best-practices","text":"Review stories early in the refinement process to allow time for improvements Use review staging as discussion points in refinement sessions, not as criticism Focus on testability\u2014if you can't write a test for it, the criteria needs clarification Ensure acceptance criteria are specific, measurable, and observable Check that the story follows INVEST principles (Independent, Negotiable, Valuable, Estimable, Small, Testable) Validate that the story includes the \"who, what, why\" (persona, capability, benefit) Look for missing error handling, edge cases, and non-functional requirements Ensure story size is appropriate\u2014large stories may need splitting Review related stories together to identify inconsistencies or gaps","title":"Tips &amp; Best Practices"},{"location":"skills/review-user-story/description/#limitations","text":"Cannot validate business value or priority\u2014focuses on story quality and clarity Does not assess technical feasibility or implementation complexity Cannot determine if story is appropriately sized without team context May identify issues that are acceptable trade-offs for the team's context Does not replace collaborative refinement discussions with the team Cannot verify that acceptance criteria match actual business needs without stakeholder input Review quality depends on the completeness of the provided story content Source : core/competencies/business-analyst/prompts/review-user-story.md","title":"Limitations"},{"location":"skills/review-user-story/tutorial/","text":"Step-by-Step Tutorial \u00b6 Review User Story: Step-by-Step Tutorial \u00b6 How to Execute the \"Review User Story\" Workflow This tutorial shows exactly how to review user stories against standard templates to ensure quality, clarity, and completeness using the OLAF business-analyst competency. Prerequisites \u00b6 OLAF framework properly installed and configured A user story document or content to review Understanding of user story structure and acceptance criteria Access to the business-analyst competency pack Step-by-Step Instructions \u00b6 Step 1: Prepare the User Story Content \u00b6 [Ensure you have the user story ready for review] User Action: Locate or prepare the user story text to be reviewed Ensure the story content is accessible (either as text or file) Note any specific template requirements or review depth needed Prepare to provide the user story content to OLAF System Response: User story content should be readable and contain story elements for analysis. Step 2: Invoke the Review Command \u00b6 User Action: Execute the OLAF command to start user story review olaf review user story Provide Parameters: user_story_content : [Your user story text] - The complete user story text to be reviewed template_reference : [specific template name] - Optional template to use for evaluation review_depth : [basic/thorough/comprehensive] - Depth level for the review (optional) Step 3: User Story Loading and Parsing \u00b6 What OLAF Does: Receives and processes the user story content provided Parses and structures the story components for systematic analysis Identifies existing story elements (title, description, acceptance criteria, etc.) Prepares the content for template-based evaluation You Should See: Confirmation that the user story has been loaded and parsed successfully Step 4: Template-Based Analysis Process \u00b6 What OLAF Does: Loads the user story review template for evaluation criteria Evaluates the story against each template requirement systematically Checks for clarity, understandability, and completeness Assesses testability of acceptance criteria and verification methods Identifies missing or unclear information that needs clarification You Should See: Progress through different evaluation criteria with staging noted Step 5: Structured Review Generation \u00b6 What OLAF Does: Creates comprehensive markdown-formatted review based on analysis Structures review with standardized sections including: Overall assessment summary and quality rating Identified strengths and positive elements Areas requiring improvement with specific recommendations Clarifying questions to help improve the story Frames all feedback constructively and collaboratively You Should See: Detailed review structured according to the standard template format Step 6: Review Report Saving and Output \u00b6 What OLAF Does: Saves the review to work/staging/user-story-reviews/ directory Generates filename in format: user-story-review-YYYYMMDD-NNN.md Provides summary statistics of the review results Displays the complete review with actionable recommendations You Should See: Complete structured review of the user story File save confirmation with location Summary of strengths, improvement areas, and questions generated Overall quality assessment and rating Verification Checklist \u00b6 \u2705 User story successfully loaded and parsed for analysis \u2705 Story evaluated against standard template requirements \u2705 Clarity, testability, and completeness assessed systematically \u2705 Review structured with standardized sections (summary, strengths, improvements, questions) \u2705 Review saved to work/staging/user-story-reviews/ with proper naming \u2705 Feedback framed constructively and collaboratively Troubleshooting \u00b6 If user story content cannot be parsed: Ensure the story text is complete and properly formatted Check that the content contains recognizable story elements Verify there are no encoding or format issues with the text If template evaluation seems incomplete: Specify a particular template_reference if available Use \"comprehensive\" review_depth for more thorough analysis Ensure the user story has sufficient content for meaningful evaluation If clarifying questions are too general: Provide more detailed user story content for specific analysis Consider using \"thorough\" or \"comprehensive\" review depth Review the generated questions to ensure they address specific story elements Key Learning Points \u00b6 Template-Based Quality Assurance: The workflow uses standardized templates to ensure consistent and comprehensive user story evaluation Constructive Feedback Approach: Reviews are structured to be helpful and collaborative rather than critical Actionable Recommendations: Generates specific clarifying questions and improvement suggestions for story refinement Next Steps to Try \u00b6 Address the identified improvement areas in the user story Use the clarifying questions to gather additional story details Apply the review feedback to enhance story clarity and testability Repeat the review process after making improvements to verify enhancements Expected Timeline \u00b6 Total review time: 2-5 minutes depending on story complexity and review depth User input required: Providing user story content and configuration parameters OLAF execution time: Automated parsing, template-based analysis, and structured review generation","title":"Step-by-Step Tutorial"},{"location":"skills/review-user-story/tutorial/#step-by-step-tutorial","text":"","title":"Step-by-Step Tutorial"},{"location":"skills/review-user-story/tutorial/#review-user-story-step-by-step-tutorial","text":"How to Execute the \"Review User Story\" Workflow This tutorial shows exactly how to review user stories against standard templates to ensure quality, clarity, and completeness using the OLAF business-analyst competency.","title":"Review User Story: Step-by-Step Tutorial"},{"location":"skills/review-user-story/tutorial/#prerequisites","text":"OLAF framework properly installed and configured A user story document or content to review Understanding of user story structure and acceptance criteria Access to the business-analyst competency pack","title":"Prerequisites"},{"location":"skills/review-user-story/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/review-user-story/tutorial/#step-1-prepare-the-user-story-content","text":"[Ensure you have the user story ready for review] User Action: Locate or prepare the user story text to be reviewed Ensure the story content is accessible (either as text or file) Note any specific template requirements or review depth needed Prepare to provide the user story content to OLAF System Response: User story content should be readable and contain story elements for analysis.","title":"Step 1: Prepare the User Story Content"},{"location":"skills/review-user-story/tutorial/#step-2-invoke-the-review-command","text":"User Action: Execute the OLAF command to start user story review olaf review user story Provide Parameters: user_story_content : [Your user story text] - The complete user story text to be reviewed template_reference : [specific template name] - Optional template to use for evaluation review_depth : [basic/thorough/comprehensive] - Depth level for the review (optional)","title":"Step 2: Invoke the Review Command"},{"location":"skills/review-user-story/tutorial/#step-3-user-story-loading-and-parsing","text":"What OLAF Does: Receives and processes the user story content provided Parses and structures the story components for systematic analysis Identifies existing story elements (title, description, acceptance criteria, etc.) Prepares the content for template-based evaluation You Should See: Confirmation that the user story has been loaded and parsed successfully","title":"Step 3: User Story Loading and Parsing"},{"location":"skills/review-user-story/tutorial/#step-4-template-based-analysis-process","text":"What OLAF Does: Loads the user story review template for evaluation criteria Evaluates the story against each template requirement systematically Checks for clarity, understandability, and completeness Assesses testability of acceptance criteria and verification methods Identifies missing or unclear information that needs clarification You Should See: Progress through different evaluation criteria with staging noted","title":"Step 4: Template-Based Analysis Process"},{"location":"skills/review-user-story/tutorial/#step-5-structured-review-generation","text":"What OLAF Does: Creates comprehensive markdown-formatted review based on analysis Structures review with standardized sections including: Overall assessment summary and quality rating Identified strengths and positive elements Areas requiring improvement with specific recommendations Clarifying questions to help improve the story Frames all feedback constructively and collaboratively You Should See: Detailed review structured according to the standard template format","title":"Step 5: Structured Review Generation"},{"location":"skills/review-user-story/tutorial/#step-6-review-report-saving-and-output","text":"What OLAF Does: Saves the review to work/staging/user-story-reviews/ directory Generates filename in format: user-story-review-YYYYMMDD-NNN.md Provides summary statistics of the review results Displays the complete review with actionable recommendations You Should See: Complete structured review of the user story File save confirmation with location Summary of strengths, improvement areas, and questions generated Overall quality assessment and rating","title":"Step 6: Review Report Saving and Output"},{"location":"skills/review-user-story/tutorial/#verification-checklist","text":"\u2705 User story successfully loaded and parsed for analysis \u2705 Story evaluated against standard template requirements \u2705 Clarity, testability, and completeness assessed systematically \u2705 Review structured with standardized sections (summary, strengths, improvements, questions) \u2705 Review saved to work/staging/user-story-reviews/ with proper naming \u2705 Feedback framed constructively and collaboratively","title":"Verification Checklist"},{"location":"skills/review-user-story/tutorial/#troubleshooting","text":"If user story content cannot be parsed: Ensure the story text is complete and properly formatted Check that the content contains recognizable story elements Verify there are no encoding or format issues with the text If template evaluation seems incomplete: Specify a particular template_reference if available Use \"comprehensive\" review_depth for more thorough analysis Ensure the user story has sufficient content for meaningful evaluation If clarifying questions are too general: Provide more detailed user story content for specific analysis Consider using \"thorough\" or \"comprehensive\" review depth Review the generated questions to ensure they address specific story elements","title":"Troubleshooting"},{"location":"skills/review-user-story/tutorial/#key-learning-points","text":"Template-Based Quality Assurance: The workflow uses standardized templates to ensure consistent and comprehensive user story evaluation Constructive Feedback Approach: Reviews are structured to be helpful and collaborative rather than critical Actionable Recommendations: Generates specific clarifying questions and improvement suggestions for story refinement","title":"Key Learning Points"},{"location":"skills/review-user-story/tutorial/#next-steps-to-try","text":"Address the identified improvement areas in the user story Use the clarifying questions to gather additional story details Apply the review feedback to enhance story clarity and testability Repeat the review process after making improvements to verify enhancements","title":"Next Steps to Try"},{"location":"skills/review-user-story/tutorial/#expected-timeline","text":"Total review time: 2-5 minutes depending on story complexity and review depth User input required: Providing user story content and configuration parameters OLAF execution time: Automated parsing, template-based analysis, and structured review generation","title":"Expected Timeline"},{"location":"skills/run-redocumentation/description/","text":"Run Redocumentation \u00b6 Enhanced skill migrated from project-manager competency. Usage \u00b6 This skill provides run redocumentation functionality with self-contained dependencies and enhanced error handling.","title":"Run Redocumentation"},{"location":"skills/run-redocumentation/description/#run-redocumentation","text":"Enhanced skill migrated from project-manager competency.","title":"Run Redocumentation"},{"location":"skills/run-redocumentation/description/#usage","text":"This skill provides run redocumentation functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/run-redocumentation/tutorial/","text":"Run Redocumentation Tutorial \u00b6 Step-by-step guide for using the run-redocumentation skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Run Redocumentation Tutorial"},{"location":"skills/run-redocumentation/tutorial/#run-redocumentation-tutorial","text":"Step-by-step guide for using the run-redocumentation skill.","title":"Run Redocumentation Tutorial"},{"location":"skills/run-redocumentation/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/run-redocumentation/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"},{"location":"skills/scaffold-angular-frontend-from-spec/description/","text":"Scaffold Angular Frontend From Spec \u00b6 Purpose \u00b6 This skill helps API consumers scaffold a real consumer-facing UI from a functional spec and OpenAPI. It is intended to go beyond CRUD screens by implementing spec-defined journeys and scenarios. Defaults \u00b6 Design system: Angular Material Output folder: apps/{demand_folder}-consumer-ui-ng/ Notes \u00b6 This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Scaffold Angular Frontend From Spec"},{"location":"skills/scaffold-angular-frontend-from-spec/description/#scaffold-angular-frontend-from-spec","text":"","title":"Scaffold Angular Frontend From Spec"},{"location":"skills/scaffold-angular-frontend-from-spec/description/#purpose","text":"This skill helps API consumers scaffold a real consumer-facing UI from a functional spec and OpenAPI. It is intended to go beyond CRUD screens by implementing spec-defined journeys and scenarios.","title":"Purpose"},{"location":"skills/scaffold-angular-frontend-from-spec/description/#defaults","text":"Design system: Angular Material Output folder: apps/{demand_folder}-consumer-ui-ng/","title":"Defaults"},{"location":"skills/scaffold-angular-frontend-from-spec/description/#notes","text":"This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Notes"},{"location":"skills/scaffold-angular-frontend-from-spec/tutorial/","text":"Scaffold Angular Frontend From Spec \u00b6 Run: @[/scaffold-angular-frontend-from-spec] demand_folder: <demand_folder> You can optionally provide: - openapi_path - functional_spec_path - ui_output_dir The skill will: - select the latest spec artifacts by default - propose a UI plan (journeys, screens, components) - after approval, scaffold the Angular app and implement the first journey","title":"Scaffold Angular Frontend From Spec"},{"location":"skills/scaffold-angular-frontend-from-spec/tutorial/#scaffold-angular-frontend-from-spec","text":"Run: @[/scaffold-angular-frontend-from-spec] demand_folder: <demand_folder> You can optionally provide: - openapi_path - functional_spec_path - ui_output_dir The skill will: - select the latest spec artifacts by default - propose a UI plan (journeys, screens, components) - after approval, scaffold the Angular app and implement the first journey","title":"Scaffold Angular Frontend From Spec"},{"location":"skills/scaffold-api-from-spec/description/","text":"Scaffold API From Spec \u00b6 Purpose \u00b6 This skill incrementally scaffolds an API implementation and its consumer assets from demand artifacts: - Functional specification + OpenAPI contract (from 04-specifications/ ) - DB\u2194API fit analysis (from 05-data-fit-analysis/ ) Default target platform is Quarkus, with a TypeScript SDK for Angular/React clients. What you get \u00b6 A Quarkus server scaffold wired to the OpenAPI contract A TypeScript SDK scaffold generated from the OpenAPI contract A Bruno test suite runnable locally via CLI and in GitHub Actions How to invoke \u00b6 Run: - olaf scaffold-api-from-spec Then provide the demand_folder when asked. Notes \u00b6 This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Scaffold API From Spec"},{"location":"skills/scaffold-api-from-spec/description/#scaffold-api-from-spec","text":"","title":"Scaffold API From Spec"},{"location":"skills/scaffold-api-from-spec/description/#purpose","text":"This skill incrementally scaffolds an API implementation and its consumer assets from demand artifacts: - Functional specification + OpenAPI contract (from 04-specifications/ ) - DB\u2194API fit analysis (from 05-data-fit-analysis/ ) Default target platform is Quarkus, with a TypeScript SDK for Angular/React clients.","title":"Purpose"},{"location":"skills/scaffold-api-from-spec/description/#what-you-get","text":"A Quarkus server scaffold wired to the OpenAPI contract A TypeScript SDK scaffold generated from the OpenAPI contract A Bruno test suite runnable locally via CLI and in GitHub Actions","title":"What you get"},{"location":"skills/scaffold-api-from-spec/description/#how-to-invoke","text":"Run: - olaf scaffold-api-from-spec Then provide the demand_folder when asked.","title":"How to invoke"},{"location":"skills/scaffold-api-from-spec/description/#notes","text":"This skill uses Propose-Confirm-Act and will always ask for approval before writing any files.","title":"Notes"},{"location":"skills/scaffold-api-from-spec/tutorial/","text":"Tutorial: Scaffold API From Spec \u00b6 1) Provide the demand \u00b6 Invoke: - olaf scaffold-api-from-spec When asked, provide: - demand_folder (example: pet-clinic-01 ) 2) Review and approve the plan \u00b6 The skill will: - Locate the latest OpenAPI and DB\u2194API fit analysis - Propose an incremental implementation plan You MUST approve the plan before any files are written. 3) Run tests locally \u00b6 Once Bruno tests are created: - Install Bruno CLI: npm install -g @usebruno/cli - Run from the Bruno project folder: bru run --env local 4) Verify CI \u00b6 A GitHub Actions workflow will run the same Bruno tests using --env ci and upload reports as artifacts.","title":"Tutorial: Scaffold API From Spec"},{"location":"skills/scaffold-api-from-spec/tutorial/#tutorial-scaffold-api-from-spec","text":"","title":"Tutorial: Scaffold API From Spec"},{"location":"skills/scaffold-api-from-spec/tutorial/#1-provide-the-demand","text":"Invoke: - olaf scaffold-api-from-spec When asked, provide: - demand_folder (example: pet-clinic-01 )","title":"1) Provide the demand"},{"location":"skills/scaffold-api-from-spec/tutorial/#2-review-and-approve-the-plan","text":"The skill will: - Locate the latest OpenAPI and DB\u2194API fit analysis - Propose an incremental implementation plan You MUST approve the plan before any files are written.","title":"2) Review and approve the plan"},{"location":"skills/scaffold-api-from-spec/tutorial/#3-run-tests-locally","text":"Once Bruno tests are created: - Install Bruno CLI: npm install -g @usebruno/cli - Run from the Bruno project folder: bru run --env local","title":"3) Run tests locally"},{"location":"skills/scaffold-api-from-spec/tutorial/#4-verify-ci","text":"A GitHub Actions workflow will run the same Bruno tests using --env ci and upload reports as artifacts.","title":"4) Verify CI"},{"location":"skills/scaffold-quarkus-microservice/description/","text":"Scaffold Quarkus Microservice \u00b6 Overview \u00b6 The Scaffold Quarkus Microservice skill helps developers start a new Quarkus microservice in a standards-compliant way. It strictly enforces practices loaded from .olaf/data/practices/ (universal coding standards, Quarkus scaffolding guidance, and Git workflow guidance) and follows Propose \u2192 Confirm \u2192 Act before writing files. Key Features \u00b6 Practice Enforcement : Loads and applies required practices before scaffolding Git Safety : Requires Git worktree + new branch checks before generating files Minimal-by-default : Proposes a small extension set unless requirements demand more Runnable Baseline : Produces a service that can run locally with mvn quarkus:dev Testing Baseline : Adds at least one smoke test ( @QuarkusTest ) when generating code Practices Loaded \u00b6 Universal Coding Standards ( standards/universal-coding-standards.md ) Quarkus Microservice Scaffolding Guidance ( guidances/coding/quarkus-microservice-scaffolding-guidance.md ) Git Workflow Guidance ( guidances/git/git-workflow-guidance.md ) When to Use \u00b6 Use this skill when: - Creating a new microservice from scratch - You want consistent Quarkus baselines across projects - You want scaffolding done with Git workflow safety checks Trigger Phrases \u00b6 \"olaf scaffold quarkus microservice\" \"olaf create quarkus microservice\" \"olaf scaffold quarkus service\" \"olaf scaffold qurkus microservice\"","title":"Scaffold Quarkus Microservice"},{"location":"skills/scaffold-quarkus-microservice/description/#scaffold-quarkus-microservice","text":"","title":"Scaffold Quarkus Microservice"},{"location":"skills/scaffold-quarkus-microservice/description/#overview","text":"The Scaffold Quarkus Microservice skill helps developers start a new Quarkus microservice in a standards-compliant way. It strictly enforces practices loaded from .olaf/data/practices/ (universal coding standards, Quarkus scaffolding guidance, and Git workflow guidance) and follows Propose \u2192 Confirm \u2192 Act before writing files.","title":"Overview"},{"location":"skills/scaffold-quarkus-microservice/description/#key-features","text":"Practice Enforcement : Loads and applies required practices before scaffolding Git Safety : Requires Git worktree + new branch checks before generating files Minimal-by-default : Proposes a small extension set unless requirements demand more Runnable Baseline : Produces a service that can run locally with mvn quarkus:dev Testing Baseline : Adds at least one smoke test ( @QuarkusTest ) when generating code","title":"Key Features"},{"location":"skills/scaffold-quarkus-microservice/description/#practices-loaded","text":"Universal Coding Standards ( standards/universal-coding-standards.md ) Quarkus Microservice Scaffolding Guidance ( guidances/coding/quarkus-microservice-scaffolding-guidance.md ) Git Workflow Guidance ( guidances/git/git-workflow-guidance.md )","title":"Practices Loaded"},{"location":"skills/scaffold-quarkus-microservice/description/#when-to-use","text":"Use this skill when: - Creating a new microservice from scratch - You want consistent Quarkus baselines across projects - You want scaffolding done with Git workflow safety checks","title":"When to Use"},{"location":"skills/scaffold-quarkus-microservice/description/#trigger-phrases","text":"\"olaf scaffold quarkus microservice\" \"olaf create quarkus microservice\" \"olaf scaffold quarkus service\" \"olaf scaffold qurkus microservice\"","title":"Trigger Phrases"},{"location":"skills/scaffold-quarkus-microservice/tutorial/","text":"Scaffold Quarkus Microservice - Tutorial \u00b6 Quick Start \u00b6 Step 1: Invoke the Skill \u00b6 olaf scaffold quarkus microservice Common alias (typo-tolerant): olaf scaffold qurkus microservice Step 2: Provide Baseline Inputs \u00b6 At minimum, provide: - service_name Example: service_name: billing Step 3: Approve the Proposed Scaffold \u00b6 The skill will propose: - Output directory (default: apps/{service_name} ) - groupId , artifactId , and base package - Minimal Quarkus extensions set - Build/run/test commands You approve with: Proceed with scaffolding? yes Example Session \u00b6 User : olaf scaffold quarkus microservice for a \"billing\" REST service Skill response (high level): - Loads practices - Verifies worktree + branch safety - Proposes Maven + Java 17 + minimal extensions - After approval, scaffolds a runnable Quarkus project - Suggests a commit message for the scaffold Tips \u00b6 Keep the first scaffold minimal; add DB/messaging only when requirements are explicit. Commit right after the scaffold is runnable and tests are green. If your org has naming standards, provide group_id and base_package up front.","title":"Scaffold Quarkus Microservice - Tutorial"},{"location":"skills/scaffold-quarkus-microservice/tutorial/#scaffold-quarkus-microservice-tutorial","text":"","title":"Scaffold Quarkus Microservice - Tutorial"},{"location":"skills/scaffold-quarkus-microservice/tutorial/#quick-start","text":"","title":"Quick Start"},{"location":"skills/scaffold-quarkus-microservice/tutorial/#step-1-invoke-the-skill","text":"olaf scaffold quarkus microservice Common alias (typo-tolerant): olaf scaffold qurkus microservice","title":"Step 1: Invoke the Skill"},{"location":"skills/scaffold-quarkus-microservice/tutorial/#step-2-provide-baseline-inputs","text":"At minimum, provide: - service_name Example: service_name: billing","title":"Step 2: Provide Baseline Inputs"},{"location":"skills/scaffold-quarkus-microservice/tutorial/#step-3-approve-the-proposed-scaffold","text":"The skill will propose: - Output directory (default: apps/{service_name} ) - groupId , artifactId , and base package - Minimal Quarkus extensions set - Build/run/test commands You approve with: Proceed with scaffolding? yes","title":"Step 3: Approve the Proposed Scaffold"},{"location":"skills/scaffold-quarkus-microservice/tutorial/#example-session","text":"User : olaf scaffold quarkus microservice for a \"billing\" REST service Skill response (high level): - Loads practices - Verifies worktree + branch safety - Proposes Maven + Java 17 + minimal extensions - After approval, scaffolds a runnable Quarkus project - Suggests a commit message for the scaffold","title":"Example Session"},{"location":"skills/scaffold-quarkus-microservice/tutorial/#tips","text":"Keep the first scaffold minimal; add DB/messaging only when requirements are explicit. Commit right after the scaffold is runnable and tests are green. If your org has naming standards, provide group_id and base_package up front.","title":"Tips"},{"location":"skills/search-and-learn/tutorial/","text":"Lean and Search Skill: Step-by-Step Tutorial \u00b6 Overview \u00b6 The lean-and-search skill helps you systematically discover information and acquire knowledge through structured research workflows. This tutorial guides you through using this skill effectively for focused learning objectives. When to Use This Skill \u00b6 You need to quickly learn something new for a specific purpose You want to research a topic with structured documentation You need credible sources with proper citations You want to validate learning through practical application You need to identify knowledge gaps for future learning Prerequisites \u00b6 Basic familiarity with research concepts Access to web search capabilities Ability to evaluate source credibility Step-by-Step Process \u00b6 Step 1: Prepare Your Learning Parameters \u00b6 Before invoking the skill, prepare three key inputs: Learning Objective : Be specific about what you want to learn \u274c \"Learn about AI\" \u2705 \"Understand how to implement basic neural networks in Python for image classification\" Current Knowledge : Assess your starting point honestly Example: \"I know Python basics and some machine learning concepts, but never implemented neural networks\" Context : Define the practical application and constraints Example: \"Need to build a prototype for work presentation next week, using TensorFlow or PyTorch\" Step 2: Invoke the Skill \u00b6 Use the lean-and-search skill with your prepared parameters: olaf lean-and-search The system will prompt you for the three parameters if not provided. Step 3: Review the Learning Process \u00b6 The skill will guide you through: Goal Definition : Clarifying specific objectives Search Strategy : Planning information sources Systematic Search : Finding and documenting sources Information Synthesis : Evaluating and connecting findings Practical Application : Testing understanding Report Generation : Creating structured documentation Step 4: Validate Outputs \u00b6 Ensure your learning report includes: [ ] Clear learning summary with key concepts [ ] Credible sources with full URLs [ ] Practical examples you can implement [ ] Identified knowledge gaps [ ] Actionable next steps [ ] Learning validation exercises Best Practices \u00b6 Effective Learning Objectives \u00b6 Be specific and measurable Include practical application context Set realistic scope boundaries Consider time constraints Source Quality Guidelines \u00b6 Prioritize official documentation Cross-reference multiple sources Note publication dates and relevance Verify URLs are accessible Document author credentials when relevant Application Focus \u00b6 Always seek practical examples Test understanding through exercises Connect new knowledge to existing skills Identify real-world use cases Common Pitfalls \u00b6 Vague Objectives : Starting without clear learning goals Poor Sources : Accepting information without URL verification No Validation : Skipping practical application tests Isolated Learning : Not connecting to existing knowledge Incomplete Documentation : Missing key sections in reports Example Session \u00b6 Input Parameters \u00b6 Learning Objective : \"Learn how to optimize PostgreSQL query performance for large datasets\" Current Knowledge : \"I know basic SQL queries and database concepts, but new to performance optimization\" Context : \"Working on e-commerce application with slow product search queries, need solution within 2 weeks\" Expected Output Structure \u00b6 # Lean and Search Report: PostgreSQL Query Optimization **Generated**: 20251119-1445 UTC **Learning Objective**: Learn how to optimize PostgreSQL query performance for large datasets **Current Knowledge Level**: Basic SQL and database concepts **Context**: E-commerce application performance improvement ## Learning Summary ### Key Concepts Discovered 1. **Index Strategy**: Different index types and selection criteria 2. **Query Analysis**: Using EXPLAIN ANALYZE for performance insights 3. **Configuration Tuning**: Key PostgreSQL settings for performance ### Main Insights - Index selection affects query performance more than configuration tuning - EXPLAIN ANALYZE reveals actual bottlenecks vs assumptions - Connection pooling essential for high-concurrency applications ## Source Documentation [Detailed sources with URLs and quality ratings] ## Application Examples [Practical query optimization examples with code] ## Knowledge Gaps [Areas requiring deeper research] ## Next Steps [Immediate actions and learning plan] Integration with Other Skills \u00b6 Complementary Skills \u00b6 review-code : Validate implementation of learned concepts generate-tech-spec : Document technical solutions from research create-prompt : Share research methodology as reusable prompts Workflow Combinations \u00b6 Research \u2192 Implement \u2192 Review Use lean-and-search for research Implement learning in code Use review skills for validation Learn \u2192 Document \u2192 Share Research with lean-and-search Create documentation with generate-tech-spec Share knowledge with create-prompt Troubleshooting \u00b6 Issue: \"No sources found\" \u00b6 Cause : Overly specific or poorly formatted search terms Solution : Broaden search scope, use alternative terminology Issue: \"Conflicting information\" \u00b6 Cause : Different source perspectives or outdated information Solution : Document conflicts, prioritize authoritative sources, note date relevance Issue: \"Can't validate learning\" \u00b6 Cause : Lack of practical application opportunities Solution : Create simplified test scenarios, use online sandboxes Issue: \"Report too long/complex\" \u00b6 Cause : Scope creep during research Solution : Return to original learning objective, split into multiple sessions Advanced Usage \u00b6 Research Iterations \u00b6 For complex topics, use iterative approach: 1. Initial broad research with lean-and-search 2. Identify specific gaps or areas of interest 3. Focused follow-up sessions on specific subtopics Source Management \u00b6 Maintain bibliography of high-quality sources Create rating system for source credibility Track source updates and revisit periodically Knowledge Building \u00b6 Link reports to build knowledge network Create glossaries for technical terms Develop personal learning templates Conclusion \u00b6 The lean-and-search skill provides structured methodology for efficient learning and knowledge acquisition. Focus on specific objectives, validate understanding through application, and maintain high-quality documentation for future reference. For additional help, use the help-me-olaf skill with questions about lean-and-search usage.","title":"Lean and Search Skill: Step-by-Step Tutorial"},{"location":"skills/search-and-learn/tutorial/#lean-and-search-skill-step-by-step-tutorial","text":"","title":"Lean and Search Skill: Step-by-Step Tutorial"},{"location":"skills/search-and-learn/tutorial/#overview","text":"The lean-and-search skill helps you systematically discover information and acquire knowledge through structured research workflows. This tutorial guides you through using this skill effectively for focused learning objectives.","title":"Overview"},{"location":"skills/search-and-learn/tutorial/#when-to-use-this-skill","text":"You need to quickly learn something new for a specific purpose You want to research a topic with structured documentation You need credible sources with proper citations You want to validate learning through practical application You need to identify knowledge gaps for future learning","title":"When to Use This Skill"},{"location":"skills/search-and-learn/tutorial/#prerequisites","text":"Basic familiarity with research concepts Access to web search capabilities Ability to evaluate source credibility","title":"Prerequisites"},{"location":"skills/search-and-learn/tutorial/#step-by-step-process","text":"","title":"Step-by-Step Process"},{"location":"skills/search-and-learn/tutorial/#step-1-prepare-your-learning-parameters","text":"Before invoking the skill, prepare three key inputs: Learning Objective : Be specific about what you want to learn \u274c \"Learn about AI\" \u2705 \"Understand how to implement basic neural networks in Python for image classification\" Current Knowledge : Assess your starting point honestly Example: \"I know Python basics and some machine learning concepts, but never implemented neural networks\" Context : Define the practical application and constraints Example: \"Need to build a prototype for work presentation next week, using TensorFlow or PyTorch\"","title":"Step 1: Prepare Your Learning Parameters"},{"location":"skills/search-and-learn/tutorial/#step-2-invoke-the-skill","text":"Use the lean-and-search skill with your prepared parameters: olaf lean-and-search The system will prompt you for the three parameters if not provided.","title":"Step 2: Invoke the Skill"},{"location":"skills/search-and-learn/tutorial/#step-3-review-the-learning-process","text":"The skill will guide you through: Goal Definition : Clarifying specific objectives Search Strategy : Planning information sources Systematic Search : Finding and documenting sources Information Synthesis : Evaluating and connecting findings Practical Application : Testing understanding Report Generation : Creating structured documentation","title":"Step 3: Review the Learning Process"},{"location":"skills/search-and-learn/tutorial/#step-4-validate-outputs","text":"Ensure your learning report includes: [ ] Clear learning summary with key concepts [ ] Credible sources with full URLs [ ] Practical examples you can implement [ ] Identified knowledge gaps [ ] Actionable next steps [ ] Learning validation exercises","title":"Step 4: Validate Outputs"},{"location":"skills/search-and-learn/tutorial/#best-practices","text":"","title":"Best Practices"},{"location":"skills/search-and-learn/tutorial/#effective-learning-objectives","text":"Be specific and measurable Include practical application context Set realistic scope boundaries Consider time constraints","title":"Effective Learning Objectives"},{"location":"skills/search-and-learn/tutorial/#source-quality-guidelines","text":"Prioritize official documentation Cross-reference multiple sources Note publication dates and relevance Verify URLs are accessible Document author credentials when relevant","title":"Source Quality Guidelines"},{"location":"skills/search-and-learn/tutorial/#application-focus","text":"Always seek practical examples Test understanding through exercises Connect new knowledge to existing skills Identify real-world use cases","title":"Application Focus"},{"location":"skills/search-and-learn/tutorial/#common-pitfalls","text":"Vague Objectives : Starting without clear learning goals Poor Sources : Accepting information without URL verification No Validation : Skipping practical application tests Isolated Learning : Not connecting to existing knowledge Incomplete Documentation : Missing key sections in reports","title":"Common Pitfalls"},{"location":"skills/search-and-learn/tutorial/#example-session","text":"","title":"Example Session"},{"location":"skills/search-and-learn/tutorial/#input-parameters","text":"Learning Objective : \"Learn how to optimize PostgreSQL query performance for large datasets\" Current Knowledge : \"I know basic SQL queries and database concepts, but new to performance optimization\" Context : \"Working on e-commerce application with slow product search queries, need solution within 2 weeks\"","title":"Input Parameters"},{"location":"skills/search-and-learn/tutorial/#expected-output-structure","text":"# Lean and Search Report: PostgreSQL Query Optimization **Generated**: 20251119-1445 UTC **Learning Objective**: Learn how to optimize PostgreSQL query performance for large datasets **Current Knowledge Level**: Basic SQL and database concepts **Context**: E-commerce application performance improvement ## Learning Summary ### Key Concepts Discovered 1. **Index Strategy**: Different index types and selection criteria 2. **Query Analysis**: Using EXPLAIN ANALYZE for performance insights 3. **Configuration Tuning**: Key PostgreSQL settings for performance ### Main Insights - Index selection affects query performance more than configuration tuning - EXPLAIN ANALYZE reveals actual bottlenecks vs assumptions - Connection pooling essential for high-concurrency applications ## Source Documentation [Detailed sources with URLs and quality ratings] ## Application Examples [Practical query optimization examples with code] ## Knowledge Gaps [Areas requiring deeper research] ## Next Steps [Immediate actions and learning plan]","title":"Expected Output Structure"},{"location":"skills/search-and-learn/tutorial/#integration-with-other-skills","text":"","title":"Integration with Other Skills"},{"location":"skills/search-and-learn/tutorial/#complementary-skills","text":"review-code : Validate implementation of learned concepts generate-tech-spec : Document technical solutions from research create-prompt : Share research methodology as reusable prompts","title":"Complementary Skills"},{"location":"skills/search-and-learn/tutorial/#workflow-combinations","text":"Research \u2192 Implement \u2192 Review Use lean-and-search for research Implement learning in code Use review skills for validation Learn \u2192 Document \u2192 Share Research with lean-and-search Create documentation with generate-tech-spec Share knowledge with create-prompt","title":"Workflow Combinations"},{"location":"skills/search-and-learn/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/search-and-learn/tutorial/#issue-no-sources-found","text":"Cause : Overly specific or poorly formatted search terms Solution : Broaden search scope, use alternative terminology","title":"Issue: \"No sources found\""},{"location":"skills/search-and-learn/tutorial/#issue-conflicting-information","text":"Cause : Different source perspectives or outdated information Solution : Document conflicts, prioritize authoritative sources, note date relevance","title":"Issue: \"Conflicting information\""},{"location":"skills/search-and-learn/tutorial/#issue-cant-validate-learning","text":"Cause : Lack of practical application opportunities Solution : Create simplified test scenarios, use online sandboxes","title":"Issue: \"Can't validate learning\""},{"location":"skills/search-and-learn/tutorial/#issue-report-too-longcomplex","text":"Cause : Scope creep during research Solution : Return to original learning objective, split into multiple sessions","title":"Issue: \"Report too long/complex\""},{"location":"skills/search-and-learn/tutorial/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/search-and-learn/tutorial/#research-iterations","text":"For complex topics, use iterative approach: 1. Initial broad research with lean-and-search 2. Identify specific gaps or areas of interest 3. Focused follow-up sessions on specific subtopics","title":"Research Iterations"},{"location":"skills/search-and-learn/tutorial/#source-management","text":"Maintain bibliography of high-quality sources Create rating system for source credibility Track source updates and revisit periodically","title":"Source Management"},{"location":"skills/search-and-learn/tutorial/#knowledge-building","text":"Link reports to build knowledge network Create glossaries for technical terms Develop personal learning templates","title":"Knowledge Building"},{"location":"skills/search-and-learn/tutorial/#conclusion","text":"The lean-and-search skill provides structured methodology for efficient learning and knowledge acquisition. Focus on specific objectives, validate understanding through application, and maintain high-quality documentation for future reference. For additional help, use the help-me-olaf skill with questions about lean-and-search usage.","title":"Conclusion"},{"location":"skills/should-i-use-ai/description/","text":"Should I Use AI? \u00b6 Overview \u00b6 Evaluates whether AI is appropriate for a given task or problem through structured analysis. Purpose \u00b6 Helps decision-makers determine if AI is the right solution by analyzing the problem characteristics, data requirements, alternatives, and potential risks. Usage \u00b6 Command : should i use ai Protocol : Act When to Use : When considering AI for a task and need objective evaluation of appropriateness. Parameters \u00b6 Required Inputs \u00b6 Task/Problem Description : What you're considering using AI for Optional Inputs \u00b6 Constraints : Budget, timeline, data availability Current Approach : How the task is currently handled Success Criteria : What defines success Context Requirements \u00b6 Clear understanding of the task or problem Basic understanding of current process (if applicable) Output \u00b6 Deliverables : - Appropriateness assessment (yes/no/maybe) - Reasoning and analysis - Alternative approaches to consider - Risks and considerations - Recommendations Format : Structured analysis with clear recommendation Examples \u00b6 Example 1: Simple Classification Task \u00b6 Scenario : Considering AI for email categorization Command : should i use ai Input : \"Should I use AI to categorize customer support emails?\" Result : Analysis showing AI is appropriate, with recommendations for approach and considerations Example 2: Complex Decision Task \u00b6 Scenario : Considering AI for medical diagnosis Command : should i use ai Input : \"Should I use AI to diagnose patient conditions?\" Result : Analysis highlighting risks, regulatory requirements, and need for human oversight Example 3: Simple Rule-Based Task \u00b6 Scenario : Considering AI for data validation Command : should i use ai Input : \"Should I use AI to validate form inputs?\" Result : Analysis suggesting simpler rule-based validation is more appropriate Related Competencies \u00b6 assess-genai-initiative : Use this for deeper analysis of GenAI initiatives find-expert-contact : Find AI experts if proceeding with AI solution use-skill : Route to appropriate skill based on decision Tips & Best Practices \u00b6 Be specific about the task and context Mention data availability and quality Consider simpler alternatives first Think about maintenance and explainability needs Use for quick appropriateness checks Limitations \u00b6 Provides guidance, not guarantees Cannot assess proprietary or highly specialized domains without context Recommendations are general - may need expert consultation Cannot evaluate specific AI models or vendors","title":"Should I Use AI?"},{"location":"skills/should-i-use-ai/description/#should-i-use-ai","text":"","title":"Should I Use AI?"},{"location":"skills/should-i-use-ai/description/#overview","text":"Evaluates whether AI is appropriate for a given task or problem through structured analysis.","title":"Overview"},{"location":"skills/should-i-use-ai/description/#purpose","text":"Helps decision-makers determine if AI is the right solution by analyzing the problem characteristics, data requirements, alternatives, and potential risks.","title":"Purpose"},{"location":"skills/should-i-use-ai/description/#usage","text":"Command : should i use ai Protocol : Act When to Use : When considering AI for a task and need objective evaluation of appropriateness.","title":"Usage"},{"location":"skills/should-i-use-ai/description/#parameters","text":"","title":"Parameters"},{"location":"skills/should-i-use-ai/description/#required-inputs","text":"Task/Problem Description : What you're considering using AI for","title":"Required Inputs"},{"location":"skills/should-i-use-ai/description/#optional-inputs","text":"Constraints : Budget, timeline, data availability Current Approach : How the task is currently handled Success Criteria : What defines success","title":"Optional Inputs"},{"location":"skills/should-i-use-ai/description/#context-requirements","text":"Clear understanding of the task or problem Basic understanding of current process (if applicable)","title":"Context Requirements"},{"location":"skills/should-i-use-ai/description/#output","text":"Deliverables : - Appropriateness assessment (yes/no/maybe) - Reasoning and analysis - Alternative approaches to consider - Risks and considerations - Recommendations Format : Structured analysis with clear recommendation","title":"Output"},{"location":"skills/should-i-use-ai/description/#examples","text":"","title":"Examples"},{"location":"skills/should-i-use-ai/description/#example-1-simple-classification-task","text":"Scenario : Considering AI for email categorization Command : should i use ai Input : \"Should I use AI to categorize customer support emails?\" Result : Analysis showing AI is appropriate, with recommendations for approach and considerations","title":"Example 1: Simple Classification Task"},{"location":"skills/should-i-use-ai/description/#example-2-complex-decision-task","text":"Scenario : Considering AI for medical diagnosis Command : should i use ai Input : \"Should I use AI to diagnose patient conditions?\" Result : Analysis highlighting risks, regulatory requirements, and need for human oversight","title":"Example 2: Complex Decision Task"},{"location":"skills/should-i-use-ai/description/#example-3-simple-rule-based-task","text":"Scenario : Considering AI for data validation Command : should i use ai Input : \"Should I use AI to validate form inputs?\" Result : Analysis suggesting simpler rule-based validation is more appropriate","title":"Example 3: Simple Rule-Based Task"},{"location":"skills/should-i-use-ai/description/#related-competencies","text":"assess-genai-initiative : Use this for deeper analysis of GenAI initiatives find-expert-contact : Find AI experts if proceeding with AI solution use-skill : Route to appropriate skill based on decision","title":"Related Competencies"},{"location":"skills/should-i-use-ai/description/#tips-best-practices","text":"Be specific about the task and context Mention data availability and quality Consider simpler alternatives first Think about maintenance and explainability needs Use for quick appropriateness checks","title":"Tips &amp; Best Practices"},{"location":"skills/should-i-use-ai/description/#limitations","text":"Provides guidance, not guarantees Cannot assess proprietary or highly specialized domains without context Recommendations are general - may need expert consultation Cannot evaluate specific AI models or vendors","title":"Limitations"},{"location":"skills/should-i-use-ai/tutorial/","text":"Should I Use AI?: Step-by-Step Tutorial \u00b6 How to Execute the \"Should I Use AI?\" Workflow This tutorial shows how to evaluate whether AI is appropriate for your task or problem. Prerequisites \u00b6 Clear description of the task or problem Understanding of current approach (if applicable) Basic context about constraints and requirements Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 Start the AI appropriateness evaluation User Action: 1. Type the command: should i use ai 2. Describe the task you're considering AI for OLAF Response: OLAF will begin the appropriateness analysis Step 2: Provide Task Details \u00b6 User Action: Describe your task or problem I want to use AI to automatically generate code documentation from source code comments Provide Context: - Current Approach : Manual documentation writing - Data Available : Large codebase with comments - Goal : Save developer time on documentation Step 3: Problem Analysis \u00b6 What OLAF Does: - Analyzes task characteristics - Evaluates if AI is suitable - Considers data requirements - Identifies potential approaches - Assesses complexity vs benefit You Should See: Analysis of problem characteristics Step 4: Appropriateness Assessment \u00b6 What OLAF Provides: - Clear recommendation (yes/no/maybe) - Reasoning for the recommendation - Alternative approaches to consider - Risks and limitations - Implementation considerations You Should See: Structured assessment with recommendation Step 5: Review and Decide \u00b6 User Action: Use the assessment - Review the reasoning - Consider alternatives mentioned - Evaluate risks and benefits - Ask follow-up questions if needed - Make informed decision Verification Checklist \u00b6 \u2705 Clear recommendation provided (yes/no/maybe) \u2705 Reasoning is specific to your task \u2705 Alternatives are considered \u2705 Risks and limitations are identified \u2705 You understand the recommendation Troubleshooting \u00b6 If recommendation is unclear: - Provide more context about your specific situation - Ask for clarification: \"why is AI appropriate/inappropriate here?\" - Request comparison: \"how does this compare to rule-based approach?\" If you disagree with assessment: - Share your reasoning and ask for reconsideration - Provide additional context that might change the analysis - Ask about specific concerns: \"what if we have more data?\" If you need deeper analysis: - Use assess genai initiative for comprehensive evaluation - Ask for specific aspects: \"what about the data requirements?\" Key Learning Points \u00b6 Structured Evaluation : Systematic approach to AI appropriateness Alternatives Considered : Not every problem needs AI Risk-Aware : Highlights potential issues early Actionable : Provides clear recommendation with reasoning Next Steps to Try \u00b6 If yes: Use assess genai initiative for detailed planning If no: Explore suggested alternatives If maybe: Gather more information or run pilot Find experts: Use find expert contact for AI expertise Expected Timeline \u00b6 Total evaluation time: 2-3 minutes User input required: Task description (1 minute) OLAF execution time: Analysis and recommendation (1-2 minutes)","title":"Should I Use AI?: Step-by-Step Tutorial"},{"location":"skills/should-i-use-ai/tutorial/#should-i-use-ai-step-by-step-tutorial","text":"How to Execute the \"Should I Use AI?\" Workflow This tutorial shows how to evaluate whether AI is appropriate for your task or problem.","title":"Should I Use AI?: Step-by-Step Tutorial"},{"location":"skills/should-i-use-ai/tutorial/#prerequisites","text":"Clear description of the task or problem Understanding of current approach (if applicable) Basic context about constraints and requirements","title":"Prerequisites"},{"location":"skills/should-i-use-ai/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/should-i-use-ai/tutorial/#step-1-invoke-the-competency","text":"Start the AI appropriateness evaluation User Action: 1. Type the command: should i use ai 2. Describe the task you're considering AI for OLAF Response: OLAF will begin the appropriateness analysis","title":"Step 1: Invoke the Competency"},{"location":"skills/should-i-use-ai/tutorial/#step-2-provide-task-details","text":"User Action: Describe your task or problem I want to use AI to automatically generate code documentation from source code comments Provide Context: - Current Approach : Manual documentation writing - Data Available : Large codebase with comments - Goal : Save developer time on documentation","title":"Step 2: Provide Task Details"},{"location":"skills/should-i-use-ai/tutorial/#step-3-problem-analysis","text":"What OLAF Does: - Analyzes task characteristics - Evaluates if AI is suitable - Considers data requirements - Identifies potential approaches - Assesses complexity vs benefit You Should See: Analysis of problem characteristics","title":"Step 3: Problem Analysis"},{"location":"skills/should-i-use-ai/tutorial/#step-4-appropriateness-assessment","text":"What OLAF Provides: - Clear recommendation (yes/no/maybe) - Reasoning for the recommendation - Alternative approaches to consider - Risks and limitations - Implementation considerations You Should See: Structured assessment with recommendation","title":"Step 4: Appropriateness Assessment"},{"location":"skills/should-i-use-ai/tutorial/#step-5-review-and-decide","text":"User Action: Use the assessment - Review the reasoning - Consider alternatives mentioned - Evaluate risks and benefits - Ask follow-up questions if needed - Make informed decision","title":"Step 5: Review and Decide"},{"location":"skills/should-i-use-ai/tutorial/#verification-checklist","text":"\u2705 Clear recommendation provided (yes/no/maybe) \u2705 Reasoning is specific to your task \u2705 Alternatives are considered \u2705 Risks and limitations are identified \u2705 You understand the recommendation","title":"Verification Checklist"},{"location":"skills/should-i-use-ai/tutorial/#troubleshooting","text":"If recommendation is unclear: - Provide more context about your specific situation - Ask for clarification: \"why is AI appropriate/inappropriate here?\" - Request comparison: \"how does this compare to rule-based approach?\" If you disagree with assessment: - Share your reasoning and ask for reconsideration - Provide additional context that might change the analysis - Ask about specific concerns: \"what if we have more data?\" If you need deeper analysis: - Use assess genai initiative for comprehensive evaluation - Ask for specific aspects: \"what about the data requirements?\"","title":"Troubleshooting"},{"location":"skills/should-i-use-ai/tutorial/#key-learning-points","text":"Structured Evaluation : Systematic approach to AI appropriateness Alternatives Considered : Not every problem needs AI Risk-Aware : Highlights potential issues early Actionable : Provides clear recommendation with reasoning","title":"Key Learning Points"},{"location":"skills/should-i-use-ai/tutorial/#next-steps-to-try","text":"If yes: Use assess genai initiative for detailed planning If no: Explore suggested alternatives If maybe: Gather more information or run pilot Find experts: Use find expert contact for AI expertise","title":"Next Steps to Try"},{"location":"skills/should-i-use-ai/tutorial/#expected-timeline","text":"Total evaluation time: 2-3 minutes User input required: Task description (1 minute) OLAF execution time: Analysis and recommendation (1-2 minutes)","title":"Expected Timeline"},{"location":"skills/stash-restart-session/description/","text":"Stash Restart \u00b6 Overview \u00b6 Resumes previously stashed work by loading stashed context and restoring work state. Purpose \u00b6 Enables resumption of temporarily paused work by loading detailed stash files, allowing seamless continuation of tasks that were set aside. Usage \u00b6 Command : stash restart Protocol : Act When to Use : When you want to resume work that was previously stashed using stash work . Parameters \u00b6 Required Inputs \u00b6 None - will list available stashed work if not specified Optional Inputs \u00b6 Stash Identifier : Specific stash to resume (task name or timestamp) Context Requirements \u00b6 Must have previously stashed work using stash work Stash files must exist in carry-overs/ directory Output \u00b6 Deliverables : - Restored work context - Summary of stashed work - Progress and state information - Files and tasks involved - Ready-to-continue work state Format : Conversational summary with context restoration Examples \u00b6 Example 1: Resume Most Recent Stash \u00b6 Scenario : Want to resume the most recently stashed work Command : stash restart Result : Lists available stashed work, loads selected stash, restores context Example 2: Resume Specific Stash \u00b6 Scenario : Have multiple stashed tasks, want specific one Command : stash restart feature-authentication Result : Loads the authentication feature stash, restores that specific work context Example 3: List Stashed Work \u00b6 Scenario : Want to see what work is stashed Command : stash restart Result : Displays list of all stashed work with descriptions and timestamps Related Competencies \u00b6 stash-work : Use this to stash current work before switching tasks carry-on-work : Alternative for session-to-session continuity create-carry-over : Lighter-weight session notes vs detailed stashing Tips & Best Practices \u00b6 Review stashed work list to choose the right task Stash files include more detail than carry-over notes Use stashing for task switching, carry-over for session continuity Clean up old stashes periodically Name stashes descriptively when creating them Limitations \u00b6 Requires stash file to exist from previous stash work Cannot restore exact code state, only context Stash files are local - not synced across machines Works best when stash notes are detailed","title":"Stash Restart"},{"location":"skills/stash-restart-session/description/#stash-restart","text":"","title":"Stash Restart"},{"location":"skills/stash-restart-session/description/#overview","text":"Resumes previously stashed work by loading stashed context and restoring work state.","title":"Overview"},{"location":"skills/stash-restart-session/description/#purpose","text":"Enables resumption of temporarily paused work by loading detailed stash files, allowing seamless continuation of tasks that were set aside.","title":"Purpose"},{"location":"skills/stash-restart-session/description/#usage","text":"Command : stash restart Protocol : Act When to Use : When you want to resume work that was previously stashed using stash work .","title":"Usage"},{"location":"skills/stash-restart-session/description/#parameters","text":"","title":"Parameters"},{"location":"skills/stash-restart-session/description/#required-inputs","text":"None - will list available stashed work if not specified","title":"Required Inputs"},{"location":"skills/stash-restart-session/description/#optional-inputs","text":"Stash Identifier : Specific stash to resume (task name or timestamp)","title":"Optional Inputs"},{"location":"skills/stash-restart-session/description/#context-requirements","text":"Must have previously stashed work using stash work Stash files must exist in carry-overs/ directory","title":"Context Requirements"},{"location":"skills/stash-restart-session/description/#output","text":"Deliverables : - Restored work context - Summary of stashed work - Progress and state information - Files and tasks involved - Ready-to-continue work state Format : Conversational summary with context restoration","title":"Output"},{"location":"skills/stash-restart-session/description/#examples","text":"","title":"Examples"},{"location":"skills/stash-restart-session/description/#example-1-resume-most-recent-stash","text":"Scenario : Want to resume the most recently stashed work Command : stash restart Result : Lists available stashed work, loads selected stash, restores context","title":"Example 1: Resume Most Recent Stash"},{"location":"skills/stash-restart-session/description/#example-2-resume-specific-stash","text":"Scenario : Have multiple stashed tasks, want specific one Command : stash restart feature-authentication Result : Loads the authentication feature stash, restores that specific work context","title":"Example 2: Resume Specific Stash"},{"location":"skills/stash-restart-session/description/#example-3-list-stashed-work","text":"Scenario : Want to see what work is stashed Command : stash restart Result : Displays list of all stashed work with descriptions and timestamps","title":"Example 3: List Stashed Work"},{"location":"skills/stash-restart-session/description/#related-competencies","text":"stash-work : Use this to stash current work before switching tasks carry-on-work : Alternative for session-to-session continuity create-carry-over : Lighter-weight session notes vs detailed stashing","title":"Related Competencies"},{"location":"skills/stash-restart-session/description/#tips-best-practices","text":"Review stashed work list to choose the right task Stash files include more detail than carry-over notes Use stashing for task switching, carry-over for session continuity Clean up old stashes periodically Name stashes descriptively when creating them","title":"Tips &amp; Best Practices"},{"location":"skills/stash-restart-session/description/#limitations","text":"Requires stash file to exist from previous stash work Cannot restore exact code state, only context Stash files are local - not synced across machines Works best when stash notes are detailed","title":"Limitations"},{"location":"skills/stash-restart-session/tutorial/","text":"Stash Restart: Step-by-Step Tutorial \u00b6 How to Execute the \"Stash Restart\" Workflow This tutorial shows how to resume previously stashed work. Prerequisites \u00b6 Previously stashed work using stash work Stash files exist in carry-overs/ directory Ready to resume the stashed task Step-by-Step Instructions \u00b6 Step 1: Invoke the Competency \u00b6 Initiate stash restart User Action: 1. Type the command: stash restart 2. Optionally specify which stash to resume OLAF Response: OLAF will search for stashed work files Step 2: View Available Stashes \u00b6 What OLAF Does: - Scans carry-overs/ directory for stashed files - Lists all stashed-*.txt files - Displays task names and timestamps - Shows brief description of each stash You Should See: Numbered list of available stashed work Step 3: Select Stash \u00b6 User Action: Choose which stash to resume Option 2: feature-authentication (stashed 2 days ago) Provide Selection: - Enter the number or task name - Confirm the selection Step 4: Context Restoration \u00b6 What OLAF Does: - Reads the selected stash file - Parses work context and state - Summarizes what was being worked on - Identifies progress made before stashing - Lists files and tasks involved - Notes any blockers or issues You Should See: Detailed summary of stashed work Step 5: Resume Working \u00b6 User Action: Continue the work - Review the restored context - Verify understanding of where you left off - Ask clarifying questions if needed - Begin working on the task Verification Checklist \u00b6 \u2705 Correct stash file was loaded \u2705 Work context is accurately restored \u2705 Progress and state are clear \u2705 Files and tasks are identified \u2705 You can continue work without confusion Troubleshooting \u00b6 If no stashes found: No stashed work found in carry-overs/ directory Solution: You need to stash work first using stash work If wrong stash is loaded: - Specify the task name: \"stash restart authentication\" - List all stashes first: \"show me all stashed work\" - Select by number from the list If context seems incomplete: - Ask for more details: \"what files were being modified?\" - Request specific information: \"what was the blocker?\" - Provide additional context as needed Key Learning Points \u00b6 Task-Specific : Stashes are named by task for easy identification Detailed State : More detailed than carry-over notes Multiple Stashes : Can maintain multiple stashed tasks Timestamped : Files include timestamps for tracking Next Steps to Try \u00b6 Continue working on the resumed task Stash again if you need to switch tasks Create carry-over when ending the session Clean up completed stashes Expected Timeline \u00b6 Total restart time: 1-2 minutes User input required: Command and selection (30 seconds) OLAF execution time: File loading and context restoration (1-2 minutes)","title":"Stash Restart: Step-by-Step Tutorial"},{"location":"skills/stash-restart-session/tutorial/#stash-restart-step-by-step-tutorial","text":"How to Execute the \"Stash Restart\" Workflow This tutorial shows how to resume previously stashed work.","title":"Stash Restart: Step-by-Step Tutorial"},{"location":"skills/stash-restart-session/tutorial/#prerequisites","text":"Previously stashed work using stash work Stash files exist in carry-overs/ directory Ready to resume the stashed task","title":"Prerequisites"},{"location":"skills/stash-restart-session/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/stash-restart-session/tutorial/#step-1-invoke-the-competency","text":"Initiate stash restart User Action: 1. Type the command: stash restart 2. Optionally specify which stash to resume OLAF Response: OLAF will search for stashed work files","title":"Step 1: Invoke the Competency"},{"location":"skills/stash-restart-session/tutorial/#step-2-view-available-stashes","text":"What OLAF Does: - Scans carry-overs/ directory for stashed files - Lists all stashed-*.txt files - Displays task names and timestamps - Shows brief description of each stash You Should See: Numbered list of available stashed work","title":"Step 2: View Available Stashes"},{"location":"skills/stash-restart-session/tutorial/#step-3-select-stash","text":"User Action: Choose which stash to resume Option 2: feature-authentication (stashed 2 days ago) Provide Selection: - Enter the number or task name - Confirm the selection","title":"Step 3: Select Stash"},{"location":"skills/stash-restart-session/tutorial/#step-4-context-restoration","text":"What OLAF Does: - Reads the selected stash file - Parses work context and state - Summarizes what was being worked on - Identifies progress made before stashing - Lists files and tasks involved - Notes any blockers or issues You Should See: Detailed summary of stashed work","title":"Step 4: Context Restoration"},{"location":"skills/stash-restart-session/tutorial/#step-5-resume-working","text":"User Action: Continue the work - Review the restored context - Verify understanding of where you left off - Ask clarifying questions if needed - Begin working on the task","title":"Step 5: Resume Working"},{"location":"skills/stash-restart-session/tutorial/#verification-checklist","text":"\u2705 Correct stash file was loaded \u2705 Work context is accurately restored \u2705 Progress and state are clear \u2705 Files and tasks are identified \u2705 You can continue work without confusion","title":"Verification Checklist"},{"location":"skills/stash-restart-session/tutorial/#troubleshooting","text":"If no stashes found: No stashed work found in carry-overs/ directory Solution: You need to stash work first using stash work If wrong stash is loaded: - Specify the task name: \"stash restart authentication\" - List all stashes first: \"show me all stashed work\" - Select by number from the list If context seems incomplete: - Ask for more details: \"what files were being modified?\" - Request specific information: \"what was the blocker?\" - Provide additional context as needed","title":"Troubleshooting"},{"location":"skills/stash-restart-session/tutorial/#key-learning-points","text":"Task-Specific : Stashes are named by task for easy identification Detailed State : More detailed than carry-over notes Multiple Stashes : Can maintain multiple stashed tasks Timestamped : Files include timestamps for tracking","title":"Key Learning Points"},{"location":"skills/stash-restart-session/tutorial/#next-steps-to-try","text":"Continue working on the resumed task Stash again if you need to switch tasks Create carry-over when ending the session Clean up completed stashes","title":"Next Steps to Try"},{"location":"skills/stash-restart-session/tutorial/#expected-timeline","text":"Total restart time: 1-2 minutes User input required: Command and selection (30 seconds) OLAF execution time: File loading and context restoration (1-2 minutes)","title":"Expected Timeline"},{"location":"skills/store-conversation-record/description/","text":"Store Conversation Record \u00b6 Overview \u00b6 Creates comprehensive conversation records that capture complete dialogue, actions taken, files affected, AI models used, and full context to preserve project history and enable future reference. Purpose \u00b6 Important conversations and work sessions contain valuable context, decisions, and rationale that can be lost over time. This competency solves the problem of lost institutional knowledge by creating detailed, structured records of conversations that capture the complete narrative, all actions performed, files modified, and context needed to understand what happened and why. Usage \u00b6 Command : store conversation record Protocol : Act When to Use : Use this competency only when explicitly requested by the user to preserve important conversations, document significant work sessions, capture decision-making processes, or create historical records for future reference, audits, or knowledge transfer. Parameters \u00b6 Required Inputs \u00b6 user_request : Explicit user request for record creation (CRITICAL: never create automatically) conversation_scope : Purpose and scope of the record being created ai_model_used : Name of the AI model used in the conversation (must be provided by user - never infer) Optional Inputs \u00b6 record_purpose : Specific use case or reason for creating this record Context Requirements \u00b6 Explicit user permission to create the record Access to conversation history and context Access to conversation records directory ( [id:conversation_records_dir] ) Access to conversation record template System time for unique timestamp generation Output \u00b6 Deliverables : - Comprehensive conversation record file with unique timestamp - Complete conversation narrative (never summarized) - Accurate dialogue capture (each user request and AI response) - All actions documented (tool calls, file operations, searches) - File operations listed (created/modified/deleted with relative paths) - Clean markdown formatting with corrected user typos - Organized by logical topic sections Format : Markdown file following conversation record template with structured sections, clear headings for each topic, and formatted dialogue using USER said: / AI said: / AI did: patterns. Examples \u00b6 Example 1: Feature Development Session \u00b6 Scenario : User wants to preserve a complex feature implementation conversation Command : store conversation record Input : User Request: Please create a conversation record for this OAuth implementation session Conversation Scope: OAuth2 authentication feature implementation AI Model Used: Claude Sonnet 4.5 Record Purpose: Document implementation decisions and approach for team reference Result : Created conversation-record-20251027-1430.md with complete dialogue, all code changes, design decisions, and implementation steps documented Example 2: Problem-Solving Session \u00b6 Scenario : Debugging session that identified root cause of production issue Command : store conversation record Input : User Request: Store this debugging conversation for the incident report Conversation Scope: Memory leak investigation and root cause analysis AI Model Used: Claude Sonnet 4.5 Record Purpose: Incident documentation and future reference Result : Created record capturing investigation process, profiling results, root cause identification, and fix implementation Example 3: Architecture Decision Session \u00b6 Scenario : Important architectural discussion that needs to be preserved Command : store conversation record Input : User Request: Create a record of this architecture discussion Conversation Scope: Microservices vs monolithic architecture decision AI Model Used: Claude Sonnet 4.5 Record Purpose: Preserve decision rationale for future team members Result : Created record with complete discussion, options considered, trade-offs analyzed, and final decision with rationale Related Competencies \u00b6 prepare-conversation-handover : Handovers capture next steps, records capture complete history create-decision-record : Formal decisions discussed in conversations can be extracted to decision records create-changelog-entry : Significant conversations can be logged in the changelog review-progress : Conversation records provide detailed context for progress reviews Tips & Best Practices \u00b6 Only create records when explicitly requested - never automatically Always ask user to specify the AI model being used - never infer or guess Create new file for each record with unique timestamp - never append to existing files Capture complete conversation - include full narrative, never summarize content Validate file path resolution via memory-map.md before creating files Organize content by logical topics with clear headings for easy navigation Correct obvious user typos in the record for readability Use relative paths from project root for all file references Include all tool calls and actions performed, not just the results Format dialogue consistently using USER said: / AI said: / AI did: patterns Limitations \u00b6 Requires explicit user request - cannot be triggered automatically Cannot infer AI model information - must be provided by user Creates new files only - cannot append to or update existing records Does not automatically categorize or tag conversations for searchability File path must be validated via memory-map.md - cannot guess locations Does not integrate with external documentation systems Cannot automatically extract decisions or action items - manual extraction needed Record quality depends on conversation clarity and completeness Source : core/competencies/project-manager/prompts/store-conversation-record.md","title":"Store Conversation Record"},{"location":"skills/store-conversation-record/description/#store-conversation-record","text":"","title":"Store Conversation Record"},{"location":"skills/store-conversation-record/description/#overview","text":"Creates comprehensive conversation records that capture complete dialogue, actions taken, files affected, AI models used, and full context to preserve project history and enable future reference.","title":"Overview"},{"location":"skills/store-conversation-record/description/#purpose","text":"Important conversations and work sessions contain valuable context, decisions, and rationale that can be lost over time. This competency solves the problem of lost institutional knowledge by creating detailed, structured records of conversations that capture the complete narrative, all actions performed, files modified, and context needed to understand what happened and why.","title":"Purpose"},{"location":"skills/store-conversation-record/description/#usage","text":"Command : store conversation record Protocol : Act When to Use : Use this competency only when explicitly requested by the user to preserve important conversations, document significant work sessions, capture decision-making processes, or create historical records for future reference, audits, or knowledge transfer.","title":"Usage"},{"location":"skills/store-conversation-record/description/#parameters","text":"","title":"Parameters"},{"location":"skills/store-conversation-record/description/#required-inputs","text":"user_request : Explicit user request for record creation (CRITICAL: never create automatically) conversation_scope : Purpose and scope of the record being created ai_model_used : Name of the AI model used in the conversation (must be provided by user - never infer)","title":"Required Inputs"},{"location":"skills/store-conversation-record/description/#optional-inputs","text":"record_purpose : Specific use case or reason for creating this record","title":"Optional Inputs"},{"location":"skills/store-conversation-record/description/#context-requirements","text":"Explicit user permission to create the record Access to conversation history and context Access to conversation records directory ( [id:conversation_records_dir] ) Access to conversation record template System time for unique timestamp generation","title":"Context Requirements"},{"location":"skills/store-conversation-record/description/#output","text":"Deliverables : - Comprehensive conversation record file with unique timestamp - Complete conversation narrative (never summarized) - Accurate dialogue capture (each user request and AI response) - All actions documented (tool calls, file operations, searches) - File operations listed (created/modified/deleted with relative paths) - Clean markdown formatting with corrected user typos - Organized by logical topic sections Format : Markdown file following conversation record template with structured sections, clear headings for each topic, and formatted dialogue using USER said: / AI said: / AI did: patterns.","title":"Output"},{"location":"skills/store-conversation-record/description/#examples","text":"","title":"Examples"},{"location":"skills/store-conversation-record/description/#example-1-feature-development-session","text":"Scenario : User wants to preserve a complex feature implementation conversation Command : store conversation record Input : User Request: Please create a conversation record for this OAuth implementation session Conversation Scope: OAuth2 authentication feature implementation AI Model Used: Claude Sonnet 4.5 Record Purpose: Document implementation decisions and approach for team reference Result : Created conversation-record-20251027-1430.md with complete dialogue, all code changes, design decisions, and implementation steps documented","title":"Example 1: Feature Development Session"},{"location":"skills/store-conversation-record/description/#example-2-problem-solving-session","text":"Scenario : Debugging session that identified root cause of production issue Command : store conversation record Input : User Request: Store this debugging conversation for the incident report Conversation Scope: Memory leak investigation and root cause analysis AI Model Used: Claude Sonnet 4.5 Record Purpose: Incident documentation and future reference Result : Created record capturing investigation process, profiling results, root cause identification, and fix implementation","title":"Example 2: Problem-Solving Session"},{"location":"skills/store-conversation-record/description/#example-3-architecture-decision-session","text":"Scenario : Important architectural discussion that needs to be preserved Command : store conversation record Input : User Request: Create a record of this architecture discussion Conversation Scope: Microservices vs monolithic architecture decision AI Model Used: Claude Sonnet 4.5 Record Purpose: Preserve decision rationale for future team members Result : Created record with complete discussion, options considered, trade-offs analyzed, and final decision with rationale","title":"Example 3: Architecture Decision Session"},{"location":"skills/store-conversation-record/description/#related-competencies","text":"prepare-conversation-handover : Handovers capture next steps, records capture complete history create-decision-record : Formal decisions discussed in conversations can be extracted to decision records create-changelog-entry : Significant conversations can be logged in the changelog review-progress : Conversation records provide detailed context for progress reviews","title":"Related Competencies"},{"location":"skills/store-conversation-record/description/#tips-best-practices","text":"Only create records when explicitly requested - never automatically Always ask user to specify the AI model being used - never infer or guess Create new file for each record with unique timestamp - never append to existing files Capture complete conversation - include full narrative, never summarize content Validate file path resolution via memory-map.md before creating files Organize content by logical topics with clear headings for easy navigation Correct obvious user typos in the record for readability Use relative paths from project root for all file references Include all tool calls and actions performed, not just the results Format dialogue consistently using USER said: / AI said: / AI did: patterns","title":"Tips &amp; Best Practices"},{"location":"skills/store-conversation-record/description/#limitations","text":"Requires explicit user request - cannot be triggered automatically Cannot infer AI model information - must be provided by user Creates new files only - cannot append to or update existing records Does not automatically categorize or tag conversations for searchability File path must be validated via memory-map.md - cannot guess locations Does not integrate with external documentation systems Cannot automatically extract decisions or action items - manual extraction needed Record quality depends on conversation clarity and completeness Source : core/competencies/project-manager/prompts/store-conversation-record.md","title":"Limitations"},{"location":"skills/store-conversation-record/tutorial/","text":"Store Conversation Record: Step-by-Step Tutorial \u00b6 How to Execute the \"Store Conversation Record\" Competency This tutorial shows exactly how to create comprehensive conversation records capturing dialogue, actions taken, files affected, and AI models used for future reference and continuity. Prerequisites \u00b6 OLAF framework loaded and active Completed conversation session to record Conversation record template available Knowledge of AI model being used Understanding of record purpose and scope Step-by-Step Instructions \u00b6 Step 1: Explicit User Request (CRITICAL) \u00b6 User Action: 1. Explicitly request record creation: olaf store conversation record 2. Or use aliases: olaf conversation record , olaf save conversation , olaf record conversation 3. Press Enter IMPORTANT: - Records are NEVER created automatically - User must explicitly request record creation - AI will confirm permission before proceeding AI Response: Acknowledges request and confirms permission to create record using Act protocol. Step 2: Clarify Record Purpose \u00b6 AI Asks: \"What is the purpose and scope of this conversation record?\" User Provides: - conversation_scope : \"OAuth 2.0 token refresh implementation session\" - record_purpose : \"Document implementation decisions and code changes for team reference\" - ai_model_used : \"Claude Sonnet 4.5\" (MUST be provided by user) CRITICAL: - AI model information MUST come from user - AI will NOT infer or guess the model name - User must explicitly specify which AI model is being used Example: Scope: OAuth 2.0 token refresh implementation session Purpose: Document implementation decisions and code changes for team reference AI Model: Claude Sonnet 4.5 Step 3: Get Timestamp \u00b6 What AI Does: Retrieves current time using terminal commands: Time Retrieval: - Use MCP time tools first, fallback to shell command if needed - Get current timestamp in YYYYMMDD-HHmm format Result: Unique timestamp like \"20251027-1530\" You Should See: Confirmation of timestamp retrieved. Step 4: Validate File Location (CRITICAL) \u00b6 What AI Does: 1. Reads memory map to resolve .olaf/work/staging/ reference 2. Verifies resolved path is .olaf/work/staging/conversation-records/ 3. STOPS if path resolution fails or points elsewhere 4. Ensures directory exists or creates it if missing MANDATORY PATH VALIDATION: - Path MUST resolve correctly before proceeding - If validation fails, AI HALTS and asks user for clarification - No guessing or assuming paths You Should See: Confirmation of validated path. Step 5: Create New File \u00b6 What AI Does: - Creates NEW file: .olaf/work/staging/conversation-records/conversation-record-20251027-1530.md - Uses unique timestamp to prevent filename conflicts - NEVER appends to existing files - Initializes file with proper structure File Naming: conversation-record-[timestamp].md Step 6: Follow Template Structure \u00b6 What AI Does: Loads and applies conversation record template: Template Location: core/competencies/project-manager/templates/conversation-record-template.md Template Sections: 1. Metadata (date, time, AI model, participants) 2. Conversation Purpose 3. Complete Conversation Narrative 4. Actions Taken 5. Files Affected 6. Key Decisions 7. Next Steps Step 7: Capture Complete Conversation \u00b6 What AI Does: Documents conversation with: Format: # Conversation Record - OAuth 2.0 Token Refresh Implementation **Date:** 2025-10-27 **Time:** 15:30 EST **AI Model:** Claude Sonnet 4.5 **Participants:** Jane Smith (Developer) ## Purpose Document OAuth 2.0 token refresh implementation decisions and code changes ## Conversation Narrative ### Topic 1: Initial Requirements Discussion **USER said:** \"We need to implement automatic token refresh for OAuth 2.0\" **AI said:** \"I'll help you implement OAuth 2.0 token refresh with PKCE flow. Let's start by reviewing the current authentication implementation.\" **AI did:** 1. Read current authentication files 2. Analyzed token validation logic 3. Identified integration points ### Topic 2: Implementation Planning **USER said:** \"What's the best approach for implementing this?\" **AI said:** \"I recommend implementing the refresh token endpoint first, then adding client-side refresh logic. Here's the plan...\" **AI did:** 1. Created implementation plan 2. Generated task breakdown 3. Identified dependencies ### Topic 3: Code Implementation **USER said:** \"Let's implement the token refresh endpoint\" **AI said:** \"I'll create the refresh endpoint with proper error handling...\" **AI did:** 1. Created `src/auth/token-refresh.js` 2. Implemented refresh endpoint logic 3. Added error handling 4. Created test file `tests/auth/token-refresh.test.js` 5. Updated token validator ## Files Affected **Created:** - `src/auth/token-refresh.js` - Token refresh endpoint implementation - `tests/auth/token-refresh.test.js` - Test coverage for refresh logic **Modified:** - `src/auth/token-validator.js` - Updated validation for refresh tokens - `docs/authentication.md` - Added refresh token documentation **Deleted:** - None ## Key Decisions 1. Use PKCE flow for enhanced security (DR-20251027-01) 2. Implement automatic refresh 5 minutes before expiry 3. Store refresh tokens in secure HTTP-only cookies ## Next Steps 1. Complete error handling edge cases 2. Deploy to staging environment 3. Update client libraries Formatting Rules: - Clear headings for each distinct topic - Format: USER said: / AI said: / AI did: - Numbered lists for actions - Bullet lists for files - Relative paths from project root - Complete narrative, NEVER summarize - Correct user typos in record Step 8: Confirmation \u00b6 AI Provides: - Conversation record created with file path - Number of distinct topics documented - Number of actions captured - Number of files affected - Record location confirmation You Should See: Complete confirmation with file location and statistics. Verification Checklist \u00b6 \u2705 Explicit user request confirmed (never automatic) \u2705 AI model specified by user (not inferred) \u2705 New file created with unique timestamp \u2705 Path validated via memory-map.md \u2705 Complete conversation captured (not summarized) \u2705 All actions documented with tool calls \u2705 Files listed with relative paths \u2705 Template structure followed exactly \u2705 Clean markdown formatting applied Troubleshooting \u00b6 If path validation fails: - Check memory-map.md exists and is readable - Verify [id:conversation_records_dir] is defined - Manually specify path if needed If file creation fails: - Check directory permissions - Verify sufficient disk space - Ensure no file locks If timestamp conflicts: - Wait one minute and retry - Manually specify different timestamp If conversation seems incomplete: - Review conversation history manually - Add missing context explicitly - Include references to external files Key Learning Points \u00b6 Explicit Permission : Records only created when explicitly requested by user AI Model Transparency : User must specify AI model, never inferred Complete Narrative : Full conversation captured, never summarized Path Validation : Mandatory validation prevents incorrect file locations Unique Files : Each record is separate file, never appended Next Steps to Try \u00b6 Use stored records for project continuity Reference records in handover documents Create records at end of significant sessions Link records to job files and decision records Archive records for project history Expected Timeline \u00b6 Total time: 5-10 minutes User input: 1-2 minutes for purpose and AI model AI execution: 4-8 minutes for conversation analysis and documentation","title":"Store Conversation Record: Step-by-Step Tutorial"},{"location":"skills/store-conversation-record/tutorial/#store-conversation-record-step-by-step-tutorial","text":"How to Execute the \"Store Conversation Record\" Competency This tutorial shows exactly how to create comprehensive conversation records capturing dialogue, actions taken, files affected, and AI models used for future reference and continuity.","title":"Store Conversation Record: Step-by-Step Tutorial"},{"location":"skills/store-conversation-record/tutorial/#prerequisites","text":"OLAF framework loaded and active Completed conversation session to record Conversation record template available Knowledge of AI model being used Understanding of record purpose and scope","title":"Prerequisites"},{"location":"skills/store-conversation-record/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/store-conversation-record/tutorial/#step-1-explicit-user-request-critical","text":"User Action: 1. Explicitly request record creation: olaf store conversation record 2. Or use aliases: olaf conversation record , olaf save conversation , olaf record conversation 3. Press Enter IMPORTANT: - Records are NEVER created automatically - User must explicitly request record creation - AI will confirm permission before proceeding AI Response: Acknowledges request and confirms permission to create record using Act protocol.","title":"Step 1: Explicit User Request (CRITICAL)"},{"location":"skills/store-conversation-record/tutorial/#step-2-clarify-record-purpose","text":"AI Asks: \"What is the purpose and scope of this conversation record?\" User Provides: - conversation_scope : \"OAuth 2.0 token refresh implementation session\" - record_purpose : \"Document implementation decisions and code changes for team reference\" - ai_model_used : \"Claude Sonnet 4.5\" (MUST be provided by user) CRITICAL: - AI model information MUST come from user - AI will NOT infer or guess the model name - User must explicitly specify which AI model is being used Example: Scope: OAuth 2.0 token refresh implementation session Purpose: Document implementation decisions and code changes for team reference AI Model: Claude Sonnet 4.5","title":"Step 2: Clarify Record Purpose"},{"location":"skills/store-conversation-record/tutorial/#step-3-get-timestamp","text":"What AI Does: Retrieves current time using terminal commands: Time Retrieval: - Use MCP time tools first, fallback to shell command if needed - Get current timestamp in YYYYMMDD-HHmm format Result: Unique timestamp like \"20251027-1530\" You Should See: Confirmation of timestamp retrieved.","title":"Step 3: Get Timestamp"},{"location":"skills/store-conversation-record/tutorial/#step-4-validate-file-location-critical","text":"What AI Does: 1. Reads memory map to resolve .olaf/work/staging/ reference 2. Verifies resolved path is .olaf/work/staging/conversation-records/ 3. STOPS if path resolution fails or points elsewhere 4. Ensures directory exists or creates it if missing MANDATORY PATH VALIDATION: - Path MUST resolve correctly before proceeding - If validation fails, AI HALTS and asks user for clarification - No guessing or assuming paths You Should See: Confirmation of validated path.","title":"Step 4: Validate File Location (CRITICAL)"},{"location":"skills/store-conversation-record/tutorial/#step-5-create-new-file","text":"What AI Does: - Creates NEW file: .olaf/work/staging/conversation-records/conversation-record-20251027-1530.md - Uses unique timestamp to prevent filename conflicts - NEVER appends to existing files - Initializes file with proper structure File Naming: conversation-record-[timestamp].md","title":"Step 5: Create New File"},{"location":"skills/store-conversation-record/tutorial/#step-6-follow-template-structure","text":"What AI Does: Loads and applies conversation record template: Template Location: core/competencies/project-manager/templates/conversation-record-template.md Template Sections: 1. Metadata (date, time, AI model, participants) 2. Conversation Purpose 3. Complete Conversation Narrative 4. Actions Taken 5. Files Affected 6. Key Decisions 7. Next Steps","title":"Step 6: Follow Template Structure"},{"location":"skills/store-conversation-record/tutorial/#step-7-capture-complete-conversation","text":"What AI Does: Documents conversation with: Format: # Conversation Record - OAuth 2.0 Token Refresh Implementation **Date:** 2025-10-27 **Time:** 15:30 EST **AI Model:** Claude Sonnet 4.5 **Participants:** Jane Smith (Developer) ## Purpose Document OAuth 2.0 token refresh implementation decisions and code changes ## Conversation Narrative ### Topic 1: Initial Requirements Discussion **USER said:** \"We need to implement automatic token refresh for OAuth 2.0\" **AI said:** \"I'll help you implement OAuth 2.0 token refresh with PKCE flow. Let's start by reviewing the current authentication implementation.\" **AI did:** 1. Read current authentication files 2. Analyzed token validation logic 3. Identified integration points ### Topic 2: Implementation Planning **USER said:** \"What's the best approach for implementing this?\" **AI said:** \"I recommend implementing the refresh token endpoint first, then adding client-side refresh logic. Here's the plan...\" **AI did:** 1. Created implementation plan 2. Generated task breakdown 3. Identified dependencies ### Topic 3: Code Implementation **USER said:** \"Let's implement the token refresh endpoint\" **AI said:** \"I'll create the refresh endpoint with proper error handling...\" **AI did:** 1. Created `src/auth/token-refresh.js` 2. Implemented refresh endpoint logic 3. Added error handling 4. Created test file `tests/auth/token-refresh.test.js` 5. Updated token validator ## Files Affected **Created:** - `src/auth/token-refresh.js` - Token refresh endpoint implementation - `tests/auth/token-refresh.test.js` - Test coverage for refresh logic **Modified:** - `src/auth/token-validator.js` - Updated validation for refresh tokens - `docs/authentication.md` - Added refresh token documentation **Deleted:** - None ## Key Decisions 1. Use PKCE flow for enhanced security (DR-20251027-01) 2. Implement automatic refresh 5 minutes before expiry 3. Store refresh tokens in secure HTTP-only cookies ## Next Steps 1. Complete error handling edge cases 2. Deploy to staging environment 3. Update client libraries Formatting Rules: - Clear headings for each distinct topic - Format: USER said: / AI said: / AI did: - Numbered lists for actions - Bullet lists for files - Relative paths from project root - Complete narrative, NEVER summarize - Correct user typos in record","title":"Step 7: Capture Complete Conversation"},{"location":"skills/store-conversation-record/tutorial/#step-8-confirmation","text":"AI Provides: - Conversation record created with file path - Number of distinct topics documented - Number of actions captured - Number of files affected - Record location confirmation You Should See: Complete confirmation with file location and statistics.","title":"Step 8: Confirmation"},{"location":"skills/store-conversation-record/tutorial/#verification-checklist","text":"\u2705 Explicit user request confirmed (never automatic) \u2705 AI model specified by user (not inferred) \u2705 New file created with unique timestamp \u2705 Path validated via memory-map.md \u2705 Complete conversation captured (not summarized) \u2705 All actions documented with tool calls \u2705 Files listed with relative paths \u2705 Template structure followed exactly \u2705 Clean markdown formatting applied","title":"Verification Checklist"},{"location":"skills/store-conversation-record/tutorial/#troubleshooting","text":"If path validation fails: - Check memory-map.md exists and is readable - Verify [id:conversation_records_dir] is defined - Manually specify path if needed If file creation fails: - Check directory permissions - Verify sufficient disk space - Ensure no file locks If timestamp conflicts: - Wait one minute and retry - Manually specify different timestamp If conversation seems incomplete: - Review conversation history manually - Add missing context explicitly - Include references to external files","title":"Troubleshooting"},{"location":"skills/store-conversation-record/tutorial/#key-learning-points","text":"Explicit Permission : Records only created when explicitly requested by user AI Model Transparency : User must specify AI model, never inferred Complete Narrative : Full conversation captured, never summarized Path Validation : Mandatory validation prevents incorrect file locations Unique Files : Each record is separate file, never appended","title":"Key Learning Points"},{"location":"skills/store-conversation-record/tutorial/#next-steps-to-try","text":"Use stored records for project continuity Reference records in handover documents Create records at end of significant sessions Link records to job files and decision records Archive records for project history","title":"Next Steps to Try"},{"location":"skills/store-conversation-record/tutorial/#expected-timeline","text":"Total time: 5-10 minutes User input: 1-2 minutes for purpose and AI model AI execution: 4-8 minutes for conversation analysis and documentation","title":"Expected Timeline"},{"location":"skills/switch-context/description/","text":"Context Switch - Description \u00b6 Overview \u00b6 Context Switch allows users to switch between different project contexts by selecting from available templates stored in .olaf/data/context/ . What It Does \u00b6 Lists all available context files (context-*.md) from .olaf/data/context/ Displays them as a numbered list User selects a context by number Copies the selected context to context-current.md Reminds user to start new session for context to activate How It Works \u00b6 List Phase : Scans .olaf/data/context/ for all context-*.md files (excluding context-current.md ) Selection Phase : User picks a number from the list Copy Phase : Selected context file is copied to .olaf/data/context/context-current.md Activation Phase : User starts new conversation/session to load the new context Bootstrap Integration \u00b6 The OLAF bootstrap process (see .windsurf/rules/olaf-bootstrap-skills.md ) automatically loads the active context at the start of each new session. Load order : - .olaf/context/current-context.md (preferred) - .olaf/data/context/context-current.md (legacy) - .olaf/data/context/context-default.md (fallback) Key Files \u00b6 Context Templates : .olaf/data/context/context-*.md (e.g., context-default.md) Active Context : .olaf/data/context/context-current.md (loaded at bootstrap) Bootstrap Rules : .windsurf/rules/olaf-bootstrap-skills.md Commands \u00b6 context switch - List contexts and switch context list - List available contexts context clear - Delete context-current.md context status - Show current active context When to Use \u00b6 Switching between different projects Applying project-specific configurations Changing working context without editing files manually","title":"Context Switch - Description"},{"location":"skills/switch-context/description/#context-switch-description","text":"","title":"Context Switch - Description"},{"location":"skills/switch-context/description/#overview","text":"Context Switch allows users to switch between different project contexts by selecting from available templates stored in .olaf/data/context/ .","title":"Overview"},{"location":"skills/switch-context/description/#what-it-does","text":"Lists all available context files (context-*.md) from .olaf/data/context/ Displays them as a numbered list User selects a context by number Copies the selected context to context-current.md Reminds user to start new session for context to activate","title":"What It Does"},{"location":"skills/switch-context/description/#how-it-works","text":"List Phase : Scans .olaf/data/context/ for all context-*.md files (excluding context-current.md ) Selection Phase : User picks a number from the list Copy Phase : Selected context file is copied to .olaf/data/context/context-current.md Activation Phase : User starts new conversation/session to load the new context","title":"How It Works"},{"location":"skills/switch-context/description/#bootstrap-integration","text":"The OLAF bootstrap process (see .windsurf/rules/olaf-bootstrap-skills.md ) automatically loads the active context at the start of each new session. Load order : - .olaf/context/current-context.md (preferred) - .olaf/data/context/context-current.md (legacy) - .olaf/data/context/context-default.md (fallback)","title":"Bootstrap Integration"},{"location":"skills/switch-context/description/#key-files","text":"Context Templates : .olaf/data/context/context-*.md (e.g., context-default.md) Active Context : .olaf/data/context/context-current.md (loaded at bootstrap) Bootstrap Rules : .windsurf/rules/olaf-bootstrap-skills.md","title":"Key Files"},{"location":"skills/switch-context/description/#commands","text":"context switch - List contexts and switch context list - List available contexts context clear - Delete context-current.md context status - Show current active context","title":"Commands"},{"location":"skills/switch-context/description/#when-to-use","text":"Switching between different projects Applying project-specific configurations Changing working context without editing files manually","title":"When to Use"},{"location":"skills/switch-context/tutorial/","text":"Context Switch: Step-by-Step Tutorial \u00b6 How to Execute the \"Context Switch\" Workflow This tutorial shows exactly how to switch between different project contexts in OLAF. Prerequisites \u00b6 OLAF framework installed and active At least one context template file in .olaf/data/context/ Access to GitHub Copilot Chat or compatible IDE Step-by-Step Instructions \u00b6 Step 1: List Available Contexts \u00b6 Brief: Check what contexts are available to switch to User Action: 1. Open GitHub Copilot Chat 2. Type: context switch 3. Press Enter Copilot Response: Available contexts: 1. default 2. springboot-hexagonal Select context by number: Step 2: Select Context by Number \u00b6 User Action: Type the number of the context you want 2 Provide Selection: - Enter the number corresponding to your desired context - Example: We selected \"2\" for springboot-hexagonal Step 3: Context Switch Execution \u00b6 What Copilot Does: - Validates the selected context file exists - Copies .olaf/data/context/context-springboot-hexagonal.md to .olaf/data/context/context-current.md - Confirms the switch You Should See: \u2713 Switched to context: springboot-hexagonal \u26a0\ufe0f Start new conversation for context to activate Step 4: Start New Session \u00b6 User Action: 1. Close the current Copilot Chat conversation 2. Open a new Copilot Chat conversation 3. The new context is now automatically loaded via bootstrap What Happens: - OLAF bootstrap loads the active context file - Project-specific context is applied to the session - You're now working with the new context active Verification Checklist \u00b6 \u2705 Context file copied - Check .olaf/data/context/context-current.md exists \u2705 New session started - Opened fresh Copilot conversation \u2705 Context loaded - Bootstrap loaded the new context automatically \u2705 Ready to work - Can now work with project-specific context Troubleshooting \u00b6 If context doesn't seem active: Make sure you started a NEW conversation. Context changes only take effect in fresh sessions. If no contexts are listed: - Check .olaf/data/context/ directory exists - Ensure you have at least one context-*.md file - File naming must follow pattern: context-{name}.md If \"context not found\" error: - Verify the context file exists in .olaf/data/context/ - Check file name matches pattern exactly Key Learning Points \u00b6 Context switch requires new session: Changes only take effect when you start a fresh conversation because the bootstrap process runs at session start. context-current.md is the active file: This file gets overwritten each time you switch. The template files (context-*.md) remain unchanged. Bootstrap automatic loading: You don't need to manually load the context. In this repo, bootstrap behavior is defined in .windsurf/rules/olaf-bootstrap-skills.md and loads (in order): .olaf/context/current-context.md (preferred) .olaf/data/context/context-current.md (legacy) .olaf/data/context/context-default.md (fallback) Next Steps to Try \u00b6 Create your own custom context template in .olaf/data/context/context-myproject.md Use context status to check which context is currently active Use context clear to remove the active context and return to default OLAF framework Switch between multiple project contexts as you work on different codebases Expected Timeline \u00b6 Total context switch time: 10-30 seconds User input required: Select context number, start new session Copilot execution time: Instant (file copy operation)","title":"Context Switch: Step-by-Step Tutorial"},{"location":"skills/switch-context/tutorial/#context-switch-step-by-step-tutorial","text":"How to Execute the \"Context Switch\" Workflow This tutorial shows exactly how to switch between different project contexts in OLAF.","title":"Context Switch: Step-by-Step Tutorial"},{"location":"skills/switch-context/tutorial/#prerequisites","text":"OLAF framework installed and active At least one context template file in .olaf/data/context/ Access to GitHub Copilot Chat or compatible IDE","title":"Prerequisites"},{"location":"skills/switch-context/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/switch-context/tutorial/#step-1-list-available-contexts","text":"Brief: Check what contexts are available to switch to User Action: 1. Open GitHub Copilot Chat 2. Type: context switch 3. Press Enter Copilot Response: Available contexts: 1. default 2. springboot-hexagonal Select context by number:","title":"Step 1: List Available Contexts"},{"location":"skills/switch-context/tutorial/#step-2-select-context-by-number","text":"User Action: Type the number of the context you want 2 Provide Selection: - Enter the number corresponding to your desired context - Example: We selected \"2\" for springboot-hexagonal","title":"Step 2: Select Context by Number"},{"location":"skills/switch-context/tutorial/#step-3-context-switch-execution","text":"What Copilot Does: - Validates the selected context file exists - Copies .olaf/data/context/context-springboot-hexagonal.md to .olaf/data/context/context-current.md - Confirms the switch You Should See: \u2713 Switched to context: springboot-hexagonal \u26a0\ufe0f Start new conversation for context to activate","title":"Step 3: Context Switch Execution"},{"location":"skills/switch-context/tutorial/#step-4-start-new-session","text":"User Action: 1. Close the current Copilot Chat conversation 2. Open a new Copilot Chat conversation 3. The new context is now automatically loaded via bootstrap What Happens: - OLAF bootstrap loads the active context file - Project-specific context is applied to the session - You're now working with the new context active","title":"Step 4: Start New Session"},{"location":"skills/switch-context/tutorial/#verification-checklist","text":"\u2705 Context file copied - Check .olaf/data/context/context-current.md exists \u2705 New session started - Opened fresh Copilot conversation \u2705 Context loaded - Bootstrap loaded the new context automatically \u2705 Ready to work - Can now work with project-specific context","title":"Verification Checklist"},{"location":"skills/switch-context/tutorial/#troubleshooting","text":"If context doesn't seem active: Make sure you started a NEW conversation. Context changes only take effect in fresh sessions. If no contexts are listed: - Check .olaf/data/context/ directory exists - Ensure you have at least one context-*.md file - File naming must follow pattern: context-{name}.md If \"context not found\" error: - Verify the context file exists in .olaf/data/context/ - Check file name matches pattern exactly","title":"Troubleshooting"},{"location":"skills/switch-context/tutorial/#key-learning-points","text":"Context switch requires new session: Changes only take effect when you start a fresh conversation because the bootstrap process runs at session start. context-current.md is the active file: This file gets overwritten each time you switch. The template files (context-*.md) remain unchanged. Bootstrap automatic loading: You don't need to manually load the context. In this repo, bootstrap behavior is defined in .windsurf/rules/olaf-bootstrap-skills.md and loads (in order): .olaf/context/current-context.md (preferred) .olaf/data/context/context-current.md (legacy) .olaf/data/context/context-default.md (fallback)","title":"Key Learning Points"},{"location":"skills/switch-context/tutorial/#next-steps-to-try","text":"Create your own custom context template in .olaf/data/context/context-myproject.md Use context status to check which context is currently active Use context clear to remove the active context and return to default OLAF framework Switch between multiple project contexts as you work on different codebases","title":"Next Steps to Try"},{"location":"skills/switch-context/tutorial/#expected-timeline","text":"Total context switch time: 10-30 seconds User input required: Select context number, start new session Copilot execution time: Instant (file copy operation)","title":"Expected Timeline"},{"location":"skills/tell-me/description/","text":"Tell Me \u00b6 Overview \u00b6 Lightweight knowledge retrieval skill that searches existing documentation artifacts before suggesting analysis. Returns fast, accurate answers from YOUR repository's documentation with source citations. Purpose \u00b6 Provides instant access to project knowledge by searching local artifacts first, eliminating unnecessary analysis and providing immediate answers to common project questions. Usage \u00b6 Command : tell me | ask about | info about Protocol : Act When to Use : When you need quick answers about your project from existing documentation. Parameters \u00b6 Required Inputs \u00b6 Question or Topic : What you want to know about the project Optional Inputs \u00b6 Context : Specific area or scope to search (e.g., \"build process\", \"coding standards\") Detail Level : Brief summary or comprehensive explanation Context Requirements \u00b6 .olaf/data/product/{repo}/ folder with documentation (generated by onboard-me ) OR .olaf/data/practices/ folder with team practices Output \u00b6 Deliverables : - Synthesized answer from existing artifacts - Source citations with file paths and line numbers - OR suggestion to run appropriate analysis skill if no documentation exists Format : Markdown with sources Examples \u00b6 Example 1: Build Instructions \u00b6 Scenario : Developer needs to know how to build the project Command : olaf tell me how to build this project Result : # How to Build This Project Prerequisites: Node.js 18+, npm 9+ Build Steps: 1. npm install 2. npm run build --- \ud83d\udcda Source: .olaf/data/product/my-repo/repo-guide.md (lines 45-62) Example 2: Coding Standards \u00b6 Scenario : Developer needs coding standards for the project Command : olaf tell me about coding standards Result : Returns content from .olaf/data/practices/coding-standards.md with sources Example 3: Missing Documentation \u00b6 Scenario : User asks about contributor risk but no docs exist Command : olaf tell me about contributor risk Result : \u274c No existing documentation found for: \"contributor risk\" \ud83d\udca1 Suggested Action: Run `olaf analyze-contributor-risk` to generate this information. Key Features \u00b6 \u2705 Search-First Approach - Checks local artifacts before suggesting analysis \u2705 Fast Answers - Returns results from existing docs instantly \u2705 Smart Fallback - Suggests which skill to run if no docs found \u2705 Source Citations - Always cites file paths and line numbers \u274c No Generic Knowledge - Only answers from YOUR repository's artifacts Search Locations (Priority Order) \u00b6 .olaf/data/product/{repo-name}/ - Project-specific documentation .olaf/data/practices/ - Team practices and standards README.md , CONTRIBUTING.md - Root documentation .olaf/data/kb/ - Knowledge base entries Related Skills \u00b6 onboard-me : Generates project documentation that tell-me searches analyze-contributor-risk : Generates contributor analysis measure-ai-impact : Generates AI impact reports Tips & Best Practices \u00b6 Run olaf onboard-me first to generate comprehensive documentation Ask specific questions for better matches Use natural language - no need for exact keywords Check suggested skills if documentation doesn't exist Browse available documentation with olaf tell me (no question) Limitations \u00b6 Only searches existing artifacts, doesn't generate new analysis Requires onboard-me to have run first for best results Quality depends on available documentation Cannot answer questions beyond repository scope No access to external/generic knowledge bases Dependencies \u00b6 onboard-me skill : For generating initial documentation artifacts Local documentation : Requires .olaf/data/product/ or .olaf/data/practices/ folders How It Works \u00b6 Parse Question : Extracts keywords and intent from user's question Search Artifacts : Searches documentation files in priority order Rank Results : Scores relevance of found content Synthesize Answer : Combines relevant sections from top matches Cite Sources : Provides file paths and line numbers for all sources Fallback : Suggests appropriate analysis skill if no documentation exists","title":"Tell Me"},{"location":"skills/tell-me/description/#tell-me","text":"","title":"Tell Me"},{"location":"skills/tell-me/description/#overview","text":"Lightweight knowledge retrieval skill that searches existing documentation artifacts before suggesting analysis. Returns fast, accurate answers from YOUR repository's documentation with source citations.","title":"Overview"},{"location":"skills/tell-me/description/#purpose","text":"Provides instant access to project knowledge by searching local artifacts first, eliminating unnecessary analysis and providing immediate answers to common project questions.","title":"Purpose"},{"location":"skills/tell-me/description/#usage","text":"Command : tell me | ask about | info about Protocol : Act When to Use : When you need quick answers about your project from existing documentation.","title":"Usage"},{"location":"skills/tell-me/description/#parameters","text":"","title":"Parameters"},{"location":"skills/tell-me/description/#required-inputs","text":"Question or Topic : What you want to know about the project","title":"Required Inputs"},{"location":"skills/tell-me/description/#optional-inputs","text":"Context : Specific area or scope to search (e.g., \"build process\", \"coding standards\") Detail Level : Brief summary or comprehensive explanation","title":"Optional Inputs"},{"location":"skills/tell-me/description/#context-requirements","text":".olaf/data/product/{repo}/ folder with documentation (generated by onboard-me ) OR .olaf/data/practices/ folder with team practices","title":"Context Requirements"},{"location":"skills/tell-me/description/#output","text":"Deliverables : - Synthesized answer from existing artifacts - Source citations with file paths and line numbers - OR suggestion to run appropriate analysis skill if no documentation exists Format : Markdown with sources","title":"Output"},{"location":"skills/tell-me/description/#examples","text":"","title":"Examples"},{"location":"skills/tell-me/description/#example-1-build-instructions","text":"Scenario : Developer needs to know how to build the project Command : olaf tell me how to build this project Result : # How to Build This Project Prerequisites: Node.js 18+, npm 9+ Build Steps: 1. npm install 2. npm run build --- \ud83d\udcda Source: .olaf/data/product/my-repo/repo-guide.md (lines 45-62)","title":"Example 1: Build Instructions"},{"location":"skills/tell-me/description/#example-2-coding-standards","text":"Scenario : Developer needs coding standards for the project Command : olaf tell me about coding standards Result : Returns content from .olaf/data/practices/coding-standards.md with sources","title":"Example 2: Coding Standards"},{"location":"skills/tell-me/description/#example-3-missing-documentation","text":"Scenario : User asks about contributor risk but no docs exist Command : olaf tell me about contributor risk Result : \u274c No existing documentation found for: \"contributor risk\" \ud83d\udca1 Suggested Action: Run `olaf analyze-contributor-risk` to generate this information.","title":"Example 3: Missing Documentation"},{"location":"skills/tell-me/description/#key-features","text":"\u2705 Search-First Approach - Checks local artifacts before suggesting analysis \u2705 Fast Answers - Returns results from existing docs instantly \u2705 Smart Fallback - Suggests which skill to run if no docs found \u2705 Source Citations - Always cites file paths and line numbers \u274c No Generic Knowledge - Only answers from YOUR repository's artifacts","title":"Key Features"},{"location":"skills/tell-me/description/#search-locations-priority-order","text":".olaf/data/product/{repo-name}/ - Project-specific documentation .olaf/data/practices/ - Team practices and standards README.md , CONTRIBUTING.md - Root documentation .olaf/data/kb/ - Knowledge base entries","title":"Search Locations (Priority Order)"},{"location":"skills/tell-me/description/#related-skills","text":"onboard-me : Generates project documentation that tell-me searches analyze-contributor-risk : Generates contributor analysis measure-ai-impact : Generates AI impact reports","title":"Related Skills"},{"location":"skills/tell-me/description/#tips-best-practices","text":"Run olaf onboard-me first to generate comprehensive documentation Ask specific questions for better matches Use natural language - no need for exact keywords Check suggested skills if documentation doesn't exist Browse available documentation with olaf tell me (no question)","title":"Tips &amp; Best Practices"},{"location":"skills/tell-me/description/#limitations","text":"Only searches existing artifacts, doesn't generate new analysis Requires onboard-me to have run first for best results Quality depends on available documentation Cannot answer questions beyond repository scope No access to external/generic knowledge bases","title":"Limitations"},{"location":"skills/tell-me/description/#dependencies","text":"onboard-me skill : For generating initial documentation artifacts Local documentation : Requires .olaf/data/product/ or .olaf/data/practices/ folders","title":"Dependencies"},{"location":"skills/tell-me/description/#how-it-works","text":"Parse Question : Extracts keywords and intent from user's question Search Artifacts : Searches documentation files in priority order Rank Results : Scores relevance of found content Synthesize Answer : Combines relevant sections from top matches Cite Sources : Provides file paths and line numbers for all sources Fallback : Suggests appropriate analysis skill if no documentation exists","title":"How It Works"},{"location":"skills/tell-me/tutorial/","text":"Tell Me: Step-by-Step Tutorial \u00b6 How to Execute the \"Tell Me\" Skill for Quick Knowledge Retrieval This tutorial shows how to get instant answers about your project from existing documentation. Prerequisites \u00b6 OLAF framework installed and loaded onboard-me skill executed (recommended for best results) OR existing documentation in .olaf/data/practices/ folder Step-by-Step Instructions \u00b6 Step 1: Invoke the Tell Me Skill \u00b6 Start the knowledge retrieval process User Action: Type one of these commands: olaf tell me [your question] olaf ask about [topic] olaf info about [subject] Example: olaf tell me how to build this project OLAF Response: OLAF will search existing documentation for answers Step 2: OLAF Searches Documentation \u00b6 What OLAF Does: - Searches .olaf/data/product/{repo}/ for project-specific docs - Searches .olaf/data/practices/ for team practices - Searches root docs (README.md, CONTRIBUTING.md) - Ranks results by relevance You Should See: Search in progress message (if configured) Step 3: Results Returned \u00b6 Scenario A: Documentation Found What OLAF Does: - Extracts relevant sections from found documents - Synthesizes a comprehensive answer - Includes source citations with file paths and line numbers Example Output: # How to Build This Project Prerequisites: - Node.js 18+ - npm 9+ Build Steps: 1. Install dependencies: npm install 2. Build the project: npm run build 3. Run tests: npm test Development Mode: - npm run dev (starts development server on port 3000) --- \ud83d\udcda Sources: - .olaf/data/product/my-repo/repo-guide.md (lines 45-62) - .olaf/data/product/my-repo/development-setup.md (lines 12-18) Scenario B: No Documentation Found What OLAF Does: - Reports that no documentation exists for the topic - Suggests the appropriate skill to generate the documentation Example Output: \u274c No existing documentation found for: \"contributor risk analysis\" \ud83d\udca1 Suggested Action: Run `olaf analyze-contributor-risk` to generate this information. This skill will: - Analyze git commit history - Identify key contributors - Assess knowledge concentration - Generate risk mitigation recommendations Step 4: Browse Available Documentation (Optional) \u00b6 User Action: Type olaf tell me without a question What OLAF Does: - Lists all available documentation topics - Groups by category (Development, Architecture, Operations, etc.) - Shows what questions can be answered Example Output: \ud83d\udcda Available Documentation \ud83d\udd28 For Developers: \u2022 How do I build this project locally? \u2022 How do I run the application? \u2022 What are the coding standards? \u2022 How do I run tests? \ud83c\udfd7\ufe0f For Architects: \u2022 What architectural pattern is used? \u2022 What are the key components? \ud83d\udcca For Managers: \u2022 What is the AI impact analysis? \u2022 What are the contributor risks? Verification Checklist \u00b6 \u2705 Answer is relevant to your question \u2705 Sources are cited with file paths \u2705 Information comes from YOUR repository \u2705 Suggested skills are actionable (if no docs found) Troubleshooting \u00b6 Issue: \"No artifacts found\" \u00b6 Cause: No documentation has been generated yet Solution: olaf onboard-me This will generate comprehensive project documentation. Issue: \"Low relevance results\" \u00b6 Cause: Question may be too vague or use different terminology Solutions: - Rephrase your question with more specific terms - Try broader keywords - Browse available docs: olaf tell me - Check if topic requires analysis: try suggested skill Issue: \"Answer is incomplete\" \u00b6 Cause: Documentation may not cover all aspects of your question Solutions: - Ask more specific sub-questions - Check source files directly for more detail - Run suggested analysis skill to generate comprehensive docs - Contribute missing information to documentation Issue: \"Wrong topic returned\" \u00b6 Cause: Keywords matched different documentation Solutions: - Use more specific terminology - Include context: \"tell me about [topic] in [area]\" - Exclude unrelated terms: \"tell me about builds, not deployments\" Common Use Cases \u00b6 1. Onboarding New Developers \u00b6 Question: \"How do I get started with this project?\" Expected Flow: 1. Tell me searches for setup guides 2. Returns build instructions, prerequisites, first-run steps 3. Cites development setup documentation 2. Checking Team Practices \u00b6 Question: \"What are our git commit message standards?\" Expected Flow: 1. Tell me searches practices folder 2. Returns git guidelines from .olaf/data/practices/git-guidelines.md 3. Shows commit message format and examples 3. Understanding Architecture \u00b6 Question: \"What design patterns are used in this codebase?\" Expected Flow: 1. Tell me searches architecture documentation 2. Returns patterns from .olaf/data/product/{repo}/architecture-overview.md 3. Cites specific sections with line numbers 4. Pre-Analysis Check \u00b6 Question: \"What metrics do we have on AI usage?\" Expected Flow (No Docs): 1. Tell me searches and finds no documentation 2. Suggests: \"Run olaf measure-ai-impact \" 3. Explains what the skill will generate Advanced Usage \u00b6 Scoped Searches \u00b6 # Search only in specific area olaf tell me about error handling in the API layer # Search for specific file types olaf tell me about configuration files Follow-up Questions \u00b6 # Initial question olaf tell me how to deploy # Follow-up based on answer olaf tell me more about production deployment prerequisites Cross-Referencing \u00b6 # Ask about related topics olaf tell me about testing strategy olaf tell me about code coverage requirements Key Learning Points \u00b6 Documentation-First : Always searches existing docs before suggesting analysis Source Citations : Every answer includes file references for verification Smart Fallback : Suggests the right skill when documentation is missing Repository-Specific : Only answers from YOUR project's documentation Fast & Lightweight : No heavy analysis, just quick retrieval Integration with Other Skills \u00b6 With onboard-me \u00b6 # First: Generate documentation olaf onboard-me # Then: Ask questions about the project olaf tell me how to build this project With Analysis Skills \u00b6 # Check if analysis exists olaf tell me about contributor risk # If not, run suggested skill olaf analyze-contributor-risk # Then ask again olaf tell me about contributor risk Expected Timeline \u00b6 Total execution time: 5-30 seconds Search time: 2-10 seconds (depends on documentation size) Answer synthesis: 3-20 seconds (depends on answer complexity) User action required: Initial question only (no interactive prompts) Next Steps to Try \u00b6 Explore Available Docs : Run olaf tell me to see what's available Ask Common Questions : Build process, coding standards, architecture Generate Missing Docs : Run olaf onboard-me if few results Use Daily : Make it your first stop for project questions Contribute : Add to .olaf/data/practices/ for team-wide knowledge Best Practices \u00b6 \u2705 Do: - Ask specific, clear questions - Use natural language - Check sources for more detail - Run suggested skills when docs missing - Use for quick reference during coding \u274c Don't: - Expect generic programming knowledge (repository-specific only) - Ask questions requiring new analysis without running suggested skill - Ignore source citations (verify information) - Skip running onboard-me first Success Indicators \u00b6 You're using tell-me effectively when: - Getting instant answers to project questions - Saving time by not searching through files manually - Finding accurate information with source citations - Knowing which skill to run when documentation is missing - Onboarding new team members faster with documentation access","title":"Tell Me: Step-by-Step Tutorial"},{"location":"skills/tell-me/tutorial/#tell-me-step-by-step-tutorial","text":"How to Execute the \"Tell Me\" Skill for Quick Knowledge Retrieval This tutorial shows how to get instant answers about your project from existing documentation.","title":"Tell Me: Step-by-Step Tutorial"},{"location":"skills/tell-me/tutorial/#prerequisites","text":"OLAF framework installed and loaded onboard-me skill executed (recommended for best results) OR existing documentation in .olaf/data/practices/ folder","title":"Prerequisites"},{"location":"skills/tell-me/tutorial/#step-by-step-instructions","text":"","title":"Step-by-Step Instructions"},{"location":"skills/tell-me/tutorial/#step-1-invoke-the-tell-me-skill","text":"Start the knowledge retrieval process User Action: Type one of these commands: olaf tell me [your question] olaf ask about [topic] olaf info about [subject] Example: olaf tell me how to build this project OLAF Response: OLAF will search existing documentation for answers","title":"Step 1: Invoke the Tell Me Skill"},{"location":"skills/tell-me/tutorial/#step-2-olaf-searches-documentation","text":"What OLAF Does: - Searches .olaf/data/product/{repo}/ for project-specific docs - Searches .olaf/data/practices/ for team practices - Searches root docs (README.md, CONTRIBUTING.md) - Ranks results by relevance You Should See: Search in progress message (if configured)","title":"Step 2: OLAF Searches Documentation"},{"location":"skills/tell-me/tutorial/#step-3-results-returned","text":"Scenario A: Documentation Found What OLAF Does: - Extracts relevant sections from found documents - Synthesizes a comprehensive answer - Includes source citations with file paths and line numbers Example Output: # How to Build This Project Prerequisites: - Node.js 18+ - npm 9+ Build Steps: 1. Install dependencies: npm install 2. Build the project: npm run build 3. Run tests: npm test Development Mode: - npm run dev (starts development server on port 3000) --- \ud83d\udcda Sources: - .olaf/data/product/my-repo/repo-guide.md (lines 45-62) - .olaf/data/product/my-repo/development-setup.md (lines 12-18) Scenario B: No Documentation Found What OLAF Does: - Reports that no documentation exists for the topic - Suggests the appropriate skill to generate the documentation Example Output: \u274c No existing documentation found for: \"contributor risk analysis\" \ud83d\udca1 Suggested Action: Run `olaf analyze-contributor-risk` to generate this information. This skill will: - Analyze git commit history - Identify key contributors - Assess knowledge concentration - Generate risk mitigation recommendations","title":"Step 3: Results Returned"},{"location":"skills/tell-me/tutorial/#step-4-browse-available-documentation-optional","text":"User Action: Type olaf tell me without a question What OLAF Does: - Lists all available documentation topics - Groups by category (Development, Architecture, Operations, etc.) - Shows what questions can be answered Example Output: \ud83d\udcda Available Documentation \ud83d\udd28 For Developers: \u2022 How do I build this project locally? \u2022 How do I run the application? \u2022 What are the coding standards? \u2022 How do I run tests? \ud83c\udfd7\ufe0f For Architects: \u2022 What architectural pattern is used? \u2022 What are the key components? \ud83d\udcca For Managers: \u2022 What is the AI impact analysis? \u2022 What are the contributor risks?","title":"Step 4: Browse Available Documentation (Optional)"},{"location":"skills/tell-me/tutorial/#verification-checklist","text":"\u2705 Answer is relevant to your question \u2705 Sources are cited with file paths \u2705 Information comes from YOUR repository \u2705 Suggested skills are actionable (if no docs found)","title":"Verification Checklist"},{"location":"skills/tell-me/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/tell-me/tutorial/#issue-no-artifacts-found","text":"Cause: No documentation has been generated yet Solution: olaf onboard-me This will generate comprehensive project documentation.","title":"Issue: \"No artifacts found\""},{"location":"skills/tell-me/tutorial/#issue-low-relevance-results","text":"Cause: Question may be too vague or use different terminology Solutions: - Rephrase your question with more specific terms - Try broader keywords - Browse available docs: olaf tell me - Check if topic requires analysis: try suggested skill","title":"Issue: \"Low relevance results\""},{"location":"skills/tell-me/tutorial/#issue-answer-is-incomplete","text":"Cause: Documentation may not cover all aspects of your question Solutions: - Ask more specific sub-questions - Check source files directly for more detail - Run suggested analysis skill to generate comprehensive docs - Contribute missing information to documentation","title":"Issue: \"Answer is incomplete\""},{"location":"skills/tell-me/tutorial/#issue-wrong-topic-returned","text":"Cause: Keywords matched different documentation Solutions: - Use more specific terminology - Include context: \"tell me about [topic] in [area]\" - Exclude unrelated terms: \"tell me about builds, not deployments\"","title":"Issue: \"Wrong topic returned\""},{"location":"skills/tell-me/tutorial/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"skills/tell-me/tutorial/#1-onboarding-new-developers","text":"Question: \"How do I get started with this project?\" Expected Flow: 1. Tell me searches for setup guides 2. Returns build instructions, prerequisites, first-run steps 3. Cites development setup documentation","title":"1. Onboarding New Developers"},{"location":"skills/tell-me/tutorial/#2-checking-team-practices","text":"Question: \"What are our git commit message standards?\" Expected Flow: 1. Tell me searches practices folder 2. Returns git guidelines from .olaf/data/practices/git-guidelines.md 3. Shows commit message format and examples","title":"2. Checking Team Practices"},{"location":"skills/tell-me/tutorial/#3-understanding-architecture","text":"Question: \"What design patterns are used in this codebase?\" Expected Flow: 1. Tell me searches architecture documentation 2. Returns patterns from .olaf/data/product/{repo}/architecture-overview.md 3. Cites specific sections with line numbers","title":"3. Understanding Architecture"},{"location":"skills/tell-me/tutorial/#4-pre-analysis-check","text":"Question: \"What metrics do we have on AI usage?\" Expected Flow (No Docs): 1. Tell me searches and finds no documentation 2. Suggests: \"Run olaf measure-ai-impact \" 3. Explains what the skill will generate","title":"4. Pre-Analysis Check"},{"location":"skills/tell-me/tutorial/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/tell-me/tutorial/#scoped-searches","text":"# Search only in specific area olaf tell me about error handling in the API layer # Search for specific file types olaf tell me about configuration files","title":"Scoped Searches"},{"location":"skills/tell-me/tutorial/#follow-up-questions","text":"# Initial question olaf tell me how to deploy # Follow-up based on answer olaf tell me more about production deployment prerequisites","title":"Follow-up Questions"},{"location":"skills/tell-me/tutorial/#cross-referencing","text":"# Ask about related topics olaf tell me about testing strategy olaf tell me about code coverage requirements","title":"Cross-Referencing"},{"location":"skills/tell-me/tutorial/#key-learning-points","text":"Documentation-First : Always searches existing docs before suggesting analysis Source Citations : Every answer includes file references for verification Smart Fallback : Suggests the right skill when documentation is missing Repository-Specific : Only answers from YOUR project's documentation Fast & Lightweight : No heavy analysis, just quick retrieval","title":"Key Learning Points"},{"location":"skills/tell-me/tutorial/#integration-with-other-skills","text":"","title":"Integration with Other Skills"},{"location":"skills/tell-me/tutorial/#with-onboard-me","text":"# First: Generate documentation olaf onboard-me # Then: Ask questions about the project olaf tell me how to build this project","title":"With onboard-me"},{"location":"skills/tell-me/tutorial/#with-analysis-skills","text":"# Check if analysis exists olaf tell me about contributor risk # If not, run suggested skill olaf analyze-contributor-risk # Then ask again olaf tell me about contributor risk","title":"With Analysis Skills"},{"location":"skills/tell-me/tutorial/#expected-timeline","text":"Total execution time: 5-30 seconds Search time: 2-10 seconds (depends on documentation size) Answer synthesis: 3-20 seconds (depends on answer complexity) User action required: Initial question only (no interactive prompts)","title":"Expected Timeline"},{"location":"skills/tell-me/tutorial/#next-steps-to-try","text":"Explore Available Docs : Run olaf tell me to see what's available Ask Common Questions : Build process, coding standards, architecture Generate Missing Docs : Run olaf onboard-me if few results Use Daily : Make it your first stop for project questions Contribute : Add to .olaf/data/practices/ for team-wide knowledge","title":"Next Steps to Try"},{"location":"skills/tell-me/tutorial/#best-practices","text":"\u2705 Do: - Ask specific, clear questions - Use natural language - Check sources for more detail - Run suggested skills when docs missing - Use for quick reference during coding \u274c Don't: - Expect generic programming knowledge (repository-specific only) - Ask questions requiring new analysis without running suggested skill - Ignore source citations (verify information) - Skip running onboard-me first","title":"Best Practices"},{"location":"skills/tell-me/tutorial/#success-indicators","text":"You're using tell-me effectively when: - Getting instant answers to project questions - Saving time by not searching through files manually - Finding accurate information with source citations - Knowing which skill to run when documentation is missing - Onboarding new team members faster with documentation access","title":"Success Indicators"},{"location":"skills/test-create-skill/description/","text":"Test Create Skill - Description \u00b6 Overview \u00b6 The test-create-skill is a comprehensive regression testing skill designed to validate the create-skill functionality within the OLAF framework. This skill ensures that the skill creation process remains reliable and functional across framework updates and modifications. Purpose \u00b6 This skill addresses the critical need for automated testing of the create-skill workflow, preventing regressions that could break skill generation capabilities and ensuring consistent quality in the OLAF framework. Key Features \u00b6 Comprehensive Test Coverage \u00b6 Template Validation : Verifies skill templates load correctly and maintain proper structure Parameter Handling : Tests required and optional parameter collection and validation Component Support : Validates creation of templates, tools, helpers, and knowledge base components Schema Compliance : Ensures generated skills conform to manifest schema requirements Reindexing Functionality : Tests competency index update and skill discoverability Error Scenarios : Tests error handling for edge cases and invalid inputs Test Scopes \u00b6 Full Testing : Complete validation of all create-skill functionality Basic Testing : Core functionality validation for quick checks Specific Testing : Targeted testing of particular scenarios or components Automated Cleanup \u00b6 Optional cleanup of test artifacts after execution Isolated test environment to prevent conflicts Preservation of failure evidence for debugging Usage Context \u00b6 Use this skill when: - Validating create-skill functionality after framework changes - Running routine regression tests on OLAF skill creation - Debugging issues with skill generation - Ensuring quality before framework releases - Onboarding new team members to validate their environment Integration \u00b6 Part of the olaf-testers competency, designed to work alongside other testing and validation skills within the OLAF framework testing suite. Quality Assurance \u00b6 This skill follows OLAF standards for: - Imperative language usage - Comprehensive error handling - Clear success criteria definition - Proper protocol compliance - Structured output formatting","title":"Test Create Skill - Description"},{"location":"skills/test-create-skill/description/#test-create-skill-description","text":"","title":"Test Create Skill - Description"},{"location":"skills/test-create-skill/description/#overview","text":"The test-create-skill is a comprehensive regression testing skill designed to validate the create-skill functionality within the OLAF framework. This skill ensures that the skill creation process remains reliable and functional across framework updates and modifications.","title":"Overview"},{"location":"skills/test-create-skill/description/#purpose","text":"This skill addresses the critical need for automated testing of the create-skill workflow, preventing regressions that could break skill generation capabilities and ensuring consistent quality in the OLAF framework.","title":"Purpose"},{"location":"skills/test-create-skill/description/#key-features","text":"","title":"Key Features"},{"location":"skills/test-create-skill/description/#comprehensive-test-coverage","text":"Template Validation : Verifies skill templates load correctly and maintain proper structure Parameter Handling : Tests required and optional parameter collection and validation Component Support : Validates creation of templates, tools, helpers, and knowledge base components Schema Compliance : Ensures generated skills conform to manifest schema requirements Reindexing Functionality : Tests competency index update and skill discoverability Error Scenarios : Tests error handling for edge cases and invalid inputs","title":"Comprehensive Test Coverage"},{"location":"skills/test-create-skill/description/#test-scopes","text":"Full Testing : Complete validation of all create-skill functionality Basic Testing : Core functionality validation for quick checks Specific Testing : Targeted testing of particular scenarios or components","title":"Test Scopes"},{"location":"skills/test-create-skill/description/#automated-cleanup","text":"Optional cleanup of test artifacts after execution Isolated test environment to prevent conflicts Preservation of failure evidence for debugging","title":"Automated Cleanup"},{"location":"skills/test-create-skill/description/#usage-context","text":"Use this skill when: - Validating create-skill functionality after framework changes - Running routine regression tests on OLAF skill creation - Debugging issues with skill generation - Ensuring quality before framework releases - Onboarding new team members to validate their environment","title":"Usage Context"},{"location":"skills/test-create-skill/description/#integration","text":"Part of the olaf-testers competency, designed to work alongside other testing and validation skills within the OLAF framework testing suite.","title":"Integration"},{"location":"skills/test-create-skill/description/#quality-assurance","text":"This skill follows OLAF standards for: - Imperative language usage - Comprehensive error handling - Clear success criteria definition - Proper protocol compliance - Structured output formatting","title":"Quality Assurance"},{"location":"skills/test-create-skill/tutorial/","text":"Test Create Skill - Tutorial \u00b6 This tutorial will guide you through using the test-create-skill to validate create-skill functionality. Prerequisites \u00b6 Before running the test: 1. Ensure you have access to the OLAF framework 2. Verify you're in a workspace with the .olaf directory structure 3. Confirm you have write permissions to the skills directory Basic Usage \u00b6 Step 1: Invoke the Skill \u00b6 olaf test create skill The skill will automatically run with default settings: - Full test scope - Automatic cleanup enabled - Standard test skill name Step 2: Monitor Test Execution \u00b6 The skill will provide progress updates as it executes: - Template access validation - Parameter collection tests - Component handling tests - Schema validation tests - Reindexing functionality tests - Error handling tests Step 3: Review Results \u00b6 After execution, you'll receive: - Test summary with pass/fail counts - Detailed results for each test category - Regression report if issues detected - Cleanup confirmation Advanced Usage \u00b6 Custom Test Scope \u00b6 To run only basic tests: olaf test create skill Then specify: test_scope: \"basic\" Preserve Test Artifacts \u00b6 To keep test files for inspection: olaf test create skill Then specify: cleanup_after: false Custom Test Skill Name \u00b6 To use a specific test skill name: olaf test create skill Then specify: test_skill_name: \"my-custom-test\" Understanding Test Results \u00b6 Success Indicators \u00b6 \u2705 All tests passed No regressions detected Clean test artifact removal Schema compliance validated Failure Indicators \u00b6 \u274c Specific test failures reported Regression details provided Error conditions documented Remediation steps suggested Troubleshooting \u00b6 Common Issues \u00b6 Template Access Errors - Verify ~/templates/ exists - Check file permissions on template files - Confirm templates contain expected content Directory Permission Errors - Verify write access to skills directory - Check competencies directory permissions - Ensure test workspace can be created Schema Validation Failures - Review create-skill template structure - Verify manifest generation logic - Check for schema definition changes Getting Help \u00b6 If tests fail consistently: 1. Review the detailed error messages 2. Check the specific failure conditions 3. Validate your OLAF framework installation 4. Consult with the OLAF development team Best Practices \u00b6 Regular Testing \u00b6 Run regression tests before framework releases Execute tests after any create-skill modifications Include testing in CI/CD pipelines Test Environment \u00b6 Always test in isolated environments Use cleanup to prevent artifact accumulation Preserve evidence when investigating failures Documentation \u00b6 Document any recurring test failures Track regression patterns over time Share results with the development team Next Steps \u00b6 After successful testing: - Consider the create-skill functionality validated - Document any improvements needed - Schedule next regression test cycle - Update test scenarios if new features added","title":"Test Create Skill - Tutorial"},{"location":"skills/test-create-skill/tutorial/#test-create-skill-tutorial","text":"This tutorial will guide you through using the test-create-skill to validate create-skill functionality.","title":"Test Create Skill - Tutorial"},{"location":"skills/test-create-skill/tutorial/#prerequisites","text":"Before running the test: 1. Ensure you have access to the OLAF framework 2. Verify you're in a workspace with the .olaf directory structure 3. Confirm you have write permissions to the skills directory","title":"Prerequisites"},{"location":"skills/test-create-skill/tutorial/#basic-usage","text":"","title":"Basic Usage"},{"location":"skills/test-create-skill/tutorial/#step-1-invoke-the-skill","text":"olaf test create skill The skill will automatically run with default settings: - Full test scope - Automatic cleanup enabled - Standard test skill name","title":"Step 1: Invoke the Skill"},{"location":"skills/test-create-skill/tutorial/#step-2-monitor-test-execution","text":"The skill will provide progress updates as it executes: - Template access validation - Parameter collection tests - Component handling tests - Schema validation tests - Reindexing functionality tests - Error handling tests","title":"Step 2: Monitor Test Execution"},{"location":"skills/test-create-skill/tutorial/#step-3-review-results","text":"After execution, you'll receive: - Test summary with pass/fail counts - Detailed results for each test category - Regression report if issues detected - Cleanup confirmation","title":"Step 3: Review Results"},{"location":"skills/test-create-skill/tutorial/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"skills/test-create-skill/tutorial/#custom-test-scope","text":"To run only basic tests: olaf test create skill Then specify: test_scope: \"basic\"","title":"Custom Test Scope"},{"location":"skills/test-create-skill/tutorial/#preserve-test-artifacts","text":"To keep test files for inspection: olaf test create skill Then specify: cleanup_after: false","title":"Preserve Test Artifacts"},{"location":"skills/test-create-skill/tutorial/#custom-test-skill-name","text":"To use a specific test skill name: olaf test create skill Then specify: test_skill_name: \"my-custom-test\"","title":"Custom Test Skill Name"},{"location":"skills/test-create-skill/tutorial/#understanding-test-results","text":"","title":"Understanding Test Results"},{"location":"skills/test-create-skill/tutorial/#success-indicators","text":"\u2705 All tests passed No regressions detected Clean test artifact removal Schema compliance validated","title":"Success Indicators"},{"location":"skills/test-create-skill/tutorial/#failure-indicators","text":"\u274c Specific test failures reported Regression details provided Error conditions documented Remediation steps suggested","title":"Failure Indicators"},{"location":"skills/test-create-skill/tutorial/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"skills/test-create-skill/tutorial/#common-issues","text":"Template Access Errors - Verify ~/templates/ exists - Check file permissions on template files - Confirm templates contain expected content Directory Permission Errors - Verify write access to skills directory - Check competencies directory permissions - Ensure test workspace can be created Schema Validation Failures - Review create-skill template structure - Verify manifest generation logic - Check for schema definition changes","title":"Common Issues"},{"location":"skills/test-create-skill/tutorial/#getting-help","text":"If tests fail consistently: 1. Review the detailed error messages 2. Check the specific failure conditions 3. Validate your OLAF framework installation 4. Consult with the OLAF development team","title":"Getting Help"},{"location":"skills/test-create-skill/tutorial/#best-practices","text":"","title":"Best Practices"},{"location":"skills/test-create-skill/tutorial/#regular-testing","text":"Run regression tests before framework releases Execute tests after any create-skill modifications Include testing in CI/CD pipelines","title":"Regular Testing"},{"location":"skills/test-create-skill/tutorial/#test-environment","text":"Always test in isolated environments Use cleanup to prevent artifact accumulation Preserve evidence when investigating failures","title":"Test Environment"},{"location":"skills/test-create-skill/tutorial/#documentation","text":"Document any recurring test failures Track regression patterns over time Share results with the development team","title":"Documentation"},{"location":"skills/test-create-skill/tutorial/#next-steps","text":"After successful testing: - Consider the create-skill functionality validated - Document any improvements needed - Schedule next regression test cycle - Update test scenarios if new features added","title":"Next Steps"},{"location":"skills/validate-prompt-value/description/","text":"Validate Prompt Value \u00b6 Overview \u00b6 The validate-prompt-value skill provides comprehensive evaluation of prompt effectiveness, business value, and implementation quality. This tool helps assess whether prompts deliver real value and identifies specific improvement opportunities. Key Features \u00b6 Multi-dimensional validation : Evaluates effectiveness, business value, and technical quality Quantified scoring : Provides 1-10 scale scores for objective comparison Actionable recommendations : Specific, prioritized improvement suggestions Flexible scope : Choose from targeted or comprehensive validation approaches Validation Dimensions \u00b6 Effectiveness Analysis \u00b6 Prompt clarity and specificity Instruction structure quality Parameter completeness Error handling comprehensiveness Success criteria definition Business Value Assessment \u00b6 Problem-solution alignment Automation potential Scalability factors Integration potential Time savings estimation Technical Quality Review \u00b6 Best practices adherence Framework compliance Maintainability assessment Extensibility evaluation Security considerations Use Cases \u00b6 Pre-deployment prompt validation Prompt optimization initiatives Quality assurance workflows ROI assessment for automation projects Framework compliance verification Expected Outcomes \u00b6 Comprehensive validation report with scores Prioritized improvement recommendations Implementation effort estimates Next steps for enhancement","title":"Validate Prompt Value"},{"location":"skills/validate-prompt-value/description/#validate-prompt-value","text":"","title":"Validate Prompt Value"},{"location":"skills/validate-prompt-value/description/#overview","text":"The validate-prompt-value skill provides comprehensive evaluation of prompt effectiveness, business value, and implementation quality. This tool helps assess whether prompts deliver real value and identifies specific improvement opportunities.","title":"Overview"},{"location":"skills/validate-prompt-value/description/#key-features","text":"Multi-dimensional validation : Evaluates effectiveness, business value, and technical quality Quantified scoring : Provides 1-10 scale scores for objective comparison Actionable recommendations : Specific, prioritized improvement suggestions Flexible scope : Choose from targeted or comprehensive validation approaches","title":"Key Features"},{"location":"skills/validate-prompt-value/description/#validation-dimensions","text":"","title":"Validation Dimensions"},{"location":"skills/validate-prompt-value/description/#effectiveness-analysis","text":"Prompt clarity and specificity Instruction structure quality Parameter completeness Error handling comprehensiveness Success criteria definition","title":"Effectiveness Analysis"},{"location":"skills/validate-prompt-value/description/#business-value-assessment","text":"Problem-solution alignment Automation potential Scalability factors Integration potential Time savings estimation","title":"Business Value Assessment"},{"location":"skills/validate-prompt-value/description/#technical-quality-review","text":"Best practices adherence Framework compliance Maintainability assessment Extensibility evaluation Security considerations","title":"Technical Quality Review"},{"location":"skills/validate-prompt-value/description/#use-cases","text":"Pre-deployment prompt validation Prompt optimization initiatives Quality assurance workflows ROI assessment for automation projects Framework compliance verification","title":"Use Cases"},{"location":"skills/validate-prompt-value/description/#expected-outcomes","text":"Comprehensive validation report with scores Prioritized improvement recommendations Implementation effort estimates Next steps for enhancement","title":"Expected Outcomes"},{"location":"skills/validate-prompt-value/tutorial/","text":"How to Use Validate Prompt Value \u00b6 Step-by-Step Tutorial \u00b6 Prerequisites \u00b6 Have a prompt ready for validation (file, text, or name) Understand your intended use case for the prompt Know what validation scope you need Step 1: Invoke the Skill \u00b6 Use any of these commands: - validate prompt value - assess prompt value - evaluate prompt effectiveness - prompt quality check Step 2: Provide Required Parameters \u00b6 The skill will request: - Prompt source : File path, copy-paste text, or prompt name - Validation scope : Choose from: - effectiveness - Focus on prompt clarity and instruction quality - business-value - Assess ROI and automation potential - technical-quality - Review best practices and compliance - complete - Comprehensive evaluation across all dimensions Step 3: Optional Context (Recommended) \u00b6 Provide additional details for better assessment: - Use case context : How you plan to use the prompt - Success metrics : What outcomes you expect - Target audience : Who will use this prompt Step 4: Review Assessment Results \u00b6 The skill provides: - Quantified scores (1-10) for each validation dimension - Detailed analysis of strengths and weaknesses - Prioritized improvement recommendations - Implementation effort estimates Step 5: Act on Recommendations \u00b6 Follow the prioritized action items: - Address critical issues first - Implement high-impact, low-effort improvements - Plan for complex enhancements - Schedule follow-up validation Example Scenarios \u00b6 Scenario 1: Pre-Deployment Check \u00b6 Input: New automation prompt for code review Scope: complete Context: Team workflow integration Result: Full assessment with deployment readiness score Scenario 2: Optimization Project \u00b6 Input: Existing prompt with performance issues Scope: effectiveness Context: Improving output quality Result: Targeted recommendations for clarity improvements Scenario 3: Business Case Development \u00b6 Input: Proposed prompt for customer service automation Scope: business-value Context: ROI justification needed Result: Value assessment with time savings calculations Best Practices \u00b6 Always provide use case context for accurate assessment Start with complete scope for new prompts Use targeted scopes for specific improvement areas Re-validate after implementing major changes Document validation results for future reference Common Issues and Solutions \u00b6 Issue : Low effectiveness scores Solution : Focus on clarity, specificity, and instruction structure Issue : Poor business value assessment Solution : Better define use case and success metrics Issue : Technical quality concerns Solution : Review framework compliance and best practices Tips for Success \u00b6 Be honest about prompt limitations during assessment Prioritize recommendations by business impact Consider maintenance and scalability in improvements Test changes incrementally Validate effectiveness with real use cases","title":"How to Use Validate Prompt Value"},{"location":"skills/validate-prompt-value/tutorial/#how-to-use-validate-prompt-value","text":"","title":"How to Use Validate Prompt Value"},{"location":"skills/validate-prompt-value/tutorial/#step-by-step-tutorial","text":"","title":"Step-by-Step Tutorial"},{"location":"skills/validate-prompt-value/tutorial/#prerequisites","text":"Have a prompt ready for validation (file, text, or name) Understand your intended use case for the prompt Know what validation scope you need","title":"Prerequisites"},{"location":"skills/validate-prompt-value/tutorial/#step-1-invoke-the-skill","text":"Use any of these commands: - validate prompt value - assess prompt value - evaluate prompt effectiveness - prompt quality check","title":"Step 1: Invoke the Skill"},{"location":"skills/validate-prompt-value/tutorial/#step-2-provide-required-parameters","text":"The skill will request: - Prompt source : File path, copy-paste text, or prompt name - Validation scope : Choose from: - effectiveness - Focus on prompt clarity and instruction quality - business-value - Assess ROI and automation potential - technical-quality - Review best practices and compliance - complete - Comprehensive evaluation across all dimensions","title":"Step 2: Provide Required Parameters"},{"location":"skills/validate-prompt-value/tutorial/#step-3-optional-context-recommended","text":"Provide additional details for better assessment: - Use case context : How you plan to use the prompt - Success metrics : What outcomes you expect - Target audience : Who will use this prompt","title":"Step 3: Optional Context (Recommended)"},{"location":"skills/validate-prompt-value/tutorial/#step-4-review-assessment-results","text":"The skill provides: - Quantified scores (1-10) for each validation dimension - Detailed analysis of strengths and weaknesses - Prioritized improvement recommendations - Implementation effort estimates","title":"Step 4: Review Assessment Results"},{"location":"skills/validate-prompt-value/tutorial/#step-5-act-on-recommendations","text":"Follow the prioritized action items: - Address critical issues first - Implement high-impact, low-effort improvements - Plan for complex enhancements - Schedule follow-up validation","title":"Step 5: Act on Recommendations"},{"location":"skills/validate-prompt-value/tutorial/#example-scenarios","text":"","title":"Example Scenarios"},{"location":"skills/validate-prompt-value/tutorial/#scenario-1-pre-deployment-check","text":"Input: New automation prompt for code review Scope: complete Context: Team workflow integration Result: Full assessment with deployment readiness score","title":"Scenario 1: Pre-Deployment Check"},{"location":"skills/validate-prompt-value/tutorial/#scenario-2-optimization-project","text":"Input: Existing prompt with performance issues Scope: effectiveness Context: Improving output quality Result: Targeted recommendations for clarity improvements","title":"Scenario 2: Optimization Project"},{"location":"skills/validate-prompt-value/tutorial/#scenario-3-business-case-development","text":"Input: Proposed prompt for customer service automation Scope: business-value Context: ROI justification needed Result: Value assessment with time savings calculations","title":"Scenario 3: Business Case Development"},{"location":"skills/validate-prompt-value/tutorial/#best-practices","text":"Always provide use case context for accurate assessment Start with complete scope for new prompts Use targeted scopes for specific improvement areas Re-validate after implementing major changes Document validation results for future reference","title":"Best Practices"},{"location":"skills/validate-prompt-value/tutorial/#common-issues-and-solutions","text":"Issue : Low effectiveness scores Solution : Focus on clarity, specificity, and instruction structure Issue : Poor business value assessment Solution : Better define use case and success metrics Issue : Technical quality concerns Solution : Review framework compliance and best practices","title":"Common Issues and Solutions"},{"location":"skills/validate-prompt-value/tutorial/#tips-for-success","text":"Be honest about prompt limitations during assessment Prioritize recommendations by business impact Consider maintenance and scalability in improvements Test changes incrementally Validate effectiveness with real use cases","title":"Tips for Success"},{"location":"skills/work-on-job/description/","text":"Work On Job \u00b6 Enhanced skill migrated from project-manager competency. Usage \u00b6 This skill provides work on job functionality with self-contained dependencies and enhanced error handling.","title":"Work On Job"},{"location":"skills/work-on-job/description/#work-on-job","text":"Enhanced skill migrated from project-manager competency.","title":"Work On Job"},{"location":"skills/work-on-job/description/#usage","text":"This skill provides work on job functionality with self-contained dependencies and enhanced error handling.","title":"Usage"},{"location":"skills/work-on-job/tutorial/","text":"Work On Job Tutorial \u00b6 Step-by-step guide for using the work-on-job skill. Prerequisites \u00b6 OLAF framework installed Appropriate permissions Steps \u00b6 Execute the skill using OLAF Follow the prompts Review results","title":"Work On Job Tutorial"},{"location":"skills/work-on-job/tutorial/#work-on-job-tutorial","text":"Step-by-step guide for using the work-on-job skill.","title":"Work On Job Tutorial"},{"location":"skills/work-on-job/tutorial/#prerequisites","text":"OLAF framework installed Appropriate permissions","title":"Prerequisites"},{"location":"skills/work-on-job/tutorial/#steps","text":"Execute the skill using OLAF Follow the prompts Review results","title":"Steps"}]}